a couple of announcements before we get started so first of all ps1 is out problem set 1 it is due on 17th that's 2 weeks from today you have exactly 2 weeks to work on it you could take up to 2 or 3 late days I think you can take up to three late days there is there's a good amount of programming and a good amount of math you need to do so ps1 needs to be uploaded the solutions need to be uploaded to great scope you'll have to make two submissions one submission will be a PDF file which you can either which you can either use a latex template that we provide or you can handwrite it as well but you're strongly encouraged to use the the latex template and there is a separate coding assignment for which you'll have to submit code as a separate great scope assignment so they're going to you're going to see two assignments in great scope one is for the written part the others for the is for the programming part with that let's let's jump right into today's topics so today we are going to cover briefly we're going to cover the perceptron algorithm and then you know good chunk of today is going to be exponential family and generalized linear models and we'll we'll end it with softmax regression for multi-class classification so perceptron we saw in logistic regression so first of all the perceptron algorithm I should mention is not something that is widely used in practice we study it mostly for historical reasons oh and also because it is it's nice and simple and you know it's easy to analyze and we also have homework questions on it so logistic regression we saw logistic regression uses the sigmoid function right so the logistic regression user the sigmoid function which which essentially squeezes the entire real line from minus infinity to infinity between zero and one and and the zero and one kind of represents the probability right you could also think of a variant of that which will be like the perceptron where so in the in in the sigmoid function at at z equals 0 at z equals 0 g of z is a half and as Z tends to minus infinity Z tends to 0 and as Z tends to plus infinity G tends to 1 the perceptron algorithm uses a somewhat similar but different function which right so G of Z in this case is 1 if Z is greater than equal to 0 and 0 if Z is less than 0 right so you can you can think of this as the hard version of the son of the sigmoid function right and this needs to this leads to the hypothesis function here being H theta of X is equal to G of theta transpose X so theta transpose X here theta is the parameter X is the X is the input and H state of X will be 0 or 1 depending on whether theta transpose X was less than 0 or or greater than 0 and it all and similarly in logistic regression we had a H state of X is equal to essentially G of G of Z where G is the Sigma sigmoid function both of them have a common update rule which on the surface looks similar so theta J theta J plus alpha times y minus H right so the update rules for perceptron and logistic regression they look the same except each state of X means different things in in in the two different scenarios we also saw that it was similar for a linear regression as well and we're going to see why this this is you know that this is actually a more common common theme so what's happening here so if you inspect this equation to get a better sense of what's happening in in the perceptron algorithm this quantity over here is a scalar right it's the difference between y i which can be either 0 and 1 and eight state of X I which can either be 0 or 1 right so when the algorithm makes a prediction of each state of eight set of X I for a given X I this quantity will either be 0 if if the algorithm got it right already and it will be either plus 1 or minus 1 if if Y i if the actual if the ground truth was plus 1 and the algorithm predicted 0 then it this will evaluate to 1 if wrong and why I equals 1 and similarly it is minus 1 if wrong and why I so what's happening here to see what's what's happening it's useful to see this picture so this is the input space right and let's imagine there are two two classes boxes and let's say circles and you want to learn I'm going to learn an algorithm that can separate these two classes right and if you imagine that the what what the algorithm has learned so far is a theta that represents this decision boundary so this represents theta transpose x equals zero and anything about is theta transpose X is greater than zero and anything below is a transpose X less than zero right and let's say the algorithm is learning one example at a time and a new example comes in and this time it happens to be the new example happens to be a square or a box and but the algorithm has miss misclassified right now this line the separating boundary if the vector equivalent of that would be a vector that's normal to the line so this would be theta and this is our new X this is the new X so this got misclassified this R this is lying to you know lying on the bottom of the decision boundary so what what what's gonna happen here weii let's call this the one class and this is this as the zero class right so why I minus eight state of I will be plus one and what the algorithm is doing is it sets theta to be theta plus alpha times X right so this is the old theta this is X alpha is some small learning rate so it adds let me use a different color here it adds right alpha times X to theta and now say this is let's call it theta prime is the new vector that's that's the updated value right and they and the separating hyperplane corresponding to this is something that is normal to it yeah so so it updated the decision boundary such that X is now included in the positive class right the the idea here is that theta we want theta to be similar to X in general where such where Y is 1 and we want theta to be not similar to X when y equals 0 the reason is when two vectors are similar the dot product is positive and they are not similar the dot product is negative what does that mean if let's say this is X and let's say you have theta if there are kind of pointed outwards their dot product would be negative and when when if you have a theta that looks like this Teta prime then the dot product will be positive if their angle is less than so this essentially means that as theta is rotating the decision boundary is kind of perpendicular to theta and you want to get all the positive X's on one side of the decision boundary and what's the what's the most naive way of taking theta and given X try to make theta more and closer to X simple thing is to just add a component of X in that direction you know add it here and kind of make theta and so this this is a very common technique used in lots of algorithms where if you add a vector to another vector you make the second one in a closer to the first one essentially so this is this is the perceptron algorithm you go example example in an online manner and if the example is already classified you do nothing you get a 0 over here if it is misclassified you either are the add a small component of you add the vector itself the example itself but your theta or you subtract it depending on the class of the vector that's about it any questions about the perceptron cool so let's move on to the next topic exponential families so exponential family is essentially a class of yeah it's not used in practice because aid it does not have a probabilistic interpretation of what's what's happening you kind of have a geometrical feel of what's happening with with the hyperplane but it doesn't have a probabilistic interpretation also it's it was in I think the perceptron was a pretty famous and I think the nineteen fifties or the sixties where people thought this is a good model of how the brain works and I think it was Marvin Minsky who wrote a paper saying you know the perceptron is it's kind of limited because it it could never classify points like this there's no possible separating boundary that can you know do something as simple as this and kind of people lost interest in it but yeah and in fact what we see is in logistic regression is like a softer version of the perceptron itself in a way yeah yeah it's it's it's up to you know it's it's a design choice that you make what you could do is you can you can kind of anneal your learning rate with every step every time you see a new example decrease your learning rate until something until you stop changing theta by a lot you can you're not guaranteed that you'll you'll be able to get every example right for example here no matter how long you learn you're never going to you know find a learning boundary so it's it's up to you when you want to stop training common things to just decrease the learning rate with every time step until you stop making changes all right let's move on to exponential families so exponential families is is a class of probability distributions which are somewhat nice mathematically right they're also very closely related to GLM's which we will be going over next right but first we kind of take a deeper look at exponential families and and and what they're about so an exponential family is one whose PDF so whose PDF can be written in the form my PDF I mean probability density function with a discrete distribution then it would be the probability mass function and this PDF can be written in the form right this looks pretty scary let's let's kind of break it down into you know what what they actually mean so why over here is the data right and there is a reason why we call it why because yeah a bit larger sure this is better so why is the data and the reason there's a reason what we call it Y and not X and and that's because we're going to use exponential families to model the output of your of your data you know in a supervised learning setting and and we're going to see X when we move on to GLM's until you know until then we're just going to deal with Y's for now so Y is the data it is is called the natural parameter right T of Y is called a sufficient statistic if you have a statistics background and you you know if you come across the word sufficient statistic before it's the exact same thing but you don't need to know much about this because for all the distributions that we're going to be seeing today or in this class T of Y will be equal to just Y so you can you can just replace T of Y with Y for for all the examples today and in the rest of the of the class B of Y it's called a base measure right and finally a of beta is called the lock partition function and you're going to be seeing a lot of this function not partition function right so again why is the data that this probability distribution standard model eta is the parameter of the distribution T of Y which will mostly be just Y technically we you know T of Y is more more correct to B of Y which means it is a function of only Y this function cannot involve data right and similarly T of Y cannot involve data it should be purely a function of Y B of Y is called the base measure and a of eita which has to be a function of only eight and constants no no Y can can can be part of a of data it's called the lock partition function right and the reason why this is called the lock partition function is pretty easy to see because this can be written as B of Y so these two are exactly the same just take this out and it's fine these are exactly the same and oh yeah you're right this should be positive thank you so this is you can think of this as a normalizing constant of the distribution such that the the whole thing integrates to 1 right and therefore the log of this will be a of 8 other so H is called the log of the partition function so the partition function is a technical term to indicate the normalizing constant of probability distributions now you can plug in any definition of B a and P yep sure so why is your Y and for most of most of our example it's going to be a scalar eita can be a vector but we will also be focusing except maybe in softmax this would be a scalar T of Y has to match so these the dimension of these two has to match and these are scalars right so for any choice of a B and T that you put that's that that can be your choice completely as long as the expression integrates to 1 you have a family in the exponential family right what does that mean for a specific choice of say for some choice of a B and T this can actually this will be equal to say the PDF of the Gaussian in which case you got for that choice of T a and and and B you got the Gaussian distribution a family of Gaussian distribution such that for any value of the parameter you get a member of the Gaussian family right and this is mostly to show that a distribution is in the exponential family the most straightforward way to do it is to write out the PDF of the distribution in the form that you know and just do some algebraic massaging to bring it into this form right and then you do a pattern match to two and you know conclude that it's a member of the exponential family so let's do it for a couple of examples so a Bernoulli distribution is one you used to model a binary data right and it has a parameter let's call it fee which is you know the probability of the event happening or not right now the what is the PDF of a Bernoulli distribution one way to write this is fee of Y times 1 minus V 1 minus y make sense this this pattern is like a way of writing a programming programmatic if-else in in math right so whenever Y is 1 this term cancels out so the answer would be fee and whenever Y is 0 this term cancels out and the answer is 1 minus V so this is just a mathematical way to represent an if/else that you would do in programming right so this is the PDF of Bernoulli and our goal is to take this form and massage it into that form right and and see what what the individual TB and a turn out to be right so whenever you see a distribution in this form a common technique is to wrap this with a log and an X because these two cancel out so this is actually exactly equal to this and if you do some more algebra on this we will see that this turns out to be XP plus it's pretty straightforward to go from here to here I'll let you guys verify it yourself but once we have it in this form it's easy to kind of start doing some pattern matching from this expression to that expression so what what we see here is the base measure B of Y is equal to if you match this with that B of Y will be just 1 because there's no B of Y term here and so this would be B of Y this would be beta this would be P of Y this would be a 8 right so that would be you know you can see that you know that they kind of match in pattern so B of Y would be 1 T of Y is just Y as as expected well so eta is equal to log P over 1 minus P and this is an equivalent statement is to invert this operation and say P is equal to 1 over 1 plus e to the minus beta I'm just flipping the operation from this this went from fee to a tahir you know it's it's the equivalent now here it goes from a Tartar fee right and a of eita is going to be so here we have it as a function of fee but we got an expression for fee in terms of eita so you can plug this expression in here and with the change of minus sign so let me work out the sub-sites gonna be minus log of 1 minus P this is I just it pattern matching there and minus log 1 minus 8 the reason is because we want an expression in terms of eita here we got it in terms of Phi but we need to plug in plug in a tower here beta and this will just be log of 1 plus e to the 8th so there we go so this this kind of verifies that the Bernoulli distribution is a member of the exponential family any questions here so note that this may look familiar it looks like the sigmoid function somewhat like the sigmoid function and this is actually no accident we will see why it is actually the sigmoid how it kind of relates to logistic regression in a minute so another example so a Gaussian with fixed millions all right so a Gaussian distribution has two parameters the mean and the variance for our purposes we're going to assume a constant variance you can have you can also consider the options with with where the variance is also a variable but for our course we're only interested in gaussians with fixed variance and we are going to assume assume variance is equal to one so this gives the PDF of a Gaussian to look like this P of Y parametrized is mu so note here when we start writing out we start with the parameters that we are commonly used to you know they are also called like the canonical parameters and then we set up a link between the canonical parameters and the natural parameters that's part of the massaging exercise that we do so we're going to start with the canonical parameters is equal to 1 / - so this is the gaussian PDF with with with variance equal to 1 right and this can be rewritten as again I'm skipping a few algebra steps you know straightforward no tricks there yeah our fixed variance e to the minus y square over 2 again we go through the same exercise you know pattern match this is B of Y this is 8 this is T of Y and this would be right so we have a B of Y note that this is a function of only why there's no eita here T of Y is just Y and in this case a natural parameter is mu theta is mu and the lock partition function is equal to MU square by 2 and when we and we repeat the same exercise we did here we start with a lock partition function that is parametrized by the canonical parameters and we use the the link between the canonical and the natural parameters invert it and so in this case it's the it's the same search a tower - so a of beta is a function of only eita again here a of ETA was a function of only 8 ax and T of Y is a function of only Y and B of I is a function of you.why as well any questions on this yeah yeah you if the variance is unknown you can write it as an exponential family in which case ADA will now be a vector it won't be a scalar in mode it will be it will have to like eight a one and eight or two and you will also have you will have a mapping between each of the canonical parameters and each of the natural parameters you can do it it's pretty straightforward right so this is this is exponential these are exponential families right the reason why we are why we use exponential family is because it has some nice mathematical properties right so so one property is now on if we perform maximum likelihood on on the exponential family as as when when when the exponential family is parameterized in the natural parameters then the optimization problem is concave so MLE with respect to ETA is concave similarly if you flip the sign and use the the what's called the negative log likelihood so take the log of the expression negated and in in this case the negative log likelihood is like the cost function equivalent of doing maximum likelihood you're just flipping a sign instead of maximizing you minimize the negative log likelihood so the and and you know the NLL is there for convex the expectation of why what does this mean each of the distribution we start with a of a to differentiate this with respect to Etta the lock partition function with respect to a toss and you get another function with respect to beta and that function will is the mean of the distribution as parameterize by a turn and similarly the variance of y it's just the second derivative this was the first derivative this is the second derivative so the reason why this is nice is because in general for probability distributions to calculate the mean and the variance you generally need to integrate something but over here you just need to differentiate which is a lot easier operation and and you will be proving these properties in your first homework you provided hint search should be right so now we're going to move on to generalized linear models this this is all we want to talk about exponential families any questions yeah exactly so if you're if you're if you're if it's a multivariate Gaussian then this data would be a vector and this would be the Hessian all right let's move on to GLM's so the GLM is is somewhat like a natural extension of the exponential families to include include covariates or include your input features in some way right so over here we are only dealing with in the exponential families you're only dealing with the Y which in our case it will kind of map to the outputs but we can actually build a lot of many powerful models by by choosing an appropriate family in the exponential family and kind of plugging it down to a linear model so the assumptions we're going to make for GLM is that one so these are the assumptions or design choices that are going to take us from exponential families to generalize linear models so the most important assumption is that well yeah assumption is that Y given X parametrized by theta is a member of an exponential family by exponential family of kata I mean that form it could it could in in a particular scenario that you have it could take on any one of these distributions we only we only talked about the Bernoulli and Gaussian there are also other distributions that are those are part of the exponential family for example forgot to mention this so if you have real valued data you use a Gaussian if you have binary Bernoulli if you have counts my counts here so this is a real-valued it can take any value between 0 and infinity by count like means just non-negative integers but not anything it we need so if you have count you can use a Poisson if you have positive real valued integers like say the volume of some object or the time to an event which you know you're only predicting into the future so here you can use like gamma or exponential so so there is the exponential family and there is also a distribution called the exponential distribution which are you know two distinct things the exponential distribution happens to be a member of the exponential family as well but they're not the same thing the exponential and ya and you can also have you can also have probability distributions over probability distributions like beta delay these mostly show up in Bayesian machine learning or Bayesian statistics so depending on the kind of data that you have if your Y variable is is is if you're trying to do a regression then your Y is going to be say a Gaussian if you're trying to do a classification then your Y is and if it's a binary classification then the exponential family would be Bernoulli so depending on the problem that you have you can choose any member of the exponential family as parametrized by theta and so that's the first assumption that y condition on Y given X is a member of the exponential family and the second the design choice that we are making here is that eta is equal to theta transpose X so this is where your X now comes into the picture right so theta is our N and X is also in our n now this n has nothing to do with anything in the exponential family it's purely dimensions of your of your data that you have the axis of your inputs and and this does not show up anywhere else I mean that that's and ETA is is we we make a design choice that Etta will be theta transpose transpose X and another kind of assumption is that at test time right when we want output for a new X given a new X we want to make an output right so the output will be right so given an X and given an X we get an exponential family distribution right and the mean of that distribution will be the prediction that we make for a given for a given X on this may sound a little abstract but you know we're going to make this more clear so this what does essentially mean is the hypothesis function is actually just right this is our hypothesis function and we'll see that you know what we do over here if you plug in the exponential family as Gaussian then the hypothesis will be the same you know Gaussian hypothesis that we saw in linear regression if we plug in a Bernoulli then this will turn out to be the same hypothesis that we saw in logistic regression and so on so one way to kind of visualize this is [Music] right so one way to think of is if this is there is a model and there is a distribution right so the model we are assuming it to be a linear model right given X there is a learnable parameter theta and theta transpose X will give you a parameter right this is the model and here is the distribution now the distribution is a member of the exponential family and the parameter for this distribution is the output of the linear model right this is the picture you want to have in your mind and the exponential family we make depending on the data that we have whether it's you know whether it's a classification problem or a regression problem or a time to end problem you would choose an appropriate B a and T based on the distribution of your choice right so this entire thing and from this you can say get the expectation of Y given theta and this is same as expectation of Y given theta transpose X right and this is essentially our hypothesis function that's exactly right so so the question is are we training theta two to predict the parameter of the exponential family distribution whose mean is the prediction that we are going to make for Y that's that's correct right and so this is what we do at test time and during train time how do we train this model so in this model the parameter that we are learning by doing gradient descent are these parameters right so you're not learning any of the parameters in the in the exponential family we are not learning mu or Sigma square or or eita we are not learning this we are learning theta that's part of the model and not part of the distribution and the output of this will become the the distributions parameter it's unfortunate that we use the word parameter for this and that but there there it's important to understand what what is being learned during training phase and and what's not so this parameter is the output of a function it's not it's not a variable that we that we do gradient descent on so during learning what we do is maximum likelihood maximized with respect to theta right so you're doing gradient ascent on the locked probability of of Y where the the natural parameter was Reap aramet rised with a linear model right and we are doing gradient descent by taking gradients on theta right the this like the big picture of what's happening with GLM's and how they kind of are an extension of exponential families yuri parameterize the parameters with a linear model and you get a GL m so let's let's look at some more detail on what happens at train time so another kind of incidental benefit of using GLM's is that a train time we saw that we want to do maximum likelihood on the log problem using the log probability with respect to theta right now at first it may appear that you know we need to do some more algebra figure out what the expressions for you know P is represented in the in as a function of theta transpose X and take the derivatives and you know come up with a gradient update rule and so on but it turns out that no matter which what kind of GLM you are doing no matter which choice of distribution that you make the learning update rule is the same the learning update rule is theta you guys have seen this so many times by now so this is you can you can straight away just apply this learning rule without ever having to do any more algebra to figure out what the gradients are or what the what the loss is you can go straight to the update rule and do your learning you plug in the appropriate H theta of X you plug in the appropriate H theta of X depending on the choice of distribution that you make and you can start learning initialize your theta to some random values and and and you can start learning so any question on this yeah you can do if you want to do it for batch gradient descent then you just sum over all your examples yeah so the Newton method is is is probably the most common you would use with GLM's and that again comes with the assumption that your dimensionality of your data is not extremely high as long as the number of features is less than a few thousand then you can do Newton's method any other question cool so so this is the same update rule for any any any specific type of GLM based on the choice of distribution that you have whether you are modeling you know you're doing classification whether you doing regression whether you're doing you know a Poisson regression the update rule is the same you just plug in a different age state of X and you get your learning rule another some more terminology so eta is what we call the natural parameter so eta is the natural parameter and the function that links a natural parameter to the mean of the distribution and this has a name it's called the canonical response function right and similarly you can also let's call it mu it's like the mean of the distribution similarly you can go from me back to ETA with the inverse of this and this is also called the canonical link function there's some terminology we also already saw that G of eta is also equal to the the the gradient of the law partition function with respect to theta so side not G right and it's also helpful to make explicit the distinction between the three different kinds of parameterizations we have so we have three parameterizations so we have the model parameters that's theta the natural parameters that's 8 and we have the canonical parameters and this is a fee for Bernoulli mu and Sigma square for Gaussian lambda for Poisson so these are three different ways we are we can parameterize either the exponential family or the GLM and whenever we are learning a GLM it is only you know this thing that we learn right that is the theta in the linear model this is the theta that is that is learnt right and the connection between these two is is linear so theta transpose X will give you the natural parameter and this is the design choice that we are making and we choose to reaper ammeter is a 2 by a linear model a linear of a linear in your data and between these two you have G to go this way G inverse come back this way where G is also the derivative of the partition so yeah so it's important to to kind of realize it can get pretty confusing when you're seeing this for the first time because you have so many parameters that are being swapped around and you know getting repairmen tries there are three kind of spaces in which three different ways in which we are parameterizing or generalized your models the model parameters the ones that we learn and the output of this with this the natural parameter for the exponential family and you can you know do some algebraic manipulations and get the canonical parameters for the distribution that we are choosing depending on the task whether it's classification or regression any questions on this so now it's actually pretty you know you can see the you know when you're doing logistic regression right so each theta of X so H state of X is the expected value of y condition and this is equal to V because here the choice of distribution is a Bernoulli and the mean of a Bernoulli distribution is just V the in the in the canonical parameter space and if we write that as in terms of t minus theta transpose X so the logistic function which when we introduced linear logistically agression we just you know pulled out the logistic function out of thin air and said hey this is something that can squash minus infinity to infinity between 0 and 1 seems like a good choice but but now we see that it is it is a natural outcome it just pops out from this more elegant generalized linear model where if you choose Bernoulli to be to be the distribution of your output then you know the logistic regression just just pops out naturally so [Music] any questions yeah yeah so the the choice of what distribution you're going to choose is really dependent on the task that you have so if your task is regression where you want to output real valued numbers like price of the house or something then you choose a distribution over the real real numbers like a Gaussian if your task is classification that your output is binary 0 or 1 you choose a distribution that models binary data right so the task in a way influences you to pick the distribution and you know most of the times that choice is pretty obvious if you want to model the number of visitors to a website which is like a count you know you want to use a Poisson distribution because Poisson distribution is a distribution over integers so the task decide you know pretty much tells you what distribution you want to choose and then you you do the you know you do this you know all you you go through this machinery of figuring out what are the what what a trait of X is and you plug in each state of X over there and you have your learning role any more questions so it so we made some assumptions these assumptions now it's it's also helpful to kind of get a visualization of what these assumptions actually mean so to expand upon your point you know if you think of the question are GLM's used for classification or are they used for regression or are they used for you know something else the answer really depends on what is the choice of distribution that you're going to choose you know GLM's are just a general way to model data and that data could be you know binary it could be real valued and as long as you have a distribution that can model that kind of data and falls in the exponential family it can be just plugged in to a GL m and everything just works out nicely so so the assumptions that we made well let's start with regression right so for aggression we assume there is some X to simplify I'm I'm drawing X as one dimension but you know X could be multi-dimensional and there exists a theta right and theta transpose X would would be some linear some linear hyperplane and this we assume is beta right and in case of regression eight I was also mu so eight I was also mu and then we are assuming that the Y for any given X is distributed as a Gaussian with mu as the mean so which means for every X every possible X you have the appropriate data and with this as the mean let's let's think of this as Y so there is a Gaussian distribution at every possible we assume a variance of one so this is like a Gaussian with standard deviation or variance equal to one right so for every possible X there is a Y given X which is parameterized by by by theta transpose X s as the mean right and you assume that your data is generated from this process right so what does it mean it means given X and let's say this is y so you would have examples in your training set that may look like this the Assumption here is that for every X there is let's say for this particular value of x there was a Gaussian distribution that started from with a mean over here and from this Gaussian distribution this value is sampled right you're just sampling it from from the distribution now the this is how your data is generated again this is our assumption right now that now based on these assumptions what we're doing with the GLM is we start with the data we don't know anything else we make an assumption that there is some linear model from which the data was was generated in this format and we want to work backwards right to find theta that will give us this line right so for a different choice of theta we get a different line right we assume that you know if that line represents the the Meuse or the means of the Y's for that particular X from which it's sampled from we are trying to find a line which is which will be like your theta transpose x from which these Y's are most likely to have samples that that's essentially what's happening when you do maximum likelihood with with with the GLM similarly similarly for classification again let's assume there's an X right and there's some theta transpose X right and and this theta transpose X is equal to his data we assign this to be later right and this data is from this a table we we run this through the sigmoid function 1 over 1 plus e to the minus beta to get fee right so if these are the a TAS for each for each a tar we run it through the sigmoid and we get something like this right so this tends to 1 this tends to 0 and when at this point when eita is 0 the sigmoid is is 0.5 and now at each point at any given choice of X we have a probability distribution in this case it's a it's a binary so let's assume probability of Y is the height till the sigmoid line and here it is so every X we have a different Bernoulli distribution essentially that's obtained where you know the probability of Y is there is the height to the sigmoid through the natural parameter and from this you have a data generating distribution that would look like so X and you have a few X's in your training set and for those X's you calc you you know why distribution is and sample from it so let's say right and now again our goal is to stop given given this data so over here this is the X and this is y so this is these are points for which Y is 0 these are points for which Y is 1 and so given given this data we want to work backwards to find out you know what theta was what's the theta that would have resulted in sigmoid like curve from which these these Y's were most likely to have been sampled that's and and figuring out that Y is is is essentially doing logistic regression any questions alright so in the last ten minutes or so we will go over softmax regression so softbox aggression is so in the lecture notes softmax regression is explained as as yet another member of the GLM family however in today's lecture we'll be taking a non GLM approach and kind of seeing and see how softmax is is essentially doing what's also called as cross entropy minimization we'll end up with the same same formulas and equations you can you can go through the GLM interpretation in the notes it's a little messy to kind of do it on the whiteboard so whereas this has it has a nicer interpretation and it's good to kind of get this cross-entropy interpretation as well so let's assume so here we are talking about multi-class classification so let's assume we have three cat three classes of data let's call them circles squares and triangles now if here you know this is x1 and x2 this just you're just visualizing your input space and the output space Y is kind of implicit in the shape of this so on so in multik like a multi-class classification our goal is to start from this data and learn a model that can given a new data point you know make a prediction of whether this point is a circle square or a triangle right you're just looking at three because it's easy to visualize but this can work over thousands of classes and so what we have is so you have x i's in RN right so the label y is zero okay so K is the number of classes so the labels Y is a one hot vector what would you call it as a one hot vector where it's a vector which indicates which class the X corresponds to so each each element in the vector corresponds to one of the classes so this may correspond to the triangle class circle class square class or maybe something else so the labels are in this one hot vector where we have a vector that's filled with zeros except with a one in one of the places and the way we're going to the very gonna think of softmax regression is that each class has its its own set of parameters so we have theta class and and there are K such things where class so in logistic regression we had just one theta which would do a binary you know yes versus no in softmax we have one such vector of theta per class right so you could also optionally represent them as a matrix I just an N by K matrix where you have a theta class right so in softmax regression it's it's a generalization of logistic regression where you have a set of parameters per class right and we're going to do something something similar to so so corresponding to each each class of parameters there exists so there is that exists this line which represents say theta triangle transpose x equals zero and anything to the left will be theta triangle transpose X is greater than zero and over here to be less than zero right so if for for the theta triangle class there is there is this line which which corresponds to theta transpose x equals zero anything to the left will give you a value greater than zero anything to the right similarly there is also so this corresponds to theta square transpose x equals zero anything below will be greater than zero anything above will be less than zero similarly you have another one for this corresponds to theta circle transpose x equals zero and this half plane we have to be greater than zero to the left is less than zero right so we have a different set of parameters per class which which hopefully satisfies this property and now our goal is to take these parameters and let's see what happens when we feed a new example so given an example X we get a set of given X and who are here we have classes right so we have the circle class the triangle class the square class right so over here we plot theta class transpose X so we may get something that looks like this so let's say for a new point x over here if that's our new X we would have theta transpose theta transfer data square transpose X to be positive so right and maybe for for the others we may have some negative and maybe something like this for this right so this piece is it's also called the logic space I mean so these are real numbers this will this will this is not a value between 0 & 1 this is between plus infinity and minus infinity right and and our goal is to get a probability distribution over the classes and in order to do that we perform a few steps so we exponentiate the logits which would give us now it is x buff theta class transpose x and this will make everything positive squares triangles and circles right now we got a set of positive numbers and next we normalize this my normalize I mean divide everything by the sum of all of them so here we have theta e to the theta at class transpose x over some of I in triangle square circle e to the theta I transpose X so once we do this operation we now get a probability distribution where the sum of the heights will add up to one so so given so if given a new point X and we run through this pipeline we get a probability output over the classes for which class that example is most likely to belong to right and this whole process so let's call this P hat of Y for the given X right so this is like our hypothesis the output of the hypothesis function will output this probability distribution in the other cases the output of the hypothesis function generally output a scalar or a probability in this case it's outputting a probability distribution over all the classes and now the true why would look something like this right let's say the point over there was let's say it was a triangle for whatever reason right if that was the triangle then the P of Y which is also called the label you can think of that as a probability distribution which is one over the correct class and 0 elsewhere right so P of Y this is essentially representing the one heart representation as a probability distribution right now the goal or the learning approach that we are going to do is in a way minimize the distance between these two distributions right this is one distribution this is another distribution we want to change this distribution to look like that distribution right and and technically that the term for that is minimize the cross entropy between the two distributions so the cross-entropy between P and P hat is equal to 4y in circle angle square P of Y times y I don't think we will have time to go over the interpretation of cross-entropy but you can so here we see that P of Y will be 1 for just one of the classes and 0 for the others so let's say in this say this example P of Y will say a triangle so this will essentially boil down to P and we saw that this hypothesis is essentially and on this you you treat this as the loss and do gradient descent gradient descent with respect to the parameters right yeah with that I think any questions on softmax okay so we will break for today in that is thanks