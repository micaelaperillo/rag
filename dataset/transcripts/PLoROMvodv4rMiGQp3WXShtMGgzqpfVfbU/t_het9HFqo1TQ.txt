what I'd like to do today is continue our discussion of supervised learning so lost Wednesday you saw the linear regression algorithm including both gradient descent how poorly the problem then great in a sense and then the normal equations what I'd like to do today is talk about locally weighted regression which is a way to modify linear regression to make it fit very nonlinear functions so you're on just a straight lines and then we'll talk about property interpretation of linear regression and that will lead us into the first classification algorithm you've seen this also called logistic regression and we'll talk about an algorithm called Newton's method for logistic regression and so the dependency of ideas in this class is that locally weighted regression will depend on what you learned in linear regression and then where are you gonna just cover the key ideas of locally weighted regression and let you play some of the ideas yourself in the problem set one which will release later this week and then I guess give a probability interpretation of linear regression logistic rest on depend on that and new test method is for logistic regression to recap the notation you saw on Wednesday we use this notation X I comma iy I to denote a single training example where X I was n plus 1 dimensional so if you had two features the size of a house and the number of bedrooms then X I would be two plus one repeat three-dimensional because we had introduced a new sort of fake feature x0 which was always set to the value of 1 and then why I in the case of regression is always a real number and was the number of training examples and was the number of features and this was the hypothesis right as the linear function of the features X including this feature x0 which is always set to 1 and J was the cost function you would minimize you minimizes as function of J to find the parameter theta for your straight line fit to the data okay so that's what you saw last Wednesday um now if you have a data set that looks like that where this is the size of a house and this is the price of a house what you saw on Wednesday last Wednesday was an algorithm to fit a straight line right to this data so the hypothesis was on the phone theta 0 plus theta 1 EXO EXO theta 1 x1 right same thing but with this data set maybe it actually looks you know maybe the data looks a little bit like that and so one question that you have to address when fitting models to the data is what are the features you want do you want to fit a straight line to this problem or do you want to fit a hypothesis of the form theta 1x plus theta 2 x squared since this may be a quadratic function right now the problem quadratic function is a quadratic function eventually starts you know curving back down no that would be a quadratic function this starts curving back down so maybe you don't want to fit a quadratic function instead maybe you want um it's a fit something like that if housing prices sort of curve down a little bit but you don't want it to eventually curve back down the way a quadratic function weight right so oh and and if you want to do this the way you would implement this is you define the first feature x1 equals x and the second feature x2 equals x squared or you define X 1 to be equal to X and X 2 equals square root of x right and by defining a new feature X 2 which can be the square of X the square root of x then the machinery that you solve from wednesday of linear regression applies to fit these types of these types of functions the data later this quarter you hear about feature selection algorithms which is a type of algorithm for automatically deciding do you want x squared as a feature or square root of x as a feature or maybe you want some longer of X as a feature right but what's other features does the best job fitting the data that you have if it's not fit well by a perfectly straight line what I'd like to do today is so you hear about feature selection later this quarter what I want to share you today is a different way of accessing this out this problem of one of the data isn't just fit Y by a straight line and in particular my share of you an idea called a locally weighted regression or locally weighted linear regression so let me use a slightly different example to illustrate this which is which is that you know if you have a data set that looks like that so it's pretty clear what the shape of this data is but how do you fit a curve that you know kind of looks like that right and it's actually quite difficult to find features is it square root of x log of X X cubed like third root of X except off 2/3 but what is the set of features that lets you do this so well sidestep all those problems of an algorithm called locally weighted regression and so introduce if it will machine learning terminology in machine learning we sometimes distinguish between parametric learning algorithms and non parametric learning algorithms but in a parametric learning algorithm there's a you fit some fixed set of parameters such as theta I to data and so linear regression as you saw last Wednesday is a parametric learning algorithm because there's a fixed set of parameters the theta I so you fit the data and then you're done right locally weighted regression will be our first exposure to a nonparametric learning algorithm and what that means is that the amount of data / parameters you need to keep throws and in this case it grows linearly with the size of the data size the training set okay so with a parametric learning algorithm no matter how big your training your training set is you fit the parameters stay there I then you could erase the training set from your computer memory and make predictions just using the parameters data all in a nonparametric learning algorithm which we'll see in a second the amount of stuff you need to keep around in computer memory or the net amount stuff you need to store around grows linearly as a function of the training set size and so this type of algorithm is you know we may not be great if you're a really really massive dataset because you keep all of the data you're in computer memory or on this just to make predictions okay so but we'll see an example of this and one of the effects of this is that will that it will be able to fit that data that I drew up there quite well without you needing to fiddle manually with features again you get to practice implementing locally way to regression that whole work so I'm going to go for the height of ideas relatively quickly and then let you gain practice in the problem set all right so let me redraw that data set something like this all right so say you have a data set like this now for linear regression if you want to evaluate it at a certain value of the input so to make a prediction at a certain value of X what's you for linear regression what you do is you fit theta you know to minimize this cost function and then you return say the transpose X right so you for the straight line and then you know if you want to make a prediction that this value X you then return say the transpose X for locally weighted regression you do something slightly different which is if this is the value of actually you want to make a prediction around that value of X what you do is you look in a little local neighborhood at the training examples close to that point X we want to make a prediction and then I'll describe this informally for now but we'll formalize this in math in a second but focusing mainly on these examples and you know looking a little bit at further examples but really focusing mainly on these examples you're trying to fit a straight line like that focusing on the training examples that close to where you want to make a prediction and by close I mean the values are similar on the x axis the x values are similar and then to actually make a prediction you will use this Green Line there you just fit to make a prediction at that value of x now if you want to make a prediction at a different point let's say that you know the user now says hey make a prediction for this point then what you would do is gain focus on this local area kind of look at those points and when I say focus saying you know put most of the weight on these points but you kind of take a glance at the points further away but most of the attention is on these for the straight lines of that and then you use that straight line to make a prediction okay and so to formalize this and locally weight a regression you will fit theta to minimize a modified cost function where WI is a weight function and so a good well the default choice a common choice of WI will be this I'm gonna add something to this equation a little bit later but WI is a weighting function where notice that this this formula has defining property right if X I minus X is small then the weight will be close to one because if X I X so X is the location where you want to make a prediction and X I is the input X for your life training example so WI is a weighting function there's a value which is 0 and 1 that tells you how much should you pay attention to the values of X I comma Y I when fitting say this green line or that red line and so if X I minus X is small so that's the training example that is close to where you want to make the prediction for X then this is about e to the zero right e to the negative 0 if the numerator you are small and e to the 0 is close to 1 right and conversely if X I minus X is large then WI it's close to 0 and so if X is very far away so let's see a fitting this green line and this is your example X I Y I then the saying give this example all the way out there if your fitting the Green Line right look at this verse X saying that example shadow weight very close to 0 ok and so if you look at the cost function the main modification to the cost function with main is that we've added this weighting term and so what locally weighted regression does is the same if an example X I is far from where you want to make a prediction multiply get error term by 0 or by a constant very close to zero whereas if it's close to where you want to make prediction multiply the error term by one and so the net effect of this is that this is something if you know the terms multiplied by zero disappear right so the net effect of this is that this sums over essentially only the terms for the squared error for the examples they're close to the value close to the value of x where you want to make a prediction and that's why when you fit theta to minimize this you end up paying attention only to the points only to the examples close to where you wanna make friction and fitting a line like the Green Line over there okay so let me draw a couple more pictures to illustrate this so if you're slightly smaller data set just to make this easier illustrate so that's your training set so that's the Oh example 6 1 X 2 X 3 X 4 and if you want to make a prediction here right at that point X then this curve here looks the the shape of this curve is actually like this and it this is the shape of a Gaussian bell curve but this is nothing to do with a Gaussian density right so this thing does not integrate the 1 it's just sometimes your awesome one is this is using Gaussian density the answer is no this is just a function that is shaped a lot like a Gaussian but you know Gaussian density is probably the C functions have to integrate to one and distance so there's nothing to do for Gaussian probably density question oh so how do you choose well let me get back to that and so for this example this height here says if this example a weight equal to the height to that thing give this example a way to go height of this height of this height of that right which is why if you actually if you have an example this way out there you know it's given a weight that's essentially zero which is why it's waiting or neither nearby the examples when trying to fit a straight line right for that for making predictions close to this okay um now so one last thing I want to mention which is the question just now which is how do you choose the width of this Gaussian density right how fast is it how thin should it be and this decides how big a neighborhood should you look in order to decide what's the neighborhood of points that you use to fit this your local straight line and so for a Gaussian function like this this i'm gonna call this the bandwidth parameter towel and this is a parameter or hyper parameter of the algorithm and depending on the choice of towel you can choose a fatter or thinner bell-shaped curve which causes you to look in a bigger or a narrower window in order to decide you know how many nearby examples used in order to fit the straight line okay and it turns out that and I wonder the I want to leave you to discover this yourself in the problem set if if you've taken a little bit of machine learning elsewhere I've heard of the terms oh yes it turns out that um the choice of the bandwidth towel has an effect on over 15 another fitting if you don't know what those terms being don't worry about it to find them later this quarter but what you get to do in the problem sets is play with Tao yourself and see why if tau is too broad you end up fitting your end up over smoothing the data and if tau is too thin you end up fitting a very jagged fit to the data and if any of these things don't make sense yet don't worry about it they'll make sense after you play of it in the in the problem set okay yeah since since you you play with the varying tau and the problem set and see for yourself the net impact okay thank you this is tau screen yeah what happens you need to defer the value of H outside school they said it turns out that you can still use this algorithm it's just that it's results may not be very good yeah locally within the linear regression is usually not greater than extrapolation but then most many learning armors are not great at extrapolation so all the formulas still work is so implement is but um yeah you know also try you can also try the your problem set and see what happens yes this is multiple the variable towel Devon yes it is and there are quite complicated ways to choose tau based on how many points there on the local region and so on yes there's a huge literature on different formulas actually for example it serves as Gaussian bumping there's a sometimes people use that triangle shape function so it happily goes to zero upsides and small me so there are there are many versions of this algorithm so I tend to use locally weighted linear regression when you have a relatively low dimensional dataset so when the number features it's not too big right so when n is quite all right two or three or something and we have a lot of data and you don't want to think about what features to use right so that's the scenario so if you actually a data set that looks like these up and drawing you know locally way to the interaction is a pretty good algorithm oh sure yes the remote data wanted to accomplish an expensive yes it would be I guess what data is relative yes we have you know two three four dimensional later and hundreds of examples of many thousand examples it turns out the computation needed to fit the minimization is similar to the normal equations and so you involve solving a linear system of equations of dimension equal the number of training examples you have so that's you know like a thousand or a few thousand that's not too bad if you have millions of examples then then there are also most of skilled algorithms like KT trees and much more complicated algorithms to do this when you have millions or tens of millions of examples yeah okay so ready you get a better sense of this algorithm when you play of it in the problem set now the second topic when so I'm going to put aside locally weighted regression we won't talk about that said ideas anymore today but but what I want to do today is on last Wednesday I had said that I had promised last Wednesday that today I'll give a justification for why we use the squared error right why the squared error why not you know to the fourth power or absolute value and so what I want to show you today now is the promisee interpretation of linear regression and this properties interpretation will put us into good standing as we go on to logistic regression today and then generalized any models later this week keep up to keep the notation there a secure continue to refer to it so right so why these squares Y squared error going to present a set of assumptions under which these squares using squared error falls out very naturally which is let's say for housing price prediction let's assume that there's a true price of every house why I which is X transpose say there I plus epsilon I where epsilon I is an error term that includes unmodeled effects you know and just random noise so let's assume that the way you know housing prices truly work is that every houses price is a linear function of the size of holes and number of bedrooms plus an error term they captures unmodeled effects such as maybe one day that cell is an unusually good mood or an unusually bad mood and so that makes the price go higher or lower we just don't model that as well as random noise right or maybe I don't want to screw this straight you know percent adjusting caption that's one of the features but other things have an impact on housing prices and we're going to assume that epsilon I is distributed Gaussian with mean zero and covariance Sigma squared so I'm going to use this notation to mean so the way you read this notation is epsilon I this turtle new pronoun says is distributed and then script n for n 0 comma Sigma squared this is a normal distribution also called the Gaussian distribution same thing normal in the Spirit of God students should be in the same the normal distribution with mean zero and variance Sigma squared okay and what this means is that the probability density of epsilon I this is the Gaussian density one of the root 2 Pi Sigma e to the negative epsilon I squared over 2 Sigma squared ok oh and unlike the bell shape the bell-shaped curve I use earlier for locally weighted linear regression this thing does integrate to one right this dysfunction integrates to 1 and so this is a Gaussian density this is a probability density function and this is the familiar you know Gaussian bell-shaped curve would mean 0 and covere and variance Sigma squared right where Sigma kind of controls the width of this Gaussian okay and if you haven't seen gaussians for a while we'll go over some of the probability probably prereqs as well in the classes friday and discussion sections so in other words we assume that the way housing prices are determined is that first is a true price theta transpose X and then you know some random force of nature right the move of the seller or I I don't have other factors right perturbs it from this true value say their transpose X I and the huge assumption we're gonna make is that the epsilon is these error terms are a ID and iid from statistics sense for independently and identically distributed and what that means is that their error term for one house is independent as the error term for a different house which is actually not a true assumption right because you know if if one house this price on one street is unusually high probably a price on a different house on the same street will also be unusually high and so but this assumption that these epsilonr iid sensor independently and identically distributed is one of those assumptions that that you know it's probably not absolutely true but may be good enough that if you make this assumption you get a pretty good model and so let's see under the set of assumptions this implies that the density or the probability of Y given X I and theta this is going to be this and I'll take this and writes in another way in other words given X and theta what's the density well what's the probability of a particular house this price well it's going to be Gaussian working in given by theta transpose X I or theta transpose X and the area is given by Sigma squared okay and so because the way that the price of a house is determined is by thinking theta transpose X was the you know the quote true price of the house and then adding noise or adding error of variance Sigma squared to it and so the the assumptions on the left imply that given X and theta the density of Y you know has this distribution which is really this is the random variable Y and that's the mean that's the variance of the Gaussian density okay now um two pieces of notation I have one more that that you should get familiar with the reason I wrote the semicolon here is that the way you read this equation is the semicolon should be read as a parameterised ass and so because you know the alternative way to write this would be to say P of X are given why I give Y given X I comma theta but if you were to write this notation this way this would be conditioning on theta but theta is not a random variable so you shouldn't conditional on theta which is why I'm gonna write a semicolon and so the way you read this is the program Y are given X I and parameterised excuse me parametrized by theta is equal to that formula okay if you don't understand this distinction again don't worry too much about it in statistics there are multiple schools of statistics called Bayesian statistics and frequencies statistics this is a frequentist interpretation for the purpose of machine learning don't worry about it but I find there being more consistent terminology some of our statisticians friends from getting really upset but you know some try to follow statistics convention so because just only unnecessary flag I guess but for the practical purposes is not that important if you get this notation wrong your homework don't worry about it we won't penalize you but our child be consistent but this just means that theta in this view is not a random variable it's just theta as a set of parameters that parameterize is this probably distribution okay and the way to read the second equation is when you write these equations usually don't write down with parentheses but the way to pause this equation is to say that this thing as a random variable the random variable Y given X and parametrized by theta this thing that I just drew in green parentheses is this you take Gaussian with that distribution okay all right any questions about this so it turns out that if you are willing to make those assumptions then the new regression falls out almost naturally of the assumptions we just made and in particular under the assumptions we just made the likelihood of the parameters theta so this is pronounced the likelihood of the parameters theta L of theta which is defined as the probability of the data right so this is probably of all the values of Y of y1 up to Y M given all the X's and given the parameters theta a parametrized by theta this is equal to the product from I equals 1 through m appear why I even X my franchise by theta because we assume the examples were because we assume the errors are iid right then the error terms are independently and identity destroys each other so the probability of all of the observations of all the values of Y in our training set is equal to the product of the probabilities because of the independence assumption we made and so plugging in the definition that P of Y given X franchise by theta that we had up there this is equal to product okay now again one more piece of terminology you know another question about mandalas if you say hey Andrew what's the difference between likelihood and probability right and so the likelihood of parameters is exactly the same thing as the probability of the data but the reason we sometimes talk about likelihood and some to solve a probability is we think of likelihood so this is some function right this thing is a function of the data as well as a function of the parameters theta and if we viewed this number whatever this number is if you view this thing as a function of the parameters holding the data fix then we call that the likelihood so you think of the training set the data is a fixed thing and then varying parameters theta then I'm going to use the term likelihood whereas if you view the parameters theta as fixed and maybe varying the data are going to say probability right so so you hear me use well I'll try to be consistent I find I'm pretty good at being consistent but not perfect but I'm going to try to say likelihood of the parameters and probability of the data even though those evaluate to the same thing it's just you know for this function this function is function the data and the parameters which one that UV leaners fixing which one are you viewing this is variable so when you view this as a function of theta when I use the term likelihood but so so hopefully you hear me say likelihood of the parameters hopefully you won't hear me say likelihood of the data right and then similarly hopefully you hear me say probably the data and not probably of the parameters like the Frances okay so probably at the data no tech got it sorry yes like your paycheck got it yes sorry yes like a theory right oh no so no so theta is a set of parameters it's not a random variable so we like you of theta doesn't mean theta is a random variable right by the way the stuff about what's a random variable and what's not the semicolon versus comma thing we explain this in more detail on the lecture notes to me this is part of them you know a little bit paying homage to the to their religion of Bayesian frequencies versus Bayesian frequencies versus Bayesian statistics from from a machine from apply machine learning operational what you write code point of view it doesn't matter that much yeah but theta is not a random variable we have likely or the parameters which another random variable what's the rationale for choosing oh sure why is epsilon I Gaussian so it turns out because the central limit theorem from statistics most error distribution or Gaussian right if something is it is an error that's made up of lots of little noise sources which are not too correlated and by the central limit theorem it will be Gaussian so if you think that hope that the rotations are the mood in the seller was the School District you know what's the weather like access to transportation and all of these sources are not too correlated and you add them up then the distribution will be Gaussian and and I think yeah so really because the central limit theorem I think the gaussians become a default noise distribution but for things where the true noise distribution is very far from Gaussian this model does do this well and in fact for when you see generalized linear models on Wednesday you see when how to generalize all of these algorithms to very different distributions like possum and so on alright so so we've seen the likelihood of the parameters theta so I'm going to use lower case L to denote the log likelihood and the log likelihood is just a longer the likelihood and so and so log of a product is equal to the sum of the logs right and so this is equal to okay and so one of the you know well tested methods in statistics for estimating parameters is to use maximum likelihood estimation which means atchoo Stata to maximize the likelihood right so you're going to dataset how would you like to estimate theta well one natural way to choose theta is to choose whatever value of theta has the highest likelihood or in other words choose the value of theta so that that value of theta maximizes the probability of the data and so for to simplify the algebra rather than maximizing the likelihood capital L is actually easier to maximize the log likelihood but the log is a strictly monotonically increasing function so the value of theta that maximizes the log likelihood it should be the same as the value of theta that maximizes our likelihood and if you derived a log likelihood we conclude that if you're using maximum likelihood estimation what you'd like to do is choose the value of theta that maximizes this thing right but this first term is just a constant theta doesn't even appear in this first term and so what you like to do is choose the value of theta that maximizes the second term notice there's a minus sign there and so what you'd like to do is ie you know choose theta to minimize this term right oh so Sigma squared is just a constant right no matter what Sigma squared is you know so so so if you want to minimize this term excuse me if you want to maximize this term negative of this thing that's the same as minimizing this term but this is just J of theta the cost function you saw earlier for linear regression okay so this little proof shows that choosing the value of theta to minimize the least squares errors like you saw last Wednesday that's just finding the maximum likelihood estimate for the parameters theta under the set of assumptions we made that the error terms are Gaussian and iid okay oh thank you Oh is there a situation using this phone as a least-squares cost function with better idea no so this I think this derivation shows that this this is completely equivalent to these squares right that if you want if you're willing to assume that the error terms are Gaussian and iid and if you want to use maximum likelihood estimation which is very natural procedure and statistics then you know then you should use these squares if you knew for some reason Arizona idea which figure about the cost function yes I know I think that you know when building learning algorithms often we make maldo we make assumptions about the world that we just know are not hunched up sent true because it leads to algorithms accomplished and efficient and so if you knew that your if you knew that your training set was very very non-id there are there most of skated modeled as you could build but yeah but but very often we wouldn't bother I think ya know more often than not we might not bother I can think of a few special cases where you would bother but only if you think the assumptions are really really bad if you don't have enough data and so something waitwait via alright I want to move on to make sure we get through the rest of things any questions all right so armed with this machinery right so so what do we do here was we set up a set of problems occur some shion's we made certain assumptions about P of Y given X where the key assumption was Gaussian errors in IIT and then through maximum likelihood estimation we derived an algorithm which turns out to be exactly the least squares algorithm right what I'd like to do is take this framework and apply it our first classification problem right and so the key steps are you know one make an assumption about P of Y given X P of Y given X parameter in a second is figure out maximum likelihood estimation it's nice to take this framework and apply it to a different type of problem where the value of y is now either zero or one size of your classification problem okay so let's see so in the classification problem in our first classification problem we're going to start with binary classification so the value of y is either 0 or 1 and sometimes we call this binary classification because there are two classes and so so that's a data set where yes this is X and this is y um so something that's not a good idea is applied linear regression to this data set some sometimes we will do it and maybe they get away with it but I wouldn't do it and here's why which is um it's tempting to just fit a straight line to this data and then take the straight line and threshold it at 0.5 and then say oh if this is above 0.5 rounds after 1 it is below 0.5 rends it off to 0 but it turns out that this is not a good idea for classification problems and here's why which is for this data set it's really obvious what the what the pattern is right everything to the left at this point for the 0 I think the right at that point for the good one but let's say we now change the data set to just add one more example there and the pattern is still really obvious is everything to the left of this breathing zero I think it's right of that for the good one but they fit a straight line to this data set with this extra one point there and just not even the outlier it's really obvious at this point way out there should be labeled one but was this extra example if you fit a straight line to the data you end up with maybe something like that and somehow having this one example it really didn't change anything right but somehow the string I fit from the green lines of the move from the blue line to the green line and if you now flash hold it at 0.5 you end up with a very different decision boundary and so linear regression is just not a good algorithm for classification some people use it and sometimes again lucky is not too bad but I personally never used the neighbor aggression for classification algorithms right because just don't know if you end up with a really bad fit to the data like this um so oh and and and the other unnatural thing about using linear regression for classification problem is that you know for a classification problem that the values are you know 0 or 1 right and so it's output negative values or values even greater than 1 seems seems strange so what I'd like to share of you now is really probably by far the most commonly used classification algorithm called logistic regression I always say the two learning are rooms I probably use the most often on linear regression and logistic regression yeah yeah and this is the algorithm so as we designed in logistic regression algorithm one of the things we might naturally want is for the hypothesis to output values between 0 & 1 right and this is mathematical notation for the values for H of X or H prime H subscript theta of X lies in the set from 0 to 1 right the 0 to 1 square bracket is the set of all real numbers from 0 to 1 so this is we want the hypothesis output values in between 0 and 1 in the set of all numbers which is from 0 to 1 and so we're going to choose the following form of the hypothesis so so will it define the function G of Z that looks like this and this is called the sigmoid or the logistic function these are synonyms they mean exactly the same thing so can we call the sigmoid function or the logistic function it means exactly the same thing but I'm gonna choose a function G of Z and this function is shaped as follows if you plot this function you find that it looks like this where if the horizontal axis is Z then this is G of Z and so it crosses x intercept at 0 and it you know starts off well really close to 0 Rises and then asymptotes towards 1 okay and so G of Z outputs values between 0 and 1 and what logistic regression does is instead of let's see so previously for linear regression we had chosen this form for the hypothesis right we just made a choice that will say that housing prices are a linear function of the features X and what logistic regression does is say the transpose X could be bigger than 1 it could be less than 0 which is not very natural but it's gonna take theta transpose X and pass it through this sigmoid function G so this force the output values only between 0 and 1 ok so you know when designing a learning algorithm sometimes you just have to choose the form of the hypothesis how are you going to represent the function H or H of H subscript theta and so we're making that choice here today and if you're wondering you know there are lots of functions that we could have chosen right there loss of why why not why not dysfunction or why not you know there lots of functions with very the shape to go but easier and so why are we choosing this specifically it turns out that there's a broader class of algorithms called generalized any models you hear about on Wednesday of which this is a special case so we've seen linear Russian you see logistic regression in a second and on Wednesday you see that both of these examples of a much bigger set of algorithms derive using a broader set of principle so so for now just you know take my word for it that we want to use the logistic function it'll turn out you see on Wednesday that this way to derive even dysfunction from from more basic principles rather than just putting all this does that happen for now let me just pull this out of a hat and say that's the one we want to use so let's make some assumptions about the distribution of Y given X franchise by theta so I'm going to assume that the data has a following distribution the probability of Y being 1 again from the breast cancer prediction that we had from the first lecture right it would be the chance of a tumor being cancerous of being malignant chance of Y be new one given the size of a tumor that's the future x parametrized by theta that this is equal to the output of your hypothesis so in other words going assume that what you want your learning algorithm to do is input the features and tell me what's the chance that this tumor is malignant right what's the chance that Y is equal to one and by logic I guess because Y can be only one or zero the chance of Y being equal to zero this has got to be one minus that right because if a tumor has a 10% chance of being malignant that means it has a 1 minus that means it must have a 90% chance of being benign right since these two probabilities must add up to one I'll say it again oh can we change Peru yes you can but I'm not yet but I think just a stick of convention in the z-direction you yeah sure because assume that P of y equals 1 was this in P of y equals 1 was that but I think either way it's just what you call positive example why you call negative example um and now bearing in mind that Y right by definition because it's a binary classification problem but bearing in mind that Y can only take on two values 0 1 there's a nifty so the algebra way to take these 2 equations and write them in one equation and this will make some of the math a little bit easier when I take these two equations take these two assumptions and take these two facts and compress it into one equation which is this oh and I dropped the theta subscript just to simplify the notation I'm gonna be a little bit sloppy sometimes well no less one more whether I write the theta there okay but these two definitions appear Y given X paralyzed by theta bear in mind that Y is either 0 one can be compressed into one equation like this and then just say Y right is because if y if one is equal to one then this becomes H of X to the power of one times this thing it's a power of zero right if Y is equal to 1 then 1 minus y is 0 and you know anything so the power of 0 is just equal to 1 and so if Y is equal to 1 you end up with P of Y given X prioritize by theta equals H of X which is just what we had there and conversely if Y is equal to 0 then this thing will be 0 and this thing would be 1 and so you end up with P of Y given X perilous theta is equal to 1 minus H of X which is just equal to that second equation ok right and so this is a nifty way to take these two equations and compress them into one line because depending on whether Y is zero one one of these two terms switches off because it's exponentiated to the power of zero and anything to the power of zero is just equal of one right so one of these terms is just you know one doesn't leaving the other term and just selecting the appropriate equation depend on whether Y is zero one okay so with that so with this little on a notational trick you'll make the later derivations simpler so all right she can reuse along with this all right so we're gonna use maximum likelihood estimation again so let's write down the likelihood of the parameters so it's actually PF otherwise given all the XS for entrance by theta which is equal to this which is now equal to product from I equals 1 through X KY ^ Y I times 1 minus H of X I - why okay where all I did was take this definition of P of Y given X parent choice by theta you know from that after we did that little exponentiation trick and wrote it in here and then what maximum likelihood estimation we'll want to find the value of theta that maximizes the likelihood maximize the likelihood of the parameters and so same as what we did for linear regression to make the algebra yeah to make the out you're a bit more simple we're going to take the log of the likelihood and so compute the log likelihood and so that's equal to let's see right I say if you take the log of that you end up with and it so so in other words the last thing you want to do is try to choose the value of theta to try to maximize L of theta now so just just to summarize where we are right if you're trying to predict your malignancy in bananas of tumors you have a training set with X I Y I you define the likelihood to find a log likelihood and then what you need to do is have an algorithm such as gradient descent agreed innocent talk about that a sec to try to find the value of theta that maximizes the log likelihood and then having chosen the value of theta when a new patient walks into the doctor's office you would you know take the features of the new tumor and then use H of theta to estimate the chance of this new tumor and the new patient that walks in tomorrow's estimate the chance that this new thing is this malignant okay so the algorithm were going to use to choose theta to try to maximize the log likelihood is gradient ascent or batch gradient ascent and what that means is we will update the parameters theta J according to theta J plus the partial derivative with respect to the log-likelihood okay and the differences from what you saw for linear regression from last time it's the following just two differences I guess for linear regression last week I have written this down theta J gets updated as theta J minus partial with respect to theta J of J of theta right so you saw this on Wednesday so the two differences between dances are well first instead of J of theta you're now trying to optimize the log likelihood instead of the squared cost function and the second change is previously you were trying to minimize the squared error that's why we had the minus and today you're trying to maximize the log likelihood which is why there's a plus sign okay and so so great in E sent you know it's trying to climb down this hill whereas gradient ascent has a has a concave function like this and it's trying to write climb up the hill rather than climb down their goal so that's why there's a plus symbol here instead of a minus because we maximize the function rather than minimize the function so the last thing to really flesh out this algorithm which is done in the lecture notes but I don't want to do to you today is to plug in the definition of H of theta into this equation and then take this thing so that's the log likelihood of theta and then through you know calculus and algebra you can take derivatives of this whole thing with respect theta this is done in detail in the lecture notes I don't want to use it cost but go ahead and take the Ritter's at this big formula with respect to the parameters theta in order to figure out what is that thing right what is this thing that I just circled and it turns out that if you do so you will find that batch gradient descent is the following you update theta J according to actually I'm sorry I forgot the learning rate yeah it's relearning the Alpha learning rate alpha times this because this term here is the partial derivative respect to theta J and the full calculus and so on derivation is given in the lecture notes is a chance of local Maxima in this case no there isn't it turns out that this function that the log-likelihood function o of theta for logistic regression that always looks like that so this is a concave function so there are no local op that the only maximum as a global Maxima there's actually another reason why we chose the logistic function because if you choose the logistic function rather than some other function reserve the one you're guaranteed that the likelihood function has only one global maximum and this there's actually a big positive actually what you see on Wednesday this is a big class of algorithms I wish linear regression is one example which is addresses another example and for all of these algorithms in this class there are no local Optima problems when you when you derived them this way so you see that on Wednesday wouldn't talk about us okay so actually I think your bun is just one question for you to think about this looks exactly the same as what we've paid it out for linear regression right actually the difference the linear regression was I had a minus sign here and I reversed these two terms I think there's a big sign - weii if you put the minus sign there and reverse these two terms so take the minus - this is actually exactly the same as when we had come up with a linear regression so why is this different right I started off saying don't use the knee regression for classification problems because of because of that problem that a single example could really you know I'm sorry I start off with an example saying that linear regression is really bad for classification and we did all this work and came back to the same algorithm so what happened all right cool awesome right so what happened is the definition of H of theta is now different than before but the surface level the equation turns out to be the same okay and again it turns out that for every algorithm and discourse around as you see on Wednesday you end up with the same thing actually there's a general property of a much bigger class of algorithms called generalize many models although yeah interesting historical divergence because of the confusion between these two algorithms in the early history of machine learning there was some debate about a Oh between academia saying no I invented that no I invented that no is actually different algorithms all right any questions oh great question is their equivalents of normal equations to logistic regression short answer is no so for linear regression the normal equations gives you like a one-shot way to just find the best value of theta there is no known way to just have a closed form equation unless you find the best value of theta which is why you always have to use an algorithm in sort of optimization out rooms such as creating ascend or and we'll see in a second Newton's method cool so there's a great lead-in to the lost topic for today which is Mutants method um you know created in a sense right it's a good algorithm I use screen to send all the time but it takes the baby step takes a baby sir taking the baby set takes a lot of iterations for gradient ascent to converge there's another algorithm called Newton's method which allows you to take much bigger jumps to let's data you know so there are problems where you might need they'll say a hundred iterations or a thousand iterations are great in ascent that if you run this algorithm called Newton's method you might need only ten iterations to get a very good value of theta but each iteration will be more expensive we talked about pros and cons a second but um let's see how let's let's describe this algorithm which is sometimes much faster for gradient than great innocent for optimizing the value of theta okay so um what we'd like to do is so let me let me use the simplify one dimensional problem to describe Newton's method so I'm going to solve a slightly different problem with Newton's method which is say you have some function f and you want to find theta such that f of theta is equal to zero okay so this is a problem that Newton's method solves and the way we're going to use this later is what you really want is to maximize L of theta right and well at the maximum the first derivative must be zero so ie you want to value where the derivative L prime of theta is equal to zero right and L prime is the derivative of theta because this is L prime is another notation for the first derivative theta so you want to maximize the function or minimize the function whether Muse's you want to find a point where the derivative is equal to zero so the way we're going to use Newton's method is we're going to set f of theta equal to the derivative and then try to find the point where the derivative is equal to zero okay but to explain your tennis method I'm gonna you know work on this other problem where you have a function f and you just want to find the value of theta where f of states is equal to zero and then it will set F equal to L prime theta and that's how we will apply this to logistic regression so let me draw in pictures how this algorithm works all right so let's say that's the function f and you know to make this drawable on a whiteboard I'm gonna assume theta is just a real number for now so theta is just a single you know like a scalar a real number so this is how Newton's method works oh and the goal is to find this point right the goal is to find the value of theta with F of theta is equal to zero okay so let's say you start off from let's see you start off at this point right at the first iteration you know randomly I stay there and nationally thing is zero something but let's say you start up at that point this is how one iteration of Newton's method will work which is start off with theta zero that's just the first value first iteration what we're going to do is look at the function f and then find a line that's just tangent to F so take the derivative of F and find a line that's just tangent to F so take that red line there this just touches a function f and we're going to use if you will use the straight line approximation to F and solve for where F touches the horizontal axis so we're gonna solve for the point where this straight line touches the horizontal axis okay and then we're going to set this and that's one iteration of Newton's method so they're going to move from this value to this value and then in the second iteration of Newton's method we're gonna look at this point and again you know take a line that's just tangent to it and then solve for where this touches the horizontal axis and then that's after two iterations of u2's men right and then you repeat take this sometimes you can overshoot a little bit but that's okay right and then that so it gives us a cycle back to rent that stay the three then you take this let's stay there for so you can tell that Tom Newton's method it's actually pretty fast algorithm right within just what one two three four iterations we've gotten really really close to the point where F of theta is equal to zero so let's write out the map for how you do this so let's see I'm going to so let me just write out and derive you know how you go from theta 0 to theta 1 so I'm going to use this horizontal distance I'm gonna denote this as Delta this triangle is upper case Greek alphabet Delta right this is lower case Delta that's upper case Delta right and then the height here well that's just f of theta 0 this is the height it's just F of theta 0 and so let's see so what we'd like to do is solve for the value of Delta because one iteration of Newton's method is a set you know theta one is set to theta zero minus Delta right so how do you solve for Delta well from calculus we know that the slope of the function f is the height over the run right height over the width and so we know that the derivative of del F prime that's the derivative of F at the point stay to zero that's equal to the height that's F of theta divided by the horizontal right so the derivative meaning the slope of the red line is by definition of derivatives is this ratio between just height over this width and so Delta is equal to f of theta 0 over F prime of theta 0 and if you plug that in then you find that a single iteration of Newton's method is the following group data T plus 1 gets updated as theta t minus f of theta t over F prime of theta T ok where instead of 0 1 I replaced it with T and T plus 1 and finally to you know the very first thing we did was let's let F of theta be equal to say L prime of theta right because we want to find the place where the first derivative of L is 0 then this becomes theta T plus 1 gets updated as theta T minus L prime of theta T over L double prime of theta T so it's really the first derivative divided by the second so Newton's mess is a very fast algorithm and it has Newton's method and Joy's property called quadratic convergence not a great name don't worry don't worry too much about what it means but the informative what it means is that if on one innovation Newton's method is 0.01 error so on the x-axis you're 0.01 away from the from the value from from the true minimum of a true value of F is zero zero after one iteration the error could go to zero point zero zero zero one error and all the two iterations it goes to zero but roughly Newton's method under certain assumptions that function is smooth not too far from quadratic the number of significant digits that you have converts the minimum doubles on a single iteration so this is called quadratic convergence and so when you get near the minimum Newton's method converges extremely rapidly right so so after a single iteration becomes much more accurate enumeration becomes way way way more accurate which is why Newton's method requires relatively few innovations and let's see I have written out Newton's method for when theta is a real number when theta is a vector then the generalization of the rule I wrote above is the following theta T plus one gets updated as theta T plus h that where X is the Hessian matrix so these details are written in lecture notes but to give you a sense it when theta is a vector this is a vector of derivatives it says I guess this part n plus 1 dimensional if nature is an RN plus 1 then this derivative respect to theta of the log-likelihood becomes a vector of derivatives and the Hessian matrix this becomes in matrixes are n plus 1 by n plus 1 so becomes a square matrix with the dimension equal to the parameter vector theta and the Hessian matrix is defined as the matrix of partial derivatives right so and so the disadvantage of Newton's method is that in high dimensional problems if theta is a vector that each step of Newton's method is much more expensive because you're either solving a linear system craisins or having to convert to pretty big matrix so if theta is 10 dimensional you know this involves inverting a 10 by 10 matrix which is fine but if theta was 10,000 or 100,000 then each innovation requires computing like a hundred thousand by a hundred thousand matrix and inverting that which is very hard it's very very difficult to do that in very high dimensional problems so you know some rules of thumb if the number of parameters you have foolish if the number of parameters religion aggression is not too big if you have 10 parameters or 50 parameters I would almost certainly I would very likely use Newton's method then you probably get convergence in maybe ten iterations or you know 15 iterations or even less than ten generations but they've a very large number of parameters if you have you know ten thousand parameters then rather than dealing over 10,000 by 10,000 matrix or even bigger than 55,000 about 50,000 matrix under 50,000 parameters I would use great in the sentence then okay but if the number of parameters is not too big so that the computational cost per iteration is manageable then Newton's method converges in a very small number of iterations and could be much faster algorithm than gradient descent all right so that's it Newton's method on Wednesday this remaining time on Wednesday you hear about generosity models I think unfortunately I promised to be in Washington DC tonight I guess through Wednesday so you hear from some I think onion will give the lecture on Wednesday but I will be back next week unfortunately what's time to do this but because of this pulse take on lecture so so thanks everyone I always say