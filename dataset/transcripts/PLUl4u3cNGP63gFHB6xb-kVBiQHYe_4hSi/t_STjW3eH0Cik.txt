it was about 1953 when a noted philosopher here at MIT named Hubert Rus when uh youber D um wrote a paper about 1963 in which he um alleged had a subject had a had a had a heading titled computers can't play chess of course he was uh subsequently invited over to the artificial intelligence laboratory to play the green black chess machine and of course he lost whereupon Seymour papet wrote a rebuttal to D's famous paper in which had a subject heading dfus can't play chess either but in a strange sense dfus might have been right and would have been right if he were to have said computers can't play chess the way humans play chess yet in any case uh around about 1968 a Chessmaster named David Levy uh bet um noted founder of artificial intelligence John McCarthy that no computer would beat the world champion within 10 years and 5 years later McCarthy gave up up because it had already become clear that no computer would um win in a way that McCarthy wanted it to win that is to say by playing chess the way humans play chess but then 20 years after that in 1997 deep blue beat the world champion and chess suddenly became uninteresting but we're going to talk about games today because um there are elements of game playay that do model some of the things that go on in our head and if they don't model things that go on in our head they do model some kind of intelligence and if we're to have a general understanding of what intelligence is all about we have to understand that kind of intelligence too so we'll start off by talking about various ways that we might design a computer program to play a game like chess and we'll conclude by talking a little bit about what uh deep blue adds to the adds to the other than tremendous speed so that's our agenda by the end of the hour you'll understand and be able to write your own deep blue if you feel like it first we want to talk about how it might be possible for a computer to play chess let's talk about several approaches that might be possible approach number one is that the machine might make a description of the board same way a human would talk about Pawn structure King safety whether it's a good time to Castle that sort of thing so it would be analysis and perhaps some strategy mixed up with some tactics and all that would get mixed up and finally result in some kind of move so if this is the uh game board the move the next thing to do would be determined by some process like that and trouble is no one knows how to do it and so in that sense dfus is Right none of the game playing programs today know how incorporate any of that kind of stuff so since nobody has to do knows how to do that we can't talk about it so we can talk about other ways though that we might try for example we could have if then rules how would that work that would work this way you you you look at the board represent by this note here and you say well if the if it's possible to move the queen Pawn forward by one then do that so it doesn't do any evaluation of the board it doesn't try anything it just says let me look at the board and select a move on that basis so that would be uh a way of approaching the game situation like this here's the situation here are the possible moves and one is selected on the basis of an if then rule like so and nobody can make a very strong chess player that works like that curiously enough someone has made a pretty good Checkers playing program that move that works like that checks to see what moves are available on the board ranks them picks the highest one that's available but in general that's not a very good approach it's not very powerful you couldn't make it well when I say couldn't means I can't think of any way that you could make a strong chest plane program that way so third way to do this is to uh look ahead and evaluate what that means is you look ahead like so you see all the possible consequences of moves and you say which of these board situations is best for me so you so that would be an approach that comes in here like so and says which one of those three situations is best and to do that we have to find have to have some way of evaluating uh the situation deciding which of those is best now I want to do a little brief aside because I want to talk about the mechanisms that are popularly used to do that kind of evaluation in the the end there are lots of features of the chess board let's call them F1 F2 and so on and we might form some function of those features and that overall is called the static value so it's stattic because you're not exploring any consequences of what might happen you're just looking at the board as it is checking a king safety checking the pawn structure each of those produces a number feeds into this function outcomes a value and that is a value of the board seen from your perspective now normally this function G is reduced to a linear polinomial so in the end the most popular kind of way of forming a static value is to take fub1 multiply it times some constant C1 add C2 multiply times FS2 and that is a linear scoring polinomial so we could use that function to produce numbers from each of these things and then pick the highest number and that would be a way of playing the game actually a scoring polinomial is a little bit more than we need because all we really need is a method that looks at those three boards and says I like this one best it doesn't have to rank them it doesn't have to give them numbers all it has to do is say which one it likes best so one way of doing that is to use a linear scoring polinomial but it's not the only way of doing that so that's uh number two and number three but now what uh else might we do well if we back on some of the searches we talked about what's the base case against which everything else is compared what's the way of doing search that doesn't require any intelligence just Brute Force we could use the British museum algorithm and simply evaluate the entire tree of possibilities I move you move I move you move all the way down to all the way down to what maybe 100 50 moves you would do 50 things I do 50 things so before we can decide if that's a good idea or not uh we probably ought to um develop some vocabulary so consider this tree of moves there'll be some number of choices considered at each level and there'll be some number of levels so the standard language for this is to call this the branching factor and in this particular case b is equal to 3 this is the depth of the tree and in this case D is two so now that produces a certain number of terminal or Leaf nodes how many of the how many of those are there well that's pretty simple computation right it's just B to the D right Christopher B to the D so if you have B to the D at this level you have one B to the D at this level you have b b b to the D at this level you have b^2 so B to the D in this particular case is nine so now we can use this vocabulary that we've developed to talk about whether it's reasonable to just do the British museum algorithm be done with it forget about Chess and go home well let's see uh it's uh about it's it's pretty it's pretty deep down there if we think about uh chess and we think about a standard game which each person does 50 things that gives a d of about a 100 and if you think about the branching factor in chest it's generally presumed to be depending on the stage of the game and so on and so forth it varies but it might average around 14 or 15 if it were just 10 that would be 10 to the 100th right but it's a little more than that because the branching factor is more than 10 so in the end it looks like according to Claude Shannon there are about 10 to 100 to the 120th Leaf nodes down there and if you're were going to do a British museum treatment of this tree you'd have to do 10 to the 120th static evaluations down there at the bottom if you're going to see which one of the moves are is best at the top so is that a reasonable number you know it didn't used to seem it didn't used to seem practicable it used to seem impossible but now we've got cloud computing everything and maybe we could actually do that right what do you think Manassa can you do that get enough computers going in the cloud you're not know you're not sure show you work it out let's work it out I need I need some help especially from uh any of you who studying cosmology so we'll start with how many atoms are there in the universe volunteers 10 to the No No No 10 to the 38th has been offered that's way too way too low last time I looked was about 10 to the 80th atoms in the universe next thing I'd like to know is how many seconds are there in a year it's a good number to have in your you know memorize and that number is approximately uh Pi * 10 7th okay so how many NCS in a second that gives us 10 9th uh and at last how many years are there in the history of the universe what uh she offers uh something on the order of 10 billion okay maybe 14 billion but we'll say 10 billion to make our calculation simple so that's uh 10 to the 10th years so if we add all that up 80 90 + 16 that's 10 to the 106 here uh 10 to the 106th nanoseconds in the history of the universe multiplied times the number of atoms in the universe so if all of the atoms in the universe were doing static evaluations at nond speeds since the beginning of the Big Bang would still be 14 orders of magnitude short so it be pretty good Cloud would' have to harness together lots of universes to so the British museum algorithm is not going to work [Music] no good so what we're going to have to do is we're going to have to put some things together and hope for the best so the fifth way is the way we're actually going to do it and what we're going to do is we're going to look ahead not just one level but as far as possible so uh we consider not only the situation that we've developed it here but we'll try to push that out as far as we can and look at these look at the static values of of of the leaf nodes down here and somehow use that as a way of playing the game so that is number five and number four is going all the way down there and this in the end is all that we can do this idea is um multiply invented most notably by Claude Shannon and also by Alan touring who I found out from a friend of mine uh spent a lot of lunchtime conversations they spent a lot of lunchtime conversations talking with each other about how a computer might play chess in against the future when there were would be computers so Donald Mickey and Alan Turing also invented this over lunch while they were taking some time off from breaking the from cracking the German codes well what is the method I I want to illustrate the method with the simplest possible tree so we're going to have a branching factor of two not 14 and we're going to have a depth of two not something highly s highly serious so here's the game tree and there going to be some numbers down here at the bottom and these are going to be the value of the board from the perspective of the player at the top and let us say that the player at the top would like to drive the play as much as possible toward the big numbers so we're going to call that player the maximizing player he would like to get over here to the eight because that's the biggest number there's another player his opponent which we'll call the minimizing player and he's hoping that the number that the play will go down to the board situation that's as small as possible because his view is the opposite of the maximizing player all right hence the name Minx but how does it work do do do you see which way the play is going to go how would you decide which way the play is going to go well it's not obvious at a glance do you see which way it's going to go it's not obvious at a glance but if we do more than a glance if we look at the situation from the perspective of the minimizing player here at the middle level it's pretty clear that if the minimizing player finds himself in that situation he's going to choose to go that way and so the value of this situation from the perspective of the minimizing player is two could never go over there to the seven similarly if the minimizing player is over here with a choice between going toward a one or toward an eight he'll obviously go toward a one and so the value of that board situation from the perspective of minimizing players one so now we've taken the scores down here at the bottom of the tree and we back them up one level and you see how we we can just keep doing this now the maximizing player can see that if he goes to the left he gets a score of two if he goes to the right he only gets a score of one so he's going to go to the left and so overall then the maximizing player is going to have a two as the perceived value of that situation there at the top so that's the Minx algorithm it's very simple you go down to the bottom of the tree you compute static values you back them up level by level and then you decide where to go and in this particular situation the maximizer goes to the left and the minimizer goes to the left two so the play ends up here far shorter the eight that the maximizer wanted and less than the one that the minimizer wanted but this is an adversarial game you're competing with each other so you don't expect to get what you want all right so maybe we see if we can make that work [Music] there's a game tree you see how it goes Let's uh let's see if the system can figure it out so there it goes crawling its way through the tree this is a branching factor of two just like our sample but now four levels you can see it's got quite a lot of work to do it's uh two to the two to the what two to the fourth that's one two three four to the fourth 16 static evaluations to do so it found the answer but it's a lot of work we could get a new tree and restart it maybe speed it up it goes down that way get a new tree those are just random numbers so each time it's going to find a different path through the tree according to the numbers that it's generated now 16 isn't bad but if you get down there around uh 10 levels deep and your branching factor is 14 well we know those numbers get pretty awful pretty bad because the number of static evaluations do down there at the bottom goes as B to the D as exponential and time has shown if you get down about seven or eight levels you're a jerk and if you get down about 15 or 16 levels you beat the world champion so You' like to get as far down in the tree as possible because when you get as far down to the into the tree as possible what happens is that these crude measures of board quality begin to clarify and in fact when you get far enough the only thing that really counts is peace count one of those features so if you get far enough peace count a few other things will give you a pretty good idea of what to do if you get far enough but getting far enough can be a problem so we want to do everything we can to get as far as possible I want to pull out every trick we can find to get as far as possible now you remember when we talked about branch and bound we knew that there were some things we could do that would cut off whole portions of the search tree and so what we like to do is find something analogous in this world of games that will cut off whole portions of the search tree so we don't have to look at those static values so what I want to do is I'm going to come back and redo this thing but this time I'm going to compute the static values one at a time I've got the same structure in the tree and just as before I'm going to assume that the top player wants to go toward the maximum values and the next player wants to go toward the minimum values but none of the static values have been computed yet so I better start Computing them that's the first one I find too now as soon as I see that two as soon as the minimizer sees that two the minimizer knows that the value of this node can't be any greater than two because he'll always choose to go down this way if this Branch produces a bigger number so we can say that the minimizer is assured already that a score there will be less than two equal to or less than two so now we go over and compute the next number there's a seven now he knows it's exactly equal two because it'll never go down toward seven as soon as the minimizer says equal to two the maximizer says okay I can do equal two or greater than two all right one minimizer says equal to or less than one now what compare those two two numbers the maximizer knows if he goes down here he can't do better than one but he already knows if he goes over here he can get a two so it's as if this Branch doesn't even exist because this the maximizer would never choose to go down there and so you have to see that because this is the important essence of the notion of Alpha Beta of the alpha beta algorithm which is a layering on top of Minimax that cuts off large sections of the search tree so one more time we've developed the situation so we know that the maximizer gets a two going down to the left and he sees that if he goes down to the right he can't do better than one so he says to himself it's as if that Branch doesn't exist and the overall score is two and it doesn't matter what that static value is it can be eight as it was it can be plus a th000 it doesn't matter it can be minus a th000 or it could be plus infinity or minus infinity it doesn't matter because the maximizer will always go the other way so that's the alpha beta algorithm can you guess why it's called the alpha beta algorithm well because in the algorithm there are two parameters Alpha and beta so it's important to understand Alpha Beta is not an alternative to Minimax it's Minimax with a flourish it's something layered on top like we layer things on top of branch and bound to make it more efficient we layer stuff on top of Minimax to make it more efficient and you say to me well that's a pretty easy example on it this so let's try a little bit more complex one just just to see if I could do it without screwing up all right the reason I do it reason I do one this complex is not just to show how tough I am in front of a large audience but rather there are certain points of interest that only occur in a tree of depth four or greater that's the reason for this example but work with me let's see if we can get our way work our way through it what I'm going to do is I'll um I'll Circle the static the numbers that we actually have to compute so we actually have to compute eight and as soon as we do that the minimizer knows that that node is going to have a score of equal to or less than eight without looking at anything else then he looks at seven so that's equal to seven because the minimizer will clearly go to the right as soon as that is determined then the maximizer knows that the score here is equal to are greater than eight now we evaluate the three the minimizer knows equal to or less than three oh sorry minimizer seven yeah okay now what happens well let's see the maximizer gets a seven going that way can't do better than three going that way so we got another one of these cut off situations it's as if this Branch doesn't even exist so this static evaluation need not be made and now we know that that's not not not merely equal to or greater than seven but exactly equal to seven and we can push that number back up so that becomes equal to or less than seven okay you with me so far let's get over on the other side of the tree as quickly as possible so there's a 9 equal to or less than 9 8 equal to 8 push the eight up equal to or greater than eight so the minimizer can go down this way and get a seven will certainly never go that way where the maximizer can get an eight so once again we've got a cut off and it's as if this Branch didn't exist and that means that these static evaluations don't have to be made and this value is now exactly seven but there's little there's one more thing to note here and that is that not only not only do we not have to make these static evaluations down here but we don't even have to generate these moves so we save two ways both on static evaluation and on move generation so this this is a real winner this Alpha Beta thing because it saves an enormous amount of computation well we're on the way now the maximizer up here is guaranteed equal to or greater than seven anybody found the winning move yet is it to the left I don't know we better keep going because we don't want to trust any oracles so let's see there's a one we've calculated that the minimizer can be guaranteed equal to or less than one at that particular point you I'll think about that for a while at the top the maximizer knows you can go left and get a seven the minimizer if the play ever gets here can Ensure he's going to drive the situation to a board number that's one so the question is would the maximizer ever permit that to happen and the answer is surely not so over here in the development of this side of the tree we're always comparing numbers at adjacent levels in the tree but here's a situation where we're comparing numbers that are separated from each other in the tree and we' still concluded that no further examination of this node makes any sense at all this is called deep cut off and that means that this whole Branch here might as well not exist and we won't have to compute that static value all right so it looks I mean you you you have this stare of disbelief which is perfectly normal I have to reconvince myself every time that this actually works but when you think your way through it it is clear that these computations that I've xed out don't have to be made so let's carry on and see if we can complete this equal to or less than 8 equal to 8 equal to 8 because the other Branch doesn't even exist equal to or less than eight and we compare these two numbers do we keep going yes we we keep going because maybe the maximizer can go to the right and actually get to that eight so we have to go over here keep working away there's a 9 equal to or less than 9 another 9 equal to 9 push that number up equal to or greater than nine let's see minimizer gets an eight going this way maximizer is insured of getting a nine going that way so once again we've got a cut off situation it's as if this doesn't exist those static evaluations are not made this move generation is not made and computation is all right so let's see if we can do better on this very example by using this Alpha Beta idea I'll slow it down a little bit we'll change the search type to minax with Alpha Beta we see two numbers on each of those nodes now guess what they're called we already know right they're Alpha and beta so what's going to happen is the algorithm proceeds through the trees that those numbers are going to to shrink wrap themselves around the situation so we'll start that up so two static evaluations were not made let's try a new tree two different ones were not made a new tree yeah two still again two different ones not made let's see what happens when we use the classroom example the one I did up there let's make sure that I didn't screw it up slow that down to one few same answer so you probably didn't realize it at the start who could and in fact the play goes down that way over this way down that way and ultimately to the eight which is not the biggest number and it's not the smallest number it's the compromised number that's arrived at in virtue of the fact that this is an adversarial situation so you say to me how much uh how much energy how much work do you actually save by doing this well it uh is the case that in the optimal situation if everything is ordered right if God has come down and arranged your tree in just the right way then the approximate amount of work you need to do the approximate number of static evaluations performed is approximately equal to 2 * B to the D over two we don't care about this tube We Care a whole lot about that two so that's the amount of work that's done it's B to the D over2 instead of B to the D what's that mean suppose that without this idea I can go down SE Seven Levels how far can I go down with this idea 14 levels so it's a difference between a jerk and a world champion so that however is only in the optimal case when God has arranged things just right but in Practical situ situations practical game situations it appears to be the case experimentally that the actual number is close to this approximation for optimal arrangements so you never not want to use Alpha Beta saves an amazing amount of time you can look at it another way suppose you suppose you go down to the same number of levels how much less work do you have to do well quite a bit the square root is much right so another way of looking at how it works so we could go home at this point except for uh one problem and that is that uh we pretended that the branching factor is uh always the same but in fact the branching Factor will vary with the the game State and will vary with the game so you can calculate how much Computing you can do in two minutes or how however much time you have for an average move and then you can say how how deep can I go and you won't know for sure because it depends on the game so in the early days of uh game playing programs the game playing program left a lot of computation on the table because it would make uh a decision in 3 seconds and it might have made a much different move if it used all the computation it had available alternatively it might be grinding away and after 2 minutes was consumed it had no move and just did something random so that's not that's not very good but that's what early game playing programs did because no one knew how deep they could go so uh let's uh have a look at the situation here uh and say well here's a game tree it's a binary gra tree that's level zero that's level one this is Level D minus one and this is Level D so down here you have situation looks like this and I've left all the game tree out in between so how many Leaf nodes are there down here B to the D right oh I'm going to forget about alpha beta for a moment as as as we did when we looked at some of those optimal searches we're going to add these things one one at a time so forget about Alpha Beta assume we're just doing straight Minimax in that case we would have to calculate all these static values down here the bottom and there are B to the D of those how many are there at this next level up well that must be B to the D minus one how many fewer nodes are there at the second to the last the penultimate level relative to the FI final level well one over B right so if I'm concerned about not getting all the way through these calculations at the D level I can give myself an insurance policy by calculating out what the answer would be if I only went down to the D minus D minus oneth level all right see how you get that insurance policy it only cost me let's say the branching factor is 10 how much does that insurance policy cost me 10% of my computation because I can do this calculation and have a move in hand here at the at level D minus one for only one/ tenth amount of of the computation it's required to figure out what I would do if I go all the way down to the de level okay is that clear so this idea is extremely important in its general form but we haven't quite got there yet because what if the branching Factor turns out to be really big and we can't get through this level either what should we do to make sure that we still have a good move right we can do it at the B minus 2 level so that would be up here and at that level the amount of computation would be B to the D minus 2 so now it's we've added 10% plus 10% of that and our knee-jerk is beginning to beginning to form right what are we going to do in the to make sure that no matter what we've got to move we're going to what's that Christopher start from the very first level start from the very first level and give oursel an insurance policy for every level we try to calculate but that might be real costly so we better figure out if this is going to be too big of an expense to bear so let's see if we do what uh Christopher suggests then the amount of computation we need in our insurance policy is going to be equal to one we're going to do it up here at this level too even though we don't need it just to make everything work out easy 1 + B that's getting our insurance policy down here at this first level and we're going to add B ^2 all the way down to B to the D minus one so that's how much we're going to spend getting an insurance policy at every level what's the sum of that high school algebra right let's let's just do it for fun oh unfortunate choice of variable names BS is equal to we're going to multiply all those by B okay now we'll subtract the first one from the second one which tells us that the amount of calculation needed for our insurance policy is equal to B to the D -1 over b - 1 is that a big number we can do a little algebra on that and say that b to the D is a huge number so that minus one doesn't count and B is probably 10 to 15 so B minus 1 is essentially equal to B so that's approximately equal to B to the D minus one so with a with an approximation factored in the amount it takes us to amount of computation need to do insurance policy at every level it's not much different from the amount of computation needs to get insurance policy at just one level the the penultimate one so this idea is called Progressive deepening and now we can visit our gostar list gostar idea list and see how these things match up with that first of all the the dead horse principle comes to the for when we talk about Alpha Beta because we knowe with Alpha Beta that we can get rid of a whole lot of the tree and not do static evaluations not even do move generation that's the dead horse we don't want to beat there's no point in doing that calculation because it can't figure into the answer the development of the progressive deepening idea I like to think of in terms of the martial arts principle we're using the enemy's characteristics against them because of this exponential blowup we have exactly the right characteristics to have a move available at every level as an insurance policy against not get through the next level and finally this whole idea of progressive deepening can be viewed as a prime example of what we like to call anytime algorithms that always have an answer ready to go as soon as an answer is demanded so as soon as that clock runs out at 2 minutes some answer is available it'll be the best one that the system can compute in the time available given the characteristics of the game tree as it's developed so far so there are other kinds of anytime algorithms this is an example of one so that's how all game playing programs work Minx plus Alpha Beta plus Progressive deepening Christopher is Alpha Beta a alternative to Minimax no no it's not it's something you layer on top of Minimax does alpha beta give you a different answer from Minx no no let's see see everybody shake their head one way or the other it does not give you an answer different from minax that's right it gives you exactly the same answer not a different answer it's a speed up it's not an approximation it's a speed up it cuts off lots of the tree it's dead horse principle at work okay you got a question Christoper yeah um the lines of progressively Computing the best result is it possible to almost keep a temporary value the values you on each of the tree and then keep and then oh an excellent suggestion Christopher has just I think if I can jump ahead a couple of steps I think Christopher has reinvented a very important idea Progressive deepening not only ensures that you get a better answer Progressive deepening not only ures you have an answer at any time it actually improves the performance of Alpha Beta when you layer alpha beta on top of it because these values that are calculated at intermediate parts of the tree are used used to reorder the nodes under the tree so as to give you maximum Alpha Beta cut off I think that's what you said Christopher but if it isn't we'll talk about your idea after class so this is what every game planing program does so what how is deep deep blue different not much so deep blue as of 1997 did about 200 million static evaluations per second and it went down using Alpha Beta went down about 14 156 levels so deep blue was minax plus Alpha Beta plus Progressive deepening plus a whole lot of parallel Computing plus an opening book plus special purpose stuff for the End Game Plus perhaps the most important thing an even tree development so far we've pretended that the tree always goes out in an even way to a fixed level but there's no particular reason why that has to be so some some situation down at the bottom of the tree may be particularly dynamic in the very next move you might be able to capture the opponent's Queen so in circumstances like that you want to blow out a little extra search So eventually you get to the idea that there's no particular reason to have the search go down to a fixed level but instead you can develop the tree in a way that gives you the most confidence that your backed up numbers are correct and so that's the most important of the extra flourishes added by Deep Blue when it beat casprov in 1997 and now we can uh come back and say well you understand deep blue but is this a model of anything that goes on in our own is this a model of any kind of human intelligence or is it a different kind of intelligence and the answer is mixed right because we are often in situations where we are playing a game we're competing with another manufacturer we have to think what the other manufacturer will do in response to what we do and down several levels on the other hand uh is going down 14 levels what human chess players do do when they win the World Championship doesn't seem even to them like that's even a remote possibility they have to do something different because they don't have that kind of computational horsepower this is doing computation in the same way that a bulldozer processes gravel it's substituting raw power for sophistication so when a human chess master plays the game they have a great deal of chest knowledge in their head and they recog nice patterns there are famous experiments by the way that demonstrate this in the following way show a chess board to a Chessmaster and ask them to memorize it they're very good at that as long as it's a legitimate chess board if the pieces are placed random randomly they're no good at it at all so it's very clear that they've developed a repertoire of Chess knowledge that makes it possible for them to recognize situations and play the game much more like number one up there so deep blue is manifesting some kind of intelligence but it's not our intelligence it's bulldozer intelligence so it's important to understand that kind of intelligence too but it's not necessarily the same kind of intelligence that we have in our own head so that concludes what we're going to do today and as you know on Wednesday we have a celebration of learning which is familiar to if you're Tak a 3091 and therefore I will see you on Wednesday all of you I imagine