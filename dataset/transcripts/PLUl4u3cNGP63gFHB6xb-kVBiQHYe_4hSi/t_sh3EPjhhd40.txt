you know uh some of you uh who for instance uh I don't know uh Sonia Krishna Shosana some of you I can count on being here every time some of you show up once in a while those of you who show up once in a while happen to be very lucky if you picked today because what we're going to do today is I'm going to tell you stuff that might make a big difference in your whole life because I'm going to tell you how you can make yourself smarter. No kidding. And I'm also going to tell you how you can package your ideas so that you'll be the one that's picked instead of some other slug. So that's what we're going to do today. It's a it's it's uh it's the it's the most important lecture of the semester. The sleep lecture is only the second most important. This is the most important. Now, the vehicle that's going to get us there is um a discussion about how it's possible to learn in a way that is a little reminiscent of what we talked about last time because last time we learned something very definite from a small number of examples. This takes it one step further and shows how it's possible to learn in a humanlike way from a single example in one shot. So it's extremely different, very different uh from everything uh you've seen before, everything that um involves uh learning from thousands of trials and uh gazillions of examples and only learns a little tiny bit if anything from each of them. This is going to learn something definite from every example. So here's a here here's the here's the classroom example. What's this? It's an arch. I know the architects are complaining that it's not an arch in architecture land. It's a post and lintil construction, but for us today, it's going to be an arch. Now, if you were from Mars and didn't know what an arch was, I might present this to you and you would get a general idea of some things that might be factors, but you'd have no idea what's really important. So then I would say that's not an arch. And you would learn something very definite from that. And then I would shove these together and put this back on and I would say that's not an arch either. And you learn something very definite from that. And then I could paint the top one blue and you learn something very definite from that. And how how how can that happen is the question. How can that happen in detail? And what might it mean for uh human learning and how you can make yourself smarter? That's that's where we're going to go. All right. So, how can we make a a program that's as smart as a Martian about learning things like that? Well, if you were writing that program, uh surely the first thing you would do is you would try to get off the picture as quickly as possible and into symbol land uh where things are clearer about what the important parts are. So, you'd be presented uh with a with an initial example that might look like this. All right, we'll call that an example. But it's more than just an example. It's the initial model. That's the starting point. And now we're going to couple that with something that's not actually an arch, but looks a whole lot like one, at least on a on the on the descriptive level to which we're about to go. So, here's something that's not an arch, but its description doesn't differ from that of an arch very much. In fact, if we were to draw this out in a kind of network, we would have a description that looks like this. And these relations would be support relations. And this would be drawn out like so. And the only difference would be this. Oh, the only difference would be that those support relations that we had in the initial model, the the the example have disappeared down here in in in this um in in this configuration. But since it's not very different from the model, we're going to call this a near miss. And now you see we've abstracted away from all the details that don't matter to us. Last time we talked about a good representation having certain qualities. Qualities like making the right things explicit. Well, this makes the structure explicit and it suppresses information about blemishes on the surface. We don't care much about how tall the objects are. We don't we don't think it matters what they're made of. So this is a representation that satisfies the first of the criteria from last time. It makes the right things explicit. And by making the right things explicit, it's it's exposing some constraint here with respect to what it takes to be an arch. And we see that if those support relations are missing, it's not an arch. So we ought to be able to learn something from that. What we're going to do is we're going to put these two things together. We're going to describe the difference between the two. We're going to reach the conclusion that since there's only one difference, one kind of difference with two manifestations, two disappearing support relations, we're going to conclude that those support relations are important. We're going to turn we're going to turn them red because they're so important. And we're going to change the name from support to must support. So this is a this is our new model. This is an evolving model that now is decorated with information about what's important. So if you're going to match something against this model, it must be the case that those support relations are there. If it's not there, if they're not there, it's not an arch. All right? So, we've learned something definite from a single example. This is not 10,000 trials. This is a teacher presenting something to the student and the student learning something immediately in one step uh about what is what's important in an arch. So, let's do it again. That was so much fun. Let's do this one. Same as before except that now when we describe this thing there are some additional relations these relations and those are touch relations. So now when we compare that is that an arch? No that's a near miss. When we compare that near mississ with our evolving model, we see immediately that once again there's exactly one difference two manifestations the touch relations. So we can immediately conclude that these touch relations are interfering with our belief that this could be an arch. So what do we do with that? We put those together again and we build ourselves a new model. It's much like the old model. It still has the imperatives up here. We have to have the support relations. But now down here, let me draw not signs through there. This these are must not touch relations. So now you can't match against that model if those two side supports are touching each other. So in just two steps, we've learned two important things about what what has to be in place in order for this thing to be considered strewed to be an art. So, our Martian is making great progress, but our Martian isn't through because there's some more things we might want it to know about the nature of arches. For example, we might present it with this one. Oh, that looks just like our initial example. It's an example just like our initial example, but this time the top has been painted red, but I'm still saying that that's an arch. So once again there's only one difference and that difference is that in the description of this object we have the additional information that the color of the top is red and we've been carrying along without saying so that the color of the top and the evolving model is white. So now we know that the top doesn't have to be white. It can be either red or white. So we'll put those two together and we'll get a new model. And that new model this time once again will have three parts. It will have the relations in imperative form that we've been carrying along now. The must support and the must not touch. But now we're going to turn that color relation itself into an imperative. And we're going to say that the top has to be either red or white. So now once again in one step we've learned something definite about archness. Two more steps. Suppose now we present it with this example. It's an example. And this time, uh, there's going to be a little paint added here as well. This time, we're going to have the top painted blue like so. Like so. And so, the description will be like so. And now we have to somehow put that together with our evolving model to make a new model. There's some choices here. And our choice depends somewhat on the nature of the world that we're working in. So suppose we're working in flag world. There are only three colors, red, white, and blue. Now we've seen them all. If we've seen them all, then what we're going to do is we're going to say that the evolving model now is adjusted yet again. like so. Oh, well, those are imperative still. Let me carry that along. But this time, this guy, the color relation goes out here to anything at all. So, we could have just not drawn it at all, but then we would have lost track of the fact that we've actually learned that anything can be there. So, we're going to retain the relation, but have it point to the anything goes marker. Well, we're making great progress, and I said there's just one more thing to go. So, let me uh let me compress that into this area here. What I'm going to add this time is I'm going to say that the example is like everything you've seen before except that the top is now one of those kinds of child's bricks. So you have a choice actually about whether this is an arch or not. But if I say, "Yeah, it's still an arch." Then we'd uh add a little something to its description. So its description would look like this. Same things that we've seen before in terms of support, but now would have a relation that says that this top is a wedge. And over here, something we've been carrying along but not writing down. This top is a block, a brick I guess in the language of the day. So if we say that it can be either a wedge or a brick on top, what do we do with that? Once again, it depends on the nature of representation. But if we say that we have a representation that has a hierarchy of parts. So bricks and wedges are both children's blocks and children's blocks are toys. Then we can think of drawing in a little bit of that hierarchy right here and saying, "Well, let's see. Immediately above that, we've got the brick or wedge. And a little bit above that, we've got block. And a little bit above that, we've got toy. and a little bit above that we eventually get to any physical object. So what does it do uh in response to that kind of situation? You have the choice. But what the program I'm speaking of actually did was to make a conservative generalization up here just to say that it's one of those guys. So once again, it's learned something definite. Let me see. Let me count the steps. One, two, three, four, five, and it's learned four things. So the generalization of the color, it took two steps to get all the way up to don't care. So note how that contrasts with anything you've seen in a neural net uh or anything you will see downstream in some of the other learning techniques that we'll be talking about that involve using thousands of samples to to uh learn what it is to learn whatever it is that is intended to be learned. Let me show you uh another example of how these uristics can be put to work. So there are two sets of drawings. Uh we have the upper set and the lower set. And your task, you smart humans working in vast parallelism. Your task is to give me a description of the top trains that distinguishes and separates them from the trains on the bottom. You got it. Nobody's got it. Well, let me try one on you. The top trains all have a short car with a closed top. So, how is it possible that a computer could have figured that out? Well, it turns out that it figured it out with much the same apparatus that I've shown you here in connection with the arches, just deployed in a somewhat different manner. In this particular case, the examples are presented one at a time by a teacher who's eager for the student to learn. In this case, the examples are presented all at once and the machine is expected to figure out a description that separates the two the two the two groups. And here's how it works. What you do is you start with one of them, but you have a lot of them. You have some examples, we'll call the examples on top the the plus examples and the examples on the bottom the negative examples. So, the first thing that you do is you pick one of the positive examples to work with. And anybody got any good guesses about what we're going to call that? Yeah, you do. We're going to call that the seed. It's just it's just highly reminiscent of what we did last time when we're doing phenology, but now at a much different level. We're going to pick one of those guys to be the seed. And then we're going to take these uristics and we're going to search for one that loosens this description so that it covers more of the positives. You see, if you have a C that is exactly a description of a particular thing and you insist that everything be just like that, then nothing will match except itself. But you can use these uristics to expand the coverage of the description to loosen it so that it covers more of the positives. So in your first step, you might cover, for example, that group of objects. Now, too bad for your side. You've also in that particular case included a negative example in your description. But perhaps in this next step beyond that, you'll get to the point where you've eliminated all of those negative examples and zeroed in on all the positive examples. So how might a program be constructed that would do that sort of thing? Well, think about the choices. The first choice that you have is to pick a positive example to be the seed. And once you've picked a particular example to be the seed, then you can apply uristics all of them that you have to make a new description that may cover the data better. It may have more of the positives and fewer of the negatives than your in your previous step. But this if you have a lot of uristics and these are a lot of uristics because there's a lot of description in that set of trains. There are lots of possible things that you could do with those uristics because you could apply them anywhere. So this tree is extremely large. So what do you do to keep it under control? Well, you know, now you now you have answers to questions like that by knee-jerk, right? The branching factor is too big. You want to keep a few solutions going. Uh you have some way of measuring how well you're doing. So you can use a beam search. This piece here was originally worked out by a friend of mine now alastky when he was at the University of Illinois. And of course he wasn't interested in toy trains. He was just interested in soybean diseases. And so this exact program was used to build descriptions of soybean diseases that turned out to be better than the plant pathology books. But you know, we now have two ways of deploying the same uristics. But my vocabulary is um is in need of enrichment because I'm talking about those uristics. And one of the nice things that Milcowski did for me a long time ago was give each of them a name. So here are the names that uh were that were developed by Milowski. What's happening here? you're going from an original model to an understanding some things are essential. So he called this the require link the heristic and here in the next step we're forbidding some things from being there. So Macowski called that uristic the forbiddling uristic and in the next step we're saying it can be either red or white. So we have a set of colors and we're extending it. And over here in this heristic going from red or white to anything goes uh that's essentially forgetting about color altogether. So we're going to call that drop link even though for reasons of keeping track we don't actually get rid of it. We just have have it pointing to the anything marker. And finally in this last step what we're doing uh with this tree of categories is we're climbing up it one step. So he called that the climb treeistic. So now we have a vocabulary of things we can do in the learning process and having that vocabulary gives us power over it. Right? Because those are names. We can now say oh well what you need here is the drop link uristic or what you need over there is the uh extend set uristic. So now I want to back up yet another time and and say well let's see uh when we were working with that phology stuff all I did was generalize. Are we just generalizing here? No we're both generalizing and specializing. So when I say that the links over here that are developed in our first step are essential this is a specialization step and when I say they can't be they cannot be touch relations that's a specialization step because we're able to match fewer and fewer things when we say you can't have touch relations but over here when I go here and say well it doesn't have to be white it can also be red that's a generalization now we can match more things and when I drop the link al together that's a generalization and when I climb the tree that's a generalization And that's why when I do this notional picture of what happens when Macausski program does a tree search to find a solution to the train problem, they're both specialization steps which draw in the number of things that can be matched and generalization steps that make it broader. So let's see. We've also got the notion of um near miss uh and we've got the notion of example. Some of these things are examples, some are near misses. And we've got generalization and specialization. Does one go with one or the other or are they all mixed up in the relationship to each other? Can you generalize and specialize with near misses? What do you think? You think what do you you don't think so you what do you think lead to specialization? The nearest seem to lead to specialization. Let's see if that's right. So we got specialization here and that's a near miss. We got specialization here and that's a near miss. We've got generalization here and that's an example. And we've got generalization here and that's an example. And we've got generalization here. And that's an example. So a ball's got that one nailed. The example is always generalized. And this near miss is always specialized. So we've got apparatus in place that allow us to both expand what we could match and shrink what we can match. So what has this got to do with anything? Well, which one of these methods is better? By the way, this one this one requires a teacher to organize everything up. This one can handle it uh in batch mode. Uh this one is the sort of thing you would need to do with a human because we don't have me much memory. That one is the sort of thing that a computer is good at because it has lots of memory. So which one's better? Well, it depends on what you're trying to do. If you're trying to build a machine uh that analyzes stock market, you might want to go that way. Or soybean diseases or any one of a variety of practical problems. If you're trying to model people, then maybe this is a way that deserves additional merit. But how do you get all that sorted out? Well, one way to get it all sorted out is to talk in terms of what are called sometimes called felicity conditions. So when I talk about felicity conditions, I'm talking about a teacher and a student and covenants that hold between them. So here's the teacher. That's me. And here's the student. That's you. And the objective of uh interaction is to transform an initial state of knowledge into a new state of knowledge. so that the student is smarter and able to make use of that new knowledge to do things that couldn't be done before by the student. So the student over here has a learner and he has something that uses what is learned And the teacher over here has a style. So if any learning is to take place, one side has to know something about the other side. For example, it's helpful if the teacher understands the initial state of the student. And here's One way of thinking about [Music] that you can think of what you know as forming a kind of network. So initially you don't know anything but as you learn you start developing quanta of knowledge and these quant of knowledge are all linked together by prerequisite relationships that might indicate how you get from one quantum to another. So maybe you have generalization links, maybe you have specialization links, maybe you have combination links, but you can think of what you know as forming this kind of network. Now your state of knowledge in any particular time can then be viewed as a kind of wavefront in that space. So if I the teacher know where your wavefront is, can I do a better job of teaching you stuff? Sure. For this reason, suppose you make a mistake M1 that depends on Q1 way, way behind your wavefront. What do I do if I know that you made a mistake of that kind? Oh, I just say, "Oh, you forgot that you need a semicolon after that kind of statement." I just remind you of something that you certainly know you just overlooked. Right? On the other hand, suppose you make a mistake that depends on a piece of knowledge way out here. That kind of mistake M2. What do I say to you then? What do you think, Patrick? What do you think I would say to you if you make that kind of mistake? Explain that to you. No, that's not what I That's not what I would say. Let me explain that to you. I know you are. What would I do? Tell us that we don't know that yet. I would say something like that. what Art suggested. I was saying, "Oh, don't worry about that. We'll get to it. We're not ready for it yet." So, in this case, I remind somebody of something they already know. In this case, I tell them to learn about it later. So, what do I do with mistake number three? That's the learning moment. That's where I can push the wavefront out because everything's in place to learn the stuff at the next radius. So if I know that the student has made a mistake on that wavefront, that's when I say this is the teaching moment. This is when I explain something. So that's why it's important for the teacher to have a good model of where the student is in the initial state of knowledge. Next thing it's important to know for the teacher to know is the way that the student learns. Because if the student is a computer that can handle the stuff in batch, that's one thing. If the student is a third grader who has a limited capacity to store stuff, then that that makes a difference in how you teach it. You might teach it that way to the third grader and that way buried underneath this board to a computer. So you need to understand the the way that the learner the computational capacity of the learner and there's also a need to understand the computational capacity of the user box down there because sometimes you can be taught stuff that you can't actually use. So by now most of you have attempted to read that sentence up there, right? And it seems screwy, right? It seems unintelligible perhaps. It's a garden path sentence. It makes perfectly It's perfectly good English, but the way you generally read it, it doesn't because you have a limited buffer in your language processor. What does this mean? You're expecting this to be two question, but it's actually a command. Here's the deal. Somebody's got to give the students their grades. Well, we could have their parents do it. have the grades given to their students by their parents then so it's a command and you garden path on it because you have limited buffer space in your language processor so with parenthesis you could understand it you could learn about it you could see that it's good English but you can't generally process that kind of sentence without going back and starting over now what about going the other way are there covenants that we have to have here that involve the student understanding some things about the teacher Well, the first thing there is is trust. The student has to presume that the teacher is teaching the student correct information, not lying to the student. I'm gratified that you're all here because presumably you all think that I'm not trying to screw you by telling you stuff that's a lie. There's also this sort of thing down here, an understanding of the teacher style. So you might say, "Well, Professor X, all he does is read slice to us in class, so why go?" You wouldn't be entirely misadvised. That's an understanding of one kind of style. Or you could say, "Well, oh, Winston, he tries to tell us something definite and convey a family of powerful ideas in every class, so maybe it's worth dragging yourself out of bed at 10:00 in the morning." Those are style issues, and those are things that the student uses to determine how to match student style against that of the of the instructor. So that helps us to uh interpret or think about uh differences in in in style so that we can appreciate whether we ought to be uh learning uh that way where that way is the way that's underneath down here the the way you would teach a computer the way Milkcowski taught a computer about soybean diseases. We can do it that way or we can do it this way with a teacher who deliberately organizes and shapes the learning sequences sequence for the benefit of a student who has a limited processing capability. Now you're humans right? So think about what the machine has to do here. The machine in order to learn anything in definite in each of those steps the machine has to build a description. So it has to describe the examples to itself. That's unquestioned, right? Because what it's doing is it's looking at the differences. So, it can't look at the differences unless it's got descriptions of things. So, if you're like the machine, then you can't learn anything unless you build descriptions unless you talk to yourself. And if you talk to yourself, you're building the kind of descriptions that make it possible for you to do the learning. and you say to me, I'm an MIT student. I want to see the numbers. So, let me show you the numbers. And what I'm going to show you numbers, what the numbers I'm going to show you show you the virtues of talking to yourself. So, here's the experiment. Experiment is done by friend of mine, Michelin Chi. Always uh seems to go by the name Mickey. Oh, I see what I've done. There it is. So, here's the deal. The students uh that she worked with were expected to learn about elementary physics 801 type stuff. And she took eight subjects and she had them um she took them through a bunch of examples and then she gave them an examination. So there eight subjects and so they divide into two groups. The bottom half and the top half. The ones who the ones who did better than average and the ones that did worse than average. So then you can say well okay uh what what did that mean? You can say how much did they talk to themselves? Well that was measured by having them talk out loud as they solve the problems on an examination. So we can ask how much self explanation was done by the the smart ones versus the less smart ones. And here are the results. The worst ones, the worst four said about 10 things to themsel. The best four said 35 things to themsel. That's pretty dramatic difference. Here it here's the data in the straightforward form. Uh this by the way points out that the smart ones scored twice as high as the less smart ones. And when we look at the number of explanations they gave themselves in two categories. The smart ones said three times as much stuff to themselves as the less smart ones. So as you can see the um explanations break down into two groups. Some uh have to do with monitoring and not with physics at all. They're things like, "Oh, hell, I'm stuck." Or, "Uh, I don't know what to do." And the others have to do with physics, like, and they're things like, "Well, maybe I should draw a force diagram, or uh, let me write down F= ma or something like that as physics knowledge." I think it's interesting that the that the that the average scores differed by a factor of two and the average talking to oneself differed by a factor of three. Now, this isn't quite there uh because what's not clear is if you encourage somebody to talk to themsel and they talk to themselves more than they would have ordinarily, does that make them score better? All we know is that the ones who talk to themselves more do score better. But anecdotally, talking to some veterans of 6034, they've started talking to themselves more when they solve problems, and they think that it makes them smarter. Now, I would caution you not to do this too much in public because people can get the wrong idea if you talk to yourself too much. But it does seem it does uh it does in fact uh seem uh seem to help. Now, what I did last time is I told you how to be a good scientist. What I'm telling you now is how to make yourself smarter. And I want to conclude this hour by telling you about how you can package your ideas so they have greater impact. So I guess I've I I could have said how to make yourself more famous, but I've limited myself to saying how to package your ideas better. And the reason you want to package your ideas better is because if you package your ideas better than the next slug, then you're going to get the faculty position and they're not. You say to me, I'm going to be an entrepreneur. Same thing. You're going to get the venture capitalist money and the next slug won't. if you package your ideas better. So, this uh little piece of work on the arch business got a whole lot more famous than I ever expected. I did it when I was young and stupid and didn't have any idea of what qualities might emerge from a piece of work that would make it well known. I only figured it out much later. But in retrospect, it has five qualities uh that uh you can think about when you're deciding whether your packaging of your idea is in a form that will lead to that idea becoming well known. And since there are five of them, it's convenient to uh put them all on the points of a star like so. So, uh, quality number one, uh, I've made these all into swords just to make them easier to remember. Quality number one is that there's some kind of symbol associated with a word, some kind of visual handle that people uh, will use to remember your idea. So, what's the visual symbol here? Well, that's astonishingly easy to figure out, right? That's the arch. For years without my intending it, this was called arch learning. So you need a symbol. Then you also need a slogan. That's a kind of verbal handle. It doesn't explain the idea, but it serves but it's enough of a handle to, as Minsky would say, put you back in the mental state you were in when you understood the idea in the first place. So what is the slogan for this work? Anybody have any ideas? It's pretty obvious. What's central? What's central to this process working? The ability to present an example that's very similar to the thing that constitutes a model but isn't one of those. So it's near and miss. Next thing you need uh if your work is going to become well known is a surprise. What's the surprise with this stuff? Well, the surprise everything that had been done in artificial intelligence having to do with learning before this time was precursors to neural nets. Thousands of examples to learn anything. So the big surprise was that it was possible for a machine to learn something definite from each of the examples. So that no now goes by the name of one-shot learning. That was the surprise that a computer could learn something definite from a single example. So let's see we're almost we've almost completed our uh star but there are two more points on it. So this point is the salient. What's a salient? What's a salient idea? Jose, do you know what a salient idea is? He's too shy to tell me. What's a salient idea, Christopher? Ah, who said important? Wrong answer, but very good. You're not shy. So, what what does it really mean? Yes. Relative to what somebody's already thinking about. uh relative to what somebody's thinking about. Not quite. Okay. If you have a if you're an expert, is there a suggestion over here? Yes. Just really clear. Really clear. We're getting closer. You study military. Yes. Maybe an idea that wasn't obviously apparent but becomes apparent gradually. Somebody starts becomes apparent gradually. Oh, we're we're zeroing. We're circling the wagons here. Zeroing in on it. Yes. If I preempt what you're about to say, uh, has sort of a doorway into how you can understand the idea. It's what sort of a a a doorway how you how you grasp the idea. That's that's sort of it too. But if you study military history, what's the salient on a fort? Well, this is a good word to have in your vocabulary because it it's it sort of means all of those things, but what it really means is something that sticks out. So on a fort, I mean, if this were a fort, these would all be salient because they stick out. So a salient idea is usually important because it sticks out, but it's not. The meaning is not important. Meaning is stick out. So a piece of work becomes more famous if it has something that sticks out. It's interesting. There are thesis that have been written in MIT that have too many good ideas. And how can you have too many good ideas? Well, you can have too many good ideas if no one idea rises above and becomes the idea that people think about when they think about you. We have people on the faculty who would have been more famous if their thesis had fewer ideas. It's amazing. So this piece of work uh did have a salient and the salient idea was that you could get oneshot learning via the use of near misses. That was the salient idea. The fifth thing uh talk more about this uh in my how to speak lecture in January. The fifth thing I like people to try to incorporate into their presentations is a story. Because we humans somehow love stories. We love people to tell us stories. We love things to be packaged in stories. And believe me, I think all of education is essentially about storytelling and story understanding. So if you want uh your idea to be sold to the venture capitalist, if you want to uh get that faculty job, if you want to get your book sold to a publisher, if you want to sell something to a customer, ask yourself if your presentation has these qualities in it. And if it has all of those things, it's a lot more likely to be effective than it doesn't. And you'll end up being famous. Now, you say to me, "Well, being famous, that sounds like the Sloan school type of concept. Isn't Isn't it immoral to want to be famous? Maybe that's a decision you can make. Uh but um whenever I think about the question, I I somehow think of the idea that your ideas are like your children. You want to be sure that they have the best life possible. And so if they're not packaged well, they won't. I'm also reminded of um an evening I spent at a suare uh with uh Julia Child. Julia uh and there's me and I have no idea how come I got to sit next to Julia Child. I think they thought I was one of the Rich Winstons, the Winston Flowers, Harry Winston Diamonds or something like that. There I was sitting next to Julia Child. And the interesting thing by the way you notice I'm now telling a story. The interesting thing uh about this experience was that um there was a constant flow of uh of uh people happened to be all women of people going past Miss Child saying how uh wonderful she was to have made such an enormous change in their life. It must have been 10 of them. It was amazing. Just steady flow. So eventually I leaned over to her and I said, "Um, Miss Child, is it fun to be famous?" And she thought about it a second and said, "You get used to it." And that had a profound effect on me because you always say, "Well, what's the opposite like is it fun to be ignored?" And the answer is no. It's not much fun to be ignored. So yeah, it's a it's something you can get used to, but you can never get used to having your stuff ignored, especially if it's good stuff. So that's why I commend to you this business about packaging ideas. And now you see that 6034 is not just about AI. It's about how to do good science. It's how to make yourself smarter and how to make yourself more famous.