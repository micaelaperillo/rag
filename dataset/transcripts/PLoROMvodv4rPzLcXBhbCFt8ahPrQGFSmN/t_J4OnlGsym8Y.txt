welcome to exploring computing today's video is computer theory analysis of algorithms so choosing the right algorithm can make a big difference when you're programming and in fact it can make the difference between having a program that runs in a reasonable amount of time and a program that takes too long to run for reasonable size data sets so for small data sets you know there's a lot of different algorithms that will work but when you start working with large amounts of uh data more and more the particular algorithm that you're using is going to make a huge difference in whether or not you're actually able to analyze the data in a reasonable amount of time or it's just going to take long enough that for all practical purposes you can't do it in this lecture we're going to start by taking a look at how to look for an item in a collection and we'll compare some different ways of doing this and then after we've done that we're going to take a little bit of a look at how computer scientists go about uh comparing different algorithms from a theoretical standpoint all right so here i've got a list of different sovereigns uh of england and the simplest way i can go about trying to find out whether or not a particular name is on the list is using something called a linear search in a linear search we're going to start off with the first item and then we would go through each of the different items one at a time in order so um suppose we're looking for the name henry we would start off with mary say hey is mary henry no it's not uh and then we go down to the next time and say is anne henry no it's not the item we're looking for is george henry that's not the item we're looking for is henry henry oh yeah that's the item we're looking for therefore the item is in our list now if we're looking for a name that's not on actually on the list we start off again by comparing to mary we compare to ann we compared to george we go through all the way through the list we get to william we still haven't found the name on the list because the name is not on the list and then we realize we're at the end of the list and so we conclude because if we've gone all the way through the list and we haven't found a particular item therefore this item is not on the list at all so one thing to be thinking about here is how long does it take to find a particular item on the list so suppose we're looking for elizabeth you can see like elizabeth is somewhere in the middle of the list suppose we're looking for mary mary's at the start of the list so we can find her pretty quick suppose we're looking for melanie melanie's not on the list so we need to go all the way through the list so basically we can consider a number of different situations when we're talking about how fast an algorithm will run we can think about what's the best case so in case of linear search the best case is well it's the first time on the list it's very very quick to determine if mary is on this list we just look at the first item it's mary we're done what's the worst case well the worst case is in this particular algorithm is the item is not on the list at all and that means we need to compare all the different items and then we finally get to the end we're like yeah we checked everything it's not on here and then we've got the average case generally when we're talking about algorithm analysis we're concerned with what happens for large numbers of items as i mentioned earlier if you've got a small number of items you can have a pretty poorly thought out algorithm and still get it to work um it's not very efficient but as long as the numbers are pretty small it will still work it's when you start getting larger and larger numbers of items that it really becomes a problem so suppose if i've got a list of a thousand items it takes an average of one minute to find an item on the list how long would it take on average to find an item if we double the list size to 2000 well i mean i think this is pretty clear uh if we double the size of the list from 1000 to 2000 we will double the amount of time on average it's going to take so instead of taking one minute on average it will take two minutes and in fact we can write a little formula that looks like this average time to find an item is equal to the number of items divided by a thousand times one minute but um it turns out that our little formula here is highly dependent upon the specific computer because if i have a faster computer i can find an item on average faster than uh one minute four thousand items and so really if we want a more general formula we would actually write it like this we would say average time defined is equal to constant times the number of items where that constant is going to vary depending upon the particular type of computer but i still know that uh this general formula where i have some given constant determined by the speed of the computer times the number of items so as the number of items increases the amount of time it's going to take me will also increase at a constant rate okay so can we do a search that is faster than linear search yes if the list is ordered we can do what's called a binary search how does a binary search work in a binary search what we're going to do is we're going to take the list and we're going to divide it in half and we will determine if the item that we're looking for is in the upper half of the list or in the lower half of the list and this is similar to uh this analogy is getting old but i have previously asked students and they continue to tell me they do understand this analogy so i'm gonna continue using it so uh the analogy would be similar to if you have a physical telephone book um and you know you're trying to find a name in that phone book you split the phone book in half and you say is the name in the first half of the phone book or is in the last half of the phone book oh it's in the first half of the phone book okay i'm going to split that half the phone book in half so i'm look at the uh now looking at quarter sections is it in the first quarter or is it in the second quarter oh it's in the first quarter i'm going to split that in half and look at an eighth versus an eighth and so on and this is the same way you would also look for a word in a dictionary if you actually had a physical dictionary so let's look at how this might work for our monarchs of england i've reordered the list because again binary search requires that the items are are ordered okay so suppose we're looking for edward what we're going to do is we're going to split the list in half now it turns out in some cases um we can't split the list evenly in half uh and so in this case i'm going to split the list in half and start with henry i'm going to compare edward to henry and see if you know maybe i split the list in half this is like i open up the telephone book and it happens to be that uh the item i'm looking for is actually um right there i split it in half and there's the name i'm looking for that happens to just exactly be on that page so it is possible uh to split the list in half and actually the halfway point that's the name we're looking for but in this case it's not and so what i can do here is i can say is edward does the name edward if it were actually on this list does that come before henry or after henry and in this case since the list is alphabetized i know that e comes before h and therefore i toss out all the items from henry on onwards i'm not interested in those and i know i'm that if edward is on the list it needs to be somewhere in the first half of the list so somewhere between ann and george so i go ahead and uh toss those items out and then i split the list in half again and again you know this list does not split evenly so you need to have some sort of rule in terms of uh you know if the list doesn't split evenly are you going to go slightly lower you're going to go slightly higher so i'm going to go slightly higher and say we're going to go ahead and look at elizabeth is edward elizabeth no it's not if edward were on the list would uh he become above elizabeth or below elizabeth well alphabetically they both start with e d comes for l and so that means i would be in the first half of the list so i'm going to go ahead and toss out elizabeth uh onwards and i'm just gonna focus on ann and edward and of course uh there's edward right there and so we're done so uh it seems pretty complicated but actually it's uh it's going to turn out this is much faster than a linear search um one of the reasons why this seems kind of complicated and you may not be seeing the benefits here is that the benefits are really going to show up as the list size increases so you know if if we've got 10 000 items the binary search is going to make a huge difference if we've got five items not so much it seems sort of complicated and you're going to be doing all these comparisons and uh you know it just may not seem like you're getting a big benefit and we're actually going to talk about that a little bit later on in terms of well if you have small amounts of items you know the algorithm that you're using there are different things to think about like is there a big startup costs um and so these are different concerns so keep in mind when we're talking about analysis of algorithms we're generally talking about what happens when the numbers get really large because when the numbers get really large that's when we can't actually you know if we choose the wrong algorithm we aren't actually able to have a program that actually completes in a reasonable amount of time so you know maybe i can write the program and run on the data set and in three years it will finish running well that's not a reasonable amount of time that program is pretty much useless okay so uh buying your search is much faster particularly as the number of items increases um the number of times we need to search doesn't increase linearly so we saw that with the linear search you know if we double the number of items in the linear search the amount of time it's going to take to carry out the linear search doubles if we quintuple the amount of times uh you know the number of items in the list um for linear search the number of amount of time it's going to take it's going to quintuple but what happens with the binary search is it doesn't increase at that linear rate because we keep on splitting the list in half we split the list in half we split the list in half and it turns out that uh binary search actually increases the log so you may recall that the way logs work is they're basically determining based on powers so if i have log 10 that's actually 1 log of 100 is 2 because 10 to the second power is 100 log of a thousand is 3 because 10 to the third power is a thousand and log of 10 000 is 4 because if i take 10 to the fourth power it's 10 000. now in computer science and in particular for binary search in computer science in general we often use powers of two and then binary search we definitely use powers of two because we are repeatedly splitting the list in half and a half and a half and a half so i've gone ahead and written the logs uh base two here um and uh we can write that it was a log with a little lower little subscript two there meaning that we are using uh base two numbers instead of base 10 numbers and this is also sometimes written as ln of n but the main thing to note here is that uh this is much faster okay so we can write the formula for how long it takes like this average time to find is equal to constant times log base 2 of the number of items and again if you actually work out log of base 2 of the number of items versus just the number of items if you were to plot two on a graph you would see that log of the base two is much much better um and again uh i've got that constant there because we are concerned with um you know the particular computer is going to vary in speed and so what i want to know is in general if i'm trying to compare this algorithm to another algorithm regardless of the specific computer i'm using and how long that computer is going to take um that's where we go ahead and put in that constant so you know i don't know if i have a fast computer or i have a slow computer but i do know that for uh binary search it's going to increase based on the log of the number of items that i'm using okay so uh log base n is actually pretty good speed improvement can i do better it actually turns out the answer is yes and when i first saw this when i was a college student this blew my mind i thought this was the greatest thing ever and so we're going to use a technique called hash tables and hash tables depends on something called a hash function which we'll take a look at in a minute so with the hash table we're going to do is we're going to store all the different items that are going to be in our data set in an array and we're going to give instant access to any item in the array so you know we had to go through each of the individual items using a linear search with the binary search let's put the items in half check the upper versus the lower half split the items in half check the upper half of the lower half split the items in half uh and then if we've got a large list that it's going to be a lot of splits there it's definitely going to be a lot for the linear search for the hash tables we're going to get instant access you tell me what item you want and i'll be like that's exactly where the item is how do we do this it's like magic it's amazing all right so as i mentioned we're going to use something called hash function a hash function is going to create an ordinal number from a more complex item and so our example we're looking at words in a table but this technique can be used for other types of data other than just words okay so i'm going to use a simple hash here this is not necessarily there's a whole science and mathematics to choosing proper hashes and i'm not going to get into it um and i have not studied any of this stuff since i was your age like literally [Music] um 35 years ago 40 years ago it's been a long time okay so uh so we're going to use a simple hash that's easy for everybody to understand what we're going to do is we're going to form our hash by adding all the oral positions of the letters in the word that we are going to place into our data set okay so suppose we have the word cat c is the third letter a is the first letter and t is the 20th letter and so i'm going to go ahead and form my hash by adding those up together i'm going to say 3 plus 1 plus because third letter plus first letter plus 20th letter and add those two together i'm going to say our hash function gives us a 24. now if we've actually got over 24 slots then we're good to go um but if we don't have 24 slots uh we've got a limited number of slots where the hash function can come with larger numbers than the actual number of positions we have which is pretty common i mean in fact in this case uh with cat um you know you can you can make the argument that well uh you know i can i can have 26 characters so it'd be 26 plus 26 plus 26 but that only works if um all of our words have three letters so um anyway so it's pretty common to have hash functions come with numbers that are much larger than the size of the table that you're starting the data in so what we're going to do is we're going to go ahead and perform a modulus you may recall that modulus gives me the integer remainder of dividing something out so i'm going to do is i'm going to take the hash function the value returned by the hash function i'm going to modulus it by the number of slots i have in my table and that's actually where i'm going to go ahead and look up the item so in this particular case suppose we were storing these items in array which has 10 slots um what we're going to do is i'm going to go ahead and take cat which gave me the 3 plus 1 plus 20 is 24 and i need that to fit between 0 and 9 and so i'm going to go ahead and take the 24 and do a modulus on 10 and so again modulus gives me the integer remainder so this is basically saying take 24 divided by 10 that would give you 2 if we were doing integer arithmetic what's the remainder the remainder is four so the modulus is four and so i would go ahead and put cat in the fourth slot in our array here okay so we can do a bunch of these so dog uh d is the fourth letter o is the fifteenth letter and g is the seventh letter and so i go ahead and add those all together that gives me 26. i take the modulus which gives me a six so i would go ahead and place captain slot four and dog and slot six tip uh and these are just three letter words but you can use whatever length word that you want and that'll get you larger and larger numbers potentially but since we're always modulating by 10 it doesn't really matter we're always going to end up with a number between 0 and 9 after we've completed that modulus okay so uh tip t is the 20th letter i is the ninth letter and p is the 16th letter that gives me 45 y just 10. i'm going to go ahead and put that slot 5. now one thing that you may be thinking here is that hey isn't it possible to end up with two items in the same slot absolutely it is so if i've got cat that's 3 plus 1 plus 20 and i've got act that's 1 plus 3 plus 20. those both hash to the same location and so this is called a collision and it's a variety of different techniques that can be used to handle collisions but we're not going to talk about them in this class uh if you have a well chosen hashing function um and if you have a lot of slots it's not a problem and it actually turns out um i haven't studied this but uh but if you study this it turns out that you can have a surprisingly small hash table and still be pretty efficient so you might be thinking well if i've got 50 items and i have a hash table that's a thousand items big enough to store a thousand items and i'm not going to have that many collisions and that is certainly true but it turns out you don't actually need a table that that's all that big in order to not have that many collisions they're kind of surprised by that result okay so we've been talking about using the hash to put items in the table and then of course if you're trying to figure out if an item is in the table as opposed to putting an item into the table you just do the same thing so suppose um i want to look up and see if box is in our table well i go ahead and calculate the hash b is the second letter o is the 15th letter and x is the 24th letter i add them all up that gives me 41. 41 minus 10 is one and then i check if the item is in this given location so i say hey let's go ahead and check item one in our table is that box you know and if there's nothing there uh then i know that box is not in the table if there's something else in slot one well that's the collision thing that we just talked about a minute ago and that has that definitely has some fairly reasonable solutions but uh they're a little complicated so we're not going to describe them in this lecture just be aware that yes hashing functions can cause collisions where two things hash the same location that's tully thing you know if you look at this going hey isn't there something i seem to recall a joke about dog and god uh won't that create a hash clip you know hat same hash value yes it will and there are ways to handle it okay um so how does hash tables compare with linear search and binary search hash tables are much much better it's like i said it's like magic this stuff's amazing so with hash tables whether my table contains 20 items 200 items 200 000 items it still takes the exact same amount of time to determine the items in the table i just go ahead and look at the item that i'm trying to look up i calculated hash function which does not change based on the number of items that are in the table right calculate function you know it'll take longer if the word's a little bit longer but in terms of how many data items i have it doesn't matter how many data items i'm working with i could have a million data items it's still going to take the same amount of time for me to determine the hash for an individual item and then i just you know it's super easy once you have the hash you just like go to a particular item in the array that's pretty much instantaneous so this works super super well um i again i i think it's pretty amazing i was amazed when i saw this when i was when i was a college student which again you know probably says quite a bit about me but i thought it was really really cool i was like wow this is great um anyway so if we want to write a formula for how long it takes to find an item in hash table here it is right here the time to find is just a constant the exact constant varies again depending upon how fast or slow our computer is so in computer science we categorize different algorithms and using what's called o notation so using o notation we'd say that linear search is of n which essentially means that the time it takes to carry out a linear search increases directly with n where n is the number of items in the list binary search is of log n which means that the amount of time to carry out a binary search increases with a logarithm of n and hash tables are of one which means the amount of time to determine if an item is in a hash table is constant and does not change with n let's take a look at the formal definition of uh of n so f of x is o of g of x if there exists constant c and k such that zero is less than or equal to f of n is less than or equal to c of g of n where n is greater than k so the f of x here is the actual performance of our algorithm so that would be for example how much time it actually takes to carry out a binary search and so the g of x in the case of binary search would be log n so i would say the performance of binary search is o of log n because the actual performance of binary search that's the f x is less than or equal to log of n times some constant for n is greater than or equal to k let's take a look at this c and k business here and see what's going on there okay so 0 is less than or equal to f of n is less than or equal to c of g of n that's telling us that what we're looking at here is an upper limit so f of n is the actual performance and g of n is the performance that we're comparing it to so we know that f of n is less than or equal to c of g of n and so if we're not able to find the exact performance but we're able to say hey i know this works better than this other algorithm i know this does better than n squared or i know this does better than n cubed that's good enough for o notation what about that c factor there why is it c of g of n instead of just g of n so that multiplier there that c multiplier there tells us that the amount of time it takes to process an individual item is not important so you know maybe it takes uh 30 seconds for one iteration of binary search and it takes one second for each iteration of linear search and so turns out that means that for small numbers of n the linear search is going to be faster but for large numbers of n the binary search is ultimately going to be much faster let's take a look at how that might work so again assuming 30 seconds for an iteration of binary search one second for an iteration of linear search it turns out that if we have 1025 items and we take log to the base 2 of 1025 i get 10 approximately 10. so this means that if i have around 1025 items on average i'm going to need to do 10 iterations of our binary search if it takes 30 seconds for each iteration of our binary search it's going to take 300 seconds to process all 1025 items or to search if i've got if i need to go to the 2025 items in contrast i said you know linear search only takes one second per iteration but if i have 1025 items i'm going to on average need to do 500 comparisons and that's going to take 500 seconds so what we're seeing here is sure for small n that 30 seconds per iteration on the binary search is going to make a big difference if i've got five items in the list and it takes 30 seconds for iteration of binary search if i only had to do single iteration i'm already in trouble but as n gets larger and larger and larger the fact that a single iteration takes a lot more time is a lot less important than the total number of iterations i need to do so that's what that c factor and they're saying it's saying i don't care if it's a constant difference in terms of the amount of time per iteration i really care about the the amount of iterations all right what about that uh n is greater than equal to k so what that's talking about is startup time so again it's possible for small numbers of items that the initial startup time is gonna to swamp the actual time in order to process each of the individual items so let's say it takes a minute for our binary search to get started whereas the linear search starts automatically maybe there's some setup stuff i need to do for the binary search i need to set up some data structures in order to do the binary search for small numbers of n this could mean that the binary search is not the right way to go but as my numbers get larger and larger you know if i'm processing a thousand items does that one minute startup time make a difference if i'm processing 10 000 items is that one minute of start make a difference by processing a hundred thousand items at some point the better algorithm the algorithm with the better o notation is going to win out over the algorithm that has a smaller setup time but ends up having many many more iterations of uh processing that it needs to carry out so that's the basic idea here behind o notation so we're saying is first of all we're saying that this is the a upper end on the performance that the performance of our algorithm might actually be better than the stated o notation uh we'll talk about that in a little bit later there's some other related notations that tighten that up i'm saying that it doesn't matter how long it takes on a particular iteration and i'm saying it doesn't matter how much startup time there is that ultimately for large numbers of items the o notation is going to to the the type of o notation will overwhelm these other factors uh regardless of the startup time regardless of the amount of uh time in each iteration ultimately the big winner is going to be the number of iterations and that's what o notation is measuring okay so here are some common authentications here uh along with their names of one is what we refer to as constant so that's without like we say with the hash table doesn't matter how many times uh you know it doesn't matter how many items i'm processing uh it's always going to take the same amount of time of login that's logarithmic and we saw that with our binary search uh logarithmic is great great uh no notations if you've got a algorithm that works on o of login that's a good algorithm of n that's linear uh of and log n um that's okay it's going to kind of depend upon the particular algorithm we're using so if we're doing a sorting algorithm of n log n that's pretty good of n squared that's quadratic that's bad and of 2 to the n that's exponential and that's pretty much like you might as well just give up that that's not going to be able to finish in any reasonable amount of time for any reasonable amount of items all right so let's take a look at some related notations um okay so we're using o notation or we've been talking about oh notation that's actually the most common way to talk about these algorithms and as we've seen oh notation says our algorithm is equal to or better than the given notation so if i say it's o of n squared that means it's it's no worse than n squared and it might actually be a bit better than n squared there's also big omega notation and that means our algorithm is equal to or worse than a given formula so you know if i say something is big omega n squared that means we know we aren't better than n squared but we actually might be worse and then there's big theta notation which means our algorithm is exactly equal to the given form why do we have these it's because when we're trying to analyze a particular algorithm it's not always obvious exactly what the big theta notation is but you know we can often find either an upper bound or a lower bound also when we're talking about o notation typically we're talking about time but we could also be talking about space so usually i'm saying as the number of items increases how much time is this going to take to process but i might actually be saying as the number of items increases some algorithms require some extra space in addition to the space actually used to store those items and so how does that space complexity increase and in fact we will find that there's often a time space trade-off where i can process something quickly but it requires a lot of space or i can process something in a small amount of space but it's going to take a lot more time merge sort is an example of something where the time and space complexities change and so merge sort actually has pretty good time complexity to sort all the items in a list but it actually turns out in contrast to most of the sorting algorithms where we can go ahead and sort the items in their original location so it turns out that merge sort is going to need some additional space in order to sort the individual items so when considering whether or not to use merge store you need to consider both the amount of time it's going to take and the fact that it is going to require some extra space and we should also be concerned with average case versus worst case performance in general the most important thing to be concerned with is average case but if you start worrying about what the worst case performance is this is useful both you know if you want to make absolutely sure that this this performance doesn't start dropping off well how's this going to perform in the worst case it also turns out that analyzing the worst case performance can lead to some tweaks in the algorithm to avoid ever running into that worst case so probably one of the better examples of this is quick sort so quick start is on average one of the best sorting algorithms that's out there on average just gets us of m log n performance however if the list is already sorted it actually turns out that the performance of quickstart is actually much worse it gives us of n squared performance and so there's different games that people play in order to ensure that the list that quickstart is using is not in fact already sorted and it is sorted they kind of tweak the list around a little bit to make it no longer completely sorted and that uh reverts quick start back to uh having close and login performance all right that's it for our analysis of algorithms next we're going to take a look at what are called undecidable problems i'll talk to you soon