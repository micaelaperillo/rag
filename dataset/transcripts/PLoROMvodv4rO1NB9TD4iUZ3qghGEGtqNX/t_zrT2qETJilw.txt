okay so let's get started with the actual technical content so remember from last time we gave an overview of the class we talked about different types of models that we're going to explore reflex models state based models variable based models and logic models which we'll see throughout the course but underlying all of this is you know machine learning because machine learning is what allows you to take data and tune the parameters of the model so you don't have to work as hard designing the model so in this lecture I'm gonna start with the simplest of the models of reflex based models and show how machine learning can be applied to these type of models and throughout the class we're going to talk about different types of models on how learning well help with those as well so there's going to be three parts we're going to talk about linear predictors which includes classification and regression loss minimization which is basically saving objective function of how you want to train your machine learning model and then sarcasstik gradient descent which is an algorithm that allows you to actually do the work so let's start with perhaps the most cliched example of you know machine learning so you have we want to do spam classifications so the input is X an email message and you want to know whether an email message is a spam or not spam so we're going to denote the output of the classifier to be Y which is in this case either spam or not spam and our goal is to produce a predictor F right so a predictor in general is going to be of a function that map's some input X to some output Y in this case it's going to take an email message and map it to whether the email message is spam or not okay so there's many types of prediction problems binary classification is the simplest one where the output is one of two possibilities either yes or no and we're gonna usually denote this as plus 1 or minus 1 sometimes you also see 1 & 0 there's regression where you're trying to predict a numerical value for example let's say housing price there's a multi-class classification where why is not just two items but possibly 100 items maybe cat dog truck tree and different categories there's ranking where the output is a permutation of input this could be useful for example if the input is a set of articles or products or webpages and you want to rank them in some order to show to a user structured prediction is where why the output is an object that is much more complicated perhaps it's a whole sentence or even an image and it's something that you have to kind of construct you have to build this thing from scratch it's not just a labeling and there's many more types of prediction problems but underlying all of this you know whenever if someone says I'm gonna do machine learning the first question you ask is okay what's the data because without data there's no learning so we're gonna call an example XY pair is something that specifies what the output should be when the input is X okay and a training data or a set of examples so the training set is going to be simply a list or multi set of examples so you can think about this as a partial specification of behavior so remember we're trying to design a system that has certain certain types of behaviors and we're going to show you examples of what that system should do if I have some email message that has C just 221 then it's not spam but if it has lots of dollar signs then it might be spam and so remember this is not a full specification behavior these are ten examples or even a million examples might not tell you what exactly this function is supposed to do it's just examples of what the function could do on those particular examples okay so once you have this data so we're gonna use d-train to denote the data set remember it's a set of input-output pairs we're going to push this into a learning algorithm or a learner and what is the learning algorithm going to produce it's going to produce a predictor so the predictors are F and the predictor remember is what it's actually itself a function that takes an input X and maps it to an output Y okay so there's kind of two levels here and you can understand this in terms of the modeling inference learning paradigm so modeling is about the question of what should the types of predictors after you should consider our inferences about how do you compute Y given X and learning is about how you take data and produce a predictor so that you can do inference okay any questions about this so far so this is pretty high-level and abstracted in generic right now and this is kind of kind of on purpose because I want to highlight how general machine learning is before going into the specifics of linear predictors right so this is an abstract framework okay so let's dig in a little bit to this actual an actual problem so just to simplify the email problem let's consider a task of predicting whether a string is an email address or not okay so the input is an email is a string and the output is it's a binary classification problem it's either one if it's an email or minus one if it's not that's where you want so the first step of doing linear prediction is known as feature extraction and the question you should ask yourself is what properties of the input ax might be relevant for predicting the output Y right so I say a really high line might be right at this point you're not trying to encode the actual set of rules that solves the problem that would you know involve no learning that would just be trying to do it directly but instead for learning you're kind of taking a you know more of a backseat and you're saying well here are some hints that could help you okay so formally a feature extractor takes an input and outputs a set of feature named feature you pears right so I'll go through an example here so fi of ABC at gmail.com what are the properties that might be useful for determining whether a string is an email address or not well you might consider the life of the string if it's greater than 10 maybe long strings are less likely to be email addresses and shorter ones and here the feature name is length greater than 10 so that's just kind of label of that feature and the value of that feature is one representing its true so it would be 0 if it's false there's another feature the fraction of alphanumeric characters right so that happens to be 0.85 which is the number there might be features that test for particular you know letters for example there's a container at sign well that as you know feature value of 1 because there is an @ sign and without com is 1 and without org is 0 because that's not true so and there you could have many many more features we'll talk more about features on next time but the point is that you have a set of properties you're kind of distilling down this input which is could be a string it could be an image or could be something more complicated into kind of you know ground-up fashion that later we'll see how a machine learning algorithm can take advantage of ok so you have this feature vector which has is a list of feature values and their associated names or labels ok but later we'll see that the names don't matter to the learning algorithm so actually what you should also think about the feature vector is simply a list of numbers and just kind of on the side make a note that oh this you know a position number 3 corresponds to contains at and so on right so I've distilled the the email address ABC at gmail.com into the list of numbers 0 or 1 0.85 1 1 0 ok so that's a feature extraction it's kind of distilling complex objects into lists of numbers which we'll see is what the kind of the lingua franca of these machine learning algorithm says okay so I'm gonna write some concepts on the board there's gonna be a bunch of concepts I'm gonna introduce and now just keep them up on the board for reference so feature vector is a kind of important notion and it's denoted fee of X on input Sophy itself sometimes you think about you call it the feature map which takes an input and returns a vector and this notation means that it returns in general d dimensional vector so a list of D numbers and the components of this feature vector we can write down as v1 v2 all the way to feed B of X okay so this notation is your convenient because we're going to start shifting our focus from thinking about the features as properties of input to features as kind of mathematical objects so in particular fee of X is a point in a high dimensional space so if you have two features that would be a point in two dimensional space but in general you might have a million features so that's a feature it's a point enough 100 a million dimensional space so it might be hard to think about that space but well we'll see how we can you know deal without it you know later in a bit okay so so that's a feature vector you take an input and return a list of numbers okay and now the second piece is a weight vector so let me write down weight vector so a weight vector is going to be noted W and this is also a list of D numbers it's a point in a d-dimensional space buddy that we're gonna interpret it differently as we'll see you later okay so so way to think about a way to factor is that for each feature J so for example frac of alpha we're gonna have a real number WJ that represents the contribution of that feature to the prediction so this contribution is 0.6 so what does this cut point 6 mean so so the way to think about is that you have your weight vector and you have a feature vector of a particular input and you want the score of your prediction is going to be the dot product between the wave vector and the feature vector okay so that's written W dot a fee of X which is written out as basically looking at all the features and multiplying the feature value times the weight of that feature and summing up all those numbers so for this example it would be minus 1.2 that's the weight of the first feature times 1 that's the feature value plus 0.6 times point a 5 and so on and you know you get this number of four points five one which is happens to be the score for this example question is that supposed to be like an automated process or yeah so the question is is the feature extraction manual or automatic so a fee is going to be implemented as a function like in code right you're going to write this function manually but you know the function itself is run automatically on examples later we'll see how you can actually learn features as well so you can slowly start to do less of the manual effort but we're gonna hold off until next time for that question yeah so the question is about interpretation of weights sometimes weights can have a more precise meaning in general you can you can try to read the tea leaves but it's I don't think there is maybe in general mathematically precise thing you can say about the meaning of individual weights but intuitively and the intuition is important is that you should think about each feature as you know a little person that's gonna make a vote on this prediction right so you're moaning either plus yay or nay and the weight of a particular feature is specifies both the direction of though whether if positive weight means that that little person is voting positive and negative weight means that it's really negative and the magnitude of that weight is how strongly that little person feels about the prediction right so you know contains ad is 3 because maybe like at signs generally do occur in email addresses but you know the fraction of alphanumeric characters it's you know plus so at that level you can have some intuition but the precise numbers and why is 0.6 versus 4.5 that's you can't really say much about that yeah question keep your networks they can feel like or weight vectors afterwards it's still like like so right now we're focusing on linear classifiers so the question is what happens if you have neural net with more layers there's going to be more dot products but there's also good it's not just adding more features there's going to be other components which we'll get to in a later lecture yeah yeah so the question is do the weights have to add up to something their short answer is no there's obviously restricted settings where you might want to normalize the weights or something but we're not gonna you know consider that right now um later we'll see that the magnitude of weight does tell you you know something okay so so just to summarize it's important to note that the the wave vector there's only one wave vector right you have to find one set of parameters for every everybody but the feature vector is per example so for every employee you get a new feature vector so and the dot product of those two weighted combination features is this as a score okay so so now let's try to put the pieces together and define of the actual predictor all right so remember we have this a box with an F in it which takes X and returns Y so what is inside that box and I've hopefully given you some intuition let me go to a board and write a few more things so the score remember is W dot V of X and this is just going to be a number and the predictor so linear predictor well actually let me call this linear to be more precise it's a clean your classifier not just a predictor classifier is just a predictor that does classification so a linear classifier denoted F of W so f is what we're going to use to know predictors W just means that this predictor depends on a particular set of weights and this predictor is going to look at the score and return the sign of that score so what is a sign the sign looks at the score and says is it a positive a number if it's positive then we're going to return plus one if it's a negative number I'm going to return minus one and if it's zero then you know I don't care you can return plus one if you want it doesn't matter so what this is doing you remember this the score is either is a real number so it's either going to be like kind of leaning towards you know large value large positive values are leaning towards us large small negative values and the sign basically says okay you got to commit are you which side are you on are you on the positive side are you on the negative side and just kind of discretize it that's what the sign does okay okay so so let's look at a simple example because I think a lot of what I've said before is kind of more the formal machinery behind and the math behind how it works but it's really useful to have some geometric intuition because then you can draw some pictures okay so let's consider this case so we have a wave vector which is 2 1 2 minus 1 and a feature vector which is a 2 0 and another feature vector which is 0 2 + 2 4 ok so there's only two dimensions so I can try to draw them on a board so let's try to do that ok so here is a two-dimensional plot and let's draw the fee or the wave vector first ok so the wave vector is going to be at 2 - 1 okay so that's this point and the way to think about the wave vector is not that point but actually the the vector going from the origin to that point for reasons I'll become clear later ok so that's the that's the weight ok and then what about the other points so we have 2 0 0 2 so 2 0 is here 0 2 is here and 2 4 is here right ok so we have 3 points here ok so how do I think about what this weight vector is is doing so just just for reference remember the classifier is looking at the sign of W dot V of X ok so let's try to do classification on these three points ok so W is let me write alpha 2 1 and this is 0 2 so what's the score when I do W dot V of X here it's 4 right because this is 2 0 2 2 4 so this is just a dot product that's 4 and take the sign what's the sine of 4 1 ok so that means I'm going to label this point as a positive right positive point ok what about 0 2 actually sorry this is just to be a minus 1 right okay this is 2-1 okay so if I take the dot product between this I get minus two and then the sine of minus two is is minus one okay so that's a minus and what about this one so what's the dot product there it's going to be zero okay so so this classifier will classify this point as a positive this is a negative and this one I don't know okay so we can fill in more points but but you know does anyone see kind of maybe a more general pattern I don't want to have to fill in the entire board with classifications yeah yeah so so let's try to draw the orthogonal oh this needs to go through that line okay okay so let's draw the orthogonal so this is a right angle okay and what that gentleman said is that the points any point over here because it has acute angle with W is going to be classified as positive so all this stuff is you know positive positive positive positive and everything over here because that's obtuse angle with the W it's going to be negative so everything over here is negative and then everything on this line is going to be zero okay so so I don't know okay and this line is called the decision boundary which is a concept not just for linear classifiers but whenever you have any sort of classifier that this resume boundary is the separation between the regions of the space where the classification is positive versus negative okay and in this case it's it separates because it's we have linear classifiers the decision boundary is straight and we're just separating the the space into you know two house if you were in three dimensions this vector would still be just a vector but this decision boundary would be a plane so you can think about it as you know coming out of the board if you want but I'm not gonna try to draw that and that's that's kind of the geometric interpretation of how linear classifiers you know work here question yeah yeah so that's a good point so the the observation is that no matter if you scale this weight by two it's actually going to still have the same decision boundaries so the magnitude of the weight doesn't matter it's the direction that matters so this is true for just making a prediction when we look at learning the magnitude of the weight will matter because we're going to you know consider other more nuanced loss functions [Music] okay so let's move on any questions about linear predictors so so far what we've done is we haven't done any learning right if you've you know notice we've just simply defined the set of predictors that we're interested in so we have feature vector we have wave vectors multiplying together get a score and then you can send them through a sine function you get these linear classifiers right there's no specification of data yet okay so now let's actually turn to do some learning so remember this framework learning needs to take some data and return a predictor and our predictors are specified by a weight vector so you can equivalently think about the learning algorithm is outputting a weight vector if you want for linear classifiers and let's unpack the learner so the learning algorithm is going to be based on optimization which we started reviewing last lecture which separates what you want to compute from how you want to compute it so we're going to first define an optimization problem which is specifies what properties we want a classifier to have in terms of the data and then we're going to figure out how to actually optimize this and this modularity is actually really really powerful yes and it allows people to go ahead and work on different types of criteria for and different types of models separately from the people who actually develop general-purpose algorithms and this has served to kind of the field of machine learning quite well okay so let's start with optimization problem so there's an important concept call it a loss function and this is a super general idea that's using the machine learning statistics so a loss function takes a particular example X Y and a weight vector and returns a number and this is the reading number represents how unhappy we would be if we use the predictor given by W to make a prediction on X when the correct output is y okay so it's a little bit of a mouthful but this basically is trying to characterize you know if you handed me a classifier and I go on to this example and try to classify it is it going to get a ride or is it gonna get it wrong so high loss is bad you don't want to lose and low loss is good so normally zero loss is the the best you can kind of hope for okay so let's do figure out the loss function for binary classification here so just some notation the correct label is denoted Y and the predicted label remember is the score sent through the sine function and that's going to give you some a particularly Bowl and let's look at this example so W equals to minus one fee of x equals to zero and y equals minus one okay so we already defined the score as on example is w of X which is how confident we're predicting Maya plus one that's a way to interpret this okay so what's the score of this for this particular example again it's 4 right which means that you know we're kind of kind of positive that it's you know a plus one yeah question [Music] or the output yeah so the question is whether the output of loss function is usually a single and number or not in most cases it is for basically all practical cases and you should think about the loss functions out bringing in a single number the inputs can be you know crazy high dimensional yeah there are cases where you might have multiple objectives that you're trying to optimize at once but in this class it's always going to be you know one dimensional like maybe you care about you know both time and space or accuracy but robustness or something sometimes you have multi objective optimization but that's the psych way beyond the scope of this class okay so we have a score and now we're gonna define margin so let me okay so let's let's actually do this so we're talking about classification I'm gonna sneak regression in in a bit so score is W of X this is how confident we are about +1 and the margin is the score times y and this relies on Y being plus one or minus one so this might seem a little bit mysterious but let's try to you know decipher that here so in this example the score is four so what's the margin you multiply by -1 so the margin is minus four right and the margins interpretation is how correct we are right so imagine the correct answer is if if the score in the margin have the same sign then you're gonna get positive numbers and then the the confident the more confident you are then the more correct you are but if Y is -1 and the score is positive then the margin is gonna be negative which means that you're going to be confidently wrong which is bad okay so just to see if we kind of understand what's going on so when does a binary classifier making mistake on a given example so I'm gonna ask for a kind of a show of hands how many people think gets its when the margin is less than zero okay I guess we can kind of stop there I used to do these online quizzes where it was an anonymous but we're not doing that this year okay so yes the margin is less than 0 when the margin is less than zero that means Y and the score are different signs which means that you're making a mistake okay so now we have the notion of a margin let's define something called the zero of one loss and it's called zero one because it returns either a zero or one very creative so the loss function is simply did you make a mistake or not okay so this notation let's try to tie for a bit so if f of X here is the prediction when the input is X and not equal Y is saying did you make a mistake so that's think about it as a boolean and this one bracket is just notation it's called an indicator function that takes a condition and returns either 1 or 0 so if if the condition is true then it's going to return a 1 and the condition is false it returns okay so all this is doing is basically returning a one if you made a mistake and 0 if you didn't make a mistake okay and we can write that as follows we can write that as the margin less or equal to zero right because on the previous slide if the margin is less than zero then we've made a mistake and we should incur a loss of one and if the margin is greater than zero then we didn't make a mistake and we should we concur a loss of zero okay all right so it will be useful to draw these loss functions pictorially like this okay so on the access x-axis here we're going to show the margin right remember the margin is how correct you are and on the y-axis we're going to show the the loss function which is how much you're going to suffer for it okay so remember the margin if the margin is positive that means you're getting a right which means that the loss is zero but if the margin is less than zero that means you're getting it wrong and the losses one okay so this is a zero one loss that's the this thing the visual that you should have in mind when you think about your loss yeah yeah so there's this kind of boundary condition of one X what happens exactly at zero that I'm trying to sweep under the rug because it's not terribly important here it's less we go to zero to be kind of on the safe side so if you don't know you're also going to get it wrong otherwise you could always just return zero and then do be that that's you don't want that okay so is it any questions about kind of binary classification so far so we've set up these linear predictors and I've defined the zero and loss as a way to capture how unhappy we would be if we had a classifier that was operating on a particular data point X Y so just as I'm gonna go on a little bit of a digression and talk about linear regression and and the reason I'm doing this is that lots minimization is such a powerful in general framework and it transcends you know all of these you know linear classifiers regression setups so I want to kind of emphasize the overall of an overall story so I'm gonna give you a bunch of different examples classification regression side by side so we can actually see how they compare and hopefully they're the common denominator will kind of emerge more clearly from that ok so we talked a little bit about linear regression in the last lecture right so linear regression in some sense is simpler than the classification because if you have a linear predictor and you get to score W dot V of X it's already a real number so in linear regression you simply return that real number and you call that your prediction okay okay so now we let's move towards to find your loss function so there's going to be a concept that's going to be useful it's called the residual which is against kind of trying to capture how wrong you are so here is a particular linear predictor linear regressor and it's making predictions all along you know for different values of X and here's the data point of fear of X Y okay so the residual is the difference between the true value Y and the predictive value Y okay and in particular it's the amount by which the prediction is overshooting you know the target okay so this is this is a difference and if you square the difference you get something called the squared loss so this is something we mentioned last lecture residual can be either negative or positive but errors either if you're very positive or very negative that's bad and squaring a mixer so that you're gonna you know suffer equally for errors in both directions okay so the square loss is the residual squared so let's do this kind of simple example so here we have our wave vector 2 minus 1 the feature vector is to 0 what's the score it's for y is million minus 1 so the residual is 4 minus minus 1 which is 5 and it's 5 squared is 25 so the squared loss on this particular example is 25 okay so let's plot this so just like we did it for a zero on loss so let's see what this loss function looks like so the the horizontal axis here instead of being the margin is going to be this quantity for regression called the residual it's going to be the difference between the prediction and the true target and I'm gonna plot the loss function and this loss function is just you know the squared function right so with if the residual is zero then the loss is zero if as the residual grows in either direction then I'm going to pay something for it and it's a quadratic penalty which means that it actually grows you know pretty fast so if I'm you know the residual is 10 then paying a hundred okay so so that's the squared loss there's also another loss I'll throw in here called the absolute deviation loss and this might actually be the last day if you didn't know about regression you might immediately come to it's basically the absolute difference between the prediction and the actual true target turns out the squared loss there's a kind of a longer discussion about you know which loss function you know makes sense the the salient points here are that the absolute deviation loss is kind of has this kink here and so it's not smooth sometimes it makes it harder to optimize but the square loss also has this kind of thing that blows up which means that it's it really doesn't like having outliers or really large values because it's going to you're gonna pay a lot for it but at this level just think about this as you know different losses there's also something called the hueber loss which a kind of combines both of these is smooth and also grows linearly instead of quadratically okay so we have both classification um regression we can define margins and residuals we get either different loss functions out of it right and now we want to minimize the loss okay so it turns out that for one example this is really easy right so if I if I told you okay how do I minimize the loss here well okay it's zero done so that's not super interesting and this corresponds to the fact that you know if you have a classifier you trust trying to fit at one point it's really not that hard so that's kind of not the point the point of machine learning is that you have to fit all of them remember you only get one one weight vector you have all these examples you have a million examples you want to find one weight vector that kind of balances errors across all of them and in general you might not be able to achieve loss of zero right so tough lanka life is hard so you have to make trade-offs you know which examples are you going to kind of sacrifice for the good of other examples and this is actually a lot of where you know issues around fairness of machine learning actually come in because in cases where you can't actually make a prediction that's you know equally good for everyone you know how do you actually you know responsibly make these trade-offs but you know that's a that's a broader topic let's just focus on trade-offs defined by the simple sum over all the last example so let's just say we want to minimize the average loss over all the examples okay so once we have these loss functions if you averaged over the training set you get something which we're going to call the trained loss and that's a function of W right so a loss is on a particular example of train losses on the entire data set [Music] okay so any questions about this so far [Music] okay so there is this discussion about which regression loss to use which I'm going to skip you can feel free to read into the notes if you're interested the punchline is that if you want things that look like the mean square loss if you want things that look like the media and use the absolute deviation loss but I'll skip that for now yeah when do people start thinking of regressions like in terms of loss minimization so regression has least squares regression is from like the early 1800s so it's been around for is you know kind of you could call it the first machine learning that was ever done if you if you want I guess the loss minimization framework is it's hard to kind of pinpoint a particular point in time you know it's it's kind of not a terribly you know it's not like a you know innovation in some sense it's just more of a at least right now it's kind of a pedagogical tool to organize all the different methods that exist yeah do you mean that like in that particular training training set the median work even highest I casinos confident whereas like yeah so um I don't want to get into this examples but briefly if you have three points that you you can't exactly fit perfectly you if you use absolute deviation then you're gonna find the median value you're gonna basically predict the median value and if you use the square laws you're going to predict the mean value but I'm happy to talk offline okay so what we've talked about so far is we have these wonderful linear predictors which are driven by feature vectors and weight vectors and now we can define a bunch of different loss functions that capture you know how we care about you know regression and classification and now let's try to actually do some real machine learning how do you actually optimize these objectives so remember the learner is going so now we've talked about the optimization problem which is minimizing the training loss we'll come back to that next lecture and then now we're going to talk about home to my suggestion algorithm okay so what is the optimization problem now remember last time we said okay let's just abstract away from the details a little bit let's not worry about if it's the square loss or you know some other loss let's just think about as they're kind of abstract function so in one dimension the training loss might look something like this you have a single weight and for each weight you have a number which is your loss on your training examples okay and you want to find this point so in two dimensions it looks something like this and let me try and actually draw this because I think you'll be useful [Music] okay so in two dimensions what optimization looks like is this follow so I'm going to I'm now plotting [Music] w1 and w2 which are the two components of this two-dimensional weight vector so for every point I have a weight vector and that value is going to be the loss of the training loss and it's it's pretty standard in these settings to draw what are called level curves so let's do this so each curve here is a ring of points where the function value is identical so if you look at turning maps those are level curves so you know kind of what I'm talking about so this is the minimum and as you kind of grow out you get larger and larger okay I'll keep on doing this for a little bit okay all right and the goal is to find the minimum okay all right so how are we gonna do this so yeah question yeah why am i assuming there is a single minimum in general for arbitrary loss functions there's no necessary a single minimum I'm just doing this for simplicity it turns out to be true for you know many of these linear classifiers okay so last time we talked about gradient descent right and the idea behind gradient descent is that well I don't know where this is so let's just start at zero as good as any place and what I'm going to do at zero is I'm going to compute the gradient so the gradient is this vector that's perpendicular to the level curves so the gradients is going to point in this direction that says hey in this direction is where the function is increasing the most dramatically and gradient ascent says take some it goes in the opposite direction right because remember we want to minimize loss so I'm gonna go here and now I'm hopefully reduce my function value not necessarily but we hope that's that's a case now we compute the granny again the Iranian says you know maybe it's pointing this way so I go in that direction and maybe now it's pointing this way and I keep on going this is a little bit made-up but hopefully eventually I get to the Georgian and you know I'm I'm kind of simplifying things quite a bit here so in there's a whole field of optimization that studies exactly what kind of functions you can optimize and how gradient descent when it works and when it doesn't I'm just going to kind of go through the mechanics now and differ that kind of the formal proofs of when this actually works until later okay so that's kind of the the schema of how great descent works so in code this looks like this so initialized at zero and then lupine some number of iterations which let's for simplicity just think there's a fixed number of iterations and then I'm gonna pick up my weights compute the gradient move in the opposite direction and then there's going to be a step size that tells me how fast I want to you know make progress okay and we'll come back to you know what the step size does later okay so let's specialize it to least squares regression so we kind of did this last week but just to kind of review so the training loss for least squares every question is this so remember it's an average over the loss of individual examples and the loss of a particular example is the residual squared so that's this expression and then all we have to do is compute the gradient and you know if you remember your calculus it's just I've use a chain rule so this two comes down here you have the you know the residual times the derivative of what's inside here and the gradient with respect to W is fee of X okay so last time we did this in Python in one dimension so in one dimension hopefully all of you should feel comfortable doing this because this is just kind of basic calculus here we have W is a vector so we're not taking derivatives but we're taking gradients so there's you know some things to be wary of but in this case it's often kind of useful to double check that well the gradient version actually matches the the single dimensional version and you know as well because last time remember we have X out here and one thing to know here is that there's a prediction - target that's a residual so the gradient is driven by you know the kind of this quantity so if the prediction equals the target what's a gradient it's going to be zero which is kind of what you want if you're already getting the answer correct then you shouldn't want to move your your weights right so often you know we can do things in the abstract and everything will work but you know it's it's often a good idea to write down some objective functions take the gradient and see if gradient descent on using these gradients that you computed is kind of a sensible thing because there's kind of many layers you can understand and get intuition for this stuff as a kind of abstract level optimization or kind of add the algorithmic level like you pick up an example is it sensible to update when the gradient or then when the prediction equals to target okay so so let's take the code that we from how from last time and I'm going to expand on it a little bit and hopefully set the stage for doing stochastic gradient okay so so last time we had gradient descent okay so remember last time we define a set of points we define the function which is the trained loss here we define the derivative of the function and then we have great at descent okay so I'm gonna do a little bit of housecleaning just don't mind me okay so I'm gonna make this a little bit more explicit what this algorithm is Green descent depends on a function a derivative function and let's say you know the dimensionality and I can call this gradient with FTF and in this case it's D where D equals two okay you know I want to kind of separate this is that kind of algorithms and this is you know modeling so this is what we want to compute and this is you know how we compute it okay and this code should still work okay all right so what I'm gonna do now is upgrade this to vector strong remember the executor is just a number right well we want to support vectors so in Python we're gonna import numpy so which is nice vector and matrix library and I'm gonna make some you know arrays here which and this is just going to be a one-dimensional array so it's not that exciting so this this WX becomes the actual dot on you to call and I think and W it needs to be emptied our zeros okay alright so that should still run actually sorry this just one-dimensional okay so remember last time we ran this this program and it starts out with some weights and then it converges to 0.8 and the function value kind of keeps on going down okay all right so let's let's try to you know it's really hard to kind of see whether this algorithm is any doing anything interesting because we only have two points it's kind of trivial so how do we go about you know because I'm gonna also implements cassock radius and how do we have kind of a test case to see if this algorithm is you're working so there's kind of this technique which I really like and it's you know which is to call you know generate artificial data and idea is that you know what is learning you're learning is you're taking a data set and you're trying to fit find the weights that best fit that data set but in general if I generate some are below the dais I have no idea what the right kind of quote unquote right answer is so this I think where I go backwards I say okay let's let's decide what the right answer is so let's say the right answer is in one two three four five so it's a five dimensional problem okay and I'm gonna generate some data based on that so that this weight vector is kind of good for that data I'm gonna skip all my breaks in this lecture so I'm gonna generate a bunch of points so let's stare at 10,000 points the nice thing about artificial data is you can generate as much as you want there's a question yeah oh so true W just means like the correct the ground truth W so W is a weight vector so this kind of going backwards remember I want to fit the way back here but I'm just kind of saying this is the right answer so I want to make sure that the algorithm actually recovers okay so I'm gonna generate some random dude up so there's a nice function random dot R and n which generates a random D dimensional vector and why I'm going to set Y which I said Y to yeah so so I'm gonna do regression so I want to do true W dot X right so I mean if you think about it if I took this data and I found it like true why W is the right thing that will get 0 lies here ok but I'm gonna make life a little bit more interesting and we're gonna add some noise okay so let's print out what that looks like also I should add it to my data set so okay so this is my data set okay I mean can't really tell what's going on but but you can look at the code and you you can assure yourself that this data has structure in it okay so let's get rid of this print statement and let's train and see what happens so let's okay oh one thing I forgot to do so if you notice that the objective functions that I've you're in down they haven't divided by the number of data points I want the average lost not the song it turns out that you know if you have the Sun then things get really big and blow up so we just normalize that okay so okay so it's training its training actually so let me do more iterations so I did 100 iterations let's do a thousand iterations okay so you know the function values going down that's always something to know good to check and you can see the weights are kind of slowly getting to you know what appears to be one two three four or five right okay so you know this is a hard proof but it's kind of evidence that this learning algorithm is actually kind of doing the right thing okay so now let's see if I add you know more points so I now have a hundred thousand points now it gets slower and you'll know hopefully I get there one day but I'm just gonna kill it okay any questions about its right terminal got screwed up okay so what I do here I define loss functions took the derivatives the gradient descent is what we implemented last time and the only thing different I did this time is generating a data set so I can kind of check whether grading descent is working yeah question the question is whether the fact that the cranium is a residual allows their algorithm to learn from under over predictions yeah so the gradient is if you think about it yeah that's good intuition so if you look at if you're over predicting right that means the gradients kind of assumed that this is like one so that means this is going to be positive which means that hey if you up that weight you're gonna over predict more and more incur more loss so my subtracting the gradient you're kind of pushing the weights out in the other direction and same for when you're under predicting yeah so that's good intuition to have yeah what is the effect of the noise the effect of noise it makes the problem of a little bit you know harder so that it takes more examples to learn if you shut off the noise then it will you know we can try it I have never done this before but presumably you'll learn you know faster but maybe not the noise doesn't you know that much okay so so let's say you have you know like five hundred examine examples you know that's quite a few examples NL you know this algorithm runs you know pretty slowly right and in modern machine learning you have you know millions a hundred millions of examples so grain descent is gonna be you know pretty slow so how can we speed things up a lot of that and what's the problem here well if you look at the the what the algorithm is doing its iterating and each iteration its computing the grading of the training loss and the training loss is just average of all the points which means that you have to go through all the points and compute there your law grading of the loss and you add everything up and that's what is expensive and you know takes time so you know you might wonder well how can you avoid this I mean you if you wanted to create a send you have to go through all your points and the the key insight behind stochastic gradient sent is that well maybe maybe you don't have to do that so maybe you know here here's some intuition right so what what is this gradient so this gradient is actually the sum of all the gradients from all the examples in your training center right so you have 500,000 points adding to that so actually what this gradient is is it's actually kind of sum of different things which are may be pointing in slightly different directions which all averaged out to this direction okay so maybe you can actually not average all of them but you can average just a couple or maybe even in an extreme case you can just like take one of them and just you know march in that direction so so here's the idea behind stochastic gradient descent so instead of doing gradient descent we're gonna change the algorithm to say for each example in the training set I'm just gonna pick it up and just update you know it's instead of like sitting down and looking all over all the training samples and thinking really hard I'm just gonna pick up one training example and update right away so we're kind of the key idea here it's it's not about quality it's about quantity maybe not the world's best life lesson but it seems to work in it work in here and then there's also this question of watch - the step size B and in generally in stochastic gradient is and it's actually even a bit more important because when you're updating on into each individual example you're getting kind of noisy estimates of their actual gradient and and people often ask me like oh how should I set my step size and you know and the answer is like there is no formula I mean there are formulas but there's no kind of definitive answer here's some general guidance so if step size is small sorry really close to zero that means you're taking tiny steps right that means that it'll take longer to get where you want to go but you're kind of proceeding cautiously so you it's less likely you're gonna you know if you mess up and go in the wrong direction you're not gonna go too far in the wrong direction conversely if you have a to be really really large then you you know it's like a racecar you kind of drive really fast but you might just kind of bounce around a lot so pictorially what I'm this looks like is that you know here's maybe a moderate step size but if you're taking steps really big steps you know you might go over here and then you jump around and then maybe maybe you ran up in the right place but maybe sometimes you can actually get flung off out of orbit and you know diverse infinity which is a bad situation so there's many ways to set the step size you can send it to our you know constant you could usually have to you know tune it or you can set it to be decreasing the intuition being that as you optimize and get closer to the optimum you kind of want to slow down right like if you you're coming on a freeway you're driving really fast but once you get to your house you probably don't want to be like driving 60 miles an hour okay so actually I didn't implement stochastic gradient so let me do that so let's let's try to get Tsukasa cranium up and going here okay so so the interface that sarcastic gradient changes so right so do ingredients and all we need is a function and it just kind of computes the sum of all the training examples so sarcastic gradient I'm just no SF for stochastic radio I'm gonna take an index I and I'm going to update on the eighth point only so I'm going to only compute the loss on the ice point and same further its derivative gonna look at the ice point and just compute their grinny on that ice point okay and this should be called STF okay so now instead of doing gradient descent let's do circus a gradient descent I mean I'm gonna pass an SD s FS DF D and the number of points because I need to know how many points there are now copy green new sand and it's basically the same function I'm just gonna stick another for loop in there so stochastic gradient descent it's gonna take this sarcastic functions classic gradient the dimension Audion and okay so now before I was just going through number of iterations and now right I'm not gonna try to compute the value over all the training examples I'm going to loop over all the points and I'm going to call just evaluate the function at that point I it compute the gradient at that point hi instead of the entire dataset and then everything else is the same I mean one other thing I'll do here is that I'll use a different step size schedule so one divided by number of updates so I want its so that the number of the step sizes kind of decrease over time okay so I start with 8 equals 1 and then it's 1/2 and then it's 1/3 and it's 1/4 and it keeps on going down sometimes you can put a square root and that's more typical in some cases but I'm not gonna worry about that details too much question yeah so question is the word stochastic means that there should be some randomness here and you know technically speaking the the sarcastic gradient descent is where you're sampling a random point and then you're updating on it I'm cheating a little bit because I'm iterating over all the points you know in practice if you have a lot of points and you randomize the order it's it kind of you know it's similar but it's yeah there is a kind of a technical difference that I'm trying to hide okay so so this is the Cassegrain descent to iterate you know go over all the points and just you know update okay so let's see if this works okay I don't think that worked maybe hmm let's see what happened here I did try it on a hundred thousand points maybe that works I know that didn't work either and you won't see the problem oh so I'm printing this out at the at the end of each iteration so that should be fine really this should work so gradient descent was working right maybe I'll try it's probably not the best idea to be debugging this live okay let's like to make sure gradient descent works okay so that was working right okay so it's a casick gradient descent I mean it's a bit really fast and converges but it doesn't converge the right answer yeah but that should get incremented to one so that it might be okay so I do have a version of this code that does work so what am I doing here that's different okay have some water maybe I need some like okay so this version works yeah yeah that's that's probably good okay all right now it works thank you um so yeah yeah this is a good a lesson is that when you're dividing this needs to be one actually in Python 3 this is not a problem but I'm so I'm Python 2 for some reason but this should be a 1 point 0 divided by num updates otherwise I was getting okay so why is it yeah okay okay let's let's go back to 500,000 okay okay so one full sweep over the data is the same amount of time but you notice that immediately already converges to 1 2 3 4 5 right so this is like way way faster than gradient descent remember just so you kind of compare gradient descent is you run it and after one step it's like not even close right yeah Breezie what noise levels do you have to have until gradient descent becomes better so it is true that if you have more noise then greatness that might be the category and in SEM can be unstable there might be ways to mitigate that with step size choices but yeah probably you have to add a lot of noise for stochastic rate have to be really bad I mean this isn't some sense you know if you take a step back and think about what's going on is a problem it's a five dimensional problem there's only five numbers and I'm feeding at half a million data points right there aren't there's not that much to learn here and so there's a lot of redundancy in the data set and generally actually this is true like you know large data set there's going to be a lot of you know redundancy so going through all the data and then trying to make an informed decision is you know pretty wasteful where sometimes you can just kind of get a representative sample from one example or more is common to do like kind of mini batches where you maybe grab a hundred examples and you update on that which is so there's a way to somewhere between the category a greater percent okay let me move on okay summary so far we have linear predictors which are based on scores so linear prediction include both classifiers and requesters we can do loss minimization and we can if we implement it correctly we can do SGD okay so that was I'm kind of switching things I hope you're kind of following along I introduced binary classification and then I did all the optimization for linear regression so now let's go back to classification and see if we could do Socastee gradient descent here okay so first classification remember we decided that the zero one loss is the thing we want we want to minimize the number of mistakes you know who can argue with that so remember what does zero one loss look like it looks like this okay so what happens if I try to run stochastic gradient descent on this I mean I could run the code but yeah it's it won't work right and why won't it work yeah so two popular answers are it's not differentiable that's one problem but I think that the the bigger problem is kind of a deeper problem is that what is it what is the gradient zero it's like zero basically everywhere except for at this point which you know it doesn't remember so so as we learned that if you try to update with a grading of zero then you won't move your weights right so the gradient descent will not work on the zero on loss so that's that's kind of unfortunate so how should we fix this problem yeah yeah let's let's make the gradient at zero let's skew things so there's one loss which I'm gonna introduce called the hinge loss which does exactly that so when we write the hinge loss down and the hinge loss is basically is zero here when the margin is greater equal one and rises linearly so if you've gone in a correct by a margin of one so you're kind of pretty safely on the air side of I'm getting it correct then we won't charge you anything but as soon as you start you know dip it into this area we're gonna charge you a kind of a linear amount and your loss is gonna grow linearly so there's some reasons why this is a good idea so it upper bounds the zero and loss it's has a property called known as convexity which means that if you actually run the gradient descent you're actually going to converge through the global optimum I'm not going to get into that and so that's you know that's a hinge loss so what remains to be done is to compute the gradient of this your hinge loss okay so how do you compute this gradient so in some sense it's a trick question because the gradient doesn't exist because it's not differentiable everywhere but we're gonna pretend that little point doesn't exist okay so so what is this hinge loss the hinge loss is actually two functions right there's a zero function here and then there's like this one minus x function so what am i plotting here I'm plotting them with the margin and the loss okay so this is the zero function and this is a 1 minus W dot V of X 1 and the hinge loss is just the maximum of these two function so at every point I'm just taking the top function so that's how I'm able to trace out this this car ok all right so if I want to take the gradient of this function you know you can try to do the math but let's think through it you know what what should the gradient be well if we're here what should the gradient be its 0 and if I'm here what should agree everything it should be the whatever the grading of this function is right so in general when you have a grading of of this kind of Max you have to kind of break it up into cases and depending on where you are you you have a different case so loss is equal to if I'm over here and what's the condition for being over here if the margin is greater than 1 right and then otherwise I'm going to take the gradient of this with respect to W which is going to be minus V of X Y you know otherwise [Music] so again we can try to interpret the gradient of the hinge laws so remember you in stochastic gradient descent you have a wave vector and you're gonna pick up an example and you say oh let's compute the gradient move away from it so if you're getting an example right then the gray in zero don't move which is the right thing to do and otherwise you're going to move in the direction because you're minus minus of V of X Y which kind of imprints this example into your wave vector so and you can formally show that it actually increases your margin after you do this okay yeah what's the significance of the margin being one this is a little bit arbitrary you just kind of sending on nonzero value and and you know in support vector machines you set it to 1 and then you have regularization on the weights and that gives you some interpretation so I don't have time to go over that right now but feel free to ask me later there's another flossed function do you have a question yeah so why do you choose the margin so in classification we're going to look at the margin because that tells you how confidently you're predicting correctly in regression you're gonna look at residuals and square losses so it depends on the kind of what problems you're trying to solve just really quickly some of you might have heard of logistic regression logistic regression is this yellow loss function right so the point of this is saying that this loss minimization framework is you know really general and a lot of things that you might have heard of least squares let's just regression aren't kind of special cases of this so if you kind of master how they do lots of an organization you kind of can do at all ok so summary basically what's on the board here if you're doing classification you take the score which comes from W of X and you drive it into the sign and then you get either plus 1 or minus 1 regression you just use a score now to train you have to assess how well you're doing classification there's the notion of a margin in regression it's the residual and then you can define loss functions and here's we only talk about five loss functions but there's many others especially for a kind of structure prediction or ranking problems there's all sorts of different loss functions but they're kind of based on these simple ideas of you know where you have a hinge that helper balance to 0 1 if you're doing classification and some sort of square like error for you know regression and then once you have your loss functions provide it's not 0 1 you can optimize it using SJD which turns out to be a lot faster than gradient descent ok so next time we're going to talk about V of X which we've kind of left as you know someone just hands it to you and then we're also going to talk about what is it really true objective of machine learning is it really to optimize that training ok until next time