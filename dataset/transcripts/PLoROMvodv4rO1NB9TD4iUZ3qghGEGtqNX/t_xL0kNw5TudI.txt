alright let's get started so today's lecture is going to be on logic to motivate things I want to start with a hopefully easy question so if X 1 plus X 2 is 10 and X 1 minus X 2 is 4 what is X 1 someone shout out the answer once you hear that 7 so how did you come get 7 yeah you do the algebra thing that you learned a while ago right so what's the point of this so notice that this is a factor graph right we have two variables they're connected by two constraints or factors and you could in principle go and use backtracking search to try different values of X 1 and X 2 until you eventually arrive at the right answer but clearly this is not really an efficient way to do it and somehow in this problem there's extra structure that we can leverage to arrive at the answer in a much much easier way and this is kind of their going to be the poster child of what we're going to explore today and on next Monday's lecture how you can do logical inference to arrive an answer is much faster than your white house so we've arrived at the end of the class and I want to just reflect a little bit on what we've learned and maybe this will be also a good review for the exam so in this class we've bolts bolts did everything on the modeling inference learning paradigm and the picture you should have in your head is this abstractly we take some data we perform some learning on it and we produce a model and using that model we can produce a perform inference which looks like taking in a question and returning an answer so what does this look like for all the different types of instantiations we've looked at so for search problems the model is a search problem and the inference asks a question what is a minimum cost path in MVP in games we asked a question what is the maximum value policy and csps we asked the question what is a maximum weight assignment and a Bayesian networks we can answer probabilistic inference queries of the form what is the probability of some query variables conditioned on some evidence variables and for each of these case we looked at the modeling we look at the the inference algorithms and then we looked at different types of learning procedures going backwards maximum likelihood we looked at various reinforcement learning algorithms we looked at structure perceptron and so on and hopefully this this kind of sums up the kind of the world view that so yesterday one is trying to impart is that there are these different you know components and depending on what kind of modeling you choose you have different types of algorithms and learning algorithms inference algorithms and learning algorithms that emerge ok so we looked at several modeling paradigms roughly broken into three categories the first is state based model search problems MVPs and games and here the the way you think about modeling is in terms of states and as nodes in a graph and actions that take you between different states which encourage their a cost or give you some sort of reward and your goal is just to find paths or contingent paths or policies in these graphs then we shifted gears to talk about variable based models where instead we think about variables and factors that constrain or these variables to take on certain types of values so in today's lecture I'm going to talk about logical based models so we're going to look at propositional logic and first-order logic which are two different types of logical languages or models and we're going to said think about logical formulas and inference rules which is going to be another way of kind of thinking about modeling the world historically logic was actually the dominant paired I mean AI before the 1990s so it might be hard to kind of believe now but just imagine the amount of excitement that is going into deep learning today this equal amount of excitement was going into logical based methods and in AI and in the 80s and before that too but there was kind of two problems with logic one is that logic was deterministic so we didn't handle uncertainty very well and that's why probabilistic inference and other methods were developed to address this and I was also rule-based which allow didn't allow you to naturally ingest a large amount of data to know it's our guide behavior and the emergence of machine learning has addressed this but one strength that kind of has been left on the table is the expressiveness and I kind of emphasize that logic as you will see gives you the ability to express very complicated things in a very you know succinct way and that is kind of the main point of logic which I really want everyone to kind of appreciate and hopefully this will become clear through examples as I motivate on the first day of class the reason one one good way to think about why we might want logic is imagine you want to lie on the beach and you want your assistant to be able to do things for you but hopefully it's more like data from Star Trek rather than Siri you want to take an assistant you want to be able to at least tell the information and ask your questions and have these questions actually be answered in response to reflect the information that you've told them so just kind of a brief refresher on the first day of class I showed you this demo where you can talk to the system and say things and ask questions so a small example is let's say all students like CS 221 it's great and teach the important things and Alice does not like CS twenty-one and then you can ask you know is Alice a student and the answer should be no because it can kind of reason about this and just to dive in under the hood a little bit inside it has some sort of knowledge base that contains the information that it has we'll come back to this second okay so this this assistant needs to be able to digest heterogeneous information in the form of natural language you know utterances and it has to reason deeply with that information so it can't just do superficial pattern matching so I've kind of suggested natural language as an interface to this and natural language is very powerful because I can stand up here and use natural language to give a lecture and hopefully you guys can understand at least some of it and but you know let's let's go with natural language for now so here's an example of how you can draw inferences using natural language okay so a dime is better than a nickel a nickel is better than a penny so therefore a dime is better than a penny okay so this seems like pretty sound reasoning so what about this example a penny is better than nothing nothing is better than world peace therefore a penny is better than world peace right okay so something clearly went wrong here and this is because language is natural language is kind of slippery it's not very precise which makes it very easy to make these these mistakes but if we step back and think about what is the role of natural language it's really language itself is an exemplar expression so there are many types of languages there's natural languages there's programming languages which all you are you know familiar with but we're going to talk about a different type of language called logical languages like program images are gonna be formal so we're gonna be absolutely clear what we mean but when we have a statement in a logical language but and like natural language it's going to be declarative and this is might be a little bit harder to appreciate it right now but it's means that there's kind of a more of a one-to-one isomorphism between logical languages and natural languages as are compared to programming languages and natural language okay so in a logical language we want to have two properties first the logical language should be rich enough to represent knowledge about the world and secondly it's not sufficient just to represent the knowledge because you know a hard drive can represent the knowledge but you have to be able to use that knowledge in a in a way to reason with that a logic contains three ingredients which I'll go through in a in subsequent slides there's a syntax which defines what kind of expressions are valid or grammatical in this language their semantics which is for each expression or formula and what does it mean and mean means is actually mean something very precise which I'll come back to and then inference rules allow you to take various formulas and do kind of operations on them just like in the beginning when we have the algebra problem you can add equations you can move things to different sides you can perform these rules which are syntactic manipulations on these formulas or expressions that preserve some sort of semantics okay so just to talk about syntax versus semantics a little bit because I think this might be a slightly subtle point which hopefully will be clear with this example so syntax refers to are the valid expressions in this language and semantics is about what these expressions mean so here is example of two expressions which have different syntax two plus three is not the same thing as three plus two but they have the same semantics both of them mean the number you know five here's a case where we have two expressions with the same syntax 3/2 but they have different semantics be depending on which language you're at okay so in order to define a language precisely you not only have to specify the syntax but also the the semantics because just by looking at the syntax you don't actually know what its meaning is unless I tell you there's a bunch of different logics the ones highlighted in bold are the ones I'm gonna actually talk about in this class so today's lecture is going to be on propositional logic and then in the next lecture I'm going to look at first-order logic as with most models in general there's going to be a trade off between the expressivity and the computational efficiency so as I go down this list to first-order logic and beyond I'm going to be able to express more and more things using the language but it's going to be harder to do computation in that language okay so this is the the kind of a key diagram to have in your head while I go through syntax semantics and inference rules so for every I'm gonna do this for propositional logic and then in Monday's lecture I'm gonna do it for first-order logic so just to get that on the board we have syntax we have semantics then we have inference rules let's just do so this lecture is going to have a lot of definitions and concepts and just to give you a warning there's a lot of kind of ideas here they're all very kind of simple by themselves and they kind of piece together but there's just going to kind of be a barrage of terms and I'll try to write them on the board so that you can kind of remember them so in order to define a logic code language I need to specify what are the formulas so more maybe other comment about logic is that some of you probably take in CS 103 or equivalent class we've been exposed to propositional logic what I'm going to do here is kind of a much more methodological and rigorous treatment of it there I want to distinguish the difference between being able to do logic yourself like if I gave you some logical expression you can manipulate it that's different than talking about the general set of algorithms that can operate on logic itself right so remember in AI we're not interested in you guys doing logic because that's just I that's intelligence but we're interested in developing general principles or general algorithms that can actually do the work for you okay just like in in the Bayesian networks it's very fine well that you can you guys can manipulate and condition how cool a conditional marginal probabilities your self but the whole point is we devise algorithms like Gibbs sampling and variable animation ation that can work on any Bayesian network I just want to okay so let's begin this is going to be building from the ground up so first of all there are in propositional logic there are a set of propositional symbols these are typically going to be uppercase letters or even words and these are the atomic formulas these are formulas that can't be any smaller there is going to be logical connectives such as not and or implication and bi-directional implication and then the set of formulas are built up recursively so if F and G are formulas then I can these are also formulas I can have not F I can have F and G F or G F implies G M F by directional implication G or equivalent to G okay so key you know ideas here are we have propositional symbols I'm going to space so this these are things like a there's that gives rise to formulas in general which is going to be denoted and so here are some examples so a is a formula okay it's in particular it's an atomic formula which is a propositional symbol not a as a formula not be implies C as a formula this is a formula this is a formula double negation is fine this is not a formula because there's no connective between a and not B this is also not a formula because what the heck is plus it's not a connective so so I think in thinking about logic you really have to divorce yourself from the common sense that you all come with in interpreting these symbols right not is just a symbol or is just a symbol and they don't have any semantics in fact I can go and define some semantics which would be completely different than what you imagine it would be a valid Lodge call system these are just symbols you know I'm here defining is what symbols are valid and what symbols are not valid / grammatical okay any questions about the syntax of propositional logic so the syntax gives you the set of formulas or basically statements you can make so you can think about as as this is our language if we could only speak in propositional logic I could say a or not B or B or a implies C and that's all I would be able to say and of course now I have to tell you what do these things mean okay and this is the realm of semantics so semantics there's going to be a number of definitions so first is a model so this is really unfortunate and confusing terminology but this is standard in the logical literature so I'm just going to use it so a model which is different from our general notion of a model for example hidden Markov model for example a model here in propositional logic just refers to an assignment of truth values to propositional symbols okay so if you have three pops as you know symbols then there are eight possible bottles a a is 1 B is 0 C is 0 for example so these are just complete assignments that we saw from factor graphs but now in this new kind of language okay so that's the first concept and the first two logic models are going to be more complicated but for now think about them as complete that's and I'm using W because sometimes you also call them worlds because a complete assignment / a model is supposed to represent the state of the world at any one particular point in time yeah yeah so the question is can each propositional symbol either be true or false and in logic as I'm presenting it yes only true or false or zero one okay so these are models and next is a key thing that actually defines the semantics which is the interpretation function so the interpretation function takes a formula and a model and returns true if that formula is is true in this model and false you know otherwise okay so I can make the interpretation function whatever I want and that just gives me the semantics so when I talk about what are the semantics it's the interpretation function function I so the way to think about this is I'm going to represent formulas as these horizontal bars okay so this is think about this as a thing you say it sits outside the reality and so in some sense and then this box I'm going to draw on the space of all possible models so think about this is a space of situations that we could be in the world and a point here correspond to a particular model so the interpretation function takes one a formula takes a model and says is this statement true if the world look like this okay so just to ground this out a little bit more I'm going to define this for propositional logic again recursively so for propositional symbols P I'm just going to interpret that propositional symbol as a lookup in the model right so if I'm asking hey is 8 why go to my model and I see well does it say is true or false okay that's a base case so recursively I can define the interpretation of any formula in terms of its sub formulas and the way I do this is suppose I have two formulas F and G and they're interpreted in some way okay and now I take a formula let's say F and G okay so what is the interpretation of F and G in W well it's given by this truth table so if F is 0 and G is interpreted to be 0 then F and G is they also interpret to be 0 and 0 1 maps to 0 1 0 maps to 0 and 1 1 maps to 1 so you can verify that that's the kind of your intuitive notion of what and should be right or is 1 if at least one of F and G or one implication is 1 if F is 0 or G is is is one if bi-directional implication just means that if F and G evaluate to the same thing not F is no clearly just you know negation of whatever the interpretation of F is ok so this slide gives you the full semantics of propositional logic there's nothing more to propositional logic and at least the definition of what it is aside for this let me go through an example and then I'll maybe take questions so so let's look at this formula not a.m. be bi-directional implication see and this model a is 1 B is 1 C is 0 how do I interpret this formula against this model well I look at the the tree which breaks down the formula so if I look at the leaves let's start so the interpretation of a against W is just one because for proposition symbols I just look up what a is and a is one here the interpretation of not a is zero because if I look back at this table if this evaluates to 1 then this evaluates to zero I'm just looking based on the table B is 1 just by the table lookup and then not a and B is 0 because I just take these two values and I and them together C is 0 by table lookup and then bi-directional implication is interpreted as 1 here because 0 is yeah question function is yeah so the question is is the interpretation functions user-defined it is just written down this is it there's no learning that's just these are this is what you get it's not user defined in a sense that not everyone's going to go to find their own you know truth table is some logicians came up with this and that's what it is but you could define your own logics and it's kind of a fun thing start doing ok any other questions about interpretation functions and models so now we're kind of connecting syntax and semantics right so an interpretation function binds what our formulas which are in syntax land to a notion of models which are in semantics so a lot of logic is very it might seem a little bit pedantic but it's just because we're trying to be very rigorous in a way that doesn't need to appeal to your common sense intuitions about what these formulas okay any questions all right so so while we have the interpretation function and it defines everything it's really going to be useful to think about formulas in a slightly different way so we're gonna think about the formula as representing on the set of all models for which interpretation is true okay so M of F which is this is the set of models that F is true on that model okay so pictorially this is a f that you say out loud and what you mean by this is simply this subset of models which this F is true okay so if I make a statement here what I'm really saying is that I think we're in one of these models and not in one of these other models so that's a kind of an important I think intuition to have the meaning of a formula is carving out a space of possible situations that you can be you guys say there's a water bottle on the table what I'm really saying is that I'm ruling out all the possible worlds we could be in where there is no water table bottle on the table okay so models of F is going to be a subset of all the possible models in a while okay so here's an example so if I say it's either raining or wet rain or what then the set of models can be represented by this subset of this two-by-two okay so over here I have rain over here I've wet so this corresponds to no rain but it's outside this corresponds to it's raining but it's not white outside and the set of models F is this red region which are these three possible models okay so I'm gonna use this kind of pictorial depiction throughout this lecture so hopefully this makes sense so the one key idea here remember I said that logic allows you to express very complicated and large things by using very small means so here I have a very small formula that's able to represent a set of models and that set of models could be exponentially large and much of the power of logic allow it comes from the ability to do stuff like that okay so here's yet another definition this one's not somehow such a new definition sorry a new concept but it's kind of just trying to give us a little bit more intuition for what these formulas and models are doing so a knowledge base is just a set of formulas and think about this is the set of facts you know about the world so this is what you have in your head and in general it's going to be us just a set of formulas and now the the key thing is I need to connect this with semantics so I'm going to define the set of models denoted by a knowledge base to be the intersection of all the models to notify the formulas so in this case if I brain or snow being this green ellipse and traffic being this red ellipse then the model is denoted by the knowledge base is just the intersection okay so you can think about knowledge is how fine-grain we've kind of zoomed in on where we are in the world right so initially you don't know anything we say anything is possible all to to the end no models are possible and as you add formulas into your knowledge base a set of possible worlds that you think might eggs are possible is going to shrink and you know we'll see that in this in a second ok so here's an example of a knowledge base if so have rain that corresponds is this set of models rain implies what corresponds to this set of models and if I look at the models of this knowledge base is just going to be the intersection which is this red square down here ok any questions about knowledge bases models interpretation functions so far alright so as I've alluded to earlier knowledge base is the thing you're having had and as you go through life you're going to add more formulas to your knowledge base you're gonna learn more things so your knowledge base just gets a union with whatever formula you have and over time the set of models is going to shrink because you're just taking an intersection and one question is you know how much is this shrinking okay so here there's a bunch of different cases to contemplate the first case is entailment so suppose this is your knowledge base so far and then someone tells you the formula that corresponds to this set here ok so in this case intuitively f doesn't add any information or new constraints that was known before in particularly if you take the intersection of these two you end up with exactly the same set of models you had before so you didn't learn anything and this is called entailment so there's kind of three notions here there's entailment which is written this way with two horizontal bars which means that the set of models of F is at least as large as the set of models and KT or in other words it's a superset okay so for example rain and snow if you already knew it was raining and snowing someone tells you I it's snowing then you say well I didn't learn anything a second case is contradiction so if you believe the world to be in here somewhere and someone told you it's actually out here then your brain explodes right so this is where the set of models of the knowledge base and the set of models denoted by the formula is empty so it doesn't make sense okay so that's a contradiction okay so if you knew I was rainy and snowy and someone says it's actually not snowing then you if you like know that that count that can't be right okay so the third case is basically everything else its contingency where F adds a non-trivial amount of information to a knowledge base so the the new set of models the intersection here is neither empty nor is it the original knowledge base one thing to kind of not get confused by is if the set of models were actually strictly inside the knowledge base that would also be your contingency right because when you're intersected it's neither empty nor the original okay so if you knew was grainy ants raining and someone said oh it's also snowing too then you're like oh cool I learned something okay so there's a relationship between contradiction entailment so contradiction says that the knowledge base and F R have zero intersection and entailment this is equivalent to the knowledge base in tailing not F okay so justjust there's a simple proposition that says K be contradicts F if KP fan fkb entails not out okay so this is a picture you should have in here is like naught F is all the models which are not in this and you think about kind of wrapping that around it kind of looks like this okay all right so with these three notions entailment contradiction and contingency which are relationships between a knowledge base and new formula we can now go back to our kind of virtual assistant example and think about how to implement these operations so if I have a knowledge base and I tell the the virtual assistant of a particular formula F there are three possible abilities which correspond to different appropriate responses so if I say it's raining then if it's in the Tillman and I say I renew that because I didn't learn anything new if it's a contradiction then I should say I don't believe that because it's not consistent with my knowledge so far and otherwise you learn something okay there's also the ask operation which if you're asking a question again the same three entailment contradiction and contingency can hold but now the responses are should be answers this question so if it's in Tillman then I say yes and this is a strong yes and it's not like probably yes this is a definitely yes if it's a contradiction then I say no it's again it's a strong no it's impossible and then in the other case it's just contingent which you say I don't know okay so the answer to a yes or no question there's three responses not two okay okay any questions about this how many of you are following along okay good all right so this is a little bit of a digression and it's going to connect to Bayesian networks so you might be thinking in your head well we kind of did something like this already right when Bayesian networks we had these complete assignments and we actually define joint distributions over a complete assignments and and now what we're talking about is not distributions but sets of assignments or models and so we can actually think about the relation between a knowledge base and F also having an analog in a Bayesian network land given by this formula so remember a knowledge base is a set of models or possible worlds so in the probabilistic terms is an event and that event has some probability so that's that's a denominator here and when you look at F and KB and you intersect them you get some other event which is a subset of that and you can ask for the probability mass of that intersect event that's the numerator here and you divide those that actually just gives you the probability of a formula or given the knowledge base okay so this is actually a kind of pretty nice and direct probabilistic generalization of in a propositional logic yeah you have like all the variables required for that formula already exist in your set of world so like in this scenario there's a PCP we were asking something about D would still be and I don't know because yeah so the question is this only works when restricted to the set of predefined propositional symbols and you asked about D then yeah you would say I don't know and it's in fact when you define propositional logic you have to pre specify the set of symbols that you're dealing with in in general yeah we did earlier like reading wasn't in the set of examples or things that our agent knew about before we started like training yeah so the question is in the in the in practice you could imagine giving an agent like it is raining or it's snowing or sleeting and having novel concepts it is true that you can divide build systems and the system I'm showing you has that capability and this is it will be clear how we do that when we talk about inference rules because that allows to operate directly on the syntax here I'm talking about semantics where you essentially just just for convenience I mean you can be smarter but but we're just defining the world yeah yeah so in this formula why is this Union and not intersection so I'm Union in the KB with a formula which is equivalent to intersecting the models of the KB with the models of the formula okay so this is a number between 0 & 1 and this reduces actually to the logical case if if this probability of 0 um that means there's a contradiction right because this intersection is it's going to be positive probably zero and if it's 1 that means in its entailment and the cool thing is that instead of just saying I don't know you can actually give a probabilistic estimate of I could well I don't know but it's probably like 90% so you know we're not going to talk this is all I'm gonna say about probabilistic intentions to logic but there are a bunch of other things that you can do that kind of marry the expressive power of logic with some of the more advanced capability of handling uncertainty of probabilities yeah assuming that we above the distribution yeah to do this you were assuming that we actually have the Joint Distribution ahead and a separate problem is of course learning this so for logic I'm only talking about inference I'm not going to talk about learning although there are ways to actually infer logical expressions - ok so back from the digression now we know probably always any more we're just going to talk about logic there's another concept which is really useful called satisfiability and this is going to allow us to implement entailment contradiction contingency using kind of one primitive and the definition is the knowledge base is satisfiable if the set of models is non empty okay so it's not self contradictory in other words so now we can reduce asking tell to satisfy them okay remember ask and tell have three possible outcomes if I ask a satisfiable question how many possible outcomes are there two so how am I going to make this work I have to probably call satisfiable twice okay so let's start with asking if knowledge-based Union not F is satisfiable or not okay so if the answer is no what can I conclude so remember the answer is no so it's not satisfiable which means that KB contradicts not F and what is that equivalent to saying sorry yeah so it's not F so it's which one of these is it should it be a tail meant contradiction or contingency yeah so I'm interested in relation feeding KB and F I'm asking the question about KB Union not F yeah yeah yeah so exactly so this should be an intimate relation between KB and remember KB entails F is equivalent to KB contradicting not okay okay so what about if it's yes then I can ask another question is KB Union F satisfied so the answer is no then what should I say it should be a contradiction because I mean this literally says KB contradicts F and then finally if it's yes then its contingency okay so this is a way in which you can reduce answering ask and tell which is basically about assessing entailment contradiction or contingency to just two at most two satisfiability calls so why are we reducing things to satisfy ability for propositional logic checking satisfiability is just the classical sap problem is actually a special case of solving constraint satisfaction problems and the mapping here is we just call propositional symbols variables formulas constraints and we get an assignment here and we call that a model so in this case if you have a knowledge base like this then there are three variables a B and C and we define this CSP and then we can if we find a satisfying assignment then then we return satisfiable if we can't find one then we return on that okay so this is called model checking it's called mono checking because we're checking whether a model exists or is it's true so you malting takes a knowledge base and outputs whether there's a satisfying model there are a bunch of algorithms here which are you know very popular to something called DPI all named after for four people and this is essentially backtracking search plus a pruning that takes into account the structure of your CSPs which are propositional logic formulas and there's something called walks ad which is you can think about the closest analogue that we've seen is Gibbs sampling which is a randomized local search ok so at this point you really can have all the ingredients you need to do inference in propositional logic so you define what propositional logic symbols are or formulas are I define the semantics and I've told you even how to solve entailment and contradiction and contingency queries by reducing the satisfiability which is actually something we've already you know seen coincident away so that should be it ok but now coming back to the original motivation of X 1 plus X 2 equals 10 and how we were able to perform that logical query much faster we can ask the question now can we exploit that that the factors are our formulas rather than arbitrary functions and this is where inference rules is going to come into play ok so so I'll try to explain this figure a little bit since this was probably pretty mysterious from the beginning so I have a bunch of formulas this my knowledge base over time I accrue formulas and these formulas carve out a set of models in semantics land and and this formula here if it's a super set that means it's entailed by these formulas right so I know that this is true given my knowledge which means that this is kind of a logical consequence of what I know ok so so far what we talked about is taking formulas and doing everything over in semantics land what I'm going to talk about now is inference rules that are going to allow us to directly operate on the syntax and hopefully get some results that way ok so here is an example of making an inference so if I say it is raining and I tell you if it's raining it's wet rain implies what then what should you be able to conclude it's wet right so I'm gonna write this integer all this way with this kind of fraction looking like thing where there's a set of premises which is a set of formulas which I know to be true and if those things were true then I can derive a conclusion which is another formula this is an instance of a general rule called modus ponens this says for any propositional symbols P and Q if I have P & P implies Q in my knowledge base then I can that entails uh Q okay so let's talk about its rules I'm sure let me do it over here space otherwise okay so modus ponens is a first thing we're going to talk about so notice here that if I could do these type images it's much less work right because I it's very localized I all I have to do is look at these three formulas I don't have to care about all the other formulas or problem symbols that exist and going back to this question over here about oh how do I what happens if I have new concepts that occur well you can just treat everything as it's just a new symbol there's not necessary a fixed set of symbols that you're working with at any given time okay so this is the example of an infant's role in general the idea of the inference rule is that you have rules that say if I see f1 through FK which are formulas then I can add you and the key idea as I mentioned before is that in these inference rules operate directly on the syntax and not on the semantics so given a bunch of inference rules I have this kind of meta algorithm that can do logical inference as follows so I have a set of inference rules and I'm just going to repeat until there's no changes to a knowledge base I choose a set of formulas from the knowledge base if I find a matching rule inside rules that exists then I simply add G to the knowledge base okay so what the other definition I'm gonna make is this idea of derives improved so inference rule derives proves so I'm gonna write KB and now with a single horizontal line to mean that from this knowledge base given a set of inference rules I can produce F via the rules okay this is in contrast to entailment which is defined by the relationship between the models of KB and the models of F now this is just a function of mechanically applying a set of rules okay so that's a very very important distinction and if you think about it why is it called proof so whenever you do a mathematical proof or some sort of logical argument you're in sense in some sense just doing a logical inference where you have some premises and then you can apply some rule for example you can add you know multiply both sides of the equation by two that's a rule you can apply it and you get some other equation in which you can which you hope is true as well okay so here's an example maybe I'll just for fun I'll do it over here so I can say it is raining and if I dump that it gives me my knowledge base it has rain if it is raining it is wet so if I dump then I have this is the same as rain implies wet okay just is just in case you're rusty on your propositional logic if I have P implies Q that's the same as not P or Q and notice that I have also wet up here in my knowledge base because this in the background it's basically running forward inference to try to derive as many conclusions as I can ok and if I say if it is wet it is slippery again now I have I have wet imply slippery and now I also derive slippery I also derive rain implies slippery which is actually as you've seen not drivable from modus ponens so behind the scenes is actually a much more fancy inference algorithm but but but the idea here is that you have your knowledge base you can pick up rain and rain implies when and then you can add wet and you pick up ray wet wet implies slippery and then you've got slippery here and with modus ponens you can't actually derive some things you can't derive not wet which is probably good because it's not true and you also can't arrive rain imply slippery which actually is true but our modus ponens is not powerful enough to derive it ok so so the burning question you should have in your head is ok I talked about there's two relations between a knowledge base KB and a formula F there is the entailment relation and this is really what you want because this is semantics you care about meaning and you also have this KB derives F which is a syntactic relationship so what's a connection here in general there's no connection but there's kind of these concepts that will help us think about the connection so if it's semantics these are things which are when you look at semantics you think about the models implied by the the formulas and syntax is just some set of rules that someone made up okay so how do these relate okay so to understand this imagine you have a class and this class is what's inside the class is a formulas and in particular it's the formulas which are true okay so this class is all formulas such that the this formula is entailed by the knowledge base so soundness is a property of a set of rules and it says if I apply these rules until the end of time do I stay within the class am I always going to generate formulas which are inside the class which are semantically valid or until okay so soundness is good completeness says the the kind of other direction which says that I am going to generate all the formulas which are true or entail am i generating extra stuff but at least I'll cover everything that's why it means to be complete okay so the model you should have in your head is you want the truth the whole truth and nothing but the truth soundness is really about nothing but the truth and completeness is about the whole truth ideally you would want both sometimes you can't have both so you're gonna have to pick your battles but generally you want soundness you can maybe live without completeness but if you're unsound that means you're just going to generate erroneous conclusions which is bad whereas if you're incomplete then maybe you just kept in for certain notions but at least you the things that you do in for you know are actually true okay so how do we check soundness so is modus ponens sound so remember there's kind of a rigorous way to do this and the rigorous way is to look at two formulas rain rain implies wet and then look at their models okay so rain corresponds to these set of models here rain implies what corresponds to this set and when I intersect them that's the set of models which are conveyed by the knowledge base which is this corner here and I have to check whether that is a subset of the models of wet and what is over here so this one one corner is a subset of 1 1 and 0 1 so this rule is sounded remember this why is this subset the thing I want to check because that's just the definition of entailment right okay so let's do another example so if someone said it was wet and you know that rainy implies wet can you infer a rain well let's let's just double check this okay so again what are the models of wet they're here one of the models of rain implies wet they're here and I intersect them I get this um this these two over here in dark red and then is that a subset of models of rain nope so this is on south okay so when general soundness is actually a fairly easy condition to check especially in propositional logic but in higher order logics it's not as bad so now completeness is a kind of a different story which I'm not going to have time to really do full justice in this class but but here's a kind of an example showing modus ponens is incomplete so for proposition of logic so here we have the knowledge base rain rain or snow implies wet and is this entailed wet so it's raining and if I know it's raining or snowing then it should be wet how many really say yes yeah it should be entailed right okay but what is the modus ponens do well all the rules look like this so clearly you can't actually arrive at this with modus ponens because modus ponens can't reason about or or disjunction yeah that's the reader still I'm saying that it's not possible for it to not wet given rain is yeah because you're you already know that's raining right so you should say that's okay so this is incomplete so we can be you know sad about this there are two ways you can go to fix this the first way is we say okay okay propositional logic was too fancy question yeah the notation when it says VB equals rain then comma brainer snow it's wet is it him finding any type of assignment to ring their like is it saying that he is raining or is it just saying that we have the variable rate yeah so the question is what does this mean this so the knowledge base is a set of formulas so in this particular formula is rain and remember the models of a knowledge base is where the formulas are true so yes in this case it does commits to rain being one then models of KBR only include the the models where rain is one otherwise this formula would be false yeah oh it was how can we have a probability over a model so remember that a model is where to go okay so remember a model here is just an assignment to a set of proposition symbols or variables right so when we talk about Bayesian networks we're defining a distribution over assignments to all the variables so here what I'm saying is I assume there is some distribution over complete assignments to random variables and I can use that to compute probability queries of the form formula given knowledge base might answer your question they can't be in the same knowledge base if you have two models that or formulas that contradict then this intersection is going to be zero so there is exists a set of models so let me do it this way so imagine you have these two variables rain and wet a Bayesian network might assign a probability point 1 the point I should make these sum to one point what is this 5 so some distribution over these states right and and if I have rain that corresponds to these models so I can write the probability of rain is 0.2 plus 0.5 0.7 okay and if I have the probability of wet given rain this is going to be the probability of the conjunction of these which is going to be what and rain which is here it's going to be 0.5 divided by the probability of rain which is 0.7 does that help okay oops okay so okay so modus ponens a sound but it's not complete so there's two things we can do about this we can either say propositional logic is too fancy let's just restrict it so that modus ponens becomes complete with with respect to restrict a set of formulas or we can use more powerful infants rules so today we're going to restrict propositional logic to make it complete and then next time we're going to show how a resolution which is even more powerful in ritual can be used to make any arbitrary inferences and this is what's powering the system that I show you okay so few more definitions so we're going to define you know logic with with horn clauses okay so so a definite Clause is a propositional formula of the following form so you have some propositional symbols all conjoined together or join just means it's ANDed implies some other propositions in both Q and the intuition of this formula says if P 1 through P call K hold them Q also holds so here are some examples rain and snow implies traffic traffic is can be as possible this is an awning example this is a valid propositional logic formula but it's not a valid definite clause here's also another example rain and snow implies peace traffic or peaceful okay so this is not allowed because only thing allowed on the rights and I on side of the implication is a single propositional symbol and there's two things over here okay so a horn Clause is a definite clause or a goal clause which might seem a little bit mysterious but it's defined as a something that P 1 through P K implies false and the way to think about this is the negation of a conjunction of things right because remember P implies Q is not P or Q so this would be not P or true which is not P in this case okay so so now we have these horn clauses now remember the inference rule modus ponens we are going to slightly generalize this to include not just P implies Q but P 1 through P K implies Q so you get to match on premises which include formulas which are atomic propositional symbols and the rule that looks like this and you can derive or prove Q from that okay so as an example wet and weekday if you see wet weekday wet and we K implies traffic those three formulas then you can you're able to add traffic okay so so here's the claim so modus ponens is complete with respect to horn clauses for propositional logic so in other words what this means is that suppose that the knowledge base contains only horn clauses and that P is some entailed propositional symbol by the entail propositional symbol imeem like KB actually entails Pisa matically then apply modus ponens will derive P means that the two relations are equivalent and you can celebrate because you have both soundness and our completeness okay so just a quick example of this so here imagine is your knowledge base and you're asking the question is there traffic and remember because this is a set of only horn clauses and we're using modus ponens which is complete that means entailment is the same as i'll be able to derive it using these rules this particular rule and you would do it in a following way so rain rain implies what gives you what what weekday wet and weekday implies traffic gives you traffic and then you're done yeah - like rain and bky are those one causes the question is why are rain and we take horn clauses so if you look at the definition of horn clauses they're definite clauses to look at the definite issue of death then the clauses they look like this and K can be 0 here which means that there's this kind of like nothing that make sense yes it's a little bit look I'm using this notation kind of to exploit this corner case that if you have the an of zero things then that's just true or you can just say by definition definite clauses contain propositional symbols that would do it too okay so let me try to give you some intuition why modus ponens and horn clauses so the way you can think about modus ponens is that it only works with positive and information in sometimes there's no branching either or it's like every time you see this you just definitively declare Q to be true so in your knowledge base you're just going to build up all these prophecies or symbols that you know are going to be true and the only way you can add a new problems is your symbol ever is by matching a set of other things which you can definitely know to be true and some rule that tells you you should be true and then you make you true I have Q to your knowledge base as well the problem with problems you know some of the more general causes is if you look at this rain and snow implies traffic or peaceful you can't just write down traffic or or peaceful or both of them you have to reason about well it could be either one and that is outside the scope of what modus ponens can do yeah and oh yeah yeah good good question so what if happens if it were traffic and peaceful so this is an interesting case where technically it's not a definite clause but it essentially is so there's a few subtleties here so if you have a implies B and C you can rewrite that this is exactly the same as having two formulas a implies B and a implies C and these are definite clauses just like you know technically if I gave you hey what about a not a or B it's not a definite Clause by the definition but you can rewrite that as a implies B so there is slight kind of you can extend this to say not only definite clauses but all things which are morally form clauses right where you can do a little bit of rewriting and then you get a honk laws and then you can do your friends okay so resolution is this inference rule that we'll look at next time that allows us to deal with these disjunctions okay so to wrap up so today we talked about logic so logic has three pieces we introduced the syntax for propositional logic you have propositional symbols which you string together into formulas in over in syntax land these are given meaning by talking about you know semantics and we introduced an idea of a model which is a particular configuration of world that you can be in a formula denotes a set of models which are true under that formula this is given by an interpretation function then we looked at entailment contradiction and contingency which are relations between a knowledge base and a new formula that you might pick up you can either do satisfiability check a model checking which test for satisfiability to solve that or you can actually do things in syntax lam by just operating directly on impure tools so that's all I have for today and I'll see you next Monday