alright let's get started please try to have a seat if you can find a seat and let's get the show on the road so welcome everyone to CS 221 this is artificial intelligence and if you're new to Sanford welcome to Stanford so first let's do some introductions so I'm Percy I'm going to be one of your instructors teaching this class with doors over there so if dorsen wants to say hi stand up great so we're gonna be trading off throughout the quarter and we also have a wonderful teaching team so these are your CAS so if all the CAS could stand up and I'll give you each person an opportunity to say three words about what you're interested in let's start with through the head my sister and I [Music] Oh workmen working everyone I am also cook time I don't know is in the back well well there are on the slide okay so as you can see we kind of have a very diverse a team and so when you're thinking about kind of final projects later in the quarter you can tap into this kind of incredible resource so three quick announcements so there's going to be a section every week which will cover both kind of review topics and also advanced topics so this Thursday there's going to be an overview if you're kind of rusty on Python or rusty on probability come to this and we'll get you up to speed homework the first homework is out it's posted on the website it's due next Tuesday at 11 p.m. so remember the time that matters all the submissions would be on done on great scope there's going to be a great scope coast code that will be posted on Piazza so look out for that later okay so now let's let's begin so when I first started teaching this class seven years ago I used to have to motivate why AI was important and why if you study a you have a lot of impact in the world I feel like I don't really need to do this now it's kind of inescapable that you pick up the news in the morning you hear something about you know AI and indeed we've seen a lot of success stories right guys that can play jeopardy or play go dota 2 or even poker all these kind of games at superhuman level performance it can also read documents and answer questions do speech recognition face recognition even kind of medical imaging and all these tasks are you read about how successful these technologies have been and then if you take a look at outside the kind of the technical circles there's a lot of people imposing and trying to ask what is going on with AI and you hear about these kind of very broad claims of how transformative AI will be to the future of work and the society and so on and even some kind of boring on pretty you know casters catastrophic consequences so what's going to happen in the future no one knows but it is fair to say that AI will be transformative but how do we get here and to do that I want to take a step back to the summer of 1956 so the place was Dartmouth College John McCarthy who was then at MIT and then after that he founded a San Fran a I lab organized a workshop at Dartmouth College with some of the best and brightest minds of the time Marvin Minsky Claude Shannon and so on and they had this not so modest goal of trying to think that every aspect of learning or any feature of intelligence can be precisely captured so a machine can be just simulated so they were after the the big question of how do you kind of solve AI so now they didn't make that much progress over the the summer but a lot of programs and interesting artifacts came about from that time there were programs I could play checkers or prove theorems and sometimes even better than what and the human proof would look like and there was a lot of optimism people are really really excited and you can see these quotes by all these excited people who proclaimed that AI would be solved in a matter of years but we know that didn't really happen and there's this kind of flawed lore example people are trying to do machine translation so you take an English sentence like the Spirit is willing but the flesh is weak you translate into Russian which is what the choice language by the US government at that time and you could translate back into English and this is what you get the vodka is good by the media's run so the government didn't think that was too funny so they cut off the funding and it became the first AI winter so there's a period where no AI m research was not very active and was not well very well funded so what went wrong here these were really smart people right they just got a little maybe a little head of themselves so two problems one is that the compute was simply not there right is millions or even billions order magnitude compared less than what we have right now and also the problem is the way they formulate them intrinsically we rely on attempt exponential search which no matter how much compute you have you're never going to no went that race they also have a limited information this is maybe a kind of a more subtle point that if I give you infinite compute and I ask you to translate I don't think you would be able to figure it out because it's not a computation problem you just need to learn the language and you need to experience all the subtleties of language to be able to you know translate but on the other hand AI wasn't solved but a lot of interesting contributions to computer science came out of it Lisp was just I'll have a lot of ideas that underlay many of the high-level programming languages we have garbage collection time sharing allowing multiple people to use this one computer at the same time which is something that we kind of take for granted and also this paradigm of separating what you want to compute which is modeling and how you do it which is inference which we'll get to a little bit later okay so people forget quickly and in the 70s 80s there was a renewed generation of people are getting excited about AI again and this time it was all about knowledge right knowledge is power and there were a lot of expert systems which are created and the idea is that if you could encode experts knowledge about the world then you could do kind of amazing things and at the time the knowledge was encoded in generally a set of rules and there were a lot of programs that was written and you notice that the scope is much narrower now the goal isn't to solve it all of AI but to really focus on some choice some problems like diagnosing the diseases or converting customers order parts and departs and customer orders into parts and this was the first time that AI I think really had a real impact on industry so people were actually able to make useful you know products out of this and knowledge did actually play a key ingredient in curbing this in your exponential growth that people were worried about but of course it didn't last long knowledge as deterministic rules was simply not rich enough to capture all the nuances of the world it required a lot of manual effort to maintain and again a pattern of over-promising and under-delivering that seems to plague AI people led to the collapse and of the field and the kind of second AI winter okay so that's not the end of the story either but actually it's not not kind of really the beginning either um so I'm going to step back further in time to 1943 so what happened in 1943 so there was a neuroscientist McCullough and the logician pits were wandering and marveling at how the human brain is able to do all these kind of complicated things and they want to kind of formulate a theory about how this could all happen so they developed a theory of artificial neural networks and this is kind of you can think about the route as of you know deep learning in some sense and what was interesting is that they looked at neurons and logic which are two things that you might not kind of necessarily associate with each other and showed how they were kind of connected mathematically and a lot of the early work in this era were up around artificial neural networks was about studying them kind of from a mathematical perspective because at that time the compute wasn't there you couldn't really run any training models or and then 1969 something interesting happened so there's this book by Minsky and Papert called perceptrons and this book did a lot of mathematical analysis and it also showed that linear model is one of the results all over many was showing that linear classifiers couldn't solve the XOR problem the problem is another way to think about the problem is basically given two inputs can you tell whether they're the same or not or different and so it kind of not a shouldn't be a hard problem but linear classifiers couldn't do it and for some reason which I don't quite understand it killed off neural nets research even though they said nothing about if you had a deeper network what it could do but it's often cited at this book strong things from people who are interested in neural networks the field of AI being very symbolic and a logic driven but there was always this kind of minority group who were really invested in and believed in the power of neural networks and they thought was just kind of a matter of time so in the 80s there was a renewed interest people gonna discover to rediscover the backpropagation algorithm which allowed kind of a for a generic algorithm that could strain these multi-layer neural networks because single layer remember was insufficient to do a lot of things and then one of the kind of the early success stories as Yannick Owen in 1989 applied a convolutional neural network and was able to recognize handwritten digits and this actually got you know deployed by the USPS and was reading kind of zip codes so this was no great but it wasn't until this decade that the this area of neural networks really kind of took off under the c'mon occur deep learning and you know Alex net in 2012 was kind of a huge transformation where they show gains on the image net benchmark and in overnight transform their computer vision community alphago as you know many of you know and many a kind of other and they were kind of the rest is history okay so so there's these kind of two intellectual traditions you know the name AI has always been associated with H I'm John McCarthy logical vision that's kind of where it started but as you can see that there's also a kind of this neuroscience inspired a tradition of AI you know - were kind of really had some deep philosophical differences and over the decades fought with each other kind of quite a bit but I want to pause for a moment and really think about maybe they were actually do have deeper connections here remember McCulloch and Pitt's they were studying artificial neural networks but the connection was to logic right so from even in the very beginning there is kind of this synergy that you know some some people can kind of often overlook and if you take a look at alphago which if you think about the game of go or many games it's a mathematically you can write down the group rules of go in logic in just a few lines so it's a mathematically well-defined logical logic puzzle in some sense but somehow the the power of neural networks allows you to develop these models that actually play go really really well so this is kind of one of the deep mysteries that has kind of I think is a kind of opens a standard challenge you know in the eye as with any story it's not the full picture and I want to point out on this slide that AI has drawn from a lot of different you know fields many of the techniques that we're gonna look at for example maximum-likelihood came from you know statistics or games came from economics optimizations gradient descent came from was you know in the 50s completely unrelated to AI but these techniques kind of develop in a different context and so AI is kind of like in you know it's kind of like a New York City it's it's a melting pot where a lot of the these techniques get kind of unified and apply to kind of interesting problems and that's what makes it I think really interesting because of the the new avenues that are opened up by kind of unique combinations of existing techniques okay so so that was a really brief history of you know where how we got here now I want to pause for a moment and think about you know what is what is the goal what were a I people are trying to do and again this is kind of there's two ways to think about this which end in the neck sometimes the conflation of these causes a lot of confusion so I feel like to think about it as AI as agents and a eyes as tools so the first view asks the kind of the scientific question of how can we create or recreate intelligence and the second one asked you know how can we use technology to kind of benefit you know society and these two are obviously very related and they have a lot of shared technical overlap but you know philosophically they're kind of different so let me kind of explain this a little bit so the idea with AI agents is and this is I think a lot of what gets associated with AI and especially with science that kind of portrayal certainly kind of encourages this kind of view where you're human we're human beings and what you do is you look in the mirror and you say wow that's a must that's a really smart person and you think okay how what what what can humans do that is you know so you know amazing well they can they can see and they can perceive the world recognize objects they can grasp cups and drink water and not spill it they can communicate using language as I'm doing to you right now we know facts about the world declarative knowledge such as what's the capital of France and procedural knowledge of how to ride a bike we can reason with this knowledge and maybe write a bike to the capital France and then really importantly we're not born with all this right we've blown with basically nothing none of these capabilities but worth born with the capacity and potential to acquire these over time through experience and learning it seems to be kind of this critical ingredient which drives a lot of a success in AI today but also with you know human intelligence is clear that learning plays a such a central role in getting us to the level that we are offering that so each of these areas has kind of spawn entire subfields and people in it are kind of wondering about how you can make artificial systems that have the language or the motor or the individual perceptual capabilities that no humans have but are we there yet and I would I would like to think that we are very far so if you look at the way that machines or haven't successful it's all with as a narrow set of tasks and you know millions of billions of examples and you just crunch a lot of computation and you can really kind of optimize every any task you can come come up with whereas humans operating a very different regime they don't necessarily do any you know one thing well but they are have such a diverse set of you know experiences can solve the vebber set of tasks and learn from each individual task from very few examples and still it's a kind of a grand challenge and from a congress perspective how you can build systems with this level of capability and that humans have so the other view is you know AI tools basically we say okay well you know it's kind of cool to think about how we can you know recreate elegance but you know we don't really care about making more things like humans we already have a way of you know doing that that's called babies so when it said we really like to do is not making something that's like a human but making systems that help humans because you know after all we're we're humans I guess it's a little bit selfish but we're in charge right now and and a lot of these this view and a lot of the success stories in AI are really different from the things that you expect you know this this humanoid robot to comment to your house and be able to do for example this is a project from Stefano Herman's group there's a lot of poverty in the world and part of it is just kind of understanding what's what's going on and they had this idea of using a computer vision on satellite imagery to predict things like nope GDP so this is obviously not a task that you know the our ancestors in Africa were like you know getting really good at but nonetheless it uses convolution neural networks which is a technique that was inspired by you know the brain and so that's that's kind of interesting you can also have another application for a saving energy by trying to figure out when to cool data centers as AI is being deployed in more mission critical situations such as self-driving cars or authentication there are there are few issues that come up so for example there are this phenomenon called adversarial examples where you can take these cool-looking classes you can put them on your face and you can fool the computer I'll save our face recognition system to think that you're actually you know someone else or you can post these stickers on stop signs and get this save our system to think that it's a a speed limit sign so there's obviously there's clearly these are you know big problems if we think about that the widespread deploy deployment of AI there's also less catastrophic Li but also a pretty you know upsetting which is a biases that you many of you probably have read in the news about so for example if you take Malay which is the language that doesn't distinguish in this writing form between he and she and you second Google Translate you see that she works as a nurse but he works as a programmer which is encoding certain societal biases in the actual models and one kind of important point I want to bring up is that you know it's how is machine learning and kind of working today well it's you know society exists society is generating a lot of data we're training on this data and kind of trying to fit the data and trying to mimic what it's doing and then using predictions on it what could possibly go wrong right and so so certainly people a lot of people have been thinking about how these biases are kind of creeping up as an open active area of research something a little bit more kind of sensitive is you know asking well these systems are being deployed to all these all these people whether they kind of wanted or want it or not and this this actually touches on you know people's livelihoods it actually impacts people's lives in a serious way so Northpoint was his company developed a software called compass that tries to predict how risky a criminal risk or how someone how risky someone is essentially and publicly this organization realized will whoa you have the system that given that individual didn't refund is actually more twice as likely to classify blacks is incorrectly as non blacks so this is seems pretty problematic and the North moment comes back and says actually you know I think I think we're being fair so given a risk score of seven we were fair because sixty percent of whites reoffended and sixty percent of blacks reoffended the the point here is that there's there's there's actually no solution to this in some sense sadly so people have fine formulated different notions of fairness and equality between how you predict a court on different kind of groups but all you can have different notions of fairness and which all seem reasonable from first principles but mathematically they can be incompatible with each other so this is again an open area of research where we're trying to figure out as a society how to deal with the scheme and that machine learning might be using these kind of critical situations okay so summary so far there's agents view we're trying to really kind of dream and think about how do you get these capabilities like learning from very few examples that humans have into new machines and all maybe opening up a kind of a different set of technical capabilities but at the same time we really need to be thinking about how these systems are affecting the real world and things like security and biases and fairness all kind of show up it's also interesting to note that you know a lot of the challenges in deployment of AI system don't really have necessary to do with you know humans at all I'm humans are incredibly biased but that doesn't mean we want to build systems kind of in our that mimic humans and kind of inherit all the kind of the flaws that humans have okay any questions about this maybe pause for a moment so let's go on so what I want to do next is give an overview of the different topics in the course and the way to think about all of this is that in AI we're trying to solve really complex problems the real world is really complicated and but at the end of the day we want to produce some software or maybe some hardware that actually runs and does stuff right and so there's a very considerable gap between these things and so how do you even approach something like self-driving cars or you know diagnosing diseases you probably shouldn't just like go sit down at a terminal and start typing because then there's no kind of no Arbour arching structure so what this class is going to do is to give you one example of a structure which will hopefully help you approach hard problems and think about how to solve them in a kind of more principled way so this is a paradigm that I call the modeling inference and learning paradigm so the idea here is that there's three pillars which I'll explain in a bit and we can focus on each one of these things kind of in turn so the first pillar is modeling so what is mod later the model a is taking the real world which is really complicated and building a model out of it so what does a model model is a simplification that is mathematically precise so that you can you know do something with it on a computer one of the things that's necessary is that modeling necessary has to simplify things and you know throw away information so one of the kind of the you know the art is to figure out what information to pay attention to and what information to keep so this is going to be important for example when you work on your final projects and you have a real-world problem you need to figure out you can't have everything and you have to figure out judiciously how to manage your resources so here's an example if you wanted for example build a system that can find the best way to get from point A to point B in a graph in a city you can formulate the model as a graph where nodes are points in the city and edges represent ability to go between these points with some sort of cost on the edges okay so now once you have your model you can do inference and what inference means is asking questions about your model so here's a model you can ask for example how what is the shortest path from this point to this point right and that's because now you're a model and it's a mathematically well-defined problem now you can it's within the realm of you know developing algorithms to you know solve that problem and most of inference is being able to do these computations really efficiently and finally learning addresses the problem where did this model come from so in any in a realistic setting the model might have a lot of parameters maybe it has no millions of parameters and how do use if it wants to be faithful to the real world but how do you get all this information there manually encoding this information turns out not to be a good idea this is in some sense what AI from the 80s was trying to do so the learning paradigm is as follows what we're gonna do is specify a model without parameters think about it as a skeleton so in this case we have a graph but we don't know what the edge weights are and now we have some data so maybe we have data of the form people try to go from X to Y and they took ten minutes or an hour or so on and then from this data we can learn to fit the parameters of the model we can assign costs to the edges that and our representative what data is telling us okay so now in this way we can write down a model without parameters feed it data apply a generic learning algorithm and get a model with parameters and now we can go back and do inference and ask questions you know about this okay so this is kind of the paradigm and I want to really emphasize that you know learning is not as I presented is really not about any one particular algorithm like nearest neighbors or neuro networks it's really a kind of a philosophy of how you go about approaching problems by defining a model and then not having to specify all the details but filling them in later okay so here is the plan for the course we're gonna go from low-level intelligence to high-level intelligence and this is an intelligence of of the of the models that we're going to be talking about so first we're gonna talk about machine learning and like I've kind of alluded to earlier machine learning is going to be such a kind of a important building block of that can be applied to any of the models that we develop so the central tenets of machine learning is you have data and you go to model its main a driver of a lot of successes in the eye because it allows you to in software engineering terms move the complexity from code today rather having you know a million lines of code which is unmanageable you have a lot of data which is collected in kind of a more natural way and a smaller amount of code that can operate on this data and this paradigm has really been in a tree of a powerful one thing to think about in terms of machine learning is that it is requires a leap of faith right so you can go through the mechanics of you know down to downloading some machine learning code and you train them all but fundamentally it's about generalization right you have your data you fit them all but you don't care about how it performs on that data you care about how it performs on new experiences and that leap of faith is something that's I think gives machine learning its power but it's also a little bit at first glance perhaps magical it turns out you can actually formalize a lot of this using no probability theory and statistics but that's kind of a topic for another time ok so after we talk about machine learning we're going to go back and talk about the the simplest of models why so a reflex model is this so here's a quiz okay what is this animal ok zebra how did you get it so fast well it's kind of reflex right your human visual system is so good at doing these things without thinking and so reflex models are these are models which just require a fixed set of computations so examples like our linear classifiers deep neural networks and most of these models are the ones that people are your machine learning use models is almost synonymous with reflex in know machine learning an important thing that there's no feet for it it's just like you get your input bam bam bam and here's your output okay so that's that's great because it's it's fast but there's some problems that require a little bit more than that right so for example here's another problem okay quick why'd you move where you go okay there's probably like a few of you who are like chests geniuses but for the rest of us I have no idea who's moving again so so in these kind of situations we need something perhaps them a little bit more powerful than a reflex we need agents I can kind of plan and think ahead so the idea behind state based models is that we model the world as a set of states which capture any given situation like a position in a in a game and actions that take us between states which correspond to things that you can do in the in this game so a lot of game applications following this category robotics motion planning navigation also some things that are might not be you might think of planning us such as generation in natural language or generating an image your R can be cast in this way as well so there's three types of state based models each of which will cover in you know weeks of time so search problems are the classic you control everything so you're just trying to find the optimal path there are cases where there's randomness for example if you're trying to go from point A to point B maybe there's traffic that you don't you know don't know about or in a game there might be dice that are tired which are road and there's a third category which are adversarial games which is cases where you're playing an opponent who's actively trying to destroy you so what are you going to do about it so one of the games that we're going to be talking about when we talk about games is a pac-man and one of the assignments is actually building a pac-man agent such as this so why are you looking at this think about how what are the states and what are the actions and how would you go about you know devising a strategy for pac-man to eat all the dots and avoid all the ghosts so that's something to maybe look forward to there's also gonna be a competition so we'll see okay so state based models are very powerful with a value to kind of have foresight but some problems are not really most naturally castis they based models for example you know how many place the doctor or have played it before so the goal of Sudoku is to fill in these blanks with numbers so that every row column and 3x3 sub block has it is just 1 through 9 so it's a bunch of constraints and there's no kind of sense in which you have to do in a certain order right whereas the the the order in how you move in in chess or something is you know pretty important so so these type of problems are captured by these variable based models where you kind of think about a solution to the problem as an assignment to the individual variables under some constraints so constraint satisfaction problems we'll spend a week on that these are hard constraints for example two people can't be a person can't be in two places at once for example there's also Bayesian networks which we'll talk about which are variable based models with us soft dependencies for example if you're trying to track you know a car over time these are the positions of the car these variables represent position of the cars and these e's represent the the sensor readings of the position of the car at a particular position and inference looks like trying to figure out where the the car was given all this kind of noisy sensor reading so that's also give me another assignment that you're going to deal with okay so finally now we get to high level one so what is high level intelligence here and I put logic here for a reason that you'll see clear yeah is there a question yeah so the question is why is not the wisest so do Co problem not a space space model you can actually formulate this as a state-based model by just thinking about the sequence of assignments but it turns out that you can formulate in a kind of more natural way as a variable based model which allows you to take advantage of some kind of more efficient algorithm it's to solve it right it's think about these models as kind of different analogy is like a programming language so yes you could write everything in you know C++ but sometimes writing in you know Python or or sequel for some things might be more might be easier yeah yeah so question is how do you categorize state based models where there's both randomness and an adversary we're also going to talk about those as well and those would be I would classify them as adversarial but there's also a random component that you have to deal with games like common oh yeah question are we just trying to like go from the stasis so it feels like we have like problem oh yeah so question is about whether some of these are more continuous and some of them are discrete I don't necessarily think of so a lot of the reflex models actually can work in continuous spaces for example images actually it's it's almost a little bit of an opposite where the logic based models are in some sense more you know discrete but you can also have continuous elements you know in there as well so in this class we're mostly going to focus on cam discrete objects because they're just going to be simpler to work with okay so what is this logic so the motivation here is add suppose you wanted a little companion who you could boss around and and help or help you do things let's say that's a better way to say it so you like to be able to say okay you know tell us some information and you know then later you want to be able to ask some questions and have the system be able to reply to do so you know how would you go about doing this and one way you could think about is building a system that you can actually talk to using natural language okay so I'm actually going to show you a little demo which is going to come up in the last assignment on logic and well let's see what you think of that okay so this is going to be a system that is based on logic that I'm going to tell the system a bunch of things and I'm gonna ask some questions so I want you all to follow along and see if you can you know play the role of okay so I'm gonna teach you a few tips like Alice is a student okay so it says I learned something now let's let's quiz this is Alice student ok ok so that worked is a bob student should answer you I don't know who's Bob okay so now let's do students are people Alice is not a person I'll buy that okay so okay it's you know it's doing some reasoning right it's using logic it's not just okay so now let's do Alice is from Phoenix Phoenix is a hot City I know because I live there cities are places and if it is snowing it is then it is cold okay got it so is it snowing I don't know so how about this okay so if a person is from a hot place and it is cold then she is not happy okay true right guess those of you who send all your live in California with them maybe you appreciate this but okay so how is it snowing now how many say yeah it's snowing how do you say no don't know how about if I say Alice is happy okay so he's a snowy now no I should be no okay so you guys were able to do this okay so this is kind of an example of an interaction which if you think about it has is very very different from what you would see kind of in a typical you know ml system where you have to show it your millions of examples of one particular thing and then it can do kind of one task this is much more of a very open-ended set of I want to say that the experiences are super rich but they're definitely diverse I teach I just give one statement I say it once and then all of a sudden has all the ramifications and kind of consequences that built in and it kind of understands in a kind of deeper level of course this is based on you know logic systems so it is brittle but this is kind of just a proof of concepts to give you a taste of what I mean when I say logic so so these systems need to be able to digest these heterogeneous information and reason deeply with that information and we'll see kind of how logic systems can do that okay so that completes the tour of the topics of this class now I want to spend a little bit of time on course logistics so I want to all the details here are online so I'm not going to be complete in my coverage I just want to give you a general sense of what's going on here okay so what are we trying to do in this course so three requisites there's programming discrete math and probably building so you need to be able to code you need to be able to do some math and some kind of basic proofs right so these are the classes that are required or at least recommended or if you have some equivalent experience that's you'll find you and what do we what should you hope to get out of this course right so one hand the course is meant to be giving you a set of tools using the modeling inference and learning paradigm it gives you a set of tools and a way of thinking of how about problems that hopefully will be really useful for you when you go out in the world and try to solve real world problems and also a buy as a side product I also want all of you to be more proficient at know math and programming because those are kind of the core elements that are enable you to do kind of interesting things so a lot of AI you know you read about it is very flashy but really the foundations are still just you know math and programming in some sense okay so the coursework is homeworks exam in a project that's where you have to do homeworks there's eight homeworks each homework is a mix of write written and programming problems centered on a particular application covering one particular type of model essentially like I mentioned before there's a competition for extra credit there's also some extra credit problems and and homeworks and when you submit code we're going to run we have an auto grader that runs it's gonna run on all the test cases but you get a feedback only a subset so you can it's like you know in machine learning you have a train set and you have a test set so don't train on your test okay so the exam is testing your ability to use the knowledge that you learn to solve new problems right so there's um and I think it's worth taking a look at exam because there's this kind of surprises people over the exam is a little bit different than the types of problems that you see on on the homework and they're kind of more problem you know solving so the exam isn't gonna be like a multiple-choice like okay you know you know when was you know perceptrons published or you know something like that it's going to be here's a real-life problem how do you model it and how do you come up with a you know solution um they're all going to be written it's closed book except where you have a one page of notes and this is a great opportunity to actually review all the material and actually learn the content in the class so the project I think is a really good opportunity to take all the things that we've been talking about in the class and try to find something you really care about and try to apply it working groups of three and I really recommend finding a group early and as I emphasize it's your responsibility to find you know a good group right don't come to us later like one week before the project that line and say oh you know my group members they ditch me or something you really try to try to nail this down use Piazza - or your other social networks to find a good group so throughout the quarter there's going to be these milestones for the projects so to prevent you guys from procrastinating into the very end so there's going to be a proposal where you try and brainstorm some ideas progress before a poster session which is actually a whole week before the final report is due and the project is very open so this can be really liberating but also might be a little bit daunting we will hopefully give you a lot of structure in terms of saying okay how do you define your task how do you implement different baselines and oracles which I'll explain later how do you evaluate how do you analyze what you've done and each of you will each project group will be assigned a see a mentor to help you through the process and you're always welcome to come to my office hours or courses or any of the CAS to get additional help either brainstorming or figuring out what the next step is some policies all assignment will be submitted on great scope there's seven total late days you can use at most two per assignment after that there's no credit we're gonna use Piazza for all communications so don't email us directly leave a post on Piazza if I courage you to make a public if it's it's not sensitive but if it's you know personal then obviously make a private and try to help each other and we'll actually award some Etsuko credit for students who help answer you know other students questions so all the details are like of course watts okay so one last thing and it's really important and that's the honor code okay so especially if you're you know you've probably heard this if you've been at Sanford if you haven't then I want to really kind of make this clear so I encourage you all to kind of collaborate discuss together but when you when it comes to actually the homeworks you have to write up your homework and your code independently so you shouldn't be looking at someone's write up you shouldn't be looking at their code and you definitely should be like copying code off of github that's hopefully should be obvious and maybe a less obvious you should not please do not post your homework assignments on github I know you're probably proud of accurate pac-man agent is doing really well but please don't post on github because then that's going to be an honor code violation when debugging with if you're working together it's fine too as long as it's kind of looking at input output behavior so you can say to your partner oh hey I put in this input to my test case I'm getting like three what are you getting so that's fine but you can't remember don't look at each other's code and if you enforce this we're going to be running moss which is a software program that looks for code duplication to make sure that the rules are being followed and you know changing one variable name is or Uub so anyway enough set just don't don't do it okay any questions about this I want to make sure this is important or about any of the logistics yeah the final project you can put on github yeah yeah private github repos is fine yeah question in the back the question is can you can you do a solo project you can do a solo project you can do a project with two people or you can do a project with three I would encourage you to try to work in groups of three because you'll be able to do more as a group and there's definitely you know it's not like if you do a solo project will be expecting like one third of the work so okay anything else all right okay so in the final section I want to actually delve into some technical details and one thing we're going to focus on right now is the kind of inference and learning components of this course so I'm going to talk about how you can approach these through the lens of new optimization so this is going to be it might be a review for some of you but hopefully it's going to be a good you know way to get everyone on the same page okay so what is optimization there's two flavors of optimization that we care about there's a discrete optimization where you're trying to find the best discrete object for example you're trying to find the best path or some the path P that minimizes the cost of that path we're going to talk about one algorithmic tool based on dynamic programming which is a very powerful way of solving these complex optimization problems and the key no property here is that the set of paths is huge and you can't just try all of them and compute their cost and to choose the best one so do something clever the second brand of optimization is continuous optimization in formally this is just finding the best vector of real numbers that satisfies or minimizes some objective function so typical place that shows up is in learning where you define objective function like the training error and you're trying to find a waiter W so this notation just means it's a list of numbers T numbers that minimizes the training app and we're going to show that gradient descent is a you know easy and a very surprisingly effective way of solving these continuous optimization problems okay so to introduce these two ideas I'm going to look at two problems and trying to kind of work through them so this might be also a good way to think about how you might go approach you know homework problems you know trying to kind of talk through this in a bit more detail okay so the first problem is you know computing at this distance and you know this might not look you know like an AI problem but a lot of AI problems have this as kind of a no building block if you want to do some sort of matching between you know two words or two biological sequences so the input is you're given two strings we're gonna start writing over here on the board just to work this out so you're given two strings s and T so for example a cat and the cats okay so these are two strings and you want to find the minimum number of edits that is needed to take transform s into T and by edits I mean you can insert a character like you can insert s you can delete characters I can delete this a and you can substitute one character for another so you can replace this a with a t okay so here's some examples what's the edit distance of cat and cat at zero you don't have to do anything kind of dog is three an ad as one you insert the a or certain insert the C cat and cats is one and a cat and the cats is four okay so the challenge here is that there are quite a different number of ways to insert and delete right so if you have a string of that's very long there's just way too many things to like just try out all of them okay so then how do we how do we go about coming up with a solution so any ideas yeah yeah yeah so let's try to simplify the problem a bit and building up Anya what you what was said so one thing to note is that okay we're so the general principle let me just write the general principle oh is to you know reduce the problem to a simpler problem because then you can hopefully saw is it's easier to solve and then you can maybe keep on doing that if you get something that's trivial okay so there's maybe two observations we can make one is that well we're technically saying we can you insert into s right but if we insert into S it makes the problem kind of larger in some sense right I mean that's not that's not good that's not reducing the problem but but when we reinsert into s we probably want to insert things which aren t we want to cancel something out right so we want to insert a K there for any reason we probably want to insert an S in which case you know s matches that and then we've reduced that problem right so we can actually think about you know inserting into s to s as equivalent to kind of deleting from from T okay does that make sense all right so another observation we can make is that you know we can start inserting anywhere we can start inserting here and then jump over here and do this but this just introduces a lot of you know ways of doing it which all kind of result in the same answer so why don't we just start more systematically at one end and then just proceed and try to chisel off the problem kind of let's say from the end okay so start okay so so now we have this problem I'm gonna draw a problem in a box here so let's start at the end yeah question [Music] oh the question is why are we starting at the end as opposed the idea is that if you start at the end then you have kind of a more systematic and consistent way of your reducing the problem so you don't have to think about all the permutations of where I can you know delete and substitute the right we can also do love to write so the end or the start is both fine this is just I just pick the end yeah yeah the question is how do we know that starting at one end can give you the optimal strategy so you know if you wanted to approve this more rigorously there's some work but I'll just try to give you a you know intuitive answer suppose you didn't start at the end and you just made a sequence of steps like I insert here I delete here and then I went over here and did all those operations to s I could have equivalently also just sorted those by you know where I was happening and then just proceeded from one end to the other and I would arrive at the exact same answer so without loss of generality I can start that any other questions okay so yeah yeah so question is maybe you can recognize some patterns well it's like Oh cat that's a that's maybe a those should be you lined up I guess these examples are chosen so that these patterns exist but we want to solve the problem for cases where the pattern might not be obvious it could be we want to work for it to work for all strings maybe there is no pattern and we still would want to kind of efficient algorithm to do it yeah just like use dynamic programming like we go one by one there was always like Facebook you said either we're doing substitution or otherwise it's like the same character or we have to insert yeah and then we keep going and just like each like - yeah yeah great idea let's do dynamic programming so that's what I'm kind of trying to build up from build up to okay so so if you look at this so diamond program is a kind of general technique that essentially allows you to express this more complicate problem in sort of a simpler problem so let's start with this problem if we start at the end if the to match then well we can just immediately you know delete these two and that's it's gonna be the same right so we can get we can get some free right sir okay but when they differ now we have many options so what we can what could we do well we could you know substitute okay we can change the T to an S so what does that leave us with so I can do [Music] t is the cat okay so I can substitute [Music] okay what else can I do someone say something I can do so I can insert insert we're into so I'm gonna insert it s right but that's the same as you know by one deleting from T so but I can basically just the week SS so this is our cat and I deleted this s from T okay so this is let's call it you know I guess let's call this insertion it's technically insertion and then finally what can I do [Music] I can also remove tea so aka okay so this is delete and right now you're probably looking at this like well obviously you know you should do this one but in general it's hard to tell right if I just give you some arbitrary strings you know who knows what the right answer is um so in general how do you pick you mean this one so here I inserted a s right but then because there's two S's here I just cancel them out on think about this is really the lien from yeah yeah so I'm because of this I'm kind of trying to reframe the problem okay so which one should I choose yeah the substitution the other way meaning change sorry there's too many S's and you could that's you can think about that it's kind of equivalent so if you identify two letters that you want to make the same then you could you can replace the one to be the other or the other I mean officially we've been kind of framing it as we're only editing s which is the reason that it's okay so which one of these door a door B orders door C yeah yeah so you could try to look inside but but remember these are might be really complicated so we want a kind of a simple mechanized procedure to tell the next letter yeah let's let's pretend these are you can't see inside [Music] yeah okay so let's keep on going I'm not gonna draw everything but you can also try to break this down into maybe there's three actions here and three actions here and at the end of the day you hopefully have a problem that's simple enough that we're as equals T or something then you're done but then you know how do i how do I know suppose I have solved this suppose someone just told you okay I know this cost I know this cost I know this cost what should you do yeah you should take the minimum right like we remember we want to minimize the Edit distance so there's three things you can do each of them has some cost of doing that action which is no one every edit is the same cost and then there's a cost of you know continuing do whatever you're doing and so we're just going to take the minimum yeah yeah so I was trying to argue that with if you're going to write the draft it's without loss of generality because if you've when left to ride her in some other order you can also replay the edits I think it works okay so so let's um try to code this up and see if we can make this program work okay so I'm gonna do edit distance can everyone see this okay so I'm going to define a function it takes two strings and then I'm going to define a recurrence so recurrences are I guess one word I haven't really used but this is really the way you should kind of think about dynamic programs and this idea of taking complex problems and breaking it down it's going to show up and you know search problems mdps and I know games so I guess it's something that you should really be comfortable with so let's define a recurrence as follows so remember at any point in time I have let's say a sub-problem and since I'm going right to left I'm only considering the first M letters of s and the first letter and letters of T ok so recurse is going to return the minimum at a distance between two things the first letters of s and the first end letters of T I'm gonna post this online so you guys don't have to copy try to copy this okay so okay suppose I'm gonna I'm going to define this function if I had this function what should I return the curse of so M is an integer right so n is an integer so I'm gonna return the length of M and the length of that okay so that's kind of the initial State okay all right so now I need to fill out this function okay so let's let some consider a bunch of cases so here's some easy cases suppose that M is 0 right so I have comparing an empty string with something that has n letters so what should the cost of that be it should be n and symmetrically if n is 0 and result should be M and then if now we come to the kind of initial case every consider which is the end in that so if s the last letter of M this is 0 based indexing so that's why there's a -1 so this matches then what should I do so now reduce this to a sub problem right so I have a minus one n minus one okay and now hums the fun case which we looked at so there's in this case the last letter doesn't match I'm gonna have to do some sort of there's probably a way you can make this more efficient I'm just gonna try to get the basic okay so substitution okay so what's the cost of a substitution I pay one to do the substitution but and in as a reward I get to reduce the problem to M minus 1 in n minus 1 right so I lump off a letter from s and a lop off a letter from T so what else can I do so I can you know delete so that also costs 1 and when I delete I delete from s and then n so this remains the same and then now you can think about the insertion is and a minus 1 right because remember insertion into S is deletion from T that's why this is n minus 1 ok and then the result is just going to be a minimum of all these things okay a return result okay so just and then how do I call this function a cat the cats so let me prepare now to answer let's see if it works okay print out four therefore I conclude it works no I mean if you were doing this you would probably want to test this some more but in the interest of time I'll kind of move on so let me just kind of refresh okay so I'm computing this at a distance between two strings and we're gonna define a recurrence that works on sub problems where the sub problem is the first M letters of s and the first n letters of T and the reason I'm using integers instead of strings is to avoid like string copying implementation detail but it doesn't really matter so base cases so you want to reduce your problem to your case where it's it's trivial to solve and then we have the last letter matches and then we have the letter doesn't match and you have to pay some sort of cost I don't know which action to take so I'm going to take them you know minimum of all of them and then I call it by just calling recurse okay so this is great right so now have a working thing let's try another test case so I'm gonna make this so if I do times 10 this basically replicates this string ten times so it's a it's a long string longer string okay so now I'm gonna run it maybe I shouldn't wait for this there is a base case I think it works but it's it's what's wrong with this code yes it's very slow why is it slow yeah right so so I'm recursing every point recurse it's three times so you kind of get this exponential you know blow up so there's kind of a how do you solve this problem yeah you can memo I think I heard the warm my eyes which is another way to kind of think about my eyes plus I guess recurrences is dynamic programming I guess so I'm gonna show you kind of this way to do it which is pretty uninvested and generally I recommend people well get the slow version working and then try to make it faster don't try to be you know too slick at once okay so I'm gonna make this cash right and I'm gonna say if MN is in the cache then I'm going to return whatever is in the cache so the cache is just the dictionary mapping the key which is identification of the problem I'm interested in solving and the result which is the answer that computed so if I already computed it I don't need a computer again just return it and then at the end if I have to compute it then I have to put this in the cache okay so three lines or four lines I guess yeah yeah that's a great point this should be outside of the recursive aren't you yeah glad you guys are paying attention otherwise yeah it would do basically nothing any other mistakes yeah in this class are you okay if we use that or would you rather us like you can use the deck or you can be fancy yeah but but I think this is you know pretty transparent easy for learning purposes okay so let's run this so now it runs instantaneously as opposed to I actually don't know how long it would have taken otherwise okay and sanity check for D is probably the right answer because there's four words original answer and multiply by ten okay any other questions about this so this is an example of you know kind of basic dynamic programming which are you solve a problem trying to formulate it as a recurrence of a complicated problem in terms of smaller problems and like I said before this is going to kind of show up over and over again in this class yeah yeah the question is why does this reduce redundancy so maybe I can do it kind of pictorially if you think about let's say you have a a problem here right and this gets you know reduced to I'm just making kind of an arbitrary diagram here so this problem gets reduced to these two and this problem gets reduced to these two and and so on right so if you think about if you didn't have memoization you would just be paying for the number of paths every path is the kind of you have to compute from scratch whereas if you do memorization you pay in the number of nodes here which a lot of this is shared like here you know once you compute this no matter if you're coming from here or here you're kind of using the same value okay so let's let's move on so the second problem we're going to talk about is has to do with continuous optimization and the motivating question here is how do you do regression which is a kind of a bread and butter of know machine learning here so [Music] so here we go regression okay so imagine you get some points okay so I give you a point which is no.24 and then I'll give you another point let's say for two and so these are data points you want to let say predict housing price from you know square footage or something like that you want to predict health score from you know blood pressure and some other things so this is pretty common in machine learning and the question is how do you fit you know a line I'm gonna kind of consider the case where your line has to go through the origin just for simplicity so you might want to like find you know a fit I mean to two points is maybe kind of a little bit degenerate but that's the simple example we're gonna work with in general you have lots of points and you want to fit the line that best kind of is close to the points okay so how do you do this so there's a principle called least squares which says well if you give me a line which is given in this case by a slope W I'm going to tell you how bad this is and badness is measured by looking at all the training points and looking at these distances right so here I have you know this particular a particular let's say point you know X i if I hit it with W then I get basically the you know the y intercept here not the y intercept but the like the Y value here that's my prediction the real value was you know why I which is you know up here and so if I look at the difference I want a difference to be 0 right so in these squares I Square this and I say I want this to be as small as possible right now this is only for one point so I'm going to look at all the points let's suppose I have end points and that's a function that I'm gonna call F of W which basically says for a given weight vector which is a slope give you a number that characterizes how bad of a fit this is where zero means that I fit everything perfectly and large numbers mean that I fit okay all right so so that's no regression so how do I solve a regression problem so how do i optimize this do you do this in your head so if I actually have these two points which should W be [Music] okay it doesn't matter well we'll compute it so how do we go about doing this [Music] so one principle which is and maybe another general takeaway is abstract away the details right this is also true with the dynamic program but sometimes you know you get if you're too close to board and you're looking at oh man these points are here and I need to fit this slide you know how do I do that you you kind of get kind of a little bit stuck but why don't we think about this F as say some function I don't really care of what it is and let's plot this function okay so look now this is a different plot now this is a the weight and this is f of w always label your axes and let's say this function looks like this okay so which means that for this slope I pay you know this amount for this slope I paid this amount and so on and what do I want to do I want to minimize f of W which means I want to find the W which has the least value of F of W right your question okay so you take the derivative so what is the derivative give you it tells you where to move right so if you look over here so you can in general you might not be able to get there directly in this actually particular case you can because you can solve in close form but I'm gonna try to be more general so if you start here this this derivative tells you well the function is decreasing if you move to the right so then you should move to a right whereas over here if you end up over here the derivative says the function is decreasing if you move to the left so you move to the left right so what I'm going to introduces this algorithm called gradient descent it's a very simple algorithm it basically says start with some place and then compute the derivative and just follow your nose right if it's derivative says it's negative then just go this way and now you're a new point and you compute the derivative again you descend and now you're compute it again and then maybe you compute the derivative and says keep on going this way maybe you overshoot and then you come back and then you know hopefully you'll end up kind of at the minimum ok so let's try to see what this looks like in code so gradient descent is you know one of the simplest algorithms but it really underlies essentially all the algorithms that you people use in machine learning so let's do points we have two points here and I'm going to define some functions okay so f of W so what is this function so I'm going to sum over all the different you know basically at this point it's converting math into Python so I'm going to look at all the points so for every X Y what the model predicts is W times X minus y and if I square that that's going to be the error that it get on that point and then if I sum over all these errors then I get my objective function okay arrey of yeah so you can put a ray here if you want but it doesn't matter it's actually fine okay so now I need a computed derivative so how do you compute the derivative so if your calculus is a little bit rusty you might want to brush up on that so what's the derivative remember we're taking really derivative respect to W right there's a lot of symbols here always remember what you're taking derivative with respect to okay so the derivative of the sum is the sum of the derivative so now I need to take the derivative of this right and what's the derivative of this well something's squared you bring the two down here and now you multiply by the derivative of this and what's the derivative of this should be X right because this is a whyatt this is a constant and W derivative W times X with respect to W is X okay so that's it okay so now let's do gradient descent let's initialize with W equals zero and then I'm going to just you know just iterate a hundred times normally you would set some sort of stopping condition but let's just keep it simple for now okay so for every moment I'm going to have a W I can compute the value of the function and I also take the gradient or the derivative gradient just means derivative and higher dimensions which we'll want later okay and then what do I do I take W and I subtract the the gradient okay so remember okay I'll be out it yeah so I take the gradient remember I want to have the gradient gradient tells me where the function is increasing so I want to move in the opposite direction and ADA is just going to be this step size to keep you things under control we'll talk more about it next time okay so now I want to do pronounce going on here so iteration print out the function and the value okay all right so let's compute the gradient and so you can see that the iteration we first start out with W go zero then it moves to 0.3 and then it moves the point seven nine nine nine nine nine nine and then it looks like it's converging to point eight and meanwhile the function value is going down from 20 to 70 which happens to the optimal answer so the correct answer here is a point okay so that's it next time we're gonna keep we're gonna start on the machine learning lecture