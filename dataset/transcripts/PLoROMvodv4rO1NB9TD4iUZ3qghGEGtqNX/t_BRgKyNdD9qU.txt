okay welcome back everyone this is the second lecture on machine learning so just before we get started a couple of announcements homework one foundations is due tomorrow at 11 p.m. note that it's 11 p.m. not 11:59 and please I would recommend everyone try to do a test mission early right it would be unfortunate if you wait until 10 59 and you realize that your computer you can log into the website if that happens please don't just bombard me or or with yeah so just to remind you are responsible for any technical issues you encounter so please do the test submission early so you have a peace of mind and then you can go back to finishing your peer homework ok homework 2 sentiment is out this is the homework on machine learning and it will be due next Tuesday and finally there's a section this Thursday which we'll talk about back propagation and nearest neighbors and maybe a overview of scikit-learn which might be useful for your project so please come to that ok so let's jump in I'm gonna spend a few minutes reviewing what we did last time kind of starting at the very abstract level and drilling down into the details so abstract level learning is about taking a data set and outputting a predictor F which will be able to take inputs X for example an image and output a label or output Y for example whether it's a cat or a truck or so on and if you unpack the learner we talked about how we want to frame it as a optimization problem which captures what we want to optimize what properties the predictor F should satisfy apart from the optimization algorithm which is how we accomplish our objective so the optimization problem that we talked about last time was minimizing the training loss and in symbols this is the training loss which depends on a particular weight vector is the average over all examples in a training set of the loss of that particular example with respect to the weight vector W okay and we want to find the W that minimizes the training loss so we want to find the single W that makes sure's on average all the examples have low loss okay so looking at the loss functions now this is where it depends on what we're trying to do if we're doing regression then the pertinent thing to look at is the residual which remember is the models prediction - the truth label so this is kind of how much we overshoot and the loss is going to be zero if the residual is zero and increases either quadratically for the square loss or linearly for the absolute deviation depending on how much we want to penalize large deviations for classification or binary classification more specifically the pertinent quantity you look at is a margin which is the score times of the label Y which remember is plus 1 or minus 1 so the margin is a single number that captures how correct we are so large margin is good in that case we obtain either a zero or near zero loss and margin lesson zero means that we're making a mistake so the zero and lost captures that we're making a mistake of a lost one but the hinge loss in the logistic lost kind of grow linearly because allows us to optimize the function better question yeah the lost squared curve there with the residual will be the residual looks like on the graph here we just feel away from there so there are multiple graphs here so remember last time we looked at the residual if you look at X or a rather fee of X over Y so here's a line here is a particular point V of X V of X Y and the residual is that basically the difference between the models prediction and the actual point here this graph is different this graph is visualizing in is in a different space right I'll show you another graph that might make some of these things okay I guess one way to think about the residual is the residual is a number so if your residuals to then you're kind of it here and this is the loss that you pay which is two in this case and if the residual is -2 then you pay - yeah the residual is the x-axis and the margin is x-axis over here okay any other questions about this you know what the question is one would you use the absolute value versus the square loss there is a slide from the previous lecture which I skipped over which talks about when you would want it most of the time people you tend to use the square loss because it's easier to optimize but you also see absolute you know deviation the the square loss will penalize large outliers a lot more which means that it has kind of mean mean like qualities whereas the absolute deviation panels are less so it's more like a median just for kind of intuition but the general point is out all these loss functions capture properties of a desired predictor they basically say hand me a predictor and I'll try to assess for you how good this is right this is kind of establishing what we want out of it and you know also another comment is that you know I'm presenting this loss minimization framework because it is so general anything basically that you see in machine learning can be viewed as some sort of no loss minimization if you think about PCA or deep neural networks different types of auto-encoders they can all be viewed as some sort of loss function which you're trying to minimize so that's why I'm kind of keeping this framework somewhat general okay so let's go the opposite direction of generality let's look at a particular example and try to put all the pieces together so suppose we have a simple regression problem we have three training examples 1 0 the output is 2 1 0 the output is 4 and 0 1 output is minus 1 right so how do we visualize what learning on this training set looks like so let's try to form the training loss the training loss remember is the average over the losses on if each individual example so let's look at the losses on individual examples so we're doing linear regression so an X is two dimensional and fiha x equals x so in this example so we're basically trying to fit two numbers W 1 and W 2 so if you plug in these values for x and y into this loss function then you get the following quantities so the dot product between W and X is just W 1 right because X X 2 is 0 and u minus 2 and you square it because we're looking at the square loss the same thing for this point instead of 2 you have a 4 and that for this point WV of X minus y is W 2 now because now the X 2 is active minus -1 squared ok so these are the individual loss functions each of which tells what I kind of want out of W so if here I'm looking at this if W 1 is 2 then that's great I get a loss of 0 this one says if W 1 is 4 that that's great and I get a loss of 0 and obviously you can't have both and the goal of the training loss is trying to look at the average so that you can pick one W that works for as kind of on average is good for all the points ok so now this is a function in two dimensions it depends on W 1 and W 2 so let me try to draw this on the board to give you some more intuition what this looks like ok so I'm gonna draw W 1 W 2 and so the first function is W 1 minus 2 okay so so what is this function want to do it wants W want to be close to or close to 2 and it doesn't care about W 2 right so I'm not really sure how to draw this function but it really requires something in 3d so you can think about a ball shape kind of coming out of the board like this if this direction is meant to be the the loss okay so I'm gonna try to do well let's let's try it this way so it's going to be like a kind of a bunch of parabolas that look like this coming out of the board okay okay so what about the second one the second one is w1 minus four squared so that's going to be basically the same thing but kind of centered around four so route this axis [Music] okay so again this is gonna be some problem coming out of the board and then finally the other point is w2 minus minus one so it's going to be happiest when W 2 is minus 1 so it's going to be kind of a bunch of you know parabolas coming out of the board here okay so you add all three functions up and what do you get you get something that is has first of all where do you think the minimum should be intersections yeah thank you the first I like the first vertical and all the second oh the red lines I mean oh yeah it's gonna be some sort of intersection here so if you look at the W 2 axis right it should definitely be minus 1 because this is a function that cares about W 1 so it's gonna be somewhere here and both by symmetry well this one wants it to be a 2 this one that wants to be a 4 so the average is somewhere between you can work all this kind of actually mathematically out I'm just kind of giving the rough intuition and now let me draw the level curves here the level curves are going to be something like this where again if you're drawing in 3d it's like a parabola or coming out of the board here where here is the lowest point and as you venture away from this point your loss is going to increase right okay yeah how do I get this middle point so one way is that if you add these two functions up and kind of just you know plot it it turns out to be a three incredibly the the square loss when your average it acts kind of like a mean so kind of you know it's going to be somewhere between there's also related to one of the homework problems so hopefully you'll have a better appreciation for that okay so so I guess yeah question once we have the three how are you merge it with the negative one as well do we need to do another issue um so question is once we have the three how do you merge it with a minus one so the three is regarding w1 and the minus one is regarding w-2 so you just add them together they kind of don't in this particular example they don't interact in general they will could you quickly summarize that me what's going on with this example yeah so this plot shows for every possible weight vector W 1 W 2 you have a point and the amount that the function comes out of the board is the loss right and the loss function is defined on in the slides right there and all I'm doing is trying to plot this loss function so unfortunately it's hard to kind of draw in 3d here so what I'm trying to do here is taking each of the pieces and trying to explain what each piece is trying to do all right [Music] so in general the the training loss you don't have to think about kind of how exactly it composes the individual losses this is probably as complex of example we'll have to you know get to write to understand it but this kind of gives you an idea of how you connect these pictures where you see kind of these parabolas with the picture which is actually the of the you know training loss okay but for now let's assume you have a training loss it's a function of the parameter it's some function and how do you optimize this function so you do some sort of gradient descent so last time we talked about how you can just do vanilla gradient descent where you initialize with zero and then you compute the grading of the entire training loss and then you update once and the problem with that is the up computing the gradient requires going through all the training examples you have a million training example that's really slow so instead we looked at stochastic gradient descent which allows you to pick up an individual example and then make a gradient step right away right and empirically we saw encode how it can be a lot faster you know of course there are cases where it can also be less stable so there's kind of in general going to be some you know trade-off here but by-and-large sarcastic waiting to send it kind of really dominates you know machine learning applications today because you there's the only way to really have scale to large data sets okay yeah [Music] so apart from being able to scale up is there any advantage of sarcastic gradient descent another besides computation another advantage might be that your data might be coming in online fashion like over time and you want to you know update kind of on the fly so there are cases where you don't actually have all the data at once okay so that was a quick overview of the general concepts now to set the stage for what we're gonna do in this lecture I want to ask you guys a following question so can we obtain decision boundaries remember a decision boundary is the the kind of line that or the curve that separates the region of the space which is classified positively versus negatively can we have paint decision boundaries which are circles by using linear classifiers okay so does that make sense so we want to get something like this where you have now we're going into v1 of X you know feed two of X and we want to decision boundaries that look like this where you classify maybe these as positive and these as negative okay is that possible yeah you map if you make a square of those inputs and you get something it should be linear so you're saying yes okay [Music] okay well there is a punchline there so it turns out that you can actually do this which maybe on the surface seems kind of surprising right because we're talking about linear classifiers but as we will see it really depends on what you mean by linear classifiers and hopefully that would become clear sir okay so we're going to start by talking about features which is going to be able to answer this question then we're going to shift gears a little bit and talk about neural networks which is in some sense of automatic way to learn features then we're gonna show you how to train neural networks using back propagation hopefully without tears and and then talk about nearest neighbors which is another way to get really expressive models which is going to be a much simpler in a way okay so recall that we have the score so the score is a dot product between the wave vector and a feature vector and the score drives prediction so if you're doing regression you just output the score as a number if you're doing classification binary classification then your output the sign of the score and so far we focus on learning which is how you choose the wave vector based on a bunch of data and how you optimize for that and so now what we're gonna do is focus on V of X and talk about how you choose these features in the first place and this actually featured and generated feature extraction is you know such a really critical important part of kind of a machine learning pipeline which often kind of gets neglected because when you take a class you're saying okay well there's some feature vector and then let's focus on all these algorithms but whenever you go and apply machine learning the world feature extraction is turns out to be kind of the main bottleneck and neural nets can mitigate this to some extent but you still it doesn't completely make feature extraction obsolete so recall that a feature extractor takes an input such as this the string and outputs a set of properties which are useful for prediction so in this case it's a set of named feature values okay and last time we didn't really say much about this we just kind of waved our hands as I okay here are some features so you know in general how do you approach this problem what features do you include do you just like start making them up and how many features do you have we need maybe a better organizational principle here and you know in general feature engineer is going to be someone over art so I'm not going to give you a recipe but at least some framework for thinking about features so the first notion is a feature template and a feature template is informally just a group of features are all computed in the same way this is a kind of a somewhat antic but a kind of you know a terminology point that I want you all to kind of be aware of so a feature template is basically a feature name with holes so for example length greater than blank so remember the concrete feature is length greater than ten now we're gonna say length greater than blank or blank and replaced with ten nine eight or any kind of number it's a template that gives rise to multiple features last week a character is equals blank contains character blank these are all examples of feature templates so when you're going in your project or whatever and you describe your features I want you to think about kind of drooping these features in terms of know these blanks another example is pixel intensity of position so even if you have what you consider to be like a raw input like an image right there's so implicitly some sort of way to think about it as a feature template which corresponds to like the pixel intensity of position blank comma blank is a feature template guy gives a rise to the number of features equals to the number of pixels in the image and this is useful because maybe your input isn't just an image maybe it's in it's an image plus some metadata then having this kind of language for describing all the features in a unified way is really important for clarity okay so as I alluded to each feature template maps to a set of features so by writing last three characters equals blank I'm implicitly saying well I'm going to define a feature for each value of blank and that feature is going to be associated with a value which is just the natural evaluation of that feature on the input okay so all of these are 0 except for ends with com is 1 okay so and in general you are going to have each feature template game might give rise to many many you know features write the number of possible 3 detector is you know some number of characters to the cube which is a large number so one question is how do you represent this right yes first vector yeah good answer so mathematically it's really useful just think about this vector as a d-dimensional vector right just deed numbers just laid out right and because that's mathematically convenient but when you go to actually implement this stuff you might not represent things that way in particular you know what are the ways you can represent a vector well you can say I'm going to represent it as an array which is just this list of numbers that you have but this is inefficient if you have a huge number of features but in the cases where you have sparse features which means that only a very few of the feature values are nonzero then you're better off representing as a a map or in Python a dictionary which you specify the feature name is a key and the value is you know the value of that feature right and all the the the homework two will basically work in this sparse feature you know framework you know just a kind of a note a lot of you know especially in NLP and we have discrete objects um traditionally it's been common to use kind of these sparse feature maps you know one thing that has happened with the rise of neural networks is that often you take basically your inputs and embed them into some sort of fixed dimensional vector space and dense feature representations have been more you know dominant but you know sports features if you want to use linear classifiers is still kind of a good way to go so it's important to understand this okay so now in sort of storing possibly a lot of features now you just sports store the the key and the value all right so this was the feature templates the overall point is I just kind of organizational principle and you know okay so now let's switch gears a little bit so what features or feature templates should you actually you know write down and to get at that I want to introduce another notion which is you're pretty important especially if you can understand if you think about the theory of you know machine learning and that's a notion of a hypothesis class okay so remember we have this predictor so for a particular weight vector that defines a function that map's inputs into you know some sort of score or prediction in a hypothesis class is just the set of all predictors that you can get if you vary the wave vector okay so so let me give you I'm gonna come back to this slide let me give you a kind of a example here so suppose you're doing a regression and you're doing you know linear regression in particular so you learn one dimension here is X and here is you know I guess Y so if your feature map is just identity so Maps X to X then this notation just means the set of all you know linear functions like this then the set of functions you get you can visualize as this right so you have you know one function here and for every possible value of w1 you have a slope you can also have 0 they should all go through the origin and so you have you know these are your functions right so your hypothesis class f1 here is essentially all lines that go through the origin so just want to think about you when you write down a feature vector you're implicitly committing yourself to saying hey I want to think about all possible predictors defined by this feature map ok so here's another example suppose I define the feature map to be x comma x squared ok so now what are the possible functions you know I'm gonna get so does anyone want to say would have read off this slide what it is it's gonna be all quadratic functions right okay so in particular because I don't have a bias term it's going to be all choreography I go through the origin so let me actually draw another okay so it's going to be all quadratic functions that go through the origin which look like this there could be upside down and maybe like that I'm not going to draw all of them in particular it also includes the linear functions right because I can always set w2 equals 0 and very w1 which means that I also get all the linear functions too right so this means that the two if you think about the set of functions is a larger set than f1 it's more expressive that's we mean by expressive that means they can represent more things okay so for every feature vector you should think also about the set of functions that you can get by that you know feature vector okay so let's lose your question [Music] 22 cents to find the best set of w's are the more expressive sets harder the question is are the more expressive sets hard to optimize in terms of you know the short answer is not necessarily in terms of sure you have more features so that require is more expensive yeah at that level but the difficulty optimization depends on a number of different no factors and sometimes adding more features can be easier to optimize because it's easier to figure training data okay so now let's go back to this picture okay so this is on the Border's concrete example as a feature or hypothesis classes now let's think about this big blob as the set of all predictors any predictor in your wildest dreams you know there in this this set okay and whenever you go and you define a feature map that's going to carve out a you know a much smaller set of you know functions right and and then what is learning doing learning is choosing a particular element of that function family based on the data okay so this picture shows you kind of the full pipeline of how you're doing machine learning is you know they're you first declare structurally a set of functions that you're interested in and then you say okay now based on data let me go and search through that set and find the one that is you know best for me okay so now there are you know two places where things can go wrong well for feature extraction maybe you didn't have enough features so now your your your purple set is too small then no matter how much learning you do you're just not going to get good accuracy right and then conversely even if you define a nice you know hypothesis class if you don't optimize properly you're not going to find the element of that you know hypothesis class that fulfills your your goals question the function the feature function is extracting features from the input since that self is a function of them you can assume that your weight would be able to question is if so you're defining a function fee why this is fixed and then learning sets weights and together jointly they specify a particular function or predictor don't choose be appropriately you're limiting the space they will be able to predict yeah but so I'm wondering why but miners my intuition tells me that the whole point of learning is that the regardless of the fee that you choose the actual model that you choose would be able to you know learn the function fee that you would have picked Oh a so the question is does doesn't learning kind of compensate and just figure out the fee that you would have picked so the answer is short answer is no that the fee is really kind of a bottleneck here for example it just if you define fee to be X so that's the linear function when your function is all you're gonna get right so if your data that moves around in a sinusoidal way you're just gonna like fit a line through that and you'll get no horrible accuracy and no amount of learning can you know fix that the only way to fix that is by changing your new feature representation W so yes so all this assumes that W we're talking about linear predictors okay but of course the same general idea applies to any sort of function family neural nets the arcade so they're equivalent there would be not just the feature map but also the neural net architecture is a constraint on what kind of things you can express if you have them you're only a two layer neural network then there's just some things that you just you know with or with a fixed size there's just some things you just can't question I thought it is more of a question of why the form feature ization rather than taking in the raw data you have like a neural net it's still a function of linear classifiers but it has enough complexity that it can describe nonlinear behavior yeah so the question is why bother doing feature in engineering has a neural Nets kind of basically solve that so to some extent an amount of feature engineering you have to do today is know much less one thing that I think it's still important to think about in feature engineering is it's really think about is what sources of information you want to know predict for example if you want to predict you know this you know some property about your movie review you know what what the part of the first-order bits are like what even goes into that does it the texts go into that you have metadata do you have other star ratings and those are no features you can there's I guess no such thing as like raw because there's always some code that takes you know the the you know the world and distills it down into something that's fits in memory so that's you can think about as feature extraction yeah okay one last question too many features yeah yeah um so the question is why don't you just make fee as large as possible to throw on all the features and overfitting is you know one of the main concerns there which you know we'll come back to in the next lecture [Music] okay great questions so let's let's actually skip over this so there's another type of feature function you can define but in interest sometime I guess skip over that okay so now let's come back to this question is linear well I keep on saying you or linear predictors what what what is linear right so remember the prediction is driven by the score right so here's a question is this score linear in W yes right because what is a you know a linear function it's basically some kind of weighted combination of your inputs okay so is it linear in V of X by symmetry should be because it's just a dot product so is it linear in X no in fact this question doesn't even make sense because thing about X X remember was a string right it's not a it's not even a number so and that's when you know the answer should be no because you know that doesn't it there's a type error okay so here's here's kind of the cool thing now is you know these predictors can be expressive nonlinear function and decision boundaries of X you know in the case where X is is actually a real vector but the score is a linear function of W okay so this is cool because you know from a there's two perspectives right from the point of actually doing prediction you know you're thinking about like well how does this function operate on X and you can get all sorts of you know crazy functions coming out we just looked at quadratic functions which is clearly nonlinear but you can do all sorts of crazy things but from the point of view of learning it doesn't care about X all it sees is fee of X in a particular you're learning ask the question how is this function depend on W right because it's tuning W and from that perspective it's a linear function of W and you know for reasons I'm not going to you know go into these functions permit efficient learning because the loss function becomes convex which I'll that's all say about that okay so so one kind of cool way to visualize what's going on here is screen you're going back to our circles example so remember we want this two-dimensional classification problem where the true decision boundary is you know let's say a circle so how do we fit that and what does it mean for a linear thing because when you think linear it's like should be a line right so here's a kind of a cool graphic so okay so here is these points inside the circle and you know it can't be classified but the point is when you look at the feature map it actually lifts these points into a higher dimensional space now I'll have three features right and and you know in this higher dimensional space I can actually things are linear I can slice it with a kind of a knife and then you know in that high dimensional space if things are cut and what it induces in the lower dimensional space is you know this circle [Music] okay okay so hopefully that was a nice visualization that shows how you can actually get nonlinear machine functions out of kind of essentially linear machinery right so someone the next time someone says well you know you know linear classifiers they're really limited and you really need neural nets you know that's technically as false because you actually get really expressive models out of your neural networks OSR out of linear models the point with neural networks it's not that they're not you're more necessary more Express that can be more expressive but the fact that they have other advantages for example the inductive bias that comes with architectures and the fact that they're more efficient when you go to a more expressive models and so on okay so so to kind of wrap up all things I want to kind of do us you know simple exercise so here's a task so imagine you're doing a final project and you want to predict you know whether two consecutive messages in sums for forum or a chat or where the second one is a response to the first so it's binary classification input is two messages and you're asked to predict whether the second is a response to the first okay so we're going to go through this exercise of coming up with you know features that might be or feature templates might be useful to pick out properties of X my might be useful and we're going to assume that we're dealing with linear predictors okay so what are some features that might be useful let's um you know let's here so let's start with a few okay so how about time elapsed between the two messages that useful feature or not I mean you say yes okay so this information is definitely good once subtle point is that this time elapsed is a single number and this number is going to go into the score kind of in a linear fashion okay so what is what does that mean that means you know if I double the time then the score is going to or that contribution to a score is going to like multiply by two right so think about it it's it's kind of like saying them as I increase the time you know the it becomes you know linearly more likely that I'm going to be let's say not a response or a response so this is you know maybe kind of not what you want because you know the difference from that perspective like if you the time elapsed is like a year then that really kind of dominates the the score function and it's like more more likely that it's going to be a response than if it were like one minute which is and not what you want yeah question [Music] yeah so the question is can you normalize it so you have to be careful with normalization so you have if you normalize let's say the span of like over one year now now there's no difference between like you know five seconds and one minute because everything gets squashed down to zero right so one way to kind of approach that is to you know disk or ties the features so one trick that people often do is if you have a numerical value which you really kind of want to treat kind of in a sensitive way you can kind of break up into pieces so the feature template would look something like time elapses between blah and blah so you can do things like okay is it between zero seconds of five seconds and is it between five seconds and like a minute and between a minute and an hour and an hour and a year or something and then after that it doesn't matter because that will give you kind of more it's it's more domain knowledge that tells you kind of what things to look out for the difference between let's say a year and a year plus two seconds is really you know it doesn't matter right where's the difference between one second and five seconds might be significant so this is all - a long way of saying you know if you're using a linear classifiers or even if you're using neural networks I think it's really important to think about how your raw features are kind of entering the system and think about like if I change this feature by like scaling it up does the prediction change in a way that you know I expect yeah yeah question the second feature there what prevents us from hitting let's say if we have temple of Jupiter sages from 30 to 40 seconds and any soul what prevents us from hitting just the entire yeah so the question if you have every possible range isn't that like an infinite number of features so there's two answers to that one is that even if you did that you might still be okay because there's probably some if you think about like discretizing this space it is your time elapsed time elapsed and you're basically saying for every bucket I'm gonna have a feature I mean it is true that you have a empty number you know features but you know at some point you might just cut it off and if you didn't cut it off and use sparse feature representation you don't have to have a preset you know maximum because remember most of these features are going to be zero because the chances of some data point being like you know 10 years is going to be essentially you know another answer is that in general when you have features that are have multiple time scales you want to kind of space it out kind of logarithmically so you know 1 to 2 2 to 4 4 to 8 so that you can have both kind of sensitivity in the libertines but also kind of cover a large you know magnitude yeah back this is my little learn like how did this besides the features make it the most informative question is is it possible to learn how to discretize the the features there are there's definitely more automatic things you can do besides you know just like span specifying them at some level though you have to kind of input the value in a form like if you've inputted it into X versus let's say log of X those choices often can make a big difference but if you use more expressive models like neural networks you can you know mitigate some of this yeah I see the value changing time elapsed from a number to range whatever you want to retain a miracle value for future yeah a good question so when would you actually want to not discretize it so there are essentially when you expect kind of the scale of that feature to really kind of matter in in the Sun in some sense so certainly when you think that some things behave linearly then you just want to preserve the linear or if you think that it behaves quadratically then you want to keep the feature but also add like a squared term to it okay I want to maybe move on these are all good questions happy to discuss more offline so some other features might include the first message contains blank or blank as a string right so maybe things like you know question marks are more indicative of you know things being the second message me or swans second message contains certain words two messages both contain a particular word you know there's cases where it doesn't really it's not the presence in absence of particular words in the in individual messages but like the fact that they both share a common word you know that might be useful here's another feature which is you know two messages have the sum number of common words together so this feature is kind of interesting because it's there's you know for example you look at this feature it's how the number of when I say feature I actually mean feature template so for this feature template there are many many features one for possibly any number of words and this again leads to cases where you might have a lot of you know sparsity and you might not have enough data to fit all the features whereas this one is very compact that says I just have to look at the number of overlaps so the the two messages might contain a word I've never seen before but I know it's the same word and I can kind of recognize that pattern so you know there's quite a bit of things you can do to play around with features that capture you know the intuitions about what's might be relevant to your task question that one we want to do like dimensionality reduction so question is when you have a lot of sparse features do you want to do dimensionality reduction not necessarily so in terms of computation having sparse features that doesn't necessarily mean that it's going to be you know really slow because there's efficient ways of representing sparse features in terms of you know expressivity one thing that in a lot of NLP applications you actually do want a lot of features and you can have a lot more features than you might think you can handle and because you really wanted the first orbit is just to you know be expressive enough to even fit the data okay let me move on since you know I'm running short on time okay so summary so far you know we're looking at features we can define these feature templates which organize these features in a kind of meaningful way then we talked about hypothesis classes which are are defined by features and this defines what is possible out of from learning and all this is in the context of linear classifiers which incidentally can actually produce these nice nonlinear decision boundaries so at this point you can actually have kind of enough tools to you know do a lot but in the next section I want to talk about neural networks because these are even more expressive models which can be you know more powerful one thing I often recommend is that you know when you're given a problem you always try this simplest thing I will always try kind of a linear classifier and just just see where it gets because sometimes you'd be surprised at how far you can get with linear classifiers and then and then go and kind of increase the complexity as you need it I know there's sometimes a temptation to you know try the fancy new shot you know hammer but sometimes keeping it simple is you know really really good okay so neural nets there's some couple ways of motivating this one motivation is know comes from the brain I'm going to use a kind of a slightly different motivation which comes from kind of this idea of decomposing a problem you know in two parts right so this is a somewhat contrived example but hopefully it'll allow us to build up the intuitions for you know what's going on in a neural network okay so suppose I am building some sort of system to detect whether two cars are going to collide okay so the way it works is I have this car at position x1 and it's you know driving this way and then I have another car at position x2 and it's driving this way and I want to determine whether it's safe which is positive or it's if it's gonna collide okay and let's suppose for simplicity that the true function is as follows okay so just measuring whether the distance is at least one apart now this is kind of a little bit you know like what we did in the last lecture where we suppose there was a true function and then see if learning can recover that we're in practice obviously we don't know that true function but this is for kind of pedagogical purposes okay so just kind of making sure we understand what function we're talking about so if X 1 is 1 and X 2 is 3 kind of like that on the board then you're plus 1 so this is like driving in the u.s. this is like driving in the UK and that's fine too but if you're you know too close together then that's bad news ok all right so let's think about decomposing the problem right because if you look at this you know this this could be a kind of a complicated you know function but let's try to break it down into kind of linear functions right because at the end of the day neural networks are just a bunch of linear functions with which are stitched together with some non-linearity so like there are the kind of linear components that are critical to neuro that's okay so one sub problem is detecting if car one is to the far right of - okay so excellent as x2 is greater than equal to one another problem is testing whether car two is a far right of car one and then and then you can put these together by saying if at least one of them is you know one then I'm going to predict safe otherwise they would predict not safe okay so here's a kind of concrete example so 4 1 3 car 2 is a far-right of car 1 so that's a 1 you add these up take the sign that's plus 1 in the opposite direction it's still fine and in this this case both H 1 and H 2 are 0 so that's bad news okay so this is just kind of trying to take this expression which is true function and kind of write it in a kind of more modular way where you have different pieces correspond to different competitions okay so now we could just write this down obviously to solve this problem but that we are in knew what the right answer is but suppose we didn't know what the true function is and we just had data so so we don't actually know what these functions are so can we kind of learn learn these functions automatically so what I'm going to do is we're going to define a feature vector now of X which is going to be a1 x1 x2 okay and then I'm going to rewrite this intermediate sub problem on this follow so X 1 is X 2 greater than 1 is going to be represented as this vector v1 dot V of X where v1 is minus 1 plus 1 minus 1 so you could you pause for a second you can verify that this is x1 minus x2 you know greater than equal to 1 okay so this is just another way of writing you know what we wanted in terms of this like dot product and you can see kind of how this is maybe moving more towards something that looks more general yeah so they're cleaner why is there is this one here so this one typically is known as a bias term which allows you to not just you know threshold on zero but threshold on how many arbitrary number so in the linear classifiers that I have you know talked about I've kind of swept it under the rug generally you always have a bias term that allows you to kind of modulate how likely you're going to predict one versus minus one okay so you can also do it for h2 it's the same thing but just you know we're switching the roles of x1 x2 and Elsa for the sine of final sign prediction you can write it as follows now these are just weights on h1 and h2 ok so now here is the the kind of the punchline is no fraud neural network we're just going to leave v1 v2 and W as unknown quantities that we're going to try to fit through training right we motivated this problem by saying ok in this case there's some choice of V 1 V 2 W that works but now we're kind of generalizing if we didn't know this quantities we just leave them as variables and we can actually still fit fit these parameters ok so before we were just tuning W and now we're tuning both V and W V specifies the choice of the hidden problems that we're interested in and W governs how do we take the results of the hidden problems and come to a final prediction okay so there's one problem here which is that if you look at the gradient of H one with respect to V one it happens to be zero okay so if you look at the horizontal axis is V 1 dot V of X Viroqua access is h1 that function is looks like the step function right because indicator function of some quantity greater equals zero it's one over here zero over here and remember we don't like zero gradients because SGG doesn't work so the solution here is to take some sandpaper and you you know sand out this function to smooth it out and then you get something that is you know differentiable so the logistic function is this function which is a smooth out version of this which rises so it doesn't hit 1 or 0 ever but it becomes extremely close but it kind of goes up in the in the middle and you can think about this as a differentiable or I guess a smooth version of the step function okay so kind of behaves and looks like the step function it serves kind of the same intuition that you're trying to test whether some quantity is greater than 0 but it doesn't have 0 gradients anywhere ok and you can double check if you take the derivative then this is actually has this kind of really interesting nice form which is the value of the function times 1 minus the value of the function and the value function never hits 0 so this quantity never hit 0 ok so so now we can define no knots in contrast to linear functions so remember in linear functions we can visualize it as inputs go in and each of the inputs gets weighted by some W and you get the score ok so this is a linear for what a linear function looks like now neural networks with one hidden layer and two hidden units one to looks something like this where you have these intermediate hidden units which are the sigmoid function applied or the logistic function in this case and to be concrete apply to this wave vector V J times V of X so H 1 is going to be taking the input multiplying by a vector and you get some number here and then you send it through this logistic function to get some number and then finally you take the output of H 1 H 2 and you take the dot product with respect to W and then you get the final score ok so again the intuition is that neural nets are trying to break down the problem into a set of no sub problems where you the sub problems are the kind of the result of these intermediate computations and you can think about these as you know each one is really kind of output of a mini linear classifier H 2 is output of a mini linear classifier and then you're taking those outputs and then you're you know sticking them through another linear class who are in getting the score so this is what I mean by you know at the end of the day it's kind of linear classifiers packaged up and strung together and the expressive power comes from the kind of the composition yeah question [Music] H sub J when there's like no feet the question how do you get H sub J when there's multiple fees there's only one fee of X Oh so this is this is a first component of V of X so this vector there's this is a three dimensional vector which is V of X and it has [Music] function of yeah yeah so that's what kind of my next point which is that one way you can think about it is that the H J's are actually just you know features which are learn automatically from data as opposed to having a fixed set of your features fee right because at this layer w/o it ceases these you know HS which are coming through which look like you know features and for deeper neural networks you kind of just keep on stacking this so you know this output of one set of classifiers becomes the features to the next layer and then the output of that class or it becomes the features to the next layer and so on and the intuition for you know deeper networks is that you know as you proceed you can derive more abstract you know features for example images you start with pixels and then you find kind of edges and then you define kind of object parts and then now you define kind of things which are closer to the actual classification problem yeah what an age to develop the exact same value like do you have to have a bias to start with oh yeah this good question so why don't each one and H to their basically end up in the same place because you know because of symmetry if you're not careful that will happen so if you initialize all your weights to zero and or initialize these weights the same way then they will be kind of moving Lux lockstep so what is typically done as you randomly initialize so they're kind of you break symmetry and then what the network is going to do is it's trying to use learn other it kind of automatically learns the subproblems to be kind of complementary because you're doing this joint Laurie yeah how do I choose a Sigma function so this is so in general sigmoid functions are these or activation functions are these nonlinear functions so the important thing is it's a nonlinear function I chose this particular district function because it's kind of the classic neural net and it looks like the step function which is kind of takes the score and outputs a classification result I should you know responsibly note that these are may be a less in style than they used to be and the the cool thing to do now is to use what is called a rail U or a rectified linear which looks like this and you might ask like why this one well there's no one reason but this this function has less of a kind of this of gradient going to zero problem it's also simpler because of the Sun require Exponential's but there's some I'm going to just leave it at that what the benefit of this function is pedagogical reasons and it's a little bit of a throwback to ok yeah if you read the notes in the lecture slides there's more details on like why you would might change choose one versus another ok so now we're kind of ready to do neuron that learning alright so ok remember we have this optimization problem it's it's a training loss now it depends on both V and W and the training loss remember is average of losses of manger for examples the loss of each of the example let's say we're doing regression is the squared difference between y and the function value and remember the function value is the summation over though the weights at the last layer times activate of the hidden layer and and that's basically okay and now all I have to do is compute this gradient so you look at this and you say okay well you know if you get you know have enough scratch paper you can probably like work it out I'm going to show you a different way to do this without grinding through the chain rule so this is going to be based on the computation graph which will give you insight more additional insight into the kind of a structure of computations and visualize what it means what does a gradient kind of mean in some sense and it also happens that this computation graphs is really at the foundation of all these modern deep learning frameworks like tensor flow and pi torch so this is a real thing now it turns out that you know when I've taught this it many people still kind of prefer to grind out the math I can't really tell why except for maybe you're more familiar with that and so I would encourage everyone to kind of at least try to think about the computation graph as a way to understand your gradient even though initially it might not be no faster and it's not to say that you always have to draw a graph to compute gradients but you know doing it a few times might give you an additional insight that you wouldn't otherwise get ok so here we go so functions we can think about them as just boxes right the boxes you have some inputs going in and then you get some output that's all function is ok and a partial derivatives or no gradients that's the question the following question how much does the output change if the input changes a little bit okay so for example if we have this function that just computes 2 times n 1 plus n 2 in 3 you ask the question like you take input 1 and you just add a little bit Absalon so like point zero zero you ask hmm and then and you read out the output and you say what happens to the output well in this case the output changed by two epsilon additively okay so then you conclude that the gradient of this function with respect to n1 is is y 2 right because the Grady is kind of the amplification if I put in epsilon then I got 2 Epsilon out there graininess 2 or the partial derivative so okay let's do this one so if I add epsilon 2 into then I simple algebra shows I get a change in in 3 epsilon so what's the partial with respect to in 2 [Music] in 3 right ok good so you know you could have done the you know basic calculus and gone that but I really kind of want to stress the kind of interpretation of you know perturbing inputs and witnessing the output because I think that's a useful interpretation ok so now all functions are well not all functions are made out of building blocks but most of the functions that we're interested in in this class are going to be made out of this these five pieces ok and so for each of these pieces it's you know it's a function it has inputs a and B and you pump these things in and you get some output there so this is plus minus x max and the logistic function ok so on these edges I'm going to write down in green the the partial derivative with respect to the input that's going into function okay so let's do this so if I have the function a plus B the partial derivative with respect to a is 1 and the partial derivative with respect to B is 1 ok and if you have - then it's 1 and minus 1 if you have x then the partial is B and a okay everyone follow so far okay okay so max what is this this is oh maybe a little bit you know trickier so remember we kind of experience the max last time so in the max example you have just refresh so so remember the last time we have that we saw the max in the context of the the hinge loss right so you have the max of these two functions which is this which means that you know let's say one is one is a and the other is B so if a is greater than B then the then we need to take the derivative with sorry then okay let me do it this way okay ignore that thing on the board so I just have max a of B okay so suppose a is 7 and B is 3 okay so max Amb and let's say this is 7 and this is 3 so that means a is greater than B so now if I change a by a little bit then that change is going to be reflected by and the output of a max function right because this this region is small and it doesn't matter and in this case if I change B by a little bit then this output change no because like you know three point one two point nine it's all the output doesn't change so the grading is going to be zero there so the max of a function it's partial derivatives look like this so if a is greater than B then this is going to be a 1 if a is less than B this is going to be a zero and you know conversely over here if a B is greater than a then this is gonna be a 1 if P is less than a then this is gonna be a zero okay so the partial of maximum is always 1 or 0 depending on this particular you know condition okay and then the logistic function this is just a fact you can derive it in your you know free time but I had on a previous slide it's just like the sigmoid logistic function times 1 minus a logistic function okay so now you have these building blocks now you can compose and you can build castles out of them it turns out like all basically all functions that you see in you know you know deep learning are just basically bear that build build all of these blocks and how do you compose things there's this nice thing called the chain rule which says that if you think about input going to foreign function and that output going to input a new function then the partial derivative with respect to the input of the output is just a product of the partial derivative changes like you know I think about amplification so for this function amplifies by two times and this amplified this function amplifies by five then that total application is going to be two times five okay all right so now let's take an example we're going to do binary classification with a hinge loss I'm just as a warm-up and I'm gonna draw this computation graph and then compute the partial derivative with respect to W okay so what is this graph so I have W times V of X that's a score times y that's a margin one minus margin max of 1 minus margin zero is the loss okay so now for every edge I can draw the partial derivative okay so here remember the partial derivative here is left hand side greater than you know the right the right branch so one minus margin greater than zero four minus this is a minus 1/4 times this is going to be whatever is over here for this times it's gonna be one of ours over here and by the chain rule if you multiply what's on all the edges then you get the gradient of the loss with respect to W okay so this is kind of a graphical way of doing what you know probably what I did last time which is if the margin is less than greater than 1 then it's everything zero if the margin is less than one deny perform this particular update okay so in the interest of time I'm not going to do it for the simple neural network will do this in section but you know I had a high level you basically do the same thing you multiply all the blue edge the edges and you get the partial derivatives okay so so now you know we've kind of done everything kind of manually I want to kind of systemize this and talk about an algorithm called back propagation that allows you to compute gradients for arbitrary computation graph that means any kind of function that you can build out of these building blocks you can actually just get the so you know one nice thing about these packages like a PI torch or tensorflow is that you actually don't have to compute the derivatives on your own you should be the case that you know before these people would have to crank implement these derivatives by by hand which is really tedious and error-prone and part of why it's been so easy to kind of develop new models is that all that's done for you automatically okay so the back propagation is going to compute two types of values a forward value and a backward value so fi for every node I is the simply the value of that expression tree and the backward value GI is going to be the partial derivative with respect to output of that the value of that node okay so for example fi here is going to be W 1 times Sigma V 1 times V of X and G of that node is going to be the basically the product of all these edges basically how much does this no change the output at that final ad at the very top okay so the algorithm itself is is you know quite straightforward there's a forward pass which computes all the FIS and then there's a backward pass that computes all the G is so in the forward pass you start from the leaves and you go to the root and you compute each of these values kind of recursively where the computation depends on you know the sub expressions and then the backward pass you similarly have a recurrence that gives you the value of a particular a GI of a particular node is equal to the GI of its parent times whatever is on this edge okay so it's like you take a forward pass you fill in all the FIS and then you take a backward pass and you feel a lot of G eyes that you care about okay all right so a section will go through this and detail I realize this might have been a little bit quick one quick note about optimization is that now you have all the tools that you can do you can run s to D on it which doesn't really care about whether you're you're you know what the function is it's just like a function you have it you can compute the gradient that's all you need but one kind of an important thing to note is that just because you can compute a gradient doesn't mean you optimize the function so for linear function it turns out if you define these Lost's functions on top you get these convex functions or convex functions are these functions that you can hold in your hand and it and they have a one global minimum and so if you think about SPG it's going going downhill you'll converge to the global minima and you solve the problem whereas neural nets it turns out that the loss functions are non convex which means I if you try to go downhill you might get stuck in local optimum in a general optimization of neural nets is hard in practice people somehow manage to do it anyway and it works there's a gap between theory and practice which is active area of research okay so in one minute I'm two nearest neighbors it will actually be fine because nearest neighbors is really simple so you can do it in one minute so here goes so let's throw away everything we knew about linear classifier Oh nuts here's algorithm your training is you store your training examples that's it and then the predictor of a particular example that you get is you're going to go through all the training examples and find the one which is closest has an input which is closest to your your input X prime and then you're just going to train you're gonna return my ok so in the intuition here is that similar examples similar inputs should get similar outputs okay so here's an example so suppose we're in two dimensions and you're doing classification and you have Plus over here let's do this Plus and you have your - yeah okay so if you are asking what is the label asides at that point it should be plus because this is closer this is should be - this region should be - this should be plus and you know one kind of cool thing is that if where's the decision boundary so if you look at the point that is equidistant from these and draw a perpendicular that's the decision boundary there same thing over here and so you have basically carves out this region where this is - and everything here is plus okay in general this is what I've drawn is an instance of a Voronoi diagram which if you were given a bunch of points they define regions of points which are closest to that point and everything in a particular region like this yellow region is assigned those same label as on this point here and this is what is called a nonparametric a model which means that the number it doesn't mean that there's no parameters it means that the number of parameters is not fixed the more points you have the more kind of each point is its own parameter so you can actually fit really expressive models I'm using that it's very simple but it's a kind of computation expensive because you have to store your entire training examples okay so we looked at three different models and you know there's a saying that well I guess in school you there's three things study sleep and party or something you have to only pick two of them well so for learning it's kind of the same it can either be fast to predict for linear models and neural nets you can be easy to learn for the linear of models and nearest neighbors or it could be powerful for example like neural networks and nearest neighbors but there's always some sort of compromise and exactly a would method you choose will depend on kind what you care about okay see you next time [Music]