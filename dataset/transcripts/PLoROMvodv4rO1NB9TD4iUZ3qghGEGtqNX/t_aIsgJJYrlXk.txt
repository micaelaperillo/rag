everyone I'm dorsa and this week I'll be teaching the state-based models and the pine is for the next couple of weeks for me to teach the state base models MVPs and games and and after that Percy will come back and talk about the later so the later topics so a few announcements so homework three is out there just make sure to look at that and then the grades for homework one will be coming out soon so just yeah all right so so let's talk about state based models let's talk about search so just to start I was thinking maybe we can start with this question if you can so basically you're gonna let me tell you what the question is and then think about it and then after I don't get this working so so the question is you have a farmer and the farmer has a cabbage a goat and a wolf and it's on one side of the river everything is on one side of the river so you have this river you have a farmer we have the farmer with the cabbage the goat and the wolf yeah and the farmer wants to go to the other side of the river and take everything with himself and but the thing is the farmer has a boat and in that boat can only fit two things so the farmer can be in it with with one of these other things okay so the question is how many crossings can candy farmer do to take everything on the other side of the river and are a bunch of constraints the constraint is if you leave the cabbage and go together the goat is going to eat the cabbage so you can't really do that if you leave wolf with the goat the wolf is going to eat the goat you can't really do that how many crossings should you take to take everything to the other side think about it talk to your neighbors I'll get this working everyone clear on the question [Music] [Music] [Music] [Music] the link doesn't work because I can't connect to internet but alright so okay so how many people think it is four four crossings five six six some people think six seven no solution no solution okay so the point is actually not like what the answer is yes it would come back to this question and try to solve it but I think the important point to think about right now is how you went about solving it so so what were you thinking and what was the process that you were thinking when you were trying to solve solve this problem and that is kind of the commonality that search problems have and and we want to think about those types of problems or it's it's more challenging to answer these types of questions and let's say reflex based type of questions so so that's kind of just a motivating examples that you will come back later and here's an xkcd on this so basically one potential solution is the farmer takes the goat goes to the other side comes back takes the cabbage goes to the other side and just leaves the wolf because why would he need a wolf why would a former need a wolf so if yeah I searched for you probably were thinking about this and I get surprised like an interesting point in it because sometimes maybe you should change the problem your model is completely wrong maybe maybe sometimes you should rethink and go back to your model I try to fix that but anyways so we'll come back to this question so all right so this was our guideline for the class and we have already talked about reflex based model so we have talked about machine learning and how that can get applied and now we want to start talking about state based models this week we're going to talk about search problems next week MVP's and then the week after we're going to talk about games and if you remember the kind of the guideline that we had for the class was we were thinking about these three different paradigms of modeling right we talked about this already so modeling inference and learning so for reflux based models we talked about this already right so well with the model B Roley can be a linear predictor or it can be a neural network so that was the model and then we talked about and friends but in the case of reflex based models it was really simple it was just function evaluation you have you had your neural network and you just go about evaluating it and that was inference and we also spent some time talking about learning so how would we use like what's a gradient descent to try to fit the parameters of the model okay so similar thing with search based models you want to talk about these three different paradigms that we have in the class and then the plan is to talk about models and in France today and then under Wednesday we'll talk about learning and we kind of have the same sort of format next week too so we're going to start talking about modeling and inference on Mondays Wednesdays are gonna be about learning so so just to give you an idea what the plan is all right so so what are search problems let's start with a few motivating examples so so one potential example one can think of is is route-finding so you might have a map and you want to go from point A to point B on the map and you have an objective so you want to maybe find a shortest path or the fastest path or most scenic time and and that is your objective and the things you can do is you can take a bunch of action so you can do things like go straight turn left turn right and then the answer for the search problem is going to be a sequence of actions if you want to go from A to B with the shortest path the answer that one would give is maybe turned right first and then turn left and then right again or any or any of these sequences okay so so this is just a canonical example of what a search problem is there are a few other examples so for example you can think of robot a robot motion planning so if you have a robot that wants to go from point A to point B then it might want to have different objectives for doing that so again the question might be what is the fastest way of doing it or what is the most energy efficient way of getting the robot to do that or or what is the safest way of doing it like another question that we are interested in is what is the most expressive or legible way of robot doing it so so people can understand what a robot really wants so you might have again various types of objectives you can formalize that and then the actions that you can take in the case of the robot motion planning is the robot is going to have different joints and each one of the joints can translate and can rotate so translation and rotation are the type of actions that you can take so so in this case I have a robot with seven seven joints and then I need to tell what each one of those joints should do in terms of translation and rotation this is my robot yes it's a fetch robot alright so so let's look at another example so games this is a fun example so you might think about something like Rubik's Cube or or this 15 puzzle and and again what do you want to do as a search problem well you want to you want to end up in configuration that's desirable right so you want to end up in a configuration where you have this type of configuration of rubik's cube or the 15 puzzle so that is the goal that's the objective and then the action as you can move pieces around here so the sequence of actions might be how you're moving these pieces are on to get that particular configuration of the 15 puzzle ok so again another example of what a search problem is machine translation is an interesting one it's not necessarily the most natural thing you might think about when you think about search problems but what it is actually you can think about it as a search problem again so imagine you have a phrase in different language and you want to translate it to English so what is the objective here well you can think of the objective as going to fluent English and preserving meaning so that is the objective that one would have in machine translation and then the type of actions that you're taking is you're appending words so you start with there and then your appending blue to it and you're appending hostage so so as you're appending these these different different words those are the actions that you're taking so so in some sense you can have any complex sequential task and the sequence of actions that you would get to get to your objective is this going to be the answer for your search problem and you can pose it as a search problem ok all right so so what is different between let's say reflex based models and search problem so if you remember reflex based models the idea was you'd have an input X and then we wanted to find this F for example a classifier that that would output something like like this Y which is labo it's a plus 1 or minus 1 so the common thing in in these reflex based models was we were outputting this this one they this one in this case action being minus 1 or plus 1 again in search problems the idea is I've given an input I'm given a state and then given that I have that state what I want to output is a sequence of actions so I do want to think about what happens if I take this action like how is that going to affect the future of my actions okay so so the key idea in search problems is you need to consider future consequences of the actions you take at the currency like just outputting one thing and so if you rerun it so the question is yeah is it not the same as like I'm rerunning it I asked you to thing and then I rerun it again and then you could do that but that ends up being a little bit of a that would be something similar to a greedy algorithm or like let's say I want to get to the door and I want to find a find the fastest way and and right now if I just look at like my current state maybe I think the fastest way of getting there is going this way but if I actually think about a horizon and I think about how this action is going to affect my future I might call with different sequence of actions yeah all right okay so and then we've already seen this paradigm so let's start talking about modeling and in France during this class so this is the the plan for today so we're going to talk about three different algorithms for for doing inference for search problems so so we're going to talk about research which is the most naive thing one could do to solve some of these search problems but that's the simplest thing we can start with and then after that you want to look at improvements of that doing dynamic programming or uniform cost search based problem another flex pays problem the very fact that in a respect face problem the output that you give does not influence an exchange and it doesn't search yeah that's true yeah so so the output that you get and search problem instance action it actually influences your future yeah that's a good way of actually thinking about it all right so so let's talk about research so let's go back to our favorite example okay so we have the farm area cabbage go-to in both so let's think about all possible actions that one can take when we have this farmer cabbage goat interval okay so so a bunch of things we can do is the farmer I can go to the other side of the river with the boat alone so this triangle here just means like going to the other side of that de river the farmer can take the cabbage so C's for cabbage G's for it go to WC for both so another possible action is the farmer takes a cabbage or the farmer takes a goat or the farmer takes a wolf and goes to the other side of the river you also have a bunch of other actions the farmer can come back the farmer I can come back with the cabbage come back with the goat collaborative so I'm basically numerate enumerate all possible actions that that one could ever do and sure none of some of these might not be possible in particular States but I'm just creating this library of actions things that are possible yeah so then when we think about this as a search problem we could create a search tree which which basically starts from an initial state of where things are and then we can kind of think about where we could go from that initial state so the search tree is more of a what if what if tree which which allows you to think about what are the possible options that you can take so conceptually what it looks like is you're starting with your initial state where everything is on one side of the river so those two lines are it is the river white and you can take a bunch of actions right like one possible action is you can take the cabbage and go to the other side of the river and you end up in that state and that's a little not a good state so I'm making that red well why is that because the wolf is going to eat the goat that's not that great okay and every action every crossing let's say let's say every crossing takes cost of one so that one that you see on the edge is the cost of that action okay so that didn't really work that well what else can I do well I can I can do another action I can I can from the initial State I can take the goat and go to the other side of the river that ends up in this configuration from there the farmer could come back take the cabbage go to the other side end up in this configuration the farmer can come back that's again not a great States because cabbage and goat are left on the other side of the river good is going to eat the cabbage that's not great what else can I do well the farmer can come back with the goat and once the farmer comes back with the goat the farmer leaves the goat takes the wolf goes to the other side comes back gets the goat again and then okay so so how many steps is to stay cool one two three four five six and seven so so the ones mice are seven that was a right answer and that is kind of the idea of getting to this so you could have this giant tree where you go to different states but we can actually have like a counter that tells you if I visited that state and if you have visited that state maybe you don't want to go there again because because you have already explored all the possible actions from there you're not done with this tree though right like I found this this good state here but maybe there's a better way of like getting there I don't know yet I haven't explored everything so so what I can do is I can actually explore all these other things that that one could do not gonna go over them but there is another solution and turns out that other solution also takes seven steps so it's not necessarily a better solution but but you got to explore all of that because there could be another solution later on that that is better than the seven steps all right the wiser okay all right so so this is how the search tree looks like oh that's a very good point thank you for saying so for CPD students I'll try to repeat the questions I always forget this I'll try to repeat the questions the question was was the slice or the slides are up they are up they should be up okay all right so going back to our search problem so we can try to formalize this search problem so let's actually think about it more formally so what are the things that we need to keep track of so so we have a start state so let's define s start to be the start state in addition to that we can we can define this function called actions which returns all possible actions from States so actions is a function of state if I'm in a state it basically tells me what are the actions I can take from I can can you find this cost function so this cost function takes a state in action and tells me what is the cost of that and in this example the cost of crossing the river was just one but you can imagine having different cost values we can have a successor function that basically takes a state in action and and tells us where we end up at so if I'm state s and I take action a where would I end up at and that's the successor function and then we were going to define and is end the function which basically checks if you're in an end state where we don't have any other possible actions we can you can think of it as a way of like finite state machine type of type of way of looking at it yeah so like we use a similar type of formalism for MVPs and games too so it's just good idea to get like all these hormones outside but start state transitions cost position and action an extravert this thing so then so so the action okay so so action depends on the state so you start from start state where you haven't taken any actions right and then from that start state then you can think about all possible like right up there so you're in that start state and then you can think about all possible actions you can take and then those actions depend on current state but they don't depend on the future State right so based on my current state everything is on one side of the river I can think about all possible actions I can take and where I know where I end up at and then after that's like the next action depends on that that state so it's a sequential thing okay yes you have all the information on the actions and the cost that you could do beforehand how is this conceptually different than like a mini cost flow convex optimization okay so how is it different from a kind of convex optimization type of row so we have you have an objective here and you can think of what that objective is and based on what that objective is you can have different methods for solving it right so so you can basically formulate this as an optimization problem where you saw you look for the solution to a search problem as an optimization problem that's perfectly a perfect way of doing it and then we are going to talk about various types of methods for solving this problem today yeah all right so so let's look at another example so this is a transportation problem this so okay so basically what we want to do is we have straight blocks from 1 through n so 1 2 3 so on so these are straight thoughts and what we want to do is we basically want to travel from from 1 2 to some n number and we have two possible actions so at any state let's say on state s at any state I can either walk and if I walk I end up in s plus 1 so if I'm in 3 I'm going to end up in 4 and walking takes 1 minute or I can take this magic and if magic tram takes any state s 2 2 times s so if I mean 3 then I'm going to end up in 6 by taking the magic trap and the magic time always takes 2 minutes doesn't matter from that so so if I'm in to all end up in 4 or 5 min 5 I can end up in 10 by taking the trap ok so so I have two possible actions in any of these states and what I want to do is I want to go from 1 to N and then I want to basically do that in the shortest time possible so we did with the least amount of costs there's a problem all right so so this is kind of like what the search problem is so what we want to do is first off you want to just formalize it and I'm gonna do that here I'm not gonna do wife solutions cuz I'm not Percy and I did that once and it was a disaster so we are going to yeah I've taped these in 2018 but basically you're going to go over it together so so let's just do that so we're going to define the search problem this problem so we're going to define a class for transportation problems you're going to separate our search from our algorithms because remember modeling is separate from inference so let's just have a constructor for this transportation problem it takes n because we are at n box okay so n is the number of blocks well all right so so then you have miss to have a start state we are starting from one so block one and then we need to define is end state so as n state basically checks if you have reached an or not because we have to get to there and in okay alright so what else do we need so we have a successor function you also have a cost function I'm gonna put both of them together cuz that is just easier so the successor in cost function I'm saying let's just give it state s and then given a state it's going to return this triple of action new state costs so I give it a state as the initial state and then it just returns all possible actions with the new states I can end up at and how much does that cost yeah so what are my options well if I'm in state s I can walk to s plus 1 that cost 1 if I'm in state s I can take the tram I can end up in to s and that costs to okay so that's how I'm creating my Triple C and I need to check if I don't pass the enth walk remember like you have n box so we don't want to pass then walk ok so so that's just to make sure that we don't pass it so we are still below tenth block and then this is what my successor in cost function will return the debt triples okay so let's just return that okay so that is my transportation problem let's make sure it does the think the way we want it so let's say we have 10 blocks and now I want to print my transportation of my successor and cost much analysis let's say I'm returning successor and cost for 3 what should I get so from 3 I can have two actions right I can either walk or I can take the tram if I walk it costs one if I take the tram it costs two I'll end up in 4 or 6 let's just try I don't know 9 if I'm a state 9 I can only do one thing I can walk right cuz remember the the block is number of blocks is 10 and I can't go beyond that so alright okay so that was yeah let's go back here so that was just defining the search problem yeah and I haven't told you guys like how to solve it right this is we were just doing the modeling right now so we just modeled this problem just coated it up modeling it means what is this what are the actions what is a successor function what is the cost function defining an is end function say but what the initial state is okay so so now I think we are ready to think about the algorithm in terms of like going in solving these types of search problems so the simplest algorithm we want to talk about is backtracking search so the idea of backtracking search is maybe I can draw a tree here is you're starting from an initial state and then you have a bunch of possible actions and then you end up in some state and you have a bunch of water possible actions let's say you have two actions possible and this can become this exponentially blows up so I'm going to stop soon all right so so create this tree and this tree has some branching factor it's number of actions you have at every at every state and then it also has some depth so that is how many levels you go down to let me just define that by D okay and now their solutions down in this no it's right so so we want to figure out what those solutions are and backtracking search just does the simplest thing possible what it does is it starts from this initial state and it's going to go all the way down here and if it doesn't find a solution it's gonna go back here and then try again and try again and it's gonna go over all over the tree because there might be a better solution down here too so it needs to actually go over all of the truth okay so I'm going to have a table of algorithms cuz you're going to talk about a few of them yeah algorithms what sort of costs they allow in terms of time how bad they are in terms of space so if you've taken an algorithms course like some of these are probably familiar so alright so we talked about Mack tracking search tracking search that is basically this algorithm that goes through pretty much everything and it allows any type of costs so I can have any costs right I can have pretty much any cost I want on these edges because I'm going over all of the tree it doesn't matter what these costs okay so how bad is this in terms of in terms of time so in terms of time I'm going over the full tree like going over the full tree then then this is going to have this exponential blow-up where I'm looking at order of B to the D where B is again my branching factor and D is the depth of the tree because in terms of time this is not a good algorithm maybe in terms of time I have to go over everything in the tree and that's the size of my tree and in terms of space in terms of space what I mean is I need to figure out what was what was the sequence of actions I needed to take to get to some solution so let's say that my solution is down here my solution is down here then for mean or like I hate to store a bunch of things to know how I got here and the things I need to store the parents of this node and that is depth of them so in terms of space this algorithm takes order of D because because that is like the things that I need to store in my memory to be able to recover everything between the space be bigger your B to the D as well because until you get that you need to have the space to have everything right no so actually we will talk about breadth-first search later which does require have a larger space so so the reason you can forget it is the only history that I need to keep track of is this particular branch right I don't need to figure out like I don't need to keep track of like actually the history of all these other notes I can throw those out but or something else like breadth-first search where we will talk about in a few slides you actually need to keep track of like the history of everything else so so let me get back to that in a few slides but for this one make the clean ideas yeah like I want to know how I got there to know how I got there I just need to know like the minimum cost to reach your point or is it to find whether like so it depends on what your objective is like it really depends on what the search problem is asking so so in the case of that farmer good example the search problem is asking you want to move everything to the other side of the river so you have that criteria and you want to find the minimum cost one so you also add other criteria so it really depends on what the search problems asking and some of these notes might be solutions some of them might not be solutions so it's a really difference all right so so let's just look at these on the slide so the memory is order of T it's actually small it's nice in terms of time this is not a great algorithm right because even if you're branching factors too if the depth of the tree is 50 then this is going to blow up like immediately so a lot of these tree search algorithm said you're going to talk about like they have the same problem so so they pretty much have the same time complexity if you're going to just look at very minimal improvements of them and then after that we'll talk about dynamic programming and uniform cost search which are polynomial algorithms that are much better than okay all right so let's actually let's go back to a tram example and let's try to write up what backtracking search does so alright so we defined our model our model is the search problem this particular transportation search problem it could be anything else and now we're going to kind of have this main section with where we were going to put in like our algorithms in it and you're going to write them as general as possible so so we can apply them to other types of search problems yeah so let's define backtracking search it takes a search problem it can take the transportation problem okay all right so and then we're going to basically in backtracking search what we were doing is we were recursing on every state given that we have a history of getting there and the total cost that it took us to get there okay so so at the state having gone some history and some accumulated cost so far we are going to basically recurse on that state and look at the children of that state okay so so we're going to explore the rest of the subtree from from that particular state all right so how do we do that well we got to make sure that you're not in an end state or if you're an in-state like we can actually update the best solution so far okay so let's put that for to do so so the bunch of things we need to do we need to figure out if we are in an end state if you are well we gotta we gotta update our best solution if you're not in an end state then we are going to recurse on children all right so you can do that later and then in general this recurse function is going to we're going to call it on on the on the start State so let's actually do that too so so what backtracking search does is it calls this recursive function on the initial State dead behalf with history of none right if you don't have any history yet and and cost this zero so far because we haven't really gone anywhere so so we start with a start state we call recurse on it okay and how do we recurse on children well we have defined this this successor and cost function so by calling that successor and cost function on state then we can get action new state and costs so so we get this triple of action news dating cost and then we can basically recurse on the new state I'm not putting the histories right now in this code so so you need to keep track of the history too but let's just not worry about the history oh I guess I'm putting it in this one I mean the later ones I will not put them but but basically the history is keeping track of like how you got there and total cost is going to be what you've got so far costs the cost of this is new state action yeah okay so we need to keep track of the best solution so far so I'm just going to find a dictionary here just to make sure that we keep track of it and we'll Python scoping okay and then the place we are going to update our best solution so far is that to do that is left right so if you're in an end state then we can actually update the best solution so far yeah and what do we want in our best solution well we want to know what the cost is so so you can start with cost of infinity and anything below infinity is better and then we're going to start with a history of empty but we're going to throw up that's history too so that's the initialization of best solution so far then we are going to update that right if you're in an end state if the total cost that we have right now is smaller than the best solution so far then you're going to update that best solution and then you're going to update its history with whatever its histories all right and that's it that's backtracking search okay so let's just make sure it does the thing so to do that we are going to actually know we got to return the best solution so far all right so now we have defined this transportation problem now what I want to do is I want to call backtracking search on the transportation problem yeah so that all sounds good I need to write a print function also so to be able to print things so I'm going to just write a generic print function that we can call on any of these types of problems so let's let's define a print solution function that just like prints things the way you want them so we get the solution and we're going to just unpack the cost and history and just print the constant history nicely you all right so I can i can use this print solution for pretty much all the other algorithms we'll talk about today too and you're going to talk about how we get there with the history so now I have my print function I have my backtracking search algorithm I've defined my transportation problem I can just call it on this transportation problem it's been ten blocks so as you guys can see here so the total cost is six so what this means is for going from city 1 to city to city 10 then this is the best solution I got a walk walk walk walk and then after that take the tram guys like I end up in five and then after that it's actually worth taking the tram and paying constant let's try it out for 20 what do you think is the answer for 20 so similar here for a walk walk walk until we get to five then we take the tram then we take the tram again across the state and then if it is 100 it's a little bit more interesting if you have 100 so you're walking and then you're taking the tram and you get to 24 and you want you have that one step to get to 25 which is a good stay because then you can just multiply that by 2 so so you walk for that one step and take the tram again so what if I want to try out a much larger number of blocks so is this gonna work no cuz cuz remember that time was order of B to the D that wasn't that great so let's try that Oh because maximum recursion to him we can fix that so let's try fix impact so if you can't you can set your recursion limit to be whatever so if we try that is this gonna work [Laughter] well now it's just gonna take a long time right it's not gonna give you an answer because it's gonna just take a long time so all right okay let's go back here alright so that was backtracking search right so all we was doing was just going over all of this tree and it was taking exponential time as you saw and we just tried it out on that transportation problem that really fine so we just defined a search problem we use this really simple search algorithm to find solutions for that and then that's what we have so far so so now what we want to do is we want to we want to come up with a few better improvements of this backtracking search again don't get your hopes up it's not that big of an improvement but but we can do some something better so so the first improvement you want to make is by using this algorithm called depth-first search so you might have heard of it the FS or depth-first search okay so the restriction that DFS puts in is that your cost has to be zero so your cost has to be you actually draw a line between them so okay so so we're talking about the investor and the restriction is the cost has to be zero so so what the offense does is it basically does exactly the same thing as backtracking search but once it finds a solution down here then it is done it basically doesn't like explore the rest of this thing and the reason it can do that if the cost of all these edges is zero so if the cost of all these edges are zero then if I find a solution I found a solution I don't need to like find its better solution that's because that that is good enough like anything like fine also has a cost of zero so my dad's all just returned to so an example of that is if you have Rubik in rubik's cube like if you find a solution then you have found a solution right there are million different ways of like getting to a solution but like you just want one and then if you find one then you're happy you are done okay so as you can see this is a very very slight improvement to backtracking search what happens is in terms of in terms of space it's still the same thing so it's order of D so in terms of space nothing has changed it's pretty good its order of D in terms of time in practice it is better right because in practice if I find a solution I can just be done don't worry about the rest of the tree but in general if you want to talk about it in theory then the worst case scenario is just trying out all of the trees so you write it as force case scenario it's order of B to the D so so nothing has really changed in terms of in terms of exponential blow-up doll that tree assumes that you applied the subproblems to not overlap all right because you're kind of branching of a kind of different states but in fact a sub-problem could overlap so somebody to trim problem you can get to a same place with different history but the rest are the same yeah so you can it's so the question is yeah do subproblems overlap here or they don't so you could actually have it in a setting where two subproblems do overlap but you could actually add this this extra like constraint that says if I visited the state and don't add it to the tree so so you have that option or you have the option of like going down the tree with some like particular deaths and not trying out everything in the setting that we have here yeah like you're basically trying out all possible like I'm talking about the most like general form you're going over all the states and all possible actions that would come alright so that was CFS okay so the idea of the FS again as you're doing backtracking search and then you're just stopping when you find a solution because because cost is zero here so in terms of space order of D in terms of time it's still order of utility alright so that was the FS we have another algorithm called breadth-first search BFS and this is useful when cost is some constant but it doesn't need to be zero it's just so some some positive constant so what that means is all these edges have the same cost and that cost is just C the same cost so the idea of breadth first search is we can we can go layer by layer like like we're not going to try out the depth instead what we can do is we can go layer by layer try out this layer and see if you find a solution here remember the tree doesn't need to go all the way down here the tree could end here or look at any of these and any of these notes right like I can have like a tree that looks you do like this I have a solution here this tree doesn't need to be this nicely formed like I can have a tree that looks like this okay so if I have a tree that looks like this with breadth-first search I'm gonna try out this layer see if this guy is a solution if it's not I'm gonna try this guy this is the solution if not I'm gonna try here here and then when I find a solution when I get here I'm done right that's like if I find a solution here I know it took to see to get here like two of these see values and if there is any other solution anywhere else and this subtree or in this subtree those solutions are going to be worse than this because they're gonna just like take like they are going to have a higher cost so because the cost is constant throughout so then it's it's useful if your solutions are somewhere like high up in this tree and then you can find it so in terms of time I get some improvements here because I can call this steps it's shorter depth D small D I'm gonna call it a shorter depth small D and in terms of time it's still exponential but it's order of B to the small D and this is actually a huge improvement because if you think about it the trees exponentially become larger so these like lower levels are a lot of things that you need to you need to explore if you have like branching factor of 10 the next layer has a hundred things in it right so so going down these layers is actually pretty bad so so the fact that with breadth-first search i can improve the timing and then limit it to a particular depth that's pretty good still exponential but pretty good if you have no negative cost so that way you can also assume this yeah you can assume that this is best solution yeah exactly so you're assuming that there are no negative costs so at this point I know this the best solution undone like I call it and I don't know I guess for anything else the problem with breadth-first search is there's a question there sorry so same yeah we are assuming all the costs are same because maybe like all the costs are one if I don't assume that but all of these costs are 100 and then like there might be like like some water like yeah you need to explore the rest if they're not the same basically alright so so the problem with BFS is in terms of memory we are losing in terms of memory you need to actually keep track of the history of all these other like all the notes that you have explored so far so in terms of memory this is going to be order of B to the D kind of similar to the time and then the reason is I have explored this guy and then after exploring this guy I need to still have like a history of where it's going to go because next time around when I try out the Slayer I need to know everything about this parent and I'd like when I even explore here and this is not a solution I need to store everything about this because maybe I don't find a solution in this in this level and I need to come down and then I come down I need to know everything about these notes so I need to actually store pretty much like everything about the tree until I find my solution and then that's where you lose like in Brett's first search in terms of space it's not going to be that great so in terms of space it's now order P to the D it's a lot worse than what we have had in terms of time it is better it's still exponential it's better okay all right okay so now let's talk about one more algorithm and then after that we we jump to dynamic programming where is a question back here yeah so it is exponential I agree so D can be the same as Big D but in practice if small D is not the same as Big D you're winning a lot because because yeah these lower layers are so bad that that people actually like to call the call the fact that or don't be to the small D EFS be big worst case in there for the time and awkward yet so Deena fest needs to go all the way down to these lower lower levels what vnfs can stop at every level because it's doing a level by level yeah so the reason is yeah so like if you're saying okay so in DFS we were also saving some time right like why aren't you like calling that out and then the reason is with DFS you still need to get to these like more layers and that is the like that is the place that you're losing on time so so the fact that you're still like losing on time and sure like you haven't explored these other ones but you have already got to these lower trees like so far that's pretty bad so that is why or they're free to the D universe alright so this last Tyler thing I want to talk about this is an idea that tries it's a cool idea it actually tries to combine the benefits of VFS and DFS and then this is called DFS iterative deepening so what this algorithm does is it basically goes level by level same SPFs because then that way if you find a solution you're done everything is great right but with what it does is for every level it runs a full DFS and it feels it take it's gonna take a long time but it's actually good because again if you find your solution like early on it doesn't matter that you have ran like a million DSS's so far so um so it's kind of like an analogy of it is imagine that you have a dog and that dog is DFS and it's on a leash and you have like a short leash and when it is on that leash it's going to do a DFS and try out and search all the space and it doesn't find it anything so it comes back and then you're going to extend the leash a little bit and it's gonna do everything and like to search everything and do a DFS comes back doesn't find anything you extend the leash again so so that's the idea like extending the leeches this idea of extending your your levels okay so so how does how does DFS iterative deepening in yes bottom of the tree it's even worse than both of mine yes exactly yes that's okay that's a good point so the point is the point out that mentioned this if your solution is like here you're screwed it's worse than the FS or BFS right you're doing all these DFS's through like a bigger like higher level BFS and your and and it's it's a terrible situation but again in practice like we were hoping the solutions are not gonna end up like down the street but yeah if the solutions are down the tree then you're not like reading anything wait about using the SS like problems do you think the FS area name would be useful in general if you okay so the question is yeah so in what problems do we think the FSA deepening is useful in general if like there are problems that I think BFS is going to be useful usually BFS iterative deepening is useful the reason I would think that is like there is some structure about the problem that I would think I would find my solution earlier so if I if I have some reasons some some reasons about the problem about the structure of the problem and I think solutions are low depth I should use some of these algorithms and a DFS video rate of deepening in terms of space it helps to so might as well use that all right so so in terms of space it's going to be order of small Deena so in terms of space or their small D and then in terms of time it gets the same benefits of it gets the same benefits of BFS so so that's that's nice and then again like because it's has this BFS out of the loop it has the same sort of constraint on it cost it's gotta be a constant constraint guys pause alright so that is our table and again in looking at this table in terms of time you're just not doing well right like we have this exponential time algorithms here and we could avoid the exponential space reducing something like the FS iterative deepening but still this time thing is it's just not that great okay and what we want to do in a now is you want to talk about search algorithms that bring down this exponential time to polynomial time somehow and then there is no magic we'll talk about how and dynamic programming is the first so so the way iterative deepening works is it sets the local say level is 1 so if level is 1 I'm gonna do a full DFS okay because I'm doing a full DFS interpretive space it's the same as DFS in terms of space I just it's just the same as the length where we find a solution let's see the length where I find a solution is small D so now I say level is too many the level is - I'm gonna do a full DFS yeah so when I do a full DFS then in terms of space I need to I need to just remember my parents so that's why it's border of T in terms of space and in terms of time its its order of B to the D because if I find my solution here I'm done I don't need to like explore anything else and and that is exponential about the exponential in this smaller depth as opposed to longer that's similar to similar to BFS I sorry I still don't understand why let's say like that's it okay so that's a very good question so yeah I think I know it so you're asking small D small D was the same as Big D if I had my solutions down here oh why am I like differentiating here between a small D and Big D right is that what you're asking for away quite large like smoothies log oh I see what you're saying so you're saying okay like when I'm doing when I'm performing DFS iterative deepening then I'm doing DF DF SS so sure it's order of B to the D for each of them but then I'm doing D of them and if these really large I should put that here sure I do agree that is the right time but again like in the case of this exponential this is so bad that we are just dropping that like don't even worry about that extra t-that's come see but it is true you need to have that extra D like in general if you want to talk about it I don't want to move on to dynamic programming but last question just on top of that presumably though you're saving the work that you've done during the prior iteration so you're not really computing anything larger than the capital d correct yeah that's right the worst-case scenario is or to the beat all right so let's move to dynamic programming okay so so what does dynamic programming do so maybe I can I'll still use this cuz I might use this later okay so you know erase my tram on here okay so the idea of dynamic programming we have already seen this in the first lecture is I have a state s and I want to end up in some end state but to do that I can take an action that takes me to s prime right I can I can end up in s prime by cost of this a I can take an action that not ends up in s prime and then from there I can do a bunch of things I don't know what but I'll end up in some end State and what I'm interested in actually computing is for this state s is to find what is future cost of and this part of it is future cost that's fine and I don't know what it is but I can just leave it as future cost of s prime so if I want to find what future cost of s is maybe I should say feels a little bit to the right one sense right cost of si for this edge erase this what I'm interested in finding is future cost of my stakes well what is that equal to well that's going to be equal to this cost of Si right like at state s I'm gonna take action okay so it's gonna be cost of Si plus future cost of s Prime again I don't know what that is but that's future Dorset's problem so this is future cost of s Prime and then you might ask well what is a where does a come from how do I know what a is I don't know I'm gonna pick an a that minimizes this some around it okay so future cost of s is just going to be equal to minimum of cost of Si plus future cost of s prime over all possible actions and it's going to be zero if you're in an end State this is end of true okay so if I already know I'm in an end State and there is no future cost that's going to be equal to 0 otherwise future cost is just going to be cost of going from s to the next state and then future cost so that is just how one would go about formalizing this problem as a dynamic problem and they're not dynamic programming problem and then how do I find what s Primus well I wrote this successor and cost function my code remember like we know how to find a successor given that we are in state s and we are taking action a so s prime is just calling that successor function over SN a alright so let's go back to some route finding example so so this is a slightly different route finding example so let's say that you want to find the minimum cost path from going a city 1 to some city end in the future moving forward we can always just move forward and it costs CIJ to go from city I to CDJ ok so this is this is my new search problem so so this is kind of how the tree would look like so if I want to draw this research for this I can start from city one I can end up in city 2 or 3 or 4 then if I'm a city two I can end up in 3 or 4 upon 3 I can end up in or right like this is how I can have a much larger version of it if I'm talking about going to city 7 then I have this type of tree and by just like looking at this tree you see all these sub tree is just being repeated like like throughout right if just looking at five like future costs of five it's gonna be the same thing this is gonna be the same thing throughout and if I use like something liked research said we have talked about then I have to like go and explore like this whole tree and then it's gonna be really time-consuming so so the key insight here is future costs this value of future cost only depends on state okay so it only depends on where I am right now and because of that maybe I can just store that the first time that I compute future cost of five and then like in the future I just call that and then and I don't like recompute the future cost of life so so the observation here is future costs only depends on current city so so my state in this case is current city and then that state is enough for me to compute future costs all right so so if you if you think about what we have talked about so far like we have thought about like these these search problems where the stage we think of it as the past sequence of actions in the history of actions you have taken and all that but right now for this problem like see is just current city that's enough okay so and because of that you're getting all these exponential savings in time and and space because again I can compute future cost of five there and collapse that whole tree into this graph and just go about solving my search problem in this graph as opposed to that that whole tree yeah so so that's that's where you get the savings from dynamic programming and I just want to emphasize that again all let me actually do this so so the key idea here is like what I was saying there's no magic happening here the key idea here is is how to figure out what your state is it's actually important to think about what your status in this case we are we're assuming the state is summary of all parts all past actions that we have taken sufficient for us to choose the optimal future okay so so that's like a mouthful but basically what that means is the only reason dynamic programming works and for this particular example we just saw is the state the way we define it is enough for us to plan for the future I might have a different problem where the state like I defined a state in a way that it's not enough for me to define for future but if I want to use dynamic programming then I got to be smart about choosing my state because because that is the thing that decides for the future so so for example for this problem like I might visit city 1 then 3 then 4 and then 6 and and for solving this particular search problem I just need to know that I'm in City 6 that is enough but like maybe I have some other problem that requires knowing 1 3 4 and 6 and then because of that maybe I need to know the full tree ok so so this is where the saving comes from like figuring out what the state is and and defining that right all right so so we'll come back to this notion of state again and think about the state a little bit more carefully but maybe before that maybe we can just implement dynamic programming real quick all right so let's go back to our tram problem I'm back to the tram problem and let's implement dynamic programming ok so how do we do this you're basically just writing that like math over there into code that that's all we're doing so so we're going to define this future cost if you're in an end state we're in return 0 if you're not in an end state we're just going to add up cost plus future cost of s Prime how do we get S Prime well you're going to call this success a success and cost function so we can get action new state and the costs and then you're going to take the minimum of them over over all possible actions so minimum of cost plus future cost of new states that is literally what you have on your board right and we are returning a result so that is Futurecast what's your dynamic programming did it should it should return future cost over initial state right starts you and you returned the history if you want in this case I'm not returning to history okay so how do I get savings well I got to put a cache right that's the only way I'm gonna get savings so that is where I put the cash and and if I if the state is already in the cache I'll just call my cache otherwise question go supposed to go how are we getting future costs how are we getting so future caustics and States but what actually this would like we have to have like a function implemented if I calculate your costs or is that like so the future cost is going to be yes oh so we have this function right future costs overstate but you're gonna call future costs so future cost over state is going to be equal to cost of state and actions in this function I'm saying all possible actions try that out plus future cost of s Prime and s Prime comes from the successor and then cost function and a successor and cost much all right so an and yeah and so so we do the caching the proper caching type of way of doing this too and now we have dynamic programming so we can basically call this over our trying problem so I'm gonna I'm gonna move forward okay so let's do print solution dynamic programming over our problem you can again play around with this the only baby I'm taking this is if it gives me the same solution has backtracking search because I knew how that works right so let's just call it on ten and yeah it gave me the same the same answer so I can pull your own with this okay all right so let's go back okay so one assumption that we have here to just point out is we're assuming that this graph is going to be a cyclic so so that's that's an assumption that we need to make when we are solving this dynamic programming problem and the reason is well we need to compute this future cost right for me to compute future cost of s the SS prime I need to like have thought about sorry for me to compute future cost of s I need to have thought about future cost of s prime so there is kind of this natural ordering that exists between my states so if I think about an example over there are cycles then then I don't have that ordering right if I want to compute it let's say I want to go from A to D here and C so if I want to compute future cost of B I don't really know if I should have computed future cost of a before or C before or what order should I have gone to compute like future possibly so so you actually need to have some way of ordering your states in order to compute these future costs and apply the dynamic programming so that's why like we can't really have cycles like let me let me think about this algorithm but we are going to talk about a uniform cost search which actually allows us to have cycles like in a few slides so the wrong time all this is actually polynomial time into order of states so order of N yeah well remember and it's a number of states all right so all right so let's talk about the idea of States a little bit more because I think this is this is actually interesting right so so let's just reiterate what is a state state is a summary of all past actions sufficient to choose future actions optimally okay so so everyone happy but what status so now what we want to do is we want to figure out how we should define our state space because again this is an important problem right like how we were defining state space is the thing that gets the dynamic program you're working so so we got it we got to think about how to do that so so let's go back to this example and let's just change that a little bit so so this is the same example of I'm going from city one to see the end I can only move forward and it costs CIJ to go from any city I to say DJ and I'm gonna add a constraint and the constraint is I can't visit three odd cities in a row so what that means is maybe I'm in state 1 and then I went to state 3 or cd1 I went to city 3 and then after that can I go to City Simon well no based on this constraint that I've added I can't do that right so I wanted to find a state space that allows me to keep track of these things so I can solve this new search problem with this new constraint so so how should i how should i do so in the previous problem when we didn't have the constraint our state was just the current city like previously you just cared about the current city and the reason we cared about the current city is like like we were solving the search problem like they end up in a city you need to know how I'm going where I should go from 3 so I should I should have my current city in general right so so for the previous problem without the constraint current city was enough but now current city is not enough right I actually need to know like something about my path ok yeah that's actually a very good point so one suggestion is have a count of how many odd States another maybe like and different maybe the first thing I would come to our mind is something simpler so maybe we say well the state is similar to its like the state like when we say well the state is previous city and current city okay so this is one possible option for for my state right cuz cuz if I have this if I have this guy as my state and then that is enough right like if I my current city is three I know my previous city was one I know I shouldn't go to seven like that's enough for me to make like future decisions yeah but there is a problem with this well what is the problem so I have n cities right so so current city can take any possible action and n possible states previous city can also take and possible options has impossible options so if I think about the size of my state space it is n squirt if I decide to choose this state but if I decide to choose this state I'm going to have n squirt States and remember we are doing this dynamic programming thing like we need to actually like write down like like how to get from all those states that's gonna be big but there is an improvement to this and that's the improvement that you suggested which is I don't actually need to have this whole giant previous city which has n options I can just have a counter to just know whether the previous city was odd or not like that's enough right like fight I don't care if it was one or three or whatever right like I just care to know if previous city was odd or not so so another option for alright it's here another option for my state is to know if previous was odd or not okay and I need to know my current city again right currency do we need that because like we need to know how to get from there and then this brings down my state space like how does it bring down my state space because well what's the size of my state space this guy can take and possible states if my previous city was odd that's too like so I just brought down my state space from something that was N squared 2 to N and that's a good improvement so in general learning you're picking these state spaces you should pick them mini more like sufficient thing for you to make decisions so it's got to be a summary of all the previous action previous things that you need to make future decisions but pick the minimal one because you're stirring these things and it actually matters to pick the smallest one so so here is an example of like exactly that so so my state is now this tuple or whether the previous city was odd or not and my current city so if I start at city one well like I don't have a previous city and I'm at City one I could go to City three and I end up in odd and three I could try to go to City seven well that's not possible because now I have good three state and end and up here and there like the rest of the tree you can have another example so so the way I'm counting this is how so my state is a tuple of two things right if the previous city is odd or even I have two options here it's either odd or even that's too and then my current city and I have n possible options for my currency they could be sitting one city to city three so that's n so I have any options here I have two options here that's why I'm saying my whole state space is two times okay all right okay so let's try out this example let's not put it in just talk to your neighbors about this and then maybe you have ideas just let me know in a minute so okay so what is the difference here so you're traveling from city one to CDN and then the constraint has changed now we want to visit at least three odd cities so that's what we want to do and then the question is what is the minimal state talk to your neighbors all right any ideas any ideas what is a possible state like it don't worry about the minimal event like for now like what do I need to keep track of number of this number of odd City okay so is that it do I need to just know number of odd cities so number of what I meant is I also need to have chrome City right so okay so one possible option for this new example I'm gonna write that here it is I wonder is it at least three odd cities I also need my to know my current city for any of these types of like not any of these types of problems look for these particular problems that I've defined here I need to know where I am so I need to know what my current city is so so that is like that is given what I need to talk okay so I want to see at least three odd cities so one possible option is to just have a counter I keep counting number of odd cities so this could be one potential yes or maybe one three one so okay so the question is do the cities need to be different the way they are defining the problem is we're moving forward if I'm in one like I can just move forward I can't like say add one or I can't like go back so so we're always moving forward but when we talk about the state space we're talking about the more general setting like some of some of that 2n might not even be possible that's alright so so this is one option but I can actually do better than this and then you're done right so a suggestion there is we can you didn't have like you can use at least three odd cities then you need at least two art reduced and at least one art city and then you're done and one way of formalizing that that's exactly right like I don't care if I have four art cities now or five art cities like as long as I have like a buff three that's that's good enough right one odd city to our cities three art city and that is just three Foss like like that's enough for me okay so if I had this then the state space here is going to be an options here and number of odd cities it's around and over two so it's going to be N squared over two but if I use this this new suggestion where I don't keep track of four or five six seven I just keep track of one two and three plus then my state space ends up becoming three times N and I can formally write that as s is equal to minimum of number of odd cities and three and then current cities needs the current city and with this state space then size is equal to three so I just pick up brought down and squared to n and that's a nice yes not also need an option for zero visibility we're starting from city one so you're already counting that in but yeah like if you have zero answer all right so haha okay so that was that this is how it look like like you can think of your state space like this again has a two pole of I visited one two three and and then the cities I have another example here you can think about this later and yeah like work it at home but basically the question is again you're going from city 1 to n and you want to visit more odd cities than even cities what would be the minimum states but you can talk about it offline so the summary so far is is that state is going to be a summary of past actions sufficient to choose future actions optimally and then dynamic programming it's not doing any magic right it's using this notion of state to bring down this exponential time algorithm to a polynomial time algorithm and then the trick of using memorization and with the trick of choosing the right state okay and we've talked about dynamic programming and how it doesn't work for cyclic graphs and now we want to spend a little bit of time talking about uniform cost search and how that can help with the cycles so if you guys have seen Dijkstra's algorithm this is very similar to de-stress like yeah so it's basically like stars but alright so let's let's actually talk about this so so the observation here is that when we when we think about the cost of getting from start state to some s prime well that is going to be equal to cost of going from s to s prime and then some past costs of us and then been dynamic programming like we make sure that we have this ordering and these things are computed in order so we're not worried about like visiting the states like multiple times but within in uniform path search we might visit the state multiple times and if you have cycles we don't know what order to go but the order we can go is we can actually compute a past cause the suggested path cost and and basically go over the states based on increasing past costs okay so let me actually yeah so so uniform cost search what it does is it numerous states in an order of increasing past costs so and then in this case we need to actually make an assumption here we need to assume that the the cost is going to be non-negative so so I'm making this assumption for uniform cost search so here is an example of uniform cost search running oh we don't have internet I just yeah there is a video of uniform cost search running in action and if I have time now connect to internet and get it working but so so let's talk about the high-level idea of uniform cost search so in uniform cost search we have three sets that we need to keep track one is explored set which is the states that we have found the optimal path you sort of stay say we're sure like how to get to you have computed the best as possible to get there we are like done with them yeah then we have another set called a frontier where this frontier are the states that we have seen you've computed like a cost of getting there like you know somehow how to get there and what would be the cost but you're just not sure about it like you're not sure if that was the best way of getting there okay so so the frontier you can think of it as a known unknown I know they exist but like I actually I'm not sure what's the optimal way of getting there and then finally we have this unexplored part of states and these unexplored part of state I haven't even seen them yet I I don't even know how to get there and you can think of it as more of an unknown unknown so so that's like how you would think about these three so let's actually work out an example for uniform cost search I'm actually going to do this one so so I'm just gonna show how uniform cost search runs on this example so I said we are going to keep track of three sets unexplored frontier and then explore it okay all right so everything ends up an unexplored at the beginning a B C and D and what I want to do is I want to go from A to D right that's what I want to do okay so I want to find a minimum pass cloth minimum cost path to get from A to D given that I have this graph so what I'm gonna do is I'm gonna take my initial State that's a I am going to put a on my frontier and it costs zero to get to a because I'm just starting at a okay so that's on my frontier then the next step what I'm gonna do is I'm gonna pop off the thing with the lowest cost from my frontier there's one thing on my frontier I'm just gonna pop off that one thing off my frontier I'm gonna put that to export the cost of getting to a is zero and then what I'm going to do is after popping it up from my frontier is I'm gonna see how I can get from a to any other state so from a I can get to B that's one option and with the cost of one so from a I can go to be the cost of one where else can I go I can go to see speed acosta 100 okay so what I just did is I move be from unexplored to frontier and then I I know how I to get there from a and I move to say to a frontier and I know how to get there so now it's the next round I'm looking at my frontier he's not on my frontier anymore it's an export and I'm gonna pop up the thing with the best cost of my frontier well what is that that's B so I'm going to move B to my export the way the best way to get to B I already know that right that's from A to B everything is good okay so now that have popped off B from my frontier I'm gonna look at me and see what state I can get to from from P I can go to a but a is already in export like I already know the best way to get to a so so there is no reason to do that from B I can get to see and if I want to get to C then I can actually get to see with the cost of 1 plus whatever cost of B is already 1 so what I'm gonna do is I'm gonna erase this because there's a better way of getting there and that's from me okay and then from me I can get to D so I'm gonna move D from an export to front here I can get to it from B and then how do I get to it from me there's a cost of 1 0 1 alright because 100 plus cost of getting to alright so I'm done exploring everything I can do from be going back to my frontier again so these two are not on my frontier I just have C and D on my frontier I'm gonna pop off the thing with the best cost that is C I'm gonna move that to export with the cost of tooth and the way to eat the best way to get that is from B okay so we're done with C and then we're gonna see where we can go from C from C I can go to a well that's done that's already on export and export said I'm not going to touch that similar thing with P already in export don't need to worry about that from C I can get to D right and if I want to get to D from CEO what would be the cost of that it would be two plus one so I can update this and have three and I can update the way to get to D from here and then we're done we go to frontier the only thing that's left on the frontier is D I'm gonna just pop that off and then I'm gonna add that to exports and that is three and that's what I have in my exports so the way to get from A to D is is by taking this route and it costs one so a b c ND okay is that is that clear alright okay so there are two slides left and they're probably gonna kick us out soon so I'll do this next time so so yeah the to two slides left is one is going to just go over there the pseudocode so take a look at that the code is online and there's a small theorem that says this is actually doing the right thing I'll talk about that next time