alright let's get started long time no see I'm excited to be back and tell you guys about Bayesian networks so before we dive in I want to do a few announcements first there's four things that should be on your radar so the scheduling homework is due tomorrow hopefully you guys are well aware of that the car assignment is released today and it'll be due next Tuesday so there's some conceptual challenges here especially if you're not too up to speed on your probability the section Thursday will really help you go over that so please come to that then there is a final project you guys have hopefully all received your feedback for your proposal and are actively making changes so just to make sure that you guys are making progress there's a progress report that is due next Tuesday and for this one the guidelines are all on the website but just to kind of reinforce eyes especially if you didn't manage to get a baseline or Oracle you really expect that you to have that now and also we expect you to have some sort of preliminary results with you know some sort of implementation of your actual procedure or algorithm or model and it's definitely some description of what that is and be as concrete as possible as you can and finally the exam is in about two weeks I would start looking at that in the I actually the best way I think to prepare for the exam is to look at the old exam problems because there's a certain style that you have to kind of get used to when taking the exam so I know this is a busy time there's a lot of things going on but hopefully you guys will manage yeah it's Tuesday I believe but I could be wrong yeah let's say it's Tuesday yeah it's whatever the website says oh it does taste Thursday okay well then we'll defer to the website on that okay okay so the next agenda item is the pack mount competition so many of you worked hard to submit various entries into this competition the end only three could make it to the top three so here are the winners of the pac-man competition is out of town but if in the audience maybe you guys could come down let's give them a round of applause and we have these prizes which are pac-man theme cups filled with candy in case you didn't get enough for Halloween so there you go congratulations you guys want to see a little bit about what was your secret sauce okay well congrats hey alright so keep it simple I guess is a good lesson okay so back to a regular programming um last week we started talking about factor graphs just a quick review of what factor graphs are factor graphs consist a set of variables these variables could denote colors of provinces of Australia or locations of objects at different time steps factor graphs also includes a set of factors which depend on certain sets of variables and these factors are meant to specify preferences or constraints on what values are good for these variables to take on and the weight of an assignment is simply the product of all of the factors right so there's a steam that comes up in this class which is I call it specified locally and optimized globally right so it's very easy to think about how two variables might interact and how you want something local to happen and these are defined in terms of the factors but what you care about is some globally optimal solution so the weight is a global function of all the vert assignment to all the variables and last time we talked about various different types of algorithms for finding the maximum weight assignment including backtracking search beam search gibbs sampling and so forth and so forth okay so one example we looked at was object tracking and in this example we have a set of variables corresponding to the location of a unobserved object at time step I and we looked at two types of factors that captured where this object might be there's transition factors which capture the intuition that across two successive time steps the objects shouldn't move if you can't teleport it has to remain close and observation factors that incorporate the information from the sensors at each position there's going to be some factor that kind of encourages the position to be similar to what the sensor reading was so sensor readings are noisy so it's not a hard constraint but it's a better soft constraint and last time we saw this demo where you can define the factor graph and you click run and you see all the factors which are represented in these tables and when you multiply everything together you get for every joint assignment to all the variables some number that corresponds to how good that assignment was and if you look at the maximum weight assignment that's what the answer you would return us okay so so far so good and you can with this framework you can do a lot with it already you can define a bunch of factors you can run all the algorithms that we looked at last week but you know what is where these factors mean and how do you come up with intuitively you can define these factories just you know hack on a - if you like it one if you don't like it but you know philosophically maybe you should be a little bit bothered by this because these factors are kind of just arbitrary in some sense so the goal of this lecture and the next two will be to give more meaning to the factors and we're going to talk about Bayesian networks it's a way to do that so in one sentence Bayesian networks our factor graphs plus probability just taken is taking a step back where have we been in this course this course has been a lot about designing new modeling frameworks so we looked at state-based models which result in search problems and MVPs and games and this was a useful tool for solving a lot of problems already but then we looked at starting last week cases where maybe the order of actions doesn't matter so much and it's more natural to think about a set of variables that you want to find some assignment and any order is you know permitted and you can think about that as going maybe stepping up in abstraction kind of going from assembly to maybe C++ and in this lecture we're going to talk about bayesian networks you can think about loosely analyzed and analogizing going from C++ to Python it gives you a kind of a more high-level language to think about modeling and it's just another tool in your tool kit okay so let's start with the basics there's a quick review of probability usually we've see probabilities start with outcome spaces I'm gonna jump directly to random variables assuming that you have a basic CS 109 knowledge so random variables are things in this example are sunshine and rain so they're variables whose values are unknown and furthermore there is a probability distribution over all the random variables that captures how they might interact and so this is called a Joint Distribution so we write P this blackboard P of the two random variables and our and this is this entire table which specify for every possible assignment to all the variables a single number which is its probability so the probability that it's sunny and it's not rainy is 0.7 for example no so I want to distinguish two things one is that we're going to use uppercase letters to do random variables and lowercase letters to denote the values that the random variables can take in addition I want to point out that when I write P s equals s articles are that quantity expression represents a single number which is a probability for example 0.7 or is if I write P of SNR that expression denotes a whole distribution which is the table and I know these are kind of minor notational differences but I think it will avoid a lot of confusion if you kind of pay attention to this so from the DOE and Joint Distribution you can use the laws of probability to derive several quantities one quantity is called the marginal distribution and a marginal distribution you pick a subset of the variables that you care about those are called the query variables and you induce a distribution over them so in this case I've picked s and what I'm saying is I only care about the probability of s I don't care about our but our still has kind of influence on a so I need to take our into count somehow and the way I do this is I look at all possible values that s can take on so look at 0 and then I look over to the Joint Distribution and look at all the rows that match that particular s so here I'm looking at s equals 0 so that's the first two rows and I look at those probabilities and I sum them up so point two plus point zero eight is 0.28 and similarly for s equals one I look at all the worlds I match s equals one which is the last two rows and that gives me 0.72 okay so what i'm doing here is called marginally out marginalizing out our because i don't care about our I'm interested in the marginal distribution over yes so another concept which is going to be really important is the conditional distribution and the conditional distribution arises when your interest when you have some evidence so assume let's say I observe that it's raining so R equals one so I write P of s given articles one to say this is the I'm interested in distribution over s given that it's raining and to compute this I look at this condition R equals one and I simply select all the rows which match that so the second and the fourth rows so now these are numbers now probability if they don't sum to one right because it's only a subset of the rows but what I'm going to do is make them sum to one by normalizing so normalizing means taking the relevant numbers point zero eight point zero two adding them up and dividing by that number okay so I'm dividing by point one which gives me the normalized distribution point eight and point two okay so these two concepts are going to be really important and if you remember from last week there we talked about marginalization as conditioning later in this lecture I'll connect these two concepts any questions about basic probability so hopefully this is all review okay let's move on so suppose I have a Joint Distribution over some set of variables so then in this example it's sunny it's raining whether it's traffic and whether it's the autumn season the way to think about this is as a probabilistic database for every possible assignment I have a number that is either is it's between 0 1 um so I can think about this as an Oracle this is the source of truth I don't know what any of these variables is but I know how they behave in how they operate just like I know I don't know what the outcome of a coin flip is going to be but I know that it's half and half heads and tails so the main thing that we're going to do with a joint distribution is called perform probabilistic inference okay so this is an important thing to you know understand because we're gonna spend the whole time doing probably singing friends so it's good to know what it is so probably this inference the way to think about it is that you'll observe some evidence you wake up and you see I okay it's autumn and and it's a Bay Area so there's traffic outside so you're conditioning on some evidence T equals one and a equals one okay that's what you know and what you like to find out according this Oracle is you know whether it's raining so you're interested in some set of query variables okay so the general form of a problem inference a problem or task is probability of some set of query variables conditioned on some set of you know conditioning variables which are set to particular values and notice that there are some variables which are not mentioned in this query such as s and those variables are the ones that are marginalized out so you can think about this query as combining both the marginalization and the conditioning from the previous slide okay so this without loss of generality just captures everything that we seek to do with distribution for the purposes of okay so at this point you can actually just do probabilistic inference right if I give you a joint distribution which is this huge table with all the probabilities for all the assignments you can go and you compute anything you want so now there's a kind of a slight problem here which is that if you have n variables and just supposed to each variable takes on two values how many possible how many rows in the table are there anyone Judy the end right so that's exponential that's a lot so if n is 100 and that's so so clearly we can't do this naively right so the first challenge is how do you even write down this Joint Distribution compactly right I don't want to write down to the N numbers so Bayesian networks is going to allow us to define Joint Distribution using the language of factor graphs so this is really cool because now I have a very compact way of specifying what is implicitly something that's very very large the second challenge is algorithmic how do you do inference right we want to do perform probabilistic inference answering queries like this how do we do this efficiently again you don't want to have to go through to the end different possibilities because that would be really really slow and we'll see that variable in the mayshen Gibbs sampling particle filtering which is the problem sick analog of beam search all these algorithms that we talked about last week are actually going to come into play and we're just going to talk about the probabilistic analog of these as opposed to finding the maximum or yes I'm okay so now let's try to motivate why we need Bayesian networks with this following example so here's a setting so earthquake earthquakes and burglaries are things in the world they're bad things but suppose that they're independent right that kind of makes sense but in your house you've installed an alarm system which is going to detect either both earthquakes and alarms okay so one day you wake up and you hear an alarm go off okay so you should be alarmed but but then you turn on the radio and you hear that there's actually an earthquake so how does that affect your beliefs about whether there was a burglar or not okay so okay there's three options does it increase the probability of a burglary there's a decrease of probability of burglary or does it not changing okay so how many of you think that hearing the news about the earthquake on the radio increases the probability of a burglar so you see increases how many you say it decreases so many of you say it decreases how many say it doesn't change hey almost as many say it doesn't change hmm okay that's interesting so we'll answer this question but you know keep on thinking about that in your back of your head and one thing I'll say is that you know I shouldn't you shouldn't expect to necessarily find the right answer here just by kind of intuitive and one of the points of making things codified in a Bayesian network is that you don't leave anything up to your kind of vagueness it's it's there's actually a correct answer that we can derive okay so let me talk about how to go about modeling this as a Bayesian network so with this quarry example so there's four steps the first step is defining what the variables are okay variables so what are the variables here yeah okay so there's a burglary earthquake or an alarm okay great so these are the three things that we don't know about that are mentioned okay so the second step is you draw some edges okay so these are going to be directed edges that correspond to notions of influence and if you if you want cause causality but causality is a very more philosophical thing which we don't really need for this class so but I'll bail use it anyway so what causes what so there's an alarm cause Bullard burglaries no okay I think it's the other way around right so burglaries cause alarm and similarly earthquake caused alarm and these two aren't I said they were independent so let's just okay okay so now I have a direct acyclic graph that shows how all the variables are related in some okay so the third step is to define local conditional distributions so now I'm going to go one step further and say how these are what the probabilities of these variables are because in the end remember I wanted to find a joint distribution of all the variables okay so I'm going to define a local conditional distribution for each of these variables so here I have P of B P of E and P of a given B so in general a local conditional distribution is P of whatever that variable is given its parents so the parents are the variables that directly point into it so the parents of a are B and E he has no parents and a B has no cats okay so in particular what I'm going to do is now let me flush this out I love that one so what is P of B P of B is a table that specifies only what's going on in this region of space so I have B and have P of B and I just fill out this what are the possible values of B 0 1 so let's say you know 1 and 0 so let's say that probably a burglary is epsilon epsilon generally denotes a small number but you hope to be the case on here so this must be 1 minus epsilon because it has to sum to 1 and for simplicity let's say that probability of earthquake is also epsilon and 1 minus epsilon just for simplicity and then okay so this one's a little bit more complicated so I'm going to write the parents be yi and the variable itself a and I'm going to look at probability of a given B and now I'm going to list out all the 8 possible combinations here so it's 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 ok ok so for each of these n you specify the probability so 0 0 0 and I should say that this alarm system you bought was it's really good really good so it's um it detects earthquakes and burglaries are perfectly okay so if there's no burglary no earthquake then the probability of alarm not going off should be one right it's perfect and this is the failure case which is zero because if there's a burglary no burglary and earthquake the alarm should be going off and this is I'm not going to bother you with it DJ I was thinking you can just fill in the rest of this so if there's a burglary in a crate that's strip you maybe someone should check them doing this right this should be a wine this should be zero and this should be a lot something like that okay so now I have to find the local conditional distribution so remember I'm not defining the joint distribution yet I'm just defining in from zooming in on a particular variable how does it relate given its parents right any you can think about you have a million nodes I'm only each local distribution might be only touching it like a very small part okay so finally the fourth step is to define a joint distribution okay this is a thing we're all after right which is what is the joint distribution over all three variables here and the joint distribution is going to be written with a blackboard P is B equals B e equals e AE equals a so random variables equals a particular possible value and this is defined to be the product of all the local conditional distributions okay so P of B P of E and P of a okay so let me reveal the slide which hopefully should have the same content on this one thing I'll point out is that there is a difference between the small piece and these big piece so the small piece or local conditional distributions these are things that you just define right there's no right or wrong there you just define them they're just true and then there's this big P which is the joint distribution which is again defined to be just a product and then from this joint distribution you're going to read out things like marginals and conditionals which might look like some of these local disc distributions but they're right now think about them as distinct objects yeah question so a question is are we assuming B and E are independent here so let's see how do I answer that so yes in this one B and E are independent and I'll show you a little bit further how we can kind of see that more clearly okay so these are Bayesian networks so what's the connection between this and factor graphs well if you squint a little bit you see that the right-hand side here is a product of things and the left-hand side is this kind of joint you know global thing and so what does this look like looks like weight equals product of factors right so let's go with that analogy and it's actually much deeper than a just analogy and let's draw this as equivalent factor graph okay so for every Bayesian network we can actually draw it as a factor graph so here we have B E and a and okay so now it's you know it's really important to note that how did the factors arise through there's a local conditional distribution remember for every variable and that is a factor so for every variable there's a factor right it's tempting to look at these edges and draw factors on them but that's that's wrong okay remember one factor per variables okay so this variable has a factor that is P of B this variable has a factor that's P of E and this variable has a factor and this what is this depend on what is its scope B and E right okay you know again a common mistake is to just put two factors here because it it's really tempting but one way to think about it is that you know if you think about your your parents they are they're married and connected so that's why these are your parents are connected actually the I'm not making this up but there's a some people call this process moralization yeah to compute the probability amount water given just your thing or a properly given just a burglary yeah so the question is can you use this compute probably alarm given earthquake alone or burglary alone and the answer is you compute whatever you want and we'll show you how to do that okay so single factor connects all the parents one factor per variable okay got it all right so the Joint Distribution over all the variables remember is the product of all the local conditional distributions and just for reference this is what it is and now you can go and answer questions about this so this is kind of the fun part and I'm not going to go through the details of how this is done but I'm just going to show you a kind of the interface where you would expect so again this is the definition of the alarm Network using the same machinery as a factor graph because it is a factor graph and first we're going to ask what is the probability of B so what is that that says in the absence of any information is there a burglary or not okay so what do you think that should be oh um and epsilon here is a point zero five so I think I heard it point zero five someone said that ok so indeed the probability of a burglary is point zero five should be intuitive and now I'll suppose I the alarm went off okay so now what's a probability of burglary so what is P of B given a equals one let's go up or down should go up if your alarms working and indeed we see that probability of burglary given alarm equals 1 is 0.5 1 and now the monomyth truth what happens if we condition on the fact that there's also an earthquake so let's do this and you get point 0 5 so many of you are correct when you said that the probability of a earthquake goes down okay and intuitively you can think of it makes sense from this phenomenon called explaining away so explaining what happens when you have structures that look like this and you have suppose you have two causes positive influencing effect so by positive influence I mean that if you flip B equals from 0 to 1 then the probability of a goes up and so explaining ways says I conditioned on the fact conditioning on one cause reduces a probability of other one okay so at some level this makes sense because you know this a is either B or is either driven by B or e and I don't know which one it is if I just heard alarm go on but each of these is very small problem has very small probability so the moment I kind kind of see that one of them explained this cause you see that one of them is true then I kind of revert back to the my prior belief on the you know the other one okay so humans do this all the time when you're reasoning when you're thinking about like well what what causes and you find one one cause and you discount all the other ones so now the thing that's kind of interesting here is that I did say that B and E are independent which is also true right so this might have led people to think like wow it shouldn't change because they're independent so why should the probability change but their key thing is that when you condition on a you actually changed the independence structure of the model this is why writing things down really precisely is helpful to kind of reconcile these seemingly contradictory intuitions that you might get okay any questions about this all right let's move on so we've talked about the alarm Network this is your first example of small Bayesian network hopefully you have an idea of the intuition behind it so now I'm going to generalize it and the generalization shouldn't be surprising so in general I have n random variables usually denoted x1 through xn and the Bayesian networks is a directed acyclic graph over these variables and it defines a Joint Distribution over all the variables like this x1 through xn and this is defined as a product of local conditional distributions one for each node ok so this is a product of all and X i given X parents of I in this notation just means the values assigned to the parents of okay so this is a very general framework and just like factor graphs are a very you know general fabric but the key difference from factor graphs is the fact that these factors aren't arbitrary right there are local conditional distributions and what does that mean that means all factors satisfy this property so if you pick up a factor for the eighth node P of X i given X parents is equal to one if you sum over all the possible value that X I can take okay that's what it means to be a probability distribution and this is true for every setting of X parents so this property has two implications which I'll discuss consistency of sub Bayesian networks and consisting of conditional distributions and these properties are going to allow us to really you know take advantage of the probabilistic structure when we're doing inference okay so the first thing is the question is suppose I have this Bayesian network this alarm Network and I'm going to suppose I'm interested in the marginal distribution of only B and here okay I don't care about it so remember this is the Joint Distribution and by laws of probability I can derive them marginal distribution now the question is what does this marginal distribution have to do with the Bayesian network the graph here so let's go through some algebra to find out so this is a sum over all a and by definition this is just the product of all the local conditional distributions as we just discussed and now I notice that P of B and P of e don't depend on a which means that I can pull this out and push the summation in that's just a you know algebraic manipulation and then what is this value this value is just one because of the previous slide so I can just drop it and now I have P of BU times P of E and lo and behold what is what is this this is if you had just gone and defined a miniature Bayesian network over B and E this was exactly what you've written down okay so that's that's kind of cool so the general idea here is that when you're marginalizing out a leaf node that yields a Bayesian network just without that node so marginalization produces this this Bayesian network where you've just erased the theory of the leaf node along with its incoming edges right so in other words I've turned basically what was would have been a algebraic operation into a graphical one and generally those are good moves because it's much easier to kind of think graphically and make large operations and go through tons of algebra yeah definition rules it seems least for my birthday measures like oh yeah so the question is what about this first definition equals what I mean here is by the laws of probability so it's not technically a definition it's follows from the axioms of probability okay so notice that in this world P and B and E are independent so this is one way you can kind of see that actually when you define the Joint Distribution in that Joint Distribution two variables be an ER independent so one thing to note is I you know if we looked at the factor graph you know which is this thing and remember last time we talked about marginalization infarct factor graphs and what does that look like if you what happens would you if you did marginalization in this factor graph okay yeah you just remove a but this factor is does it disappear you no it doesn't right because factor garage remember the fact regrets don't know anything about this factor other than that it's it's returns non-negative numbers so you would have to keep hold on to this factor alright so the moral of the story here is that if you're using factor graphs if you convert to factor graphs too early then you might lose out on opportunities that really simplify where if you look at this the factor graph of this one there is no P of a given being you right I mean just to go back here factor graphs will create a factor which is summation of a P of a given B and E and call that a factor and we know because these are local conditional distributions that's just 1 so you can just drop it okay so so that's a first property so summarize if you marginalize out leaf nodes you get bayesian networks by just dropping them from the breath so the second property is consistency of local conditionals as I alluded to before if you have P probability of D given a and B there's two versions of this that you can might be thinking about one is a local conditional distribution which is again you just define it as such and then there is the corresponding quantity that comes about from probablistic inference so this quantity is derived from taking the definitions forming the Joint Distribution and then using the laws of probability to derive this particular quantity and this property says that don't worry about it the two are equal so you know it means that you can kind of intuitively think about they're just so convenient one notion of probability in your head but I want to make this explicit but that this is that doesn't come necessary for free you have to kind of verify it that this is true I'm not going to go through the verification step it's in the notes in the slides but I'll just state it as such okay so let's do another example just to familiarize familiarize ourselves with Bayesian networks a little bit more so the question here is that suppose you have you wake up and you are coughing and you have itchy eyes and you're wondering do I have a cold or do I have allergies okay so let's follow this four-step procedure to define this Bayesian network okay so step one what are the variables here there's um coughing let's denote that as H and itchy eyes and then cold and allergies okay so four random variables um how should I connect these things up yeah so H and I should be connected to C so if you have a cold you probably have a cough and you probably have actually ice and here you tap into your medical knowledge and with that yeah so generally I'm no doctor but let's just assume for now that allergies don't really cause a coffee cause it is probably not true let's just pretend with us okay so just to make the network a little bit more interesting okay so those are the edges and now I have to specify local conditional distributions over all of these so what are the local conditional distributions Pfc you have a remember one for every node and P of H given C and over here is P of AI given CNA right so probability of a node given its parents and then finally I have the Joint Distribution which is probability of C a H I and this is by definition just the product of everything for this example I'm not going to go through and define the actual tables because that's going to take too much time but I'm gonna do it in this demo here okay so this is a Bayesian network that I just drew on the board and this is as its associated factor graph remember a one factor per node yeah points which is eat the allergies old see a oh yeah right which one makes sense so it should be like this and then I have to adjust things okay so we're fixing this I give in a and CNA okay just for the record I'll just make this each given CNA and I give in I was into that okay thanks for catching that okay so this is the factor graph and let me show you this demo so you can click on this and you can see this Bayesian network in this factor graph and to answer this question what was the question the question was if I have if your coffee and have itchy eyes do you have cold or allergies so I conditioned on coffee equals one HDI is equals one and I'm asking for the probability of a cold okay and if you work it out you see that the probability of a cold is 0.13 and you know so why does this so okay I guess I didn't really tell you enough about the actual prior probabilities so the probability of a cold is no point one let's say and the probably of allergies is point two and then there's a kind of noisy or where if you're if you have a cold or allergies and you you end up coughing and the if you have each allergies and you have itchy eyes with probably point nine and what happened here is that if you if you condition on your coughing and you have itchy eyes there's this kind of interesting explaining away happening here where you know even though you didn't observe a you observe evidence of a and that's enough to kind of lower the probability that you have a cold so this is an example show something a little bit more subtle how information can kind of propagate along the Bayesian network in ways that if you try to do it just time intuitive that you'll probably not be able to okay so let me summarize so far what we've done so we've introduced Bayesian networks where we have random variables that capture the state of the world and we have edges between those variables that represent dependencies between those variables and based on those dependencies we go and define local conditional distributions you multiply all those local changes show distribution you get a joint distribution now without joint distribution by laws of probability you can go and ask probabilistic inference queries and ask questions about the world given evidence and we saw that this captures interesting reasoning patterns such as explaining away and finally all of this can be brought under the umbrella of the factor graph interpretation which we will see is very useful for actually doing probabilistic inference in general okay so any questions before I move on to the next section okay so now I'm gonna talk about probabilistic programs so this is going to be kind of a little bit of a whirlwind tour and hopefully give you a different perspectives and open your eyes to kind of the possibilities of Bayesian networks so let's look at this alarm Network again I can write it as on the board just a product of all the local conditional probabilities basically use math or I can think about this as a probabilistic program okay so what I'm gonna do right down is a program that it's a very simple program has three lines one for every a variable and the first lining is B is drawn from Bernoulli Epsilon so this notation just means B is set to a random value that has a distribution Bernoulli Epsilon and same with earthquake and then finally a set a equals B or okay and so the idea here is that a probabilistic program is just simply a program with randomness in it that when you run sets the random variables so this is I think a really useful way to think about Bayesian networks and just to maybe very concrete about this so you can think about Bernoulli of epsilon is just a Python program that just returns true with a probability Epsilon so here random less an epsilon the random is a number between zero one has a probability of epsilon being less than that's all okay any questions about the what this is doing yeah so question is why does ranma's help the the reason is that I'm want this program to be put a distribution over possible assignments every time I run the program is going to produce a different assignment and the distribution of that assignment is the distribution that I'm defining so this is a kind of an interesting philosophical point so normally you run programs and write programs with intention of running them and do do something useful but here the programs are just a kind of an art of artifact to define a distribution hopefully this will become a little bit clearer as I go through more examples yeah yeah so a question is why don't you just define a table directly instead of running this program so the intention here again is not to run this program because it's not an efficient way to do probabilistic inference but it's more of a metaphor a tool to help you get more intuition about probabilistic programs in bayesian networks so hopefully we can come back to this throw a question after I go through a few more examples so here's a more interesting probabilistic program so suppose you're doing object tracking and you define a program which starts with X 0 equals 0 0 so the initial location is at the origin and therefore every time step so I'm writing the program in kind of pseudocode here with probability alpha I set X I equals x I minus 1 plus 1 0 so I'm going to the right and with probability 1 minus alpha I'm going down ok so now this program you know that I just described and induces a particular Bayesian network structure where each X is only connected to X I minus 1 ok so what I'm trying to get you to think about is there's multiple ways of thinking about same object and I think when you get when you can kind of internalize all these things you kind of get a deeper understanding of what you're dealing with right we have the probabilistic of viewpoint you can look at the table you can read your equations you have this graph and now I'm giving you an additional to all the programs okay so just for fun you can actually run this program again this is not what you would do normally but I can run the program and okay so every time I hit enter this gives you a different trajectory so this is a way to visualize the distribution over problem X 1 through X whatever how many of many red squares are okay and if I change alpha that gives me distributions which are either skewed to one side or the other side so that's the distribution over programs oh sorry distribution over assignments okay so what does probablistic inference look like in this setting so remember what is probably it's inference I'm conditioning on some piece of evidence and I'm asking for the distribution over some other set of variables so in case in this case I'm conditioning on the fact that I spotted X of the object at a to at time step 10 let's say I'm interested where it could have been before that so here what I'm going to do is I'm going to run the former program and I'm only going to keep those trajectories and show it if X 10 equals a 2 so if I do that I'm good at this so this is a 2 I'm seeing that the set of possible trajectories look like this so this is the distribution over trajectories given X 10 equals a 2 okay so in support of what I'm trying to get you to think about is a Bayesian network or project program as what is the distribution you can visualize the distributions by looking at samples from that distribution it's another way to think about right because distributions are think about like it's suppose you have a dish I tell you I have a distribution over images now how do you actually get ahold of that or understand that well probably the easier easiest way is to draw samples from there and look at kind of types of images that you get question to specify a distribution or they like this way to specify Bayesian action so the question is is this way a way of specifying a joint decision by this I mean I guess you mean the so probably for me in general it is so so for every probabilistic program it specifies a joint distribution over the random variables that you set and vice-versa if I have a Bayesian networking and write down a policy for one thing you know as you'll hopefully become clear as that the reason to think about in terms of programs is that you can inherit all the nice properties of programs like the ability to find functions or even have recursion or you could do a lot more fancy stuff with programs that you can't do what I mean which would be hard to do you can think about Bayesian networks is another way to think about is I okay you're basically writing assembly code right for every variable you specify its value but if you have a million value of variables sometimes it's useful to be able to structure your you know your code in some way and we'll see that over the next few examples okay so this is going to be a march of I think around seven possible or so possible examples and just want to give you a flavor of types of probability programs that were talking about here so the first one is called just a Markov and whenever I say probably program think Bayesian networks or if generalizations of that so Markov model so this has a lot of applications in you know modeling language or time series and the program works as follows for every position I through n I'm going to generate a particular word X i given the previous word okay so this is also happens to be the same type of program as for the object tracking okay so this is a Bayesian network structure so here's another one this is called a hidden Markov model which is it was a very popular model that was used for all sorts of things like speech recognition notably before you know the rise of deep learning so the idea here is that for every time step T equals one to T I'm going to generate an object from location HT given the previous HT minus one so this part is just looks like a Markov model okay but the reason why it's called a hidden Markov model is that I'm not actually going to observe HT I'm gonna observe sensor readings et at each time step T given the hidden location okay so this is what a hit and markov model looks like sequence of objects locations we could go observe and sensor readings which I do observe which depend respectively on the given object locations and just as a convention whenever I shade a variable that means I you know observe it and if it's not shaded that means I don't have so that okay so this program defines a Joint Distribution over all these variables and now you can ask particular questions you can do probabilistic inference and the most common thing that people do here is given the sensor readings where is this object which is something we've already been exposed to through the lens of factor graphs but this is again a way to think about it through the lens of Bayesian networks so now with this kind of programming metaphor you can actually do kind of more complicated things in a very kind of succinct way so to describe a multiple object tracking you can think about there being two objects a and B and each position each time step and every object I'm going to generate a location for the object and this is going to be two independent Markov chains which are running but the thing is that at each time step I only observe one sensor reading and that sensor reading is going to be some combination some function of the actual locations with all of them a particular time okay so now hopefully you can see a little bit of advantage of thinking in terms of a program because I can write this kind of a very simple four line program that very precisely nails down what the actual model is and in particular this factorio hm as it's called is something that you're going to be exploring you're the card assignment here's another example so this is for usually used for classification it's called naive Bayes I mean you might have heard of it and the program looks like this you first generate a label Y let's suppose you generate travel and now you're gonna for every word in your document you're gonna generate a word given that label so if you generate travel you might generate words like these impairments so now the that again specifies the distribution over all the variables what are you typically interested in if you're interested in classification you're given the words and now you want to go back and figure out what the the classes or give me a text document what is the label here's a fancier model of documents called Lane deer to the allocation so here instead of have generating a single topic I'm gonna generate a distribution of our topics this is getting a little bit meta because this random variable itself is actually a distribution but you know let's not worry too much about that so this is a distribution and for every position I'm going to first generate a topic what like travel or gear up and then for that topic I'm going to generate a word given that topic ok so this allows you to model documents which talk about multiple things for example travel in your office ok so this is also a very popular model that can be used to if you're given a collection of documents trying to understand understand a latent structure inside so here's one that's kind of a generalization of the the medical diagnostics example on the board so in general let's say you have a bunch of diseases you generate the activity of a particular disease in a patient according to some you know prior distribution and now you for every symptom that you might observe or any sort of lab test you have the probability of some outcome of that symptom given the diseases and of course the probability inference question here is if a patient has particular symptoms Wacka diseases does were problems does he or she okay so I think this is a maybe the final example here's a social network analysis example where you have a set of people each person has you know a type maybe a politician or a scientist and these for every pair of people they can either interact or not interact they might be connected or not connected let's say in a social network and so in the end what you're given is a social network of connectivity and you're asked what kind of types of people are there so generally you you observe maybe some graph and you want to understand you know what kind of features or you know what is what is a concrete way of summarizing the types of people and there's this is called a sarcastic block model but there's other kind of fancier models database so that was a very quick overview of different types of politic programs or Bayesian networks and there the point is that there are many many different types of models that can be written down in the literature many things generative models can be just written down in a project program or equivalently a Bayesian network and all of them kind of have this kind of basic structure if you observe carefully all of them kind of look like that where is there some set of variable as H which you don't observe and that generates or causes a set of variables which you do observe so the mindset when you're designing Bayesian networks is you're coming up with stories of how the data which you what you observe was generated through the quantities of interest to output so this is probably kind of maybe counter intuitive and for those of you who are really used to thinking about just normal classification where you it's an opposite you start with the input and you think about what are things to do to the input that it can you know what kind of things kind of do to get it to a point where I can you know classify on the input precisely but Bayesian networks kind of go the opposite um it starts with the output or the structure is interested in which are presumably kind of more um kind of the Platonic idea or something cleaner and then you're trying to describe how that clean data gets or gives rise to this kind of messy sorry the clean structure give rise to the messy data that you observe question right so why is this call to output so I'm using input/output here in to borrow terminology for when we talked about classification where you're going from input to output input is what you are given and output is what your output I guess producing right and in the the Bayesian network you first define the model kind of going from output to end so kind of an opposite of what you would normally do and now now there's a second stage where you do props like inference which reverses that and you go from the observations which are the input to the output which is okay any other questions about this all right so now let's talk about inference this is also going to be the topic of next lecture but I'm just going to start playing around with this a little bit so remember what is probably sick inference we're given a Bayesian network to find some joint distribution we're also given some setting of the variables which is evidence for example I saw that alarm went off and I'm interested in a subset of the variables okay so what I'm trying to juice is a probability of some query variables conditioned on evidence and what this really means is I want this for all values of the query variables okay so for example if I have coffee and itchy eyes to have a cold it's an example of a probably seen first quiz okay so let's start with this simple example suppose I have this Markov model and I ask this query what is the probability of X 3 given X 2 equals 5 that condition X 2 goes 5 I'm interested in X 3 so at this point you already have the tools to do this and I'm going to show you how you can just go through the calculations and then I'm going to show you an easier way to do this so if you were just shown this right now this is probably of what you would do which might be a little bit tedious so by laws of probability this or this conditioning is equal to the joint over this marginal okay so this is just by definition of conditional probability and one thing I'm going to do here is notice that I'm only an interest in distributions over x3 so from that perspective this blood denominator is just a constant actually it doesn't depend on X 3 so what I'm gonna write is this proportional to which means that the actual value here is this thing on the right hand side times some constant which I don't care about and the reason I can do this and I don't care about is because I know that the left hand side is a distribution so whatever I get on the right hand side if it sums to 6 or something then I just divide by 6 and I get a distribution okay so this is gonna save you a lot of work if you use a proportional to song but you have to use it carefully otherwise you can get wrong answers ok so let's expand this so this is a marginal distribution of X 2 X 3 I can write in terms of the joint where I sum over the variables I don't care about so there's again lots of probability and then the definition of the Bayesian network here is a joint distribution is equal to the product or a local conditional distributions so right now I have lowercase P now because they're local distributions now I'm gonna do some algebraic manipulation so notice that this stuff doesn't depend on X 4 so I can push the summation of X 4 over here and then these two first two terms only these first two terms depend on X 1 so I can group this and have the sum over X 1 apply here and then I can look over here and use what is this sum to one second drop it and then what is this does this depend on X 3 nope so I can also drop that and I get up here of x3 and x2 equals 5 right so this hopefully shouldn't be surprising to anyone because remember that slide when I said the consistency of local conditional distributions this is should be equal to this and this is just one way of verifying that that's actually the case for this example okay so no this was you can do this I mean for this one it's actually not that bad especially when you already know the answer but I promise you there are going to be situations where you definitely don't want to grind through all the math because you can fill up 10 pages of equations I'm going to show you a kind of a faster way to do this and so let's start ok so this is going to be a five-step procedure but in many cases not all the steps are necessary and the key idea is going to be to use the structure of the Bayesian network and factor graphs to simplify some of these operations ok so let's start with ok so you have X 1 X 2 X 3 X 4 step 4 ok all right so and I'm conditioning on X 2 right ok so X 2 this takes on value 5 ok so this and I'm interested in this very variable so the first thing I want to do is I want to remove as many variables as I can I just because that's going to simplify my life so I'm going to remove our marginalize non ancestors of the query and the variable I'm conditioning so by non ancestors I mean anything that's upstream I am gonna keep for now anything that's downstream I can let go okay so what can I remove here x4 right so I can show this so I think graphically just remove x4 and that corresponds to on the slide basically the fact that this thing sums to one but I've done this again graphically which hopefully should be more intuitive okay so the second step is I'm going to convert to a factor graph because one already takes care of and basically I'm exploiting the properties of Bayesian networks but after I've done one I don't it's simpler to think about as a factor graph where I want to think about of the factors more explicitly it's just arbitrary functions and not worry about which way the conditioning is going because it's really easy to get confused by Bayesian networks where you're wondering like oh this is conditioning over here what's a marginal distribution and factor graphs I think by actually removing the directionality and some semantics actually make things easier okay so I'm gonna convert this into a factor graph which means I have let me actually just draw it down here again so here's a factor graph remember I have all the V of X 1 probability of x2 given X 1 so this might look like more work right now because I'm making things explicit but you can actually do a lot of these things so remember every variable has a suti with a factor okay so now I want to you know condition on on the evidence so I'm conditioning on X 2 equals 5 so remember what two conditioning does remember from last week's lecture conditioning just removes this and changes the factors to be each set to the value that that very exam yeah oh sorry yeah we shouldn't have X 1 this factor should be there so X 4 is this is the factor graph corresponding that okay so I'm conditioning on X 2 so I wipe X 2 from the face of earth and I'm going to set this change this factor to be a partial evaluation of where I put X 2 plus 5 and this factor is X 2 equals 5 given X 1 ok so this connection is good so now I can marginalize out the disconnected components and these are the components that I'll remember I care about X 3 so this stuff is disconnected so I don't care about it so I'm just going to and that operation corresponds to the fact that you know this thing over here I just can draw because it's not related to X 3 it's just a constant ok so finally the fifth step is actually do work ok so what does that mean you might not be so luckily to be left with just you know a single variable with a factor where where that's just the answer in that case you actually have to actually compute do the marginalization operations that we saw last in this case we are fortunate that this factor this actually represents the distribution of X 3 so that is just an answer to know the problem ok but I'll go through some of their examples where it's not okay so this is just a general strategy that I outline on the board here and again I think once you get kind of good at this you can basically the steps 1 & 4 should be kind of very kind of visual because you can just see ah well everything downstream just too clearly doesn't matter and when you see these um these are you know conditioning things you can kind of automatically just not ignore things and just jump directly to fire so that's idea I'm just doing things that are more explicitly on the board so you kind of see where things are coming from okay so I'm gonna do another example this is alarm so here I have this vision network and let's blow them interested in probability of B okay so this should be a easy one so start with one margin eyes out non-answer search so which are the non ancestors so ane right so I just removed them from the face of earth and I'm just left with this single variable B and now obviously it has a factor of P of B and then I'm done okay okay so this one's all maybe a little bit more you know complicated so this is the probability of earth sorry burglary given equals one so let's go through this example try to do it quickly all right I'll have a okay so marginalize out nan ancestor so what I mean interesting I'm interested in the probability of B given equals one okay so I have a and B that I care about so what are the non ancestors of these variables there's none right so this is an ancestor of a so I can't remove it so can't do anything there too bad convert to a factor graph we've done this before probably a fee Lorelei's the parents so this is probability of a given B and E and then this condition on the evidence now so our condition on a equals one so I'm going to remove this and change this factor to a equals 1 given B and E fourth step is margin eyes out anything that is distant it nothing's disconnected so I can't do anything and rats I have to do actual work okay so what is actual work mean here I'm interested in the probability of B so I need to marginalize out you I have to do this kind of the hard way based on last time last lecture so what we're gonna do here is you know what happens when I marginalize out e I create a new factor let me actually replicate this down here so it doesn't get too confusing so I create a new factor and this new factor what's calling F of B which is the mark-up negative e there's only one other variable B and this is going to be the product of all the factors here that touch this variable that I'm marginalizing out and the only difference between this and what we're doing last time is before we had a max because we're doing a maximum weight assignments and here I'm going to have a sum because we're doing probabilities in marginalizing so this is going to be summation over B okay and then the final query is going to be just the product of those two things okay I'm not going to have time to actually drill down into expanding these values but if you actually plug in epsilon into these then you'll find that the probability of B equals 1 given a equals 1 is 1 over 2 minus epsilon which is remember five one is for epsilon equals 0.05 okay but this calculation you know you can look into the slides to see how this is actually done but it's just algebra okay so there's another example which I'm gonna defer to section is to talk about I think into all of this you just need to do some practice to get and I'm comfortable doing these operations to summarize define Bayesian networks there's this way of defining models that allow you to specify locally and optimize globally once you have a Bayesian network you can do probabilistic inference where you condition on evidence and query variables of interest and next time we're going to focus on number five and hopefully not do things completely manually but do things more automatically okay that's it