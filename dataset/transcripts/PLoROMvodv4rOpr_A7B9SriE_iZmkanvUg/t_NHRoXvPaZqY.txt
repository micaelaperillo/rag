good afternoon cs109 we are live and back in class I hope you had a fantastic weekend and I hope you're ready for a little bit more popularity education ah yeah feeling the probability of us okay we are going to be learning some very cool things today before we jump into any of that though a couple quick announcements as you probably know problem set one is out it will be due this Friday though there is a little bit of a grace period in case you missed the deadline uh section assignments if you don't get them today that means something went wrong and somehow we didn't get your assignment uh they will be going out today uh if you can't make your time or you need a swap see the post there is more details about this um talk about this PSAT party in a second and as always or you know I've gotten this habit oh this should be fall 22. I've gotten this habit of putting up examples for today's for the lecture on the problem set app you can go to uh the link directly or you can go find cs109 go find today's lecture to do not the fastest internet in the world and once the website loads after a little suspense you can go to lecture lecture four and if you hit the little rocket ship you can go enter today's code and follow along wow man internet you're really stepping on my point here anyways the code for today is silly owl uh there you go not that important but you now know okay this problem set party hey there's some really cool people here at Stanford I want to tell you about two of them uh uh our PhD students and they're interested in the future of online education uh and for massive online classes one of the things they're interested in how they can get peers working with peers and they've built a lot of really cool technology and they want to try it out in cs109 so you might have noticed in the PSAT app there's this new button and it has this number that's how many people are online has anybody tried clicking this button couple folks if you click this button it's like would you like to learn with somebody else and you're like okay and if you hit okay then it kind of waits till somebody else in class hits the same button and it'll pop up a little video for you guys uh obviously you know nothing about this is for grade it's just for fun uh but you're kind of contributing to this experiment in for massive online courses it could be a cool feature that could change the game in cs109 there's so many as we we can interact it'll probably be just a small little demo but if you come to the pset app at 9 00 PM if you hit that button it would be great if we could try and overload our server and if anything goes wrong just let us know it's just for fun it's not that important but you know it is important the stuff that we talked about last week so just to recall last week's Focus was really uncounting and we counted lots of different things we counted orderings of objects we counted combinations of objects and we put objects in buckets uh and you know one of the big meta takeaways Beyond those three skills sometimes you get very large numbers like in the end of last class we talked about how many ways can you order 52 unique cards well that's just 52 factorial we learned this last week but you know one of the ideas is combinations and permutations can really lead to large numbers like this is what 52 factorial looks like if you wrote it out and on the end of last class if you check the slides there's an explanation for why that leads to a claim that if you have a particular ordering of cards with high probability you can say no one has ever seen that exact ordering anyways we talked about combinations of permutation and then we got into the world of probability probabilities were numbers between zero and one we started out with the three Axiom terms of probability um the first two we talked about semantically the third one that I promised we would talk about a little bit more later now is that time the third Axiom probability talks about events and it talks about the probability of either one of the two events happening so either e or F or call this a set notation for or and if you say what's the probability of either of these two events happening the third Axiom probably says it's the sum of the two probabilities if an important if it turns out these two events are mutually exclusive we mentioned this really quickly last time but I thought it'd be worth just taking a moment to go a little bit deeper into what this assumption is saying so all events are really sets of outcomes and if this event is this particular set of outcomes welcome to my little tile space and I would call this set of outcomes event e and I'm going to call this set of outcomes event F they're mutually exclusive if no event is in both or no outcome is in both events and the claim of this third Axiom is hey in this case calculating the probability of either e or F is pretty simple we're just going to calculate the sum of the probability masses now if you imagine like the outcome space of your world is any one of these tiles and if you imagine they're equally likely then we can say that the probability of e is seven outcomes over 50 and probably F would be four outcomes over 50 and so the third Axiom probably says the probability of e or F would be just adding those two things together so 7 over 50 plus 4 this is supposed to say over 50 equals 11 over 50. there you go and that's one of the things that we assume it works for more than two events if you have a whole bunch of events uh if they're all mutually exclusive so there's no event that's in there's no outcome that's in two events you can just add probabilities we'll hit this a lot but I just wanted to say it in a little bit more detail than we said it on Friday wahoo okay and we'll get into this more when we practice it but for now you should start to feel that if events are have this special property of no outcomes in both events probability of or is going to be easy on Friday though I said there's this other really intuitive law of probability which we could prove and this is intuitive law that we're going to use today it says the probability of something not happening is one minus the probability of it happening okay that kind of makes sense but I just want to show you what a proven probability would look like we can prove this just using those three axioms in fact we can start with the third Axiom of probability e or not e so either event e happens or event e doesn't happen this is a little bit of a mind game to see if you understand Mutual exclusivity but it turns out e n not e must be mutually exclusive because is there an outcome where e happens and not e also happens no one of those two has to happen so they must be mutually exclusive there's no outcome that can be in both e and not e therefore by the 30 Axiom this probability statement is just going to be the sum of the probabilities on their own okay you guys following along either e or not e not happening has to cover the whole sample space right because everything in the universe is either e or not e so that is the entire universe of outcomes and this probability the sample space one of the axioms of probability Axiom 2 says that this probability of something happening is one and at the point where here we can see hey if we're trying to derive that we're really close we just need to move probably e not happening to be on its own side in which case you get probably of e not happening equals one minus the probability of e happening you know this is what a proof and probability looks like it probably isn't that surprising to you and we can use these derivations we've got so far to prove further things okay let's take a moment and take questions if there's anything confusing about this let me know okay fantastic then I'm going to finish our warm-up with a question I'm going to give you guys some time to think about because I think it's really fun one of my favorite things in life is Serendipity when things happen which you didn't really expect to happen and they they seem to evoke the fruit of the random tree uh and they bring some good vibes to you okay so here's the problem that I pose to you Stanford has 17 000 people I don't know how many people you're friends with I'd say I'm friends with about a hundred maybe that's an overestimate but you know if you walk into a room and there's 268 random people that's how many people were enrolled in the class at the beginning of the quarter but now we're up to something like 315. what's the probability that someone is one of your friends that one of the 268 people perhaps in this class uh is one of your friends we have to make assumption we're going to assume that every person in this class is equally likely to be any of the 1700 people at Stanford if we make that assumption we can calculate the probability that if you chose a subset of 268 that at least one person would be a friend so that's your challenge and I'm going to give you this Pro tip you know how the probability of E not e not happening is equal to 1 minus probability of e happening that allows you to go from the probability of e not happening to the probability of e happening sometimes it's way easier to calculate the probability that an event doesn't happen this is one of those cases so think about my question as being the probability of e naught happening I'm asking what's the chance that out of this 268 people you don't see someone you know last Friday's class we talked about outcome spaces where every outcome was equally likely if you can utilize that we can solve this problem it's a pretty hefty warm-up problem but if you can solve this as kind of like you know upper Watermark of the sort of equally likelihood outcome space probability questions I'd asked you do you guys want to get started this talk about it with the person next you see if you can summarize what you're trying to do and see if you can solve that problem okay get to know a friend okay okay I love this it's such a hefty problem um so let's think about this together I want to figure out what are what's the probability of not seeing anybody that you know so uh out of 17 000 people we walk into a room with 268 people what's probably I know none of them and I want to set this up as a probability with equally likelihood outcome spaces if you want to do that you have to figure out the size of the sample space and the size of the event space and you want to make sure that every outcome in the sample space was equally likely so did anyone first come up with a sample space that they were happy with and that's like every outcome like what what's an outcome of this experiment too while we're thinking about it yes well I mean your sample space would have to be 17 000 choose 268. so that's the size of the sample space is 17 choose 268. but what's one element in that sample space yeah the person next to you um if you like a random selection of two human specific people yeah so every outcome in the sample space IS 268 people chosen how many outcomes are there well there's all the ways you could choose 268 people from the 17 000. that's a lot and a subset of those will be such that you don't know anybody in the class did anyone have a way of counting how many subsets of this set have no friends in the class yeah an idea over there uh you just subtract 17 000 maybe a number of friends from seventeen thousand and choose 268 again so the way you could you don't know still see people but instead of pulling from seventeen thousand we're going to pull from all the people who you don't know how many people do you not know is 17 000 minus your number of friends and I said I know a hundred people so it'd be sixteen thousand nine hundred choose 268. what are those odds so I know 100 people I walk into a room of 268 what are the odds that I don't see a single person that I know so let's do we got math.com seventeen thousand minus a hundred choose two hundred and sixty eight okay and I'm just going to call that my numerator oh that's a big number my denominator though is going to be math dot combination Seventeen hundred thousand choose 268. so the same number except in the this part we're pulling from everyone in Stanford not just the people I don't know and if you do numerator divided by denominator what's this point two zero mean it's a number between zero and one yeah it's a probability it's a problem I don't know anyone if there's a 20 probably I don't know anyone what's the chance I do know somebody is that wild if you only know 100 people on campus and you walk into a room with 268 you are very likely to know at least one person wow isn't counting cool what a time to be alive uh certainly there is this major key here and the major key here is oh my God would this problem have been much much harder if I just tried to count all the ways that I could know at least one person because I need to know all the ways that there's one person I know two people I know three people I know four people I know five oh that's so much this is counting zero people and then the chance I know one or more is going to be one minus the chance that I know zero people sometimes life is so much easier when you calculate the probability of an event not happening stretching your question looked like a good stretch I can go from stretch too okay more stretching I like this okay my daughter figured out what yoga was over the weekend and she's like the most aggressive yoga but she's like yoga every morning I don't know if she gets the vibe but she gets the stretching part to set up this problem what would it be like one leg set for the bathroom yeah I always start with thinking about the all the outcomes of the experiment so like what are all the outcomes of experiment and that was thinking of getting rooms of 268 people and I tried to figure out how could I count all the ways you could get a room of 268 people and then once I counted those and the way I count these both gave me the feeling that everything was equally likely like no room of 268 people is going to be more likely than another and once I'm there I'm in a good spot then the chance is just I need to count the smaller number of people that satisfy the event I care about The Meta step which we kind of glossed over because I told you let's just do this from the beginning is whenever I approach a probability problem I think is it easier to calculate the probability directly or the probability complement of the event complement in this case we just started by going with the event complement good question and end of review we've got a growing tool set and today we're going to add some awesome tools to the tool set we're going to add chain rule definition conditional probability you're a lot learn the law of total probability which is as impressive as it sounds and the law that is so much more impressive than it sounds based theorem we're going to hit some of the classics in probability Theory we're going to add them all to your probability tool set starts with one Concept in fact if there was a central idea to get today is this idea of conditional probability conditional probabilities really where probability starts to get exciting it's how you can update beliefs so if You observe some information how do probabilities change do you guys remember we talked about Dice and when we were talking about equally likely outcome spaces we introduced the world of dice we said let's say you have two dice and you want to know the probability that some of your dice is seven well we set up here's all the outcomes of rolling two dice and there's a subset of outcomes here that lead to the sum being seven and we said that because these are equally likelihood events we could say the probability of the sum being seven was just one two three four five six divided by 36 total outcomes equally likely outcome spaces gave us this way to calculate the probability but now let's change our problem a little bit I'm going to say not that the sum comes to 7 but that the sum comes to four and my question for you just to get us started is what's the best outcome for the first days so um so the two dice we're going to call the first ice dice one we call count the second dice dice two we care about them something before what do I want dice one to be well I say it's just as good if dice one and three or dice one is either one or three well I say it's equally good if dice one is one two or three do you think two one dice one is the best or do you think either none more than one of these answers is right think about it for a moment don't talk to the person next to you just appreciate foreign to think about this a little bit deeper let's talk about all the outcomes where two dice end up equaling four so if you take our 36 different outcomes of rolling two dice here are the three outcomes where your dice and up being sum to four it if we think about the probability of the event where the two dice equals four our sample space is 36 elements in it there's these three events that lead to the sum being four and then just using the math we learned on Friday the probability of the event is just going to be the size of this event space divided by the size of the sample space so 1 over 12. but I said the idea of today we really want you to understand is this idea of conditional probability and the conditional probability starts to introduce terms like this what's the probability of some event given you've already observed some other information and to practice I want us to enter this world of conditional probability with the simple example of what if the first dice was two what's the probability that my two dice sum to four given that dice 1 is equal to 2. there's no uncertainty as to whether not dice one equals two I'm telling you Dice 1 was 2. and if I tell you what that dice one was two I've asked you to calculate probability in the world where we have information and you can imagine when computers and probabilities got them together there's lots of situations where we have some information if I tell you that F has already happened that dice one is already two what happens to our world of probability the first thing that happens is there's no longer 36 possible outcomes to my experiment it's not possible that dice one is one it's not possible that dice one is six the only outcomes that are coherent with my claim that dice one was two are these six outcomes does that make sense so once I told you Dice one was two the world of possible outcomes shrunk quite a lot now out of all of these possible outcomes which ones of them lead to the two dice adding up to be four there's just this one if you think about if I tell you the first dice is two the only way you're going to end up with a four is if that second dice is two mathematically we'll end up with a probability of your event going up from 1 12 to 1 6. so you're probably an event happening increased When You observe that F had occurred that your first X was two the outcome space shrunk to every outcome that was consistent with what you observed the events base shrunk to every outcome that was consistent with what you observed and your probability increased because even though there's fewer things in E and there's fewer things in F all these events e there are larger ratio of things than S does that make sense though I told you what's the chance of getting a four it's kind of low but now I told you the first dice was a two and it's a little bit higher if I told you your first ice was a six what's your probability of getting a four yeah and so if I tell you your first ice is a two you're like still in the game so anyways back to my question if the first dice wasn't two but rather it was three what's your probability of the two summing up to four 1 6 because if the first ISO is a three again we'll have six things in the outcome space and again only one of those will lead to an outcome where the two dice add up to four there's only one dice on the second Throw That Could lead to a four it'll still be one over six what if that first dice was a one it's still one over six because if I observe that the first ice is one the sample space has got to be all the things consistent with the first bit I should be one so get one one two one three one four one five one six and the invent space will just be one three because there's only one outcome that leads to a four does it matter if the first text is a one two or a three they will all lead to a 1 6 probability of your sum being a four and this is our gentle introduction to the world of conditional probability if we observe some information our probabilities will change and that changing probability is what we mean when we talk about conditional probabilities it has its own notation when we talk about e condition on F we'll write it with this big vertical bar and if you read that in English it would still read as the probability of some event e given that a different event has already occurred it's known as conditioning on F and it's when probability starts to get way more exciting because you can calculate interesting derivative probabilities two things happen when you observe an event your sample space shrinks to be every outcome that's consistent with the observation your event space shrinks to be everything that's consistent with the observation and your probability can change let's go back to our world of outcome spaces in my tiles and think about what this means here's event e it's in red here is event F it's in blue ooh are these two events mutually exclusive no because there's these three events there's these three outcomes where both events happen when I talk about event conditioning on F we're going to enter the world where F has happened so if we want to calculate the probability of e given f we're going to take all of our outcomes and the sample space is going to be all the outcomes are consistent with f happening and this numerator is going to be all the outcomes of our event that are consistent with f happening it's like we shrink into the world of the green outcome spaces so if You observe F it's like f has happened only these things are possible outcomes anymore because I've told you f has happened so our outcome space will just become f and the event space will be all these things where are in both E and F that's a little bit mathematical what if we learned about this using a bit of Netflix which we'll do in just a second I want to point out a little bit you know there's this notation you'll sometimes see two sets without a symbol between them that's an implicit and and we'll talk a little about notation at the end of class I want to make sure nobody gets confused when you condition on F happening you enter the world where F has occurred your sample space will become F and your event space will become all the events that are consistent with your event space and F okay definition of conditional probability it has this definition mathematically the probability of e happening given that F happens is equal to the probability of E and F happening so all the events that are consistent with f happening divide by the probability of f happening there you go there is another way you could write this exact same equation you could take this probably of F and since it's a non-zero or you know since the number between zero and one so it's not negative well actually that's fine you can just multiply on both sides because that's math you can rearrange this equation and get probably E and F happening equals probability of f times probably e given F we'll call this a chain rule some people ask what happens if the probability of f is zero mathematically won't this blow up and let's always refer back during this lecture to what conditioning probability means it means we've observed some events is happening this is probably e given that we've observed F has already taken place what would it mean to say I've observed F has taken place but the probability of f is zero it's like it's probably f is zero it's impossible for f to happen right How Can You observe it if the probability of it happening is zero you've observed the impossible so if your conditioning on F that means you're told me f has happened it can't be the case that probably if f is zero the probability of e times f is this yeah fantastic so this is what's the chance that e happens given that F has already happened and this is what's the probability of both of them happening and it's so subtle it's so subtle so if you say e given F you've told me f is happening I've entered that world and if you say enf I don't know if f is going to happen and I have to think about F happening and E happening simultaneously super subtle but with something we're going to hit a whole bunch today because that's exactly one of the most important questions to ask now I've decided that this is very mathematical and a little bit hard to understand just from definition so let's do something a little bit more intuitive we're going to do some Netflix and learn and we're going to think about how conditional probabilities change and we'll get some nice intuition around it one of my favorite movies in the world is this movie Life is Beautiful this is not your favorite movie we can talk about that and I will convince you that's one of the greatest films ever made okay um just just to be cheeky we're going to talk about the probably that a user watches a movie in the context of this streaming uh platform called Netflix now what's the sample space of somebody watching or not watching Life is Beautiful well there's two outcomes somebody can either watch it or not watch it and the event that I care about is that they watch it is the probability of event one half no we could only do the size of the event space divided by sample space if each of these outcomes was equally likely so it's not one half so how do you think we could get the probability of somebody watching it assume we're Netflix how do you think Netflix does this they very much care about the probability that somebody watches a movie [Music] they can they could infer it it turns out Netflix is so big they can calculate it directly they can just know the problem that you like watch a movie that was a good idea yeah they take a look what other movies we've watched yeah that's very even simpler thing that they do that's a very good idea but there's an even simpler thing that they can do yeah and if they put on the French page what they can do is they how many people actually watch it uh and so here's one of the things I do it's even simpler than what you guys are thinking about they go back to that core definition of what a probability is and they just count if they want to know the probably somebody watches a movie they say well we have like a billion people on Netflix I can see I can think of each of those as an experiment and I can see what fraction of those lead to a watch and that will estimate the probability that a user watches the movie and it's like they're going back to that core definition of probability and the core definition probably is like if I ran infinite experiments what subset would lead to my event so Netflix you know 50 million point nine 50.9 million people are on Netflix of which 10.3 million watch this movie you would say that probably somebody watches this movie is 0.20 does that make sense even simpler than a lot of people a lot of people have these very good ideas if we could look at what they watch for other movies that would not give you the probability of the event on the on its own but it would give you something more interesting you guys are going down a more interesting path which is where we're all going today for lots of movies you could look at the probability that somebody watches the movie and it's just going to be counting what fraction of users watch that movie but these numbers are not that interesting the interesting thing is how do these probabilities change when you observe interesting stuff like they watched another movie and this is what everyone was getting to when we were thinking about the answer to that question because maybe we all care about this problem that's where we intuitively go to First the more interesting problem Oh I have a typo here the more interesting problem is what is the probability that somebody watches this movie condition that I've seen they've watched another movie so I'm going to introduce another movie that I like called Coda which I think is fantastic has anyone's seen this there's a two versions of code yeah isn't it so good it's freaking amazing okay anyways so now I want to change our probabilities not just what fraction of users watch this movie but if I tell you that a user has watched coda how does that change my belief that they'll watch life is beautiful and welcome to the world of conditional probabilities and these are the more interesting probabilities because you're more uh tuned to the person that you're Computing a probability for if you want to know the conditional probability you know here's the definition it's the probability that somebody watches life is beautiful and they watch coda divided by the probability that they like they watch Coda this is just our definition of conditional probability both of these could be estimated using the fact that Netflix is very large you can say this is the number of people who watch both divide by the number of people on Netflix is a good approximation of the probability that somebody watches both the number of people who watch and this should say Coda divided by a number of people of Netflix is a good approximation of the probability that somebody watches coda and if you cancel out the number of people on Netflix and you update this I used to like Emily it's still a good movie but then I saw Coda and I'm like I have to update I have to update my example for my like new second favorite movie is just so touching okay if you calculate this probability you get a different number by the way when you cancel that number of people who like Netflix you're you're left with a number of people who've watched both so you know number of outcomes are kind of consistent with E and F divided by a number of outcomes uh in F of people who watched coda and these two tell two different stories these two numbers we calculated tell two different stories and it's gonna be really hard for you to distinguish them at first but cs109 you're gonna be such a pro at this when you walk out the first number was what's the probability that somebody watches this movie given no other information and this number is what's the probability that somebody watches this movie given the information that I know they've watched this other movie and these changing probabilities are a big deal okay we can do this for every single movie you know we took life as beautiful and we figure out the probability of that given F and we can do that for every single probability that we calculated before they'll mostly change not all of them but most of them will change some will go down if I tell you that somebody's watched Coda it's possible for it to be less likely for them to watch a movie that you care about or as possible for the probability to go up quite a lot the probabilities can change a whole bunch when you get some information and that's the big idea of conditional probabilities I want to stop there I want you to talk to the person next you see if you have a cool question you can ask me try and summarize what we've talked about and see if you can come up with something that could be clarifying okay go talk talk okay I want a cool question anyone find some of this confusing it'll be confusing the first time you see it but it becomes it's important so I want to take clarification questions great time and lecture questions is this concrete example making a little bit more apparent than maybe the dice one since nodding any questions that came up so any movie can be conditioned so for example they might not Star Wars and Coda could be pretty unrelated but you can still ask the question what's the chance that somebody watches Star Wars given that they watch Coda even if they're totally unrelated movies with no with no common themes but if I'm telling you the the this piece of observation that the person watched this movie and it can change my belief of the probability that they watch Star Wars this probability went down it kind of tells you that those movies are unrelated and if they're unrelated if somebody tells you you've watched Coda maybe it gives you information that they know they like that kind of movie and if they like that kind of movie maybe it tells you they don't like this kind of movie so then maybe that's why the probability is going down we can talk about lots of causal mechanisms why these probabilities go down up or down but you can still ask the question and when you ask the question you know we can get a numerical answer we'll get deeper into the whys as we get deeper into conditional probability does that help yeah I guess yeah you know yeah some people are interested in all movies some people have genre preferences there's this like deep psychological human causality that's going on and despite all that causality you can still ask conditional of any two events that you care about and we should talk about that deep causality and I'd love to get into that after class yes yeah yeah what's the relationship between like conditional probability and like it's a compliment of an event like is it meaning what's the probability of e given that not e oh that's the problem ready I tell you that I mean it's a really good question because it talks about the semantics we enter the world where e has not e is true and if you enter this world we're not es2 there's no chance that e happens so in conditional probability you enter a new universe where everything on the right of this line has occurred and then you ask the question on the left of the line yeah that you've just rolled a six yeah because if you're saying what's it probably a dice one is one given that dice one was a six zero it's a six but if there's two dice you can say what's probably dice one equals one given dice two equals six that's totally legitimate and if you think about multiple roles of the same dice I would distinguish those in some way I'd be like the first rule is one given the second rule is a six or something like that very very good question yes if something so you're talking about PF having a probability of zero right yeah the probability of zero does that necessarily mean it can't happen yeah because what's the probability that you pick a certain number on a scale from zero to one interesting you know I would talk about it as being like a limit probability we can get into that but like if you tell me something that's probably easier and if you're right if you could be wrong you might say it's probably zero but you're wrong like the probably the sun doesn't rise you could say it's probably zero and then you're wrong and one day it doesn't rise and you observed The Impossible um but if you're right and it's truly probably zero can't happen yeah yes okay uh this is also just a gentle introduction to why probability is so exciting why we decide to offer this course of cs109 because as a computer scientist you're going to be interacting with data a lot and you're going to use computers to understand that data and language is really the or sorry probability is really the language where these two things come together um you might sometimes see people referring to that simple example we did before as machine learning machine learning is just a nice euphemism for people who know probability and can do some data with computer science at the same time okay I want to take a moment though and distinguish three concepts we've talked about unfortunately people across the world of probability use lots of different notations for them but we've got the probability of and of events the probability of the ore of events and the conditional probability of one event given another events are things that can happen the probably event what's the chance that they both happen different from this what's the probably one happens given I tell you the other one has happened subtly different but very importantly different and the probability of or saying that either e or F will happen three different concepts and I just put up those notations that so you can check later and make sure you don't get confused somebody writes this they mean and they write this they mean and if they write and thank you for saying what you mean uh same they write this they mean or or if they write or they mean or and those are two concepts are very different from the conditional probably Constable which might be new for you okay uh I was thinking about baby poop when I was writing this lecture and so now we have a baby poop example I have a baby in the morning when she wakes up there's a 50 chance that she's pooped in the night or not uh and it's not always the case that she cries when she wakes up and it's not always the case that she cries if she has poop but if she has a poop there's a 50 chance that she cries so I want us to think what's the probability that the baby has pooped and cried and we're going to use this as a chance to try and separate our difference between uh probability of and and the probability of or and here I included the definition conditional probably and the probability of and and I want to point out that this question has the word and in it so what's the probability that the baby has pooped and cries think about it for a second and then I wanted to take a moment and Define some events uh I'm going to do e for excrement I can't use P why don't I use p yeah super confusing when there's all these Capital P's around so this is going to be the event of pooped and we need a vent for cries why shouldn't I use k a c for cry compliment oh my gosh okay so what are we gonna use for cry we'll use like tea for Tears cries this question is asking what's the probability of E and T it's also given us some information we said the probability of e is 50 and then there's this line the chance that the baby cries given that she has pooped is 50 what is that telling us so the probability that the baby has pooped or sorry the baby cries tea given that the baby has pooped is 50 percent so this is hopefully just straightforward once you recognize everything that's written as a straight example of something called The Chain rule so it says there's a 50 chance that the baby poops and if the baby poops there's a 50 chance that the baby cries what's the probability that the baby poops and cries I hear it somebody tell me loud and proud 25 25 you can just multiply these you know the relationship between probability of and and conditional probability is given by these two formulas which are uh isomorphic versions of themselves so this one is saying the probability of two things happening the and of them is the probability of one thing probably times probably the other thing given that first thing so she poops and then she cries given that she poops if you multiply these two numbers together you get the and so they're different and in condition are two different things and there's a mathematical relationship that governs their how similar they are so the probability of this is going to be equal to the chain rule which will be those two things multiply together you're exactly right it's one over four fantastic uh and you know the point here is that people will find and and conditioning complicated maybe you should pause here for anyone who is thinking probably the end and probably a condition where the same thing we could pause here and see if there's a good question life of a parent man lots and lots of poop yes is the reason why why ordering of it is that why they're like two separate things good the ordering does matter okay so when we say that ordering I often think about conditional probabilities the probability of ordering an and doesn't matter ENT is the same as T and E they're both happening it doesn't matter which one probably if T given e is actually different from the probability of e given t let's think about them semantically and these are not the same the probability of you crying given that you pooped is not the same as the probably that you pooped given you cry there are two different universes one we know you're crying and we're trying to figure out whether or not you pooped the other one we know you pooped and we're trying to figure out whether or not you're crying and they're two different probabilities so in conditional probabilities order really really does matter so going off that in this case if we only have a probability that they cried and then we had the probability that they cried giving cheap food we wouldn't be able to solve this right is that like what you're saying yeah there's lots of versions where I have not given you enough information to solve this I happen to give you exactly the information you needed to solve this and so if I've given you for example if I've given you the wrong conditional probability here there may be no way to solve that very good question yes yeah our cases uh where where these two things could be equal it's just we don't know they're equal but yeah there's some cases and it's more just luck if it turns out that they're equal okay fantastic the chain rule is very helpful the chain rules what we just used and it says the probability of two things happening is the probably of one thing times probably the other thing given the first thing and it turns out you can chain rule as much as you want if there's like the probability of event one end event two and event three and event n happening you can take the chain Rule and just keep going you can say what's it probably that event one happens times are probably that event two happens given event one happened and then this is some weird notation like what is going on here this is saying what's the chance that event three has happened give an event one inventory it happened you enter the world where I know event one and two have happened and I asked what's the question that event three has happened and this kind of seems like logical it's like the chance that event one happened okay now I know event one happened what's the chance that event two happened now that I know those two events have happened what's the chance event three happen and that's a chance of all three of them happening that's what the chain Rule's stating okay whoo you guys are ready for a law that is so useful it gets the name of the law of total probability are you guys ready to dive in let's go back to poop so let's go back to this world where I give you the probability of uh the baby pooping I give you the probability that the baby cries given that she's pooped and now I want to ask you the question what's the chance that when you wake up the baby's crying and I'm not giving you enough information you can't calculate the probability that the baby's crying I've only told you a chance that she's pooped and the chance that she cries given that she's pooped and I want you to just take a moment and try to invent some probability what is the information that you're missing if you would want to be able to say the probability that she's crying and this is pushing you to kind of invent the law of total probability but talk to the person next to you for a second and let us do it says do this together okay does somebody have an idea it's totally fine if you can't invent this we will tell you but maybe somebody invented it yeah in the back you cried given that she didn't poop yeah there's two worlds that can lead to her crying either poop but it's totally possible that she's crying when there's no poop and I don't know what's the probability that she cries given no poop and no poop mathematically I write as e complement excrement compliment and that's what we're missing that's exactly what we're missing and if we had that what that would lead to would be the law of total probability the law of total probably says if I want to know the probability that my baby cried or some event and there's some background of events like pooping or not pooping the law of toad probably says you can figure out the probability that she cries by thinking about these two cases either she cries and there's poop or she cries and there is no poop and because those are mutually exclusive events by the third accident of probability if you can figure out the probably that she cries and there's poop and you can figure out the probability she cries and there's no poop then you can just add up those two probabilities so just to make this clear I only care about the problem that she cries but there's this background process of poop or no poop and you know since pooper no poop spans the entire space you can think about crying as coming from either this set of outcomes or the no poop set of outcomes is that making sense it's a hard one but if you get this that's the law of children probability you can kind of decompose your calculation the probability of crying into these two cases crying with poop and crying with no poop I can't believe how many times a managers say poop in a Stanford class uh okay does this make sense though right you're like your e can either come from E and F and E and not f these two sets must be mutually exclusive because it's not possible for both F and not F to both happen at the same time so your Mutual exclusive events so the probability space here can be added to probably a space here to get the probability of my event I care about in blue this does generalize oh by the way once you get with this statement each of these probabilities can then be to decompose you to the chain rule E and F can be probably e given F times probably of F and E and F complement can be the probability of e given F component times the probability of f complement just using the chain rule on both of those uh pieces so that is the law of total probability if you want to know probability of e you can use this calculation to solve it and you know there is a proof here for those of one who want to see the complete list but I really think that this example is going to drive it home the thing we were missing was the probability of crying given no poo so let's make that up and let's see if we can solve this the probability of her crying given no poop let's say that equals one over eight if I told you that this was one over eight what's the probability that she cries the probability that she cries oh a whole bunch of Bits good the probability that she cries is going to be either equal to the case where she cries and there is poop so the chance that she wait I want probably of crying tears so tears given poop times the probability of poop plus probably of Tears given no poop times the probability of no poop what's the probability of poop yeah one half what's the probability of Tears giving poop we're told it's one half what's the probability of no poop oh I didn't tell you that one question how do you know it's one half declare every people I know that one minus this probability will be the probability of its complement and now we say the missing information is probably that she cries given she didn't prove and we said you know there's a one in eight chance of that this probability gives us doesn't tell us what this probability is being told the probability she cries given poop doesn't give us any information about whether or not she cries when there's no poop those are two different worlds and two different outcomes for probabilities and if you think about this case and add in this mutually exclusive case we have both cases where she's crying either crying with poop or crying with no poop there you have it the love total probability what a poopy explanation okay now we're going to bump this up a notch and try and do something a little bit more interesting so see if you can use a lot of total probability and practice this world of taking a word problem and figuring out what are the probability events and what are the formulas I can use bacteria can that can cause a disease let's say 10 of those bacteria have a mutation which make them resistant to antibiotics you take half a course never take half a course if they say take the full course take the full course because if you take out of course what happens Evolution your bacteria or evolves and the process is basically that the bacteria that has mutations are much more likely to survive and bacteria that don't have mutation they're much less likely to survive so the survivors end up being filled with mutated bacteria but my question for you is what's the probability that a bacteria survives and this is a hard question it's invoking this very complicated thing the law of total probability and it's invoking your ability to read a word problem and pull out all of these probabilities step one if you're finding this hard Define events and once you have events try and figure out everything the problem is telling you and see if you can solve it so take a moment and we will think about this together in just a moment too feel free to talk if you want okay your process is first to Define events I've got an event bacteria has a mutation I call that M for mutation bacteria survives I call that s for survives now my next thing the problem tells me a lot of information and it defines a challenge it says what's the probability that bacteria survives it wants to know probability of s but it's given me a bunch of information the first thing it says 10 of mutations uh okay ten percent of bacteria have a mutation that's not telling me a conditional probability that's telling me an unconditional probability it's saying that the probability of mutation equals 10 percent it then gives me more information it says the probability of bacteria survives given it has mutation it's 20 that given is a dead giveaway that's talking about conditional probability it's telling me the probability of survival giving mutation equals 2 out of ten and the last sentence is probably bacteria survives given it doesn't have the mutation as one percent it's telling me the probability of survival given no mutation equals one over a hundred so I know probably of M probably s given M and probably s given M complement those are directly told but guess what there's three hidden probabilities that you're told which are not explicitly written if I know probability of M I also know probably them complement what's the probability that something doesn't have the mutation yeah it's clever students good times but I tell you that there's three pieces of information I'm also telling you the probability of s complement given m is eight out of ten you need to know a really important thing about conditional probabilities if you enter the world where M happens all laws of probability still hold and condition on this world M the probability of s given m is going to plus the probability of s complement given m is going to equal one it's like m is the world we've entered where there's mutation and in that world all laws of probability hold so it's still the case that probably S Plus probably s complement equals one in the world where m is uh true so this we don't need but I just want you guys to know that you also have this information okay so a lot of information was given to you in the problem but what we want is the probability of s so notice my three steps wanted to find events two I pull out all the information for my problem and three then I try and solve for the thing I care about probability of s how can I get there corner yeah we could use the log total probability there's two different background processes either it has a mutation or it doesn't so the probability of s can be the probability of it of s n mutation plus the probability of s and not mutation particularly you know you'd have to take this equation and replace every t with an s and you'd have to replace every e with an m and you get the probability of s is equal to the probability that it survives given has a mutation times it probably has a mutation do we know this yes do you know this you can all say it loud okay do we know M complement yes do we know s given M compliments do we have all of your information we need to plug a chug um uh anyways the log total probability helps us solve this problem but the really important thing is this process of pulling out events uh defining what you get from the problem and then you can just plug and chug okay law of total probability we'll get into this later when we use it more but there is a big brother version of the raw of top probability where you can have background events which aren't necessarily complements but if background events span the whole space and they're mutually exclusive there's a more grown-up version of Love 12 probability which we'll talk about when we need it I just wanted to mention it for the first time now for now though I really want you to start to feel comfortable with this version of the law of total probability okay it's not the real question though is it we don't often care about the probability that a bacteria survives what we really care about was what's the probability that of surviving bacteria has the mutation we really care about the probability of mutation given survival you're like isn't that given right here we're told about the probably survival given mutation but someone asked a good question before does the order and conditioning matter and I said absolutely does matter if I tell you the probability of survive mutation you don't know the other conditional probability but there's a way to find out and this is an idea that changed everything in fact one of the the books I brought in and the the second day of class was the the idea that would not die it's an idea that has changed mathematics and then it changed computer science for mathematics and it's something that's shown up like 10 times independently in my research it is a beautiful beautiful idea that can allows you to go from conditional probably in one direction to conditional probability another Direction one of the great things you'll walk out of cs109 knowing and we're going to see it for the first time today okay so so far we've talked about how you can use the chain Rule and definitely probability to go between E and F and the probability of e given f we've talked about the law of total probability which can allow you to use conditional probabilities and get back to an unconditioned probability and it's now time to learn how you can go from a probability of a condition in One Direction and figure out the probability condition the other direction it's time for some base theorem okay we're going to tell you about beta sermon first I need to introduce you to Tom and Bays um he was English Presbyterian Ministry invented Bayes theorem he didn't name after yourself somebody else named it after him after he passed away and I'm going to say look remarkably similar to Sean Aston who played many important characters in many important movies but that's not important right now Bayes was thinking about this math problem which might have popped into your mind I care about calculating the probability of the state of the world given some observation and I don't know how to do that it turns out in some situations the opposite's easy I can know the probability of some observation given a true state of the world and how can I go from one to the other and he was pondering this mathematical question when he came up with what was one of the most profound important contributions to mathematics that's entered computer science but also turns out to be you know kind of reasonable given what you've learned so far so to be clear he knows the probability of condition in One Direction he wants to know that probably in the other direction in the real world it often follows that there's something of unobserved that you care about inferring and there's some observation that you see and it's it's much easier to know the probability of the observation given the thing you infer rather than the probability of the thing you care about given your observation don't worry too much about that but we'll see lots of real world examples I'll keep referring to that and it'll make more sense as we go but he was trying to figure out how you can go from one condition to the other direction and he started with this definition of conditional probability I imagine he stared at it and he had he had a little lamp and the light was fading and just before the light faded he's like oh my gosh I can just plug the chain rule in to the probability of and because the chain rule says the probability of E and F is probably e given F times the probability of F and you're like wait isn't the chain rule in definition conditional probability like aren't they just opposites of each other if you plug this in should everything just cancel out well there's two versions of the chain rule you can say e and f is equal to e given F times probably F or you can say probably if E and F is probably F given e times the probability of e both are true one of these totally cancels out and the other leaves you with a deep theorem in mathematics so you just plug two rules into each other and he was left with this identity which gave us a way to calculate the probability of one conditional given the other and I imagine the next day he was looking as like that's beautiful I think he just probably spent a whole day just weeping on his parchment just like this is so gorgeous I can't believe we can finally calculate the probability of condition given the other direction and then he's like but wait we can go further he's like this is all good and fun but maybe this denominator term is sometimes hard to find and he's just like I'm just going to plug in the law of total probability so basically this Presbyterian Minister plugs three math formulas into each other like all known math formulas it becomes like the most famous mathematician of all time you're like I could have totally done that if I was born in like I don't know 1705 but anyways Bays got there at first uh he figured out that you can plug all these identities into each other and you can get a way for calculating the probability of one conditional given the other this looks very intimidating especially because I wrote one too many probably uh of ease just to make you guys feel a little bit more intimidated uh it still feels like a lot of um terms but it turns out you know these oh man how did I do that again a little too excited um technically though that's right because you'd factor out the probably bathroom though just cancel but um but this is the the actual formula of Base theorem that you'll see on something like Wikipedia this two terms you know they're the same as these two terms so even though there's a bunch of turns here those two are the same as here um Jesus I got my chain rule wrong typing too fast okay uh and and those two terms are different but there's really only four unique terms you'd need to figure out the probability of conditional probably the other ways here is it stated correctly I mean Bayes theorem is really saying that you can calculate one conditional probably the other way around uh and there's two versions of Bayes theorem if you go to Wikipedia it will quote you this one that's basically just conditional definition with the chain rule stuck into it uh but often in cs19 you'll want the expanded form where you just take that bottom thing and apply the law of total probability okay we're going to take this out for a spin here's a real world example that follows the pattern where Bayes theorem becomes so useful you care about whether or not something is spam so you want to know whether or not something spam email and You observe something about the email in this case I'm going to say that the email has the word dear in it what we would like to know is what's the probability that spam email an email is Spam given it has the word dear in it but the other direction is much easier to know if you want to know the probability that an email has a word dear knit given it spam you can go through your database of spam emails and just count what fraction have the word dear in them but in the real world when you're trying to detect spam you don't care about the chance that spam email has the word deer in it you care about whether or not you're looking at spam email and you're given the information that the email has the word dear in it so you want the opposite of what's easy to measure and Bayes theorem says that we can just apply uh this formula to go from one formulation to another here's what a Bayes theorem question could look like and I put the formula up in the top right corner sixty percent of all email is spam you need to know the background probability um of f in this case you need that twenty percent of all Spam has the word dear so that's the probability of the of One Direction and you'd like to know the probability of the condition the other direction and then you need to know what's the probability uh that F complement you need this probability stated you need to have these three probabilities stated why are those three probabilists data those are the three that are included here why is it not necessary to know the probability of f complement yeah yeah okay that super important hint from the beginning of the warm-up says classes come a whole bunch of times the probability of f complement is equal to 1 minus the probability of f so if I tell you 60 of all email is Spam forty percent is not spam if you get an email with the word dear in it can you now update a probability that the word is Spam sometimes you'll see this called belief you know what's your new belief that an email spam given that it has the word dear in it well let's define our events so I'm going to say e is the event that the email has deer in it and F is the event that it has that is Spam and this will make it perfectly match the Bayes theorem formula identify All the known probabilities in this case you know we have probability of f the probability of D or sorry e given F and we have the probability of e given F complement and then once you have those you're just going to plug those values into Bayes theorem and you are done so interestingly these terms in base theorem they have names this probability F we call it the prior it's your belief in spam before you saw that it had the word dear in it so it's your belief prior to observing deer and this is your belief After You observe dear the chance that is Spam and the chance of spam given that it has the word deer in it and it's kind of like you're taking this old probability and updating it given the evidence of the word dear you need to know the likelihood of the evidence what's the probability of deer given that it's spam and then you have to do this normalization at the bottom we're using the law of total probability okay and if you just plug this in you would get the probability of something being spam given it has the word during it one of the most canonical examples of Bayes theorem is talking about medical tests and this has shown up a lot in our lives now that we've had to live with covid for like almost three years let's not talk about covet for a second but let's talk about SARS and let's talk about it a medical test for to testing whether or not somebody has SARS these medical tests are operating you know at what we call a 98 effective rate so if somebody has SARS there's a 98 chance that it tells you they have SARS and there's a two percent chance it tells you they don't have SARS so there's this truth about the person the person either has SARS or not but the test is not perfect the observation you get could say this person has SARS even though they don't or it could say they don't have SARS even they do this is saying that if they have SARS 98 of time it says they do it has a false positive rate of one percent which means that if they don't have SARS one percent of the time it says they do so probability of saying it has SARS given that they don't is one percent a very small percentage of the US population we're going to say has SARS when this test is run and I'm going to Define these events to get us started is the event that you test positive for SARS and F is the event that you actually have stars if we did this all together the probability that we really care about in this one is what's the probability that someone actually has SARS given that they got a positive test so imagine you're at the doctor and said you just had a positive test for SARS you're like oh no what does that mean well it's not conclusive that you actually do have SARS instead we want to know what's the probability that you do have SARS so the problem that you actually have stars given that you tested positive base thermally said that this is the probability of e given f times the probability of f and then we would use the law of total probability to say that this is the probability of e given f times the probability of f plus the probability of e given not f times the probability of not f okay what's the probability of f what's the probability that somebody has SARS given no other information 0.05 wait 0.005 because it's point five percent of the US population if it was five percent of the US population 0.05.005 is uh half a percentage of the usual population so we know this number two this is also 0.05 and this number of here is going to be 0.995 so 99.5 percent of the population doesn't have SARS unconditioned on any other information but how about this one do I know the probability of e given F what's the probability of the test saying they have SARS given they actually do have SARS 98 is 98 effective at saying you have SARS given that you do have SARS so 0.98 that's this number over here and the last number I need is the probability that you have SARS given that or sorry the probability that the test says you have SARS given that you don't have SARS if you don't have SARS it has a false positive rate of one percent if you don't have SARS there's a one percent chance that it says you do if you take all these numbers you can now just plug and chunk and if you plugged and chugged you would get that there's a 33 chance that you have SARS isn't that crazy you walked into the doctors they tested you for SARS it says yes you have SARS and still your chance of having SARS is only one in three craziness Bayes theorem gives you the ability to know exactly what is your updated belief in this case that ability to know the exact probability is very useful because there's this one really confounding factor and the one really confounding factor is that very very very few people in the background population have SARS so even this tiny false positive rate can lead to a situation where you're still less likely to have it if you test positive I wanted to take a moment to go over intuition here's all people in the United States here is that half a percent of people who have SARS some of the people most of the people who have SARS are going to test positive but a whole bunch of people who don't have SARS are going to test positive too there's two ways that you can test positive you have SARS and you test positive or you don't have SARS and you get what we call a false positive but it turns out there's so many people who don't have SARS that if you enter the world of all the people who test positive there's still more people in that world who didn't have SARS and had a false positive than people who did have SARS and got a test I actually thought it would be easier to make this point by drawing you a picture of everybody in the United States I'm gonna make a person here or imagine a thousand the US is represented by a thousand people if only point five percent of people have SARS you've only got these five people with SARS and all these people don't have SARS imagine every single one of these five test positive out of these 995 people who don't have SARS most people test negative but one percent of them test positive when we condition on the fact of testing positive we enter the world where we're looking at only the people who tested positive and in this world there's more people who didn't have SARS and tested positive than there were people who did have SARS and tested positive and the ratio is exactly one-third isn't that wild Bayes is a mathematical identity I really do think of it as two equations put together but there are two equations put together that can lead you to very surprising results and when you get surprising results that's often where you get power for results and possibly that's why this equation shows up in so many algorithms for computer science I do actually talk about why it's still good to get tested you can calculate the probability of having SARS given that you got a negative test result and your chance that you get have SARS given negative test result is actually very very very very very very very small anyways not that important right now I put in one last example if for people who want to have a little bit more examples with uh Bayes theorem and that's where we're going to leave it for today in fact I'm just going to State this and I'm we're going to answer it at the end so this is something you should be able to do by the end of the day if you feel like you can't do it take some time with it between now and next class because this is really really our learning goal this is a cool example imagine you want to know the probability that somebody knows a concept and All You observe is whether or not they get a multiple choice question correct there's a lot of probabilities that people have in education Theory they say if somebody doesn't know the answer to multiple choice question there's a one-fourth chance that they can get it right now if somebody knows a question they don't always get it right uh or sorry not everyone knows the concept going in so let's say three quarters of your population knows the concept going in there's a chance to guess it right just because it's multiple choice and there's a chance that they get it wrong even if they know it sometimes the people who know a concept will slip and just make a mistake could you put all this information to infer the thing we really care about what's the chance that they really understand a concept given that we observed a correct answer this is the sort of thing you should be able to beautiful tool you have with Bayes theorem see if you can do this if you can't do it practice they come back on Wednesday and we will take this to the next level also on Wednesday sorry I wanted to promise you something on Wednesday we're going to gamble so learn this stuff so you can come see us online make some money foreign