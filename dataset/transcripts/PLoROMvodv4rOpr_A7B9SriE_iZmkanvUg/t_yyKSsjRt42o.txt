all right so welcome to the cs9 final review session um my name is will thank um I'm w t uh I'll be leading the the section so first up here's a here's CS 109 the general advice usually we want usually students focus on how to like apply formulas from class maybe try to get a numerical answer and the these are done these are like okay so one example how to take a derivative from an mle like okay that's actually kind of like that's quite challenging but also like once you know how to take a derivative it's pretty straightforward to take a derivative the hard part is usually like the modeling so like log likely like actually finding the distribution for a log likelihood if we don't tell you so on that note especially for the final if for those for those of you that have seen the practice finals there is a lot of reading like every single problem has like two three paragraphs of just like straight context and then like three bullet point questions that come right after it so in the same sense the final the midterm exam had like six questions or five or five questions or so with like very small like amount of reading and like a lot of problem solving on the final similar number of problems a lot more reading and expect a few more parts okay so please read the problems very thoroughly and then like the problem should be like doable okay all right so here's how to read probability in defund the final exam Edition so to make this slide I kind of went through the first final that I saw and just took a look at okay like what's the most common Paradigm that we saw what the most common amount amount of words by the way these slides will be posted later um so the first thing so first things are like what's a prob what's the probability of blank this is like in like three out of like or at least one of the sub parts on most of the problems I've seen how much more likely and then okay so in that case you want to write a probability of something a very common one we also see is like how much more likely is a blink than a blink usually this means you want to you want to be dividing two likelihoods or PDFs or probably or like products of of PDFs in like this in the discret case this would be like the like two probabilities and you'll be dividing them okay so we also see the word yes you mean by likelihoods oh likelihood is like like the product of like of like a PDF so like uh P4 problem 7 there was a okay maybe I should explain what that is it's uh just dis thing boy your likelihood is like this like you're just uh like as some point in time in one of your pieas you had something that looked like this right or I guess it wasn't Theta at this point it was like a x given B it was a and x given B right I have to like Duck my head down I to use microphone so that's what I mean by likelihood like this is technically like a this is kind of like a like a form of likelihood okay all right if we say the word parameterize and don't and don't specify the method which we probably will specify the method it usually means you're going to do one of mle or map and if you're going to be doing mle or map find the data like find what your what Your sums or what your products are over especially like I think on the on like the last section we had a problem about like start about setting up like a bobo place on campus there was a hidden data point in there somewhere that they you had do mle4 it was a single data point so that could happen Okay um if we say approximate so during the midterm approximate just means use a gausian or person approximation and on the final all that means is if you see a set of random variables go hand just use CLT okay that's usually what approximation means here by the way cave if you CLT make sure the continuity correct continuity correct is everywhere I did not put them in in the slides because that's kind of like a thing we cover cover before the midterm but like remember to do that here too um is blank significant uh usually that means like a bootstrap or like a P value so typically like write write an algo or like uh show like hey like count some things to be like hey the P value is like greater than 5% uh probably not probably not good as so okay all right so with that we start our journey with betas betas are the first things that we saw that were like clearly post midterm material and in a beta the way the dist the the beta distribution is set up like with two parameters A and B and they represent a minus one heads and B minus one Tails from like a bias coin y so betas are always typically over like typically characterize our belief over a beri and they represent the prob the probability of a beri parameter given like certain amount of heads and a certain amount of Tails okay um there the betas are in the range zero and one they have some they have a form of a PDF with some parameter with some like constant B that that is like that we we write explicitly later the important parts are the expectation and the variance so these are the two these are the these like two values that I saw come up in like one of the practice exams I have an example on this like the end the size so we we'll take a look at it more but generally the reason why we put beta distribution after the midterm and in its own thing is because the beta the beta distribution actually like it captures something about the parameters of a brunoli like before we just had like Beres or like just like um binomials about like random events now we're like okay what's the pro what's like the r what's the probability of like of a particular Theta in like AI okay all right then we talked about adding independent variables so the three most heavily used forms I've seen of adding Rand random variables are like pan adding pons adding normals adding binomials they all have to be like kind of they all have to be like IID like so so like if they're independent of each of each other and they're from the same pant distribution and you sum them you can like that's like just like Su suming to the L suming to the lambas K uh one particular example of this is like in evg there's three elevators if both of the the other elevators are are out of service what the the the amount of people that are going to be trying to trying to go into an elevator on or they're going to be trying to go into the last remaining elevator will be three times Lambda assuming each one of the each one of the elevators is like has a plus of Lambda for students trying to use it okay um the normal distribution so okay when you add normal distributions you want to be adding variances you don't want to be adding standard deviations so that's why we put the sigma squares over here so St like if you have two r two like normals you add add the mean add the variance and then like one particular example of this is like okay like heights are typically normally distributed so if you had like people like sitting piggyback on top of each other that's like the sum of two Cs on on on the height yeah it just literally taller um and the final one is on binomials so binomials is like if you have like when I think of binomial I think of like trials and I think of like a b of like some underlying like bruli event like I have a coin I'm trying to flip it I'm trying to get how many however many heads or however many Tails so one way to think one example to think about like binomials is you and a co-author are conducting the same experiment right and and then but you ran you like ran N1 trials and your co-author ran N2 trials like independently of each other like what is the probability distribution of like your results from those from like if you like coales the two the two sets of Trials together and the solution is well like just add the so you just increased the number of Trials you didn't change anything about the underlying parameter so you're just going to have have a binomial of like number of trials for one plus number of trials for the second one okay so this is adding independent random variables yes previous slide there's a constant FR of the data distribution yeah what does that mean uh that's not a course reader it's some complicated number yeah like we have it in the sides but like I I just yeah it's a constant like you can normalize it out usually yes we need to know that constant for the fin we'll probably give it to you if you need it honestly but real answer you got 10 pages of of riew sheets just sticking like the margin of one of them okay all right any other ones no okay so here's a central limit theorem um there's two there's kind of two flavors of the central limit theorem you could take the sum of i x IID random variables or you could take the average of some IID random variables one example of some IID random variables is give enough trials anything looks like a normal so so if I so like those like that that little graph like if I just keep rolling dice the sum that I'm going to get from those dice it's going to eventually look like a normal and that's like the approximation that we're going to use um average of IID variables they these actually these actually are used a lot in the noising so like if you like the one example like sample means are normally distributed so like the bigger your sample mean the more the more the less variance of those kinds of means that you will see so like the better so that's like like a tight like a tighter average that you would find okay make sense these are so this is like one of the critical theorems that we use and we actually given it a name okay all right so next thing that we have is sampling so in sampling we actually saw how to use the how to find the sample mean the sample standard deviation and typically whenever we sample the image I have in my head or the one that we have from the class is that here's some underline distribution you construct some like like sample histogram and then each one of these points becomes an equivalent class of that kind of point so that would be important later on in bootstrapping but just know that you're like trying to construct something that looks similar to what your underlying distribution F looks like okay um so sample mean and Sample variance are two particular quantities that we can talk about uh they are unbiased meaning that the expected value of all of the sample means that we could possibly take is actually going to be the mean and the expectation of like all the sample variances should actually come out to be the sample sorry should actually converge to the variance okay all right makes sense looks good okay so then we took an interlude and started talking about algorithmic analysis I put boost I put bootstrapping after this I promise um so there was uh there was some want about how to do about like an actually another example of of algorithmic analysis stepping through it step by by step okay and the way so I conjured up another example of recurse so I took the rec curse from lecture and then I like made it a little bit more more complicated by adding in this like random variable q and some like and the for Loop that like actually increments based on what whatever Q is this should look like problem nine from pet six no from pet five yeah so this is the one where like okay like we actually need to show that like Q is independent of something all right so here's a lot total expectation and the prompt that we're given is okay what is the expected return value of this recurse function okay so how do we start this usually all right our Target is expectation of X so random variable call call the function signature the expectation then we replace recursive function signature with the expectation of X everywhere we see it and it matches like ver verbatim okay so here we'll return the the we replace the recurse on the return statement with 7 plus expectation of X okay now where it gets complicated is in the for Loop here we technically have expectation of x times Q where Q is this is this other like uniform distribution here from or from from Q okay so the way we the way we work with that is what we see that whatever our choice Q is here is going to be independent of whatever this recurse is going to return us so we can just make the the independent something here and say that expectation of x * Q is equal to the expectation of X time the expectation of Q okay so after that okay return three three is three so no expectation here it's just this all right yes oh sure so in the for Loop here the value that we're going to turny here is like okay depending on whatever Q it like the random the random variable here is like big Q and then the random variable that we're going to get out of recurse at every step is some X right so that so when you have two random variables and we're looking for like like how many like they're independent of each other and you're trying to multiply them so like first you'll say okay the two round events multiply each other and then you say and then you say okay they're actually independent of each other so you can just split up the expectation here by Independence assumption there is one thing that's kind of tricky here is that like one question is like okay is Q like if we were to think about this outer e of X is Q independent of this outer e ofx or sorry let me let me put it the the other way is the outer e of X here independent of Q the answer is no but the the the trick here is that the inner recurse has like another random variable X this is not actually the original X that we had at the outer scope of the function it's the one from the inner scope of the function meaning that this should be like x i or something drawn from the same distribution as this X over here okay so that was one thing that that kind of came up a few times on an ad post but should should be reasonable okay does that make sense to everyone all right so plug in three okay now we just put it all together and do some math so we multiply each one of the branches by their by their expected value so we take we use the law of total expectation um the probability of entering this first Branch with seven plus recurse is one out of these 10 so that's one tenth the probability of entering like one like the recurse here is one out of is another one out of 10 so that's this term right here then 8/1 of the time we return three the reason why I chose 1/10th 11/10 and 8/10 is because if I made it any bigger the the expectation is actually in infinite and when it's infinite we can't really apply the law total total expectation but that's a that's a detail okay so now we just start so now we just start summing so Sumit we just okay we distribute that you got 10 expectation on the left six six expectations on the right and 31 clict the terms and solve and you get 31 over four did I make sense should I like go through that a little slower or we could okay yes be 37 over 9 oh no never mind I multi sorry my bet okay cool I mean I would not be surprised if there was a typo in this this was this was written late at night I didn't see the multiplications okay all right so now this bootstrapping so when we visited bootstrapping it was from sampling um we cared about two values when we were doing sampling and it was the sample mean and the sample variance that means our two flavors of bootstrapping are going to be over means and over variances so what that means is whenever you so the typical bootstrapping actually I have a good example of this I can like just have know this know the structure for boost strapping of means and boost strapping of variances the key difference is you'll be like calculating a mean on the res sample and then you have a distribution of your means on the variance version you have a variance of your resample and and then you have the distribution of your variances these are the two most common forms of like poping that we're going to throw throw at you in this class and I'll run so here is a here's an example of like how to do of like the the Corgi problem that you guys saw in section so I realized that the Corgi solution that we had on the the website actually has really like jumbled up like lot like over Leaf so we I took the stat solution we like just and just like like M example out of it so here's what we're going to state is there's two islands with the corgis we want to say that Island B Corgis have a 3inch higher variance than the height of those in a okay so if we look at the heights of the corgis in Islands A and B Island we want to assert to claim that Island B's variance is higher by three okay the way we do that is okay here's the population of all the corgis we draw population one from the island of corgis and Island a and we draw a population oh that's supposed to be two great there's a typo population two is supposed to be from from corat of B okay and then we start and then we we like combine them into like a general population and start resampling so the way we start there is okay so this boo part is the execution of the code so we first create the total population of all the quiries then we enter a for Loop and we say okay so repeat the following 50 times notice that we only repeat resampling from the total population and not resampling from like all from like the space of all Corgis or from like islands like a good way to know this is like uh like your your researchers have already left the island so they can't really go back to take more corgis right we could only have so many corgis so okay so repeat 50 times and then the the first thing we do is we resign sample two samples from the total population and then once we resample the the two samples from the total population is okay this this part is going to going to be fast we're going to five lines of cod coding one we take the count so we look at we look at the difference between the S the sample variance of Island 2 minus Island one and we look at the at the difference if this difference is greater than three we just increment by one so that's exactly what the sign is saying and one here here is the indicated random variable that says okay if this is if this like random event so happens to be true we'll increment one into the count okay does that help like any questions um yes this is this is an example of a problem will be calculating P value um maybe one of the other ones like that we saw before like calculating me where rather than combining two populations that we just have like one some population like like in the in the mean happiness example from like all we all we did was just have like a subsection of the population like we didn't like take two and then recombine them oh yeah I didn't put that in the I didn't put that in the examples because that was a lecture example already so I was thinking like I was trying to give some something that wasn't like that was like not too far from the from the lecture but still wasn't like completely totally like redundant so like could we potentially see both of those types of problems but also like if we give you guys a boost ding problem right we're not going to go give you like a giant list and say okay take a sum over all these that's not a like I'm most will say hey here's like like like two or three samples yes in the back um why are you taking the absolute value of that difference when you want to show that Island B so like sample two has a higher oh it's because we want to see okay like we want to see if we take the take the the coris from from Island a and Island B and put them into a to into like a total population we don't actually know like which one of these corg came from Island a and Island B and what our P value is trying to show is hey even if I don't know like there shouldn't like the the claim about the variance shouldn't just appear in nature like it shouldn't just appear if I just like randomly like combine these two these two samples and then just started taking like resamples so like the idea is like if like population a has like like if we combine population a and population B and we just suddenly start seeing oh yeah there's like differences in like fa in like the variance is like greater than three just like in like in general then the claim is probably not good so that would actually give us like a higher P value so like the higher the P value is higher in the probability that a hypothesis is null does that kind of explain it or okay I think I was just a little confused because like sample two would be a different size and variance is also dependent on the SLE but so you should always take the absolute value of the difference um uh one testest yeah yeah okay uh you have a okay as for what if your said if you have a two tail test take the absolute value okay two tail what is it do we need to talk okay um we can talk about this offline I gu yeah clarified offline but but in general like if like if you have a total population here right and you like try to split into two samples and you take the take the difference right like you don't you don't know if you're proving that they're small by three or bigger than three so like keep the like short answer is yes but be cautious about it don't okay the problem will probably tell you if you should should take the absolute value or not okay all right where do we get the three from oh three three inches higher higher yeah it was it was an a prompt yes is there a um time you would ever sample without rep that's called a per that's called a permutation test and no yes okay all right next all right parameter estimation okay so very uh very this is a very old meme according to my associates um so in parameter estimation you have the the the problem will tell will probably ask you what do we want and you'll say ah we want the parameters and what do they look like some Greek symbols or P or A and B and these are so these are given to you like okay if you have a bruli your Theta is going to be a p if you have a pan Lambda your Theta is going to be a Lambda if you have uniform A and B your thetas are going to be a and b and you have normal going mu and mu and sigma square right so question is like okay why why why is Thea the only one that's like left isolated here is because we will conventionally like the first Greek letter we we think of whenever we think of parameters is Theta probably because it's EAS to write or something so so yeah so this is parameter estimation okay all right then here's maximum likelihood estimators so whenever I think of mle I think of like a two-step process uh step Pro like the first step is to find the likelihood the second step is to optimize it so likelihood here is a big product over all over all the PDFs um usually you want the log likelihood because you want to take a derivative of it and then once we find the derivative we can actually solve for the arcmax of the Theta so to solve for arcmax of the Theta here you would either use gradient Ascent or you will set the derivative equal to zero and solve we will most likely tip you off about which one you should be using on a problem so so so you don't like spend too much time trying to solve for zero on like a or trying to solve derivative equals zero on a problem where we should be using gradient descent and typically those forms are like describe an algorithm I I should have put this in the English part like if a problem says describe an algorithm to optimize you almost always want to go to gradient descent if the problem doesn't say that there is a chance that you could solve it using the using the idea that the derivative should should be equal to zero okay make sense all right so here's map what's the difference between map and mle right so what I wrote here was I put the two steps of the map on the left and I put the two steps of the map on the right so ml is on the left map's on the right or I should have labeled these a little bit better so in mle I'll up I'll update these Sid I you say that like this there should be like an mle here in the left side over here you just have the PDF on the right side in the map you have some prior G of theta here we will almost always give you what this Theta is and the only point is it's multiplied so the opop so the okay I put a big space here but these are actually multiplied by each other and you want to you want to find the optimal parameter like the arcmax of this likely where they actually multiply by each other okay um the main difference is here in your ARG Max function you will have a log of the G of theta added to your original like Arc Max Target for mle okay so I mean like just just for exposition go back one like you're here just taking the argmax over like this product or or over this sum and here you're taking the arax over like that sum and the log okay that's the main difference yes so the right is the map yes the right side is the map yeah I should yeah I had labels on these but then I think they got they they got shifted around when I was trying to like squeeze in the map yes the key difference is that an map includes a prior G yes so the map is like if you had a friend that did that that has already done some experimentation on this and you want to use their work okay yes then by virtue of that map would be slightly more accurate than mle if you if your friend is a good friend and gave and gave you correct data that's not noisy which is I mean good friends could accidentally give you like that data too but is that why mle is just more common then mle is like you need Emily to solve map so we like introduce Emily first and then map why it's more common it probably is more common but I'm not quite sure I I don't actually know the general claim of that yes will the problem tell us like whether when you use M or M or will that be given like if it gives you a prior that's tip off right it gives you a prior you should probably use the prior yeah okay all righty so next one is here are MP priors I put this slide on here just for exposition but we will almost always give you these but the idea is like whatever whatever your post whatever your like full your like mle estimate is this will actually influence what your prior should be so if you're like estimated is like a beri you want to all almost always use a beta to be your prior and these are like the whole conjugate distribution things so like you guys don't have to know like every little detail about conjugate distributions because will almost always give you whatever prior this is here and all you guys need to know is how to use it in the ml in the map sense okay I mean cheat cheat sheet wise you have 10 pages if you want like just write down the names of these of these distributions and their parameters and maybe like a one sentence about like what they do or like I don't know while on like a bike rider or something and you're waiting for like a parking spot just like whip out a phone and like check it who knows okay all right so that's about map priors so here's the the general machine learning Paradigm the idea is someone someone gives you data and they want the optimal parameter because it's totally a fair trade oh yes sorry sure before you start trading okay um for the What is the the D is a is the conjugate prior of the multinomial so you know what look at the course reader they'll probably tell you look at the course reader we have a description of it it if you have to use a d State we'll give you the parameters for it okay sounds good yeah let's go let's go let's go Trace some parameters for datas all right so here so in machine learning typically you have is some real world problem you want to model and then you want to model the problem and format and use sorry using a formal model Theta here is typically where you would find like log likelihood and then you will have some training data so this is the this is the indices on your sum and then you have some learning algorithm and this learning algorithm is usually like how however how you optimize the Theta okay and then since we're all veterans on P set 6 by now here is the testing data and you're supposed to just get a score after after you get out this optimal parameter so just a brief high level about like how about how the machine learning things work um we might ask you like a true false question about about like some about like some parts of the data pipeline but we're not going to get give you like a 30 pointer on just hey design this design a machine learning model for this like that's a that's a little uh that's a little hard okay all right so after that we saw naive base um naive Bas is just using the independence assumption where like if you if I condition on a y then all the X I are independent it's naive because we're trying to condition on the independence so what's special about so what's the hard hard Parts about the naive Bas is we're trying so we're trying to like we're we're given these like two PS of like x i and y and we're trying to actually predict like okay what's the optimal y here of G given the given these LA right and the thing that you typically want to do is Ave smoothing which means Okay add one to all your numerators and then add two or however many to your denominators so so that the data set is still balanced and usually this is just like a counting problem where like okay you just count the number of times where x i equals x i and Big Y equals little Y and you divide it by like the samples were like Y is equal to little y okay and then when you do do a prediction no need to do a derivative here no need to do like any gr Ascent nothing nothing of that sort just Loop over all your all your y's look at your data do a few sums spit it out that's that's naive base okay yes can you explain what P hat me P hat oh P hat is actually is the prob is the probability that is a probability that we're like our estimated probability that Y is the actual y yes that we're going to try to that we're going to try to like drive here so p p hat is like our our estimate of like whatever the XI equal of like the XI and Y okay so this this is the thing that we actually find in training yes it's the approximate whenever you see a hat it's approximate okay yes um is the probability of Y uh being oneus zero sorry one sorry why right you plug in zero for y sure right uh it's one minus that yeah probability that y has is one prob that y had conjug uh that's if Y is a br that's if Y is a broli if it's zero one y can be four cost four right like it could be like happy face SMY face uh sad face and angry phas right it could be it could be like size four right yeah yeah like if Y is a br yeah you can do one minus but if it's not then so so in this case Zero or one yeah in this case yeah because because of 01 yeah like it exp says like okay all right so next here's logistic regression logistic regression in my opinion is like ml with a berol but the thing about a bruli is it had it's a discrete random variable so we had to like go conjure up a PDF with a bruli okay so the so that and that's where we get the inspiration for like the for like the log like likelihood yes could you explain how mle and map fit into like naive phase and um regression like one more time so I can explain how ml fits in the logistic regression because it's just logistic regression where your PDF or your likelihood function is chosen with the PDF of a br distribution for map like map is like what happens if you have like a prior but in naive B like okay so map to logistic regression you can have logistic regression problem that is Sol that is like solvable using like map so like if I give you a prior about if I give you a prior about this beri right it's going to take the form of a beta then you can Sol then you you just have have another like data point for your dat for your like prediction algorithm um how naive Bay fits in is a little bit more tricky because naive Bas doesn't like naive base you're just you're taking the independence assumption and you're just counting like I don't know I think yeah so there like midd parameter estimation just PE hat like you're you're your parameter estimation is honestly done online so like it's kind of like you don't like you have to Loop over your whole data set every single time you you want to do a you want to do a prediction which is like that's like the key difference between like mle and like uh like naive base right okay all right good all right so with that I have a bunch of problems lined up or two or three something I think it's like two or three yeah and uh I I'll walk through them slowly they're not going to be like that boost Drive example example where there was like four lines worth of like problems but sorry no four lines worth of code then in one then in one comment that won't happen but so here's the problems so the first one is an mle example it's about how to do do reliability engineering and here's a problem where you say okay we have a random variable characterized by a with some PDF this and we wish to know how long a particular model of of a phone will function before it breaks that's what this PDF is here we are going to use a reliability a reliability distribution to this end we collect n independent measurements of how long the type of phone functions before it breaks X1 through xn explaining words how you would choose parameter a using the mle framework and provide any necessary derivatives okay so what's what's the key what are the key data points here what's our parameter a where's our data set X1 through xn what which algorithm are we using mle what's what's our likelihood this thing right here the the center this like big equation so how do we map this to our two-step we draw arrows and say okay the the F just replaces like strictly with with ourf take the data points X1 through xn and repl and replace x i with them Theta Theta hat here and normal Theta here replace that with parameter a and then we apply the mle like like the like a training we apply the estimator from the mle okay so to that end I wrote out all the steps we're going to move the problem up the upper right and I hope that's not too small keep on our back are we good is okay so first we find the like we need to find a log likelihood so we we're we're given the likelihood first so we take the log yeah we just apply the log and put an L on the left then we swap the log and the product so it becomes the sum over the log is it is it is it too small is that okay that's x squ j and and this is x squ j and a and a squ and then we use some more lo we use log rules and and start splitting up the terms so this is just like mult if you have like multiplication in your log they're like added use log rules again to bring your exponents down okay now you have like this fully like almost simplified like summation term and then just break up the sums a little a little bit so it's easier to do the derivatives okay okay and then like okay take take out a few terms like uh you like use like there's no this term right here does not rely on I at all so you can just sum over sum over all n of them and that's two -2 n okay any questions about how we went from like log from like likelihood to log likelihood assuming the text is not too small for people in back to see I realize that this might be this this might be a little this might be a bit small but the slides have have all the numbers first yes simpi I mean sufficiently simplified to to to take a derivative yeah I mean this is super simplifi we're also not going to like be like hey how much do you simplify your log likelihood it just has to be simple enough to can actually take a derivative in like a reasonable way okay all right so now we take the derivative so step two optimize so to optimize we need to optimize with respect to our parameter a so that's just okay take the derivative of this of this giant thing down here and then if we apply the derivative to each one of these terms we see okay this becomes like -2 a this becomes like uh just log of XI this becomes that this becomes nothing because it's just there's no a term here and this is like positive 1 over a cub or so something of that sort and if you propagate the derivative simplify you get just those just those those terms that we saw yes so this a so so this is these are not the these are not the same not the same terms because we we dropped the a from this term about here okay so then I think at this point yeah you set the derivative equal to zero and you can solve for a so one way that you can know that you can solve for a here is that there's only one parameter like we saw in a section problem where there was like a where there was like two parameters like get both like mu and sigma but here you only have a you should be able to solve for it if you don't that's probably okay yes have two parameters you're trying to optimize take the partial with respect to both parameters optimize that yes and then so then in that case you would have like two partial derivatives right you would have like uh well you know what here we only had [Music] like partial l l over partial a right in that case it me does not look like a in that particular case you would have like partial LL over partial mu and partial LL so you have like this thing and like and then like comma partial LL over partial Sigma and then so you'll take the derivative of both of those and try to optimize usually if you have two parameters so you need to optimize for we don't expect you guys to solve setting it equal to zero and you will just use gradient Ascent yes now can you optimize both the MU and the sigma independently one will become a one will become so if you can solve for one parameter in terms of the other one then yes but if you can't like if if Sigma is dependent on moo and then moo is also dependent on Sigma then it's not so simple and you need to use it and you need to use a scent yes the Su terms in the middle oh the sum terms in in in the middle are you talking about this term uh so this one we're taking the derivative with respect to a so take your partial derivative pass it into oh here I have this I have a ho laser pointer so we take this partial derivative with respect to a pass it into the sum and then you know that like sum and like the partial derivative I can just pass the partial derivative into the sum then just take okay partial derivative of a Time log of x i is just log of XI which is this exact term we have down here okay and then this like this Su term just disappears because there's no a in there cool yes first on on the last on the solution we got -2 a a because of negative log of a right yes so log a here just the derivative here just because 1/ a * -2 n yeah cool cool yes keep keep asking the derivatives are hard we should we should practice them okay all right so yes oh sorry was oh um so for optimization MLA and map will be mostly stick with taking the partial setting zero as gradi descent will mostly stay in the realm of logistic regression you could actually tell if the problem wants to use gradient sent or not sometimes if we we'll say at the end give us like a three sentence algorithm about like how to okay this is also not a promise because like like I we we haven't like we haven't decided yet but like you you should like usually at the end of a problem if it tells you hey give us like a three like a like a three sentence thing about how you would optimize it that typically means you can solve it by set by setting it equal to zero but if we don't say anything you might be able to solve it equal to zero and might as in even if you make a mistake along the way somewhere you can always just fall back on gradient ascent and we give some some partial credit for that and we can just explain gradient words oh uh I I have a side with gradient Ascent right like uh oh it's too far back but in the in the Sid there is a gradient Ascent you can just be like theeta new equals Theta old minus partial derivative LL Theta done right yeah could just write that be like oh yeah I just execute this in a loop or something yeah okay all right so here's an example about how to use betas and how to do pseudo code so um let's say that we have observed some 30 successes and 20 failures for an event with unknown probability uh based on this information we can model the probability of success X as a beta random variable we want to make the claim of the form the probability of success is M plus or minus B okay so we need to select M here to be the expectation of X select B to be the smallest value rounded to two decimal places such that probability of n minus B is less than like X less than like M plus b is greater than or equal to like 95% and provide your answer as a pseudo code that prints out the values M andb okay so here are some key points that I had on the first pass of this problem but looking at it again this morning when I I didn't have time time to edit the sides there another two so oh here the Bolder part that I just forgot didn't didn't box in rounded to two decimal places okay what this typically means is somewhere in your pseud code you'll be doing a grid search okay what does that mean that means that if I'm after some value like oh they're both used okay so if I'm after some value say x right I want like X between uh Like A and B there should probably be like a for Loop in there that does like X plus equals like 0.01 because they say up to two decimal places and you're just going to be looping do do this until like break break if if you have some condition on X okay so this is like a g search kind of strategy where you're like okay like you just want to like sweep over all the possible values of X up to some precision and it will return to the value that that you need okay all right so for this particular problem we have a starter function yes because everything starts with Main and then we we need to combine the 30 the 30 successes and 20 failures into a beta so here the beta that that we need to initialize is 30 is a beta with 30 + 1 and 20 + 1 plus one because we always on in sorry initialize beta with an extra one okay as per like normal like beta initialization then we say okay they want they want something of the form M so we know that the M here is the expectation of X so we use the second Point here for like finding what the expectation of like what the beta is okay then now okay so how do we so how do we find X like we we're given that it has be accurate of like two decimal places and it has to be within this particular range it has to be greater than like 0.995 right so what we do that is in a in a four Loop okay so here's what I'm supposed to say just just increment it slowly and the way we do it is here's a while true so in the while true so here's the loop that that actually does a gri search approach we want to say that okay X has to be greater greater than like the lower bound which is just the mean minus X but it has to be like less than like the upper bound which is mean plus X and then the probability of that of that region is the CDF of whatever the upper side is minus the CD of of whatever the Lower Side is and if that's greater than 95% which is which is our Target then we break it otherwise we continue on with a grid search okay and then just print it out and then just like print out the values does this makes sense like but then go too fast I see confused faces I see yes oh this is a so we're trying to find X right um and the way that we find it is by by doing research oh I guess yeah just oh sorry sorry sorry it's not okay this is a B name convention we call it X but it's actually it's actually B so we're TR we're looking for like the small the smallest value B here that could like that and that's where we have like B's here like the minus X that's B is over here yeah okay we I'll go maybe I'll go edit the solutions and actually actually change it to to B because otherwise it's a little bit misleading yeah yeah because like we can't really train on that yes so how do you like know that it's a grid search approach and like would there be like another way to solve it if you like didn't get to that or there probably there most likely is another way to do it but I so I didn't peruse the solutions for this particular problem but the thing that tips it off that is a grid search is here like we want B rounded to two decimal places so typically if you wants be rounded to something places in a code and it's like approximate it might just it usually means like okay like I want to like increment it slowly somehow and that's typically like research like okay I have a boundary on the left I I have a boundary on the right I'm going to just increment until it's done sometimes we like even provide a range like here we didn't actually provide a range like we just said okay well true just make just find find a region of of B that will like actually just satisfy this and we're kind of guar we're going to pretend that we're guaranteed that this will terminate like in all like in in in real life like this whole like while true Loop might actually never break because the probability could it's possible that that the probability is never like well actually no no it will break because eventually this will become eventually X will become so big that it becomes one yeah okay yes we're actually moving the range this way oh yeah we're expanding the range yeah yeah so at some point like the the thing is we're after like the smallest value of B right and then at some point we're going to get B so big it's going to be one but then we don't want that b one the smallest one such as like greater than .95 yep okay yeah we want like tightness of like lower bound okay I think okay so I think that was the last question that was the last example that I had okay and yeah so I I was I saved like the last like 15 or 20 minutes for just like general questions about like the final exam or for like parts of 109 we can also revisit the slides if people have have questions about that but other than than that like yeah that's all that's all the material I had I had yes yeah so on one of the practice finals it had the question about like deep learning networks and some math about that but then on the like final like like on the website it says like don't you're not going to be expected to do like deep neural networks so yeah like is there just not going to be any deep neural networks only up to like logistic regression or even if we give it to you the we'll make it we'll like make a kind of of we'll make it reasonable so we're not going to be expecting you to take like vector gradients or anything like that like like we'll like we'll make it so that it's doable with the stuff that we' covered so in a problem like that particular final what likely happened was so in past iterations of 109 we used to have like derivatives where like like we could like people have like it's actually possible to be like okay find the gradient of like some like the of like the of like the log likelihood right or do like what's the part what's the partial log likelihood with like respect to like some like array of like A's right and that's probably going to be something like I don't know like xrose something right we never did that in class we're not don't worry about it we will not give you this in in the exam the even if you have a neuron network with multiple nodes um we will prob it will probably be like solvable just using partial derivatives on different on like each one of the elements of like whatever like small Network we we give okay yeah all right uh any if any other questions if not we can like well people we can have uh 20 20 or so minutes back and good luck on a [Applause] final