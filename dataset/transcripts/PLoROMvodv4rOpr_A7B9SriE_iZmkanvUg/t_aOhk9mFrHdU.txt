good afternoon cs19 how are you guys doing today okay I appreciate that I know that there for many people there is still a midterm tonight um hey I just want to say thanks for coming I really appreciate in fact actually there's bets going on in the Tas about like how many people would actually be able to come today and we thought like do we cancel lecture we're like no this is the best lecture we can't cancel it um and we were all underestimated uh there is a small note I didn't want to say there's no word of the day for for today everyone's going to get credit um but this is one of the more core lectures so if you're watching it you are doing such a good favor to your future self this is one of my favorite lectures in cs19 and if you're watching this online definitely something going to want to know and certainly need to know for your problem set coming up um we are going to be doing the most beautiful meta thing we're going to be think about the random variable of probabilities and there probably couldn't be a more CS 109 topic it's so deep and it's so profound and it solves real life problems you probably have this intuition I present you with two YouTube videos and forget about the content though if you're not into Dave 504 yet you should check it out he's a slapping bass player uh and if you saw these two YouTube videos and you're just thinking about um the probability that you'll like the movie and you just look at number of likes this one has 10,000 likes and 50 dislikes this one has 10 likes and zero dislikes if you were sorting by you know a probability of a like you might decide that this has a one probability of like and this doesn't and you might get kind of the erroneous result that this might be the movie that you're more likely to like does that make sense intuitively do you guys get the idea that this is probably a better choice if you had to just choose one based off of likes but wouldn't it be nice to put some real fundamental mathematics behind that we're going to do that today we going to learn the most cool thing it's such good practice for you it's going to solve problems like this and it's also going to be a foundation upon which we're going to build all these beautiful randomized algorithms so I presented one problem for you guys how do you choose your YouTube video but there's lots of problems that I could tell you that we don't have a good fundamental perspective on which we're going to get today and here's another issue that I could talk about here are two different people who give you a probability of8 for whether or not it's going to rain tomorrow one person just says uh I don't know my leg itches went rain so I'm going to say there's an 80% chance of rains tomorrow and somebody's like I've done some hardcore calculations I've seen a whole bunch of information in the past and based on that I have a probability point8 tomorrow until now in CS 109 both of these are treated the same they're both treated as probability of 08 but Okay who wants to go with Pro person a who thinks that like they're the more reasonable person to trust and who thinks person B yeah person B we don't have a language for how confident somebody should be and that's not so bad if you're choosing between 08 and8 but it does become a problem if you have to get more information and update a belief like now if we gather something like the weather of the day before then maybe when we have to incorporate our new information we have to think about confidence in a more interesting way okay so I'm presenting some things that we should be able to do but we can't do and then I'm going to leave you with this philosophy this is one of the deep philosophies of cs19 those who are able to represent what they do not know make better decisions if you think about it you know we take all these Concepts that you might have thought of as single numbers and we turn them into whole belief distributions we've been doing that for a while in CS 109 and we're going to take that to the next level today and today we're going to think about representing what we do not know about probabilities themselves okay so it's going to be a little bit unintuitive but the math is deeply beautiful and it is incredibly useful also did want to note that problem set four is out it's got a whole bunch of cool things like you're going to be working with real Bean networks um you are going to be expressing uncertainty as to somebody's ability uh I think this one was for chess uh you're going to be looking at biometric creas Strokes there's a whole bunch of really wonderful interesting problems and one of the interesting ones we're going to play today so I won't get too much into it now but you're going to be thinking about learning while helping if you have to make a choice between a and b and you have to dynamically make that choice while that choice is also affect in people how do you do that in a good way in the problem set the first chunk of it has to do with problemistic models and the last chunk of it is from today's lecture so learn today's lecture and then you'll finish off with the knowledge you'll need for problem set 4 not too much review we're going to build off of but if there's one concept we're really going to build off of is this idea of inference you have a prior belief you get an observation and then you update your belief and the reason that this is so interesting is this was modeling somebody's ability to see before 109 came to this test people would think about ability to see as a single number and then we turned it into a whole random variable with a whole probability distribution instead of thinking ability to see a single number we say okay there's some possibility this person really can't see and some possibility they really can see and I'm going to have a belief for every possible assignment to how well they can see and that's how I represent ability to see not just one number a whole random variable questions about that before I jump in two things okay that's what we're building off of um oh and just you know when we got into this problem uh don't forget that we really solved this problem by having base theorem you took your random variable and then when you got more information you could use a function of How likely you were to see your observations given the true state of somebody's ability to see you could use base theorem and you could update your random variables belief so not only is it more expressive to use a whole random variable but we also have this wonderful language for how to incorporate information to update our beliefs okay and then um in plain English the things you needed for Bas theorem was a prior belief you need a likelihood function How likely is an observation given a state of a random variable uh and then one of the things we've talked a lot about is ways you can deal with this denominator we called this the normalization constant and we've talked about how actually because this denominator is not changing as values of little a changes one way to think about this is this is a constant and if you solve this numerator for all the different values of little a like I calculate this for little a equals Zer I Cal this numerator for little a equal 0.1 if you calculate all those values for all the little A's if you sum them up that's what this is so you can calculate all your values of the numerator and then just normalize and that's a quick way to do B theorem over a whole random variable end of review shall we jump into the mystery that is today and I did want to let you know where we are we've getting so close we're on this last penultimate section of class where we're learning about uncertainty Theory we're going to start diving deeper into the underpinning mathematics of probability Theory okay and it starts with flipping a plate I'm going to be taking this plate here I'm going to start flipping this plate in fact I'm going to play a game I'm going to ask for a volunteer to come join it and while somebody's thinking about whether or not they want to play I'm going to let you know that I want a dividual for the slide so I asked uh AI agent Dolly to come up with a rem Branch version of me flipping a a plate in class so AI drew that painting anyone want to come play this game yeah come on up you raise your hand first yeah yeah so you get to come um and this game is very simple you're going to flip a plate three times and if you get head three times uh you win and then we'll discuss what your prize is so you've only got like a 30% chance of winning but you know like you cost cost you nothing to play from side this is Heads This is Tails does that count it's a plate it doesn't have heads and tails what are we talking about question real quick yes did you type Chris Peach into Dolly no I [Laughter] wish okay we got one tails and zero heads okay who who whoa whoa whoa whoa slow down tails and heads one Tails okay we got four more flips to go two tails okay we need three heads row do it you can do it yes okay two more heads whoa it comes down to the final flip okay Round of Applause we got this you can do it yay okay now we have to discuss Sur prize well come come talk to me after class and we'll figure out what that is round of applause thank you very much wonderful in class we know how to think about you know this binomial distribution every time you flip a coin or you you run an experiment it's independent and we think it's got equal probability of being heads uh now there's just this one assumption that really I want to Pro make problematic which is if you have a coin there's an argument why heads and tails should be equal it's symmetric you know there's no reason head should be more likely than another but with my plate it's not symmetric so you lose your ability to say there's a 50% chance of heads and a 50% chance of Tails um and and really I want to leave you with this question what is the probability of heads on this plate cuz all of our analysis is based off of us knowing it's 1/2 but we don't know it's 1/2 and how could we think about that now plates are not that interesting you know what is interesting drugs people coming up with drugs want to decide wow somebody is going to cut that Cliff uh and it's going to come across wrong uh I meant medical drugs uh and so if you give a a medical drug to somebody you want to know the probability that it solves their problem and that's not going to be 50/50 but knowing that's going to be really important and you're often going to be estimating it really quickly when you have not that much data you might have tried it on six people you need to really quickly figure out what is its probability so it leads to this final question that I want to PL to your mind what's your belief that a coin flip gives you heads and on some level that's asking the question is think about p and I want to start thinking about it as a random variable so the number of heads that was a binomial but that P for the binomial that's the probity of getting heads on the coin flip I want to do the wildest thing and we're going to take this wild leap and it's going to take us on such an adventure and the wild leap I've written on the board and I'm actually going to try and do some board work today I'm going to allow the probability of heads to be a random variable itself let me show you you know random variables we think of them as being represented by a probably Mass function or probably density function if x is a random variable it means it can take on any value between zero and one agreed why not more than one cuz it's represent a probability I want to think about X as a random variable so I might get a probability Mass function like that and if I had a probability or probably density function rather like that it would be saying that I think the probability is somewhere between like 50% and 60% or maybe like 30% and 60% so we're going to try and come up with a way of thinking about X as a random variable which means we're going to really want to try and come up with a probability density function for x now I'm going to give you a particular context to think about and the particular context to think about is I've flipped this plate 10 times and I flipped this plate 10 times and I got nine heads and if I got nine heads this would be a pretty reasonable estimate for the probability wouldn't it be but that single number is not a random variable it's just a number and it's missing the expressivity of saying I got this number from only only 10 flips you know that 90% would have been the same number you gotten if you had 100,000 flips and you know uh 90,000 of those came up as heads and they should have different confidences so I'm going to break all of the logic we've had so far and I'm going to let X be your random variable we're no longer having probability being a number it's going to be a random variable why don't I use capital P for the random variable for probability wouldn't that be so awful it' be like P of P equals x oh my God my notation would be awful so I want to have a random variable for probability I'm going to use x because I can't use capital P in probability land okay if I make x a random variable I have a different way of thinking about probability if I've seen nine heads and one Tails I can write this beautiful equation which you've never seen before but it's a really cool one it's saying what's my belief in probability given I've seen nine heads and one tail and a lot of you guys are getting primed to see this anytime you see conditional your mind goes baz do you guys want to see what happens if we just threw Baye at this wonderful question if we threw Baye at this wonderful question you get the probability of this given that as your first term so probability heads equals 9 and Tails equals 1 oh I missed a given given x = x times the probability that x = x divided by some constant and by some constant I mean like okay this should actually be the probability of heads equals 9 and Tails equals 1 kind of marginalized over all the values of X so integrate from 0 to 1 the probability of heads equals 9 tails = 1 given x = x times the probability that xal X and you're like oh that sounds so awful but recall I'm even though that's the real expression I know that it's a constant as you change the numerator this value doesn't change it doesn't solve all of our problems and before I do anything um I just want to leave you guys with this I don't want you to talk to your partner and trying to come up with an answer but I want want you to talk to your partner and try and come up with a good question to ask them make sure this is a weird statement what is that saying if it helps try putting in a 0.5 in for little X and saying what's the probability that X takes on the value of 0.5 see if you can come up with a good question see if you can think about these three terms and have a good conversation for just a minute and then we're going to dive into and we're going to solve this equation on the board okay talk to the person next to to have a nice little chat and let's get into this you don't have a blue marker do you yeah that's all I mean okay I have put a small mistake on this board but first I want to take some questions maybe some of the questions will lead me to have to think about that small mistake is this weird or what x is a random variable can I ask you guys some questions what's the probability that X is less than zero yeah yeah your random variable that represents probably can't be less than zero What's the probity that X is greater than one yeah can't be greater than one okay that sounds very good um is X discret or is it continuous it is continuous yeah we think about probabilities as being able to take on continuous values in which case there is a small notation mistake I've made there shouldn't be a probability instead it should be a density you know for continuous random variables we want this other idea which is a density and over here too our prior belief also needs to be a density this is not a density what does this statement say it says I'm entering the world where the TR true probability of a heads is equal to Little X put in5 for x and says I'm entering the world where the true probability of a heads is5 in that world what's the probability of getting nine heads in one tail that's not a probability density that is a straight probability okay questions that came up okay you actually have the tools to reason about this term this prior though it's priors are hard to just reason about from first principles normally they're given to you what is a reasonable belief before you see any evidence so I've just given you a brand new drug it could work 0% of the time it could work 100% of the time you have zero evidence what's a reasonable prior belief for how well this drug works yeah uniform yeah uniform but are there other choices so your prior belief is uniform it's just as likely to be between zero and one what about this one you could say I believe it's 1 half and I'm very confident it's one half I'm really confident it's one half if you've never seen this drug before which one do you want do you want to say I'm pretty sure it's one2 and I'm going with that or do you want to say I have no information and it's equally likely who wants I'm pretty sure it's one half and who wants I have no information yeah that's the prior we want before you see anything about your drug you have to have a prior belief and the best prior is if you've got no information all probabilities look equally likely now you have enough information for this part and that part by the way you see this because this is equal to this divide by constant do you guys know that I can move this constant over here I can just have like my one over the constant here I could just make this like one over the constant and for those of guys who are really fancy you can just write is proportional to how fancy do I it's like a little backwards fish but that just means equals that times a constant I'm getting a little more fancy than I need to okay I said you guys could reason about this term should we put in a value of 05 imagine a value of 05 in for a little X it's saying what's the probability of this given that that is the probability of getting a heads if I tell you the probability of heads and I ask you what's the chance of getting nine heads scream out what you want to do bom yeah it's a binomial you've had 10 trials you got nine successes and I've told you the probability of success because we've entered the world where this is the true probability of success because I'm conditioning off this you now know the probability this is what a binomial looks like in this notation and so we can say this is proportional to the binomial coefficient so you have 10 trials we have nine successes what's the probability of success on each Tri oo yeah it's a little X there it's not p x is our random variable that's representing P how many successes Did I Get Nine how many failures did I get o what's the probability of a failure 1 - x how fancy and there's been one failure this is just a binomial it says 10 experiments nine successes the probability of success is X now you're like but but X is a variable here yeah and we're going to be thinking about it for all possible values we'll think about it for zero we'll think about it for 0.252 75 for all values we'll be thinking about this okay how about this one this term over here seems annoying it's our prior belief that X takes on the value Little X again enter the mindset that little X is 1/2 for now what is the density of 1/2 well this is what we said our prior was if Little X is zero what's this value one if Little X is2 what's this value how about 75 I'm not getting that tricky am I no matter what you put in for a little X it will come out as a one so this whole term just becomes times one and you're left with by the way this is a constant you're left with the density of x is proportional to x ^ 9 * 1 - x ^ 1 do you guys want to know what that looks like if you were to graph it it looks like this your belief after you see nine is still a random variable it's just a random variable oh wait I got that wrong it's more confident than that like if you were to plot that equation that we just derived it would look something like this it's going to say I'm pretty sure that the true probability is close to 0.9 but I have room for doubt I think it's possible that the true probability is one2 and then I just saw a really unlucky set of heads and tails I think it is very unlikely that true probability is zero and it's possible that the true probability is greater than nine by making probability a random variable I'm able to hold all this doubt in my mind I'm able to express my belief in all the possible assignments to the probability P if you followed along this hard set of math that's the hardest thing for today and the most important thing for today and you'll understand the whole concept of a beta distribution so let's take some questions yeah so a question on our assertion of the uniform distribution repeat again why we know that every value has to be one my intuition was like okay if we are dividing every single probility is equal as an infinitely small number chance that each probability can have okay so let's go uh it's a good question so I want to pull this one up the uniform distribution it takes in a Min and a Max and you put zero and one the equation for the uniform distribution says that it's its value at all those is 1id your max minus your Min and 1 divid 1 - 0 is just one so if we have the uniforms from 0 to one this was our prior belief and its density is one everywhere does that kind of answer the question and the reason is not like the infinite this uniform is kind of doing that infinite small Division and then you know as you get into derivative space nicely this just becomes a box plot and the height of the box plot is just your max minus your minimum or one divided by that good question cool more questions more questions yes if you had G like 10 heads and no tails would that have changed the graph to look more like parabolic so that mean like there was like an upward trend for the yes you're right so hold that question because when I pull up the graphs we're going to look at a whole bunch of them and ask me again then but you're right your in is correct yes like still about like like variables like usually like when you find of like probability dity function it sums up to one how it get in this if you integrate under this box my claim is it integrates to one if you integrate over here you're going to get the area of this rectangle right the width of the area a rectangle is 1 minus 0 that's one and the height of the rectangle is one so 1 * 1 is one this integral is one good question fantastic okay that's so we talked a lot about this and then you guys seem to be following Along on this idea of the binomial very nicely yes yeah how got from second from here to here um all that I lost is I lost the minus * one and then I also lost this thing but that's because I thought it was a constant so this proportional to it's hiding that it's actually this but there's a whole bunch of constants I've multiplied everything by and if I want to be explicit everything's multiplied by 10 over choose 9 divided by you know the denominator of bay theorem but I'm going to call that K uh and so if you want to make this an equal sign it would look like this and the proportional is just capturing the fact that this is a constant it has nothing to do with little X okay such good questions so if you flip a coin 10 times I have just given you something much more sophisticated to do than just saying your probability is 9 over 10 I've allowed you to express your whole probability belief in the coin being heads the probability of a coin being heads as a random variable this is the deration we did you know this we've identified as a binomial that we've identified as the uniform if you just plug in the uniform you get a one and you're just left with the binomial and then my claim is that this is the normalization constant we've seen very many times you could calculate it in some ways or you could just find whichever value allows this thing to integrate to one okay and here is the actual plot of what that looks like I drew it by hand but this is the actual plot of x to the power of 9 * 1 - x^ of 1 if you were to find the K that makes sure that this integrates to one cool right oh I love this plot I find it so interesting um there's a little bit of a philosophy here there's a whole um world of probabilities that think you're never allowed to have a prior like there is a prior belief in here they call themselves frequentists but but a lot of people I know fall into this Camp of beijan which is like if you allow yourself to have this prior there's such elegant mathematics that can allow you to have a posterior so I just want to bring that up a little bit and we can talk more about that in office hours if people find it interesting Okay g to bump this up a little bit what if we had to solve this but we didn't have uh exactly how many many heads and tails there were but instead we just said there was n heads and M Tails so this is the exact same derivation that we did before but instead of putting in numbers n and one I'm going to allow them to be little n for number of heads and little M for number of tails you know why I want to do that because you might want to do this for numbers that are not N9 and one you might want to see what happened if I had six heads and three tails and you like to be able to do the same sort of mathematics so this is the exact same derivation but we're going to put in symbols for heads and symbols for number of Tails make sense and if you do that exact same derivation you get the exact same thing you get some constant times x to the power of number of heads Time 1 - x to the power of number of tails you look at this equation over here you see the similarity it's just we used a number nine for heads and one for tails and this is n for heads and M for Tails okay and this is a beautiful expression of a random variable I note that there's a constant here and if you wanted to find that constant you could find whatever number makes this equation integrate to one which we've done before on problem sets ah and this is it on one slide if there was a major key if you've seen n successes and M failures you can say your new belief in the prob ility of a success is given by this gorgeous equation where if you ever needed to find that constant you could but it turns out often times you don't actually need to find that constant oh and this could have been how they invented math and this could have been how they defined things but it turns out that people did things slightly different which I'll get to in a second I just want to make it clear that you know if you want to do seven heads and one tails you would just plug in seven for n and one for number of taals and you would plot it and you would get some sort of beautiful representation of your uncertainty is it possible if you've seen seven heads and one tails that the true probability is 0. five it's not that likely but it's certainly possible is it possible that it's 08 oh yeah and it's starting to look pretty likely but you know the most likely one here is uh 7 / unfortunately whoever invented this mathematics did the cheekiest little thing they did Define random variable for this but they added a hidden plus one just to mess up 109 students just to make sure that there's always one extra point on a midterm or final problem people did Define this random variables and they said I will tell you the belief in your probability if you've seen certain number of heads and certain number of Tails but just to mess you up the parameters won't be number of heads and number of Tails no no that would be too simple instead we'll make the parameters number of heads plus one and number of tails plus one just to make sure everyone's always doing their plus ones correctly and so they defined a random variable that looks exactly like what we derived but you have to take number of heads plus one and subtract off one and you have to take number of tails plus one and subtract off one what cheeky buggers but they did it and we can't fight it now it's much too late the people who did this dve this thing called a beta random variable it has this probably density function it's what we derived but the parameters are number of heads plus one and number of tals plus one so the probability density function has to subtract off the ones to make it the same derivation of what we've got here is a bunch of different betas here is a beta with one heads and seven Tails notice how I myus one there so cheeky this is a beta if you saw four heads and four tails this is a beta if you saw seven heads and one tail a question there's a reason why one so do you know why yeah some of the mathematics that are a little bit beyond like you get into like different moments like some of those more complicated things I think work out a little bit nicer and we will see a couple of them like expectation variance the equation actually yeah let's let's pull those up okay the expectation equation a little bit cleaner the variance equation a little bit cleaner and you can imagine as you go deeper into the moments which we don't do in CS 109 it the mathematics makes it much easier to have the plus one okay so when we use the beta varable we should plug in Not A and B but a plus one and B plus one or number of heads add one that becomes a you take your number of tails you add one that becomes B it's like life is hard enough when you're thinking about probably as a random variable who needs this plus one but I don't know mathematicians in those days were cruel not anymore now we're like warm and fuzzy you're mathematicians too okay so a bunch of betas and beta is the random verif for probability and it's a beautiful thing it has two parameters you take your number of successes AKA heads add one you take your number of failures add one call those A and B and then you just plug it in and now I want to go back to this deep philosophical idea now you have two ways of representing a probability this is what we did until today we would say your probability is 75 and from now on I can give you a probability not as a single point estimate that's a fancy way of saying a number but I can give it to you as a whole random variable and that whole random variable is going to do so much work for us not only does it tell you your most likely probability but it also gives you a sense of how uncertain you are about your probability it tells you how confident I should be in this 75 there's no confidence expressed in this number and by having expression of confidence we're going to open up the world of randomized algorithms and we're have so many cool things that we'll be able to do how fun is this are you guys following along this is crazy complicated stuff but it seems like like you guys are following the plot which I love to hear um it's a distribution probabilities I also want to point out it's one of the few distributions that we have that's bounded in a Min to Max uniform and betas are the two random variables we have that have a clear minimum value and a clear maximum value okay I'm going to mess things up if you follow the plot line till now you've gotten the most heart of the matter but I do want to give you the fancy details on top you guys ready for it we made a uniform decision for our prior what if you used a beta itself as a prior and what that means is somebody comes up to you and they say like I got this plate before you start flipping it I have a belief I can look at its physics and I can say I think it's more likely to be a heads than a tail I express that to you as a beta I express that to you as a beta 32 so number of imagined heads was two and imagined Tails was one 32 that's my prior belief for you that's going to mess up our math isn't it because now instead of having a one here we have to put in a beta probabbly density function boogers and by Beta probab density function I mean this beautiful equation over here what happens so what's the belief in x given n heads and there's an implicit M Tails here as well so that's the probability of You' seeing your n heads within your experiments given the true probability this is what we have up there but now we're going to have a different prior we're still going to have the same binomial over here it's just this is not going to be just a one now your prior is a beta wild ready for it just put in that whole beta probably density function right there you're like oh that's so ugly well let's clean it up a little bit why don't we get all the constants here so that's a constant that oh actually that is not a constant but um that's a constant that's a constant oh actually no sorry sorry this is a constant so I'm going to take this one this one and this one these are all constants and I'm just going to put them into one doesn't that look cleaner already by constants I mean these values don't change uh as you change X so if you change X this stays the same if you change X this stays the same if you change X this stays the same so we're going to put it all over here and we say that can be a number and it'll be whatever number it needs to be so that this thing integrates to one and we could stop out of our cleanup here and be like ah we did a nice job of clean up anybody see way we can clean this up a little bit better oh yeah we have X to ^ of n multip x^ a minus one you can combine those terms you can also combine the term that has 1 - x as its base and if you combine those terms you're left with x^ of n n + a - 1 and 1 - x^ m + b - 1 and at this point you might feel super good you're like so clean legit and then the tears start Welling because you see it you're like this isn't as simple as it it gets simpler it gets more beautiful because if you were to stare at this for long enough you might be like wait a second that's really similar to the beta probably Den function and then at some point you're like wait a second that is a beta probability density function just with different parameters and then the tears just happiness streaming from your face as you realize if your prior was a beta and then you observe n heads and M Tails your belief after that information is another beta so anyways there is a fancy term for this we call called it a conjugate prior it's like your belief in your random variable takes a part particular form in this case of beta before you get some evidence and then afterwards you get to use the same equation format if your belief before you see evidence is a beta your belief afterwards will also be a beta and that makes programming much easier because you know if you're getting new information you don't have to write new equations you just have to update parameters so this is saying you had a prior belief in A and B I saw a real number of heads and real number of tals and afterwards I can just update my parameters that's all I need to do because we've done this math once you can be left with the idea that if your prior was a beta your posterior your belief after seeeing evidence is also a beta where you just add in the number of observed heads and the number of observed Tails I talk fast so like I just said a big thing maybe I should just like let that sit like whoa cool ah okay uh what does this really mean if you didn't want to drive the mathematics you'd say that you can set your belief uh as a prior using a beta so before you do your experiment you can say I'm going to say I think that this isn't uniform before you start flipping I'd say it's more likely to be heads I have a way expressing that and then if you did that you said I'm going to imagine a fake heads and B fake tails before you start flipping if you then see n or sorry A minus one fake heads B minus one fake tails see I even forgot Theus one plus one if you then flip this and you see n heads and M Tails your posterior is just a beta as well beautiful thing there is one thing you need to know most people don't always use uniform as a prior belief you know it's a different prior belief that a fellow called llas made very popular he said my prior belief is one imagined head and one imagined tail and there's a deep philosop philosophy that he went into he's talking about the probability of the sun rising and he says even though I've seen the sunrise every single day and I believe it will likely happen tomorrow I want to imagine at least one failure and one success so I can hold in my mind some belief that it might not happen in the future long story short having a beta 2 is a popular choice for prior uniform is popular beta 22 is popular okay funny name simple prior okay then one last thing before we start playing games I want to just show you a cool derivation what if you asked what happens of a is one and B is one remember a is your number of heads plus one and B is your number of tails plus one so if you take one and you subtract off one what are you left with so this is say saying beta with zero heads and zero Tails oh so you write out your probably density function you put in your value of number of heads you get your number of Tails and this is a number to zero that's one and this is a number to zero that's also one and so you end up with this 1 * 1 divid by whatever constant makes this integrate to one and you're left with one you know at a beta with AAL 1 Bal 1 is it's uniform and that makes sense if you've seen zero heads and z tals your belief is uniform it's just the prior because you saw no information anyways that's not that deep but you know nice little rounding of the corner okay we are going to flip some plates okay I'm going to now show you guys the nice part of the course reader where you can look at a beta so I'm going to start flipping this plate and before I flip this plate my belief in the probability of heads is that it's uniform beta 1 one I've seen zero heads I've seen zero tails are you guys ready for me to flip a plate okay close ears Tails okay a is number of heads plus one I've now seen a tails look at that belief is it possible to be one probability of a heads no because we just saw a Tails but it's this beautiful straight line is there a problem because this y- axis is two like it goes all the way up to two not a problem probably densities are allowed to be outside one if you integrate under this for any range you'll get a probability flip it again close ears o i saw heads so now I've seen one head and one tail and this is my new belief it can't be zero probability it can't be one it's much more likely to be 50/50 than anything else but I have a belief now I'm going to flip it one more times but then I'm going to think about how we could update this I saw myself another heads two ways you could update this you could say I've seen two heads and one tails and make my Beta or you could say this was my prior belief and I've just observed one heads and zero tails and because of this conjugate prior thing they lead to the exact same result it is still the case I've seen three heads and one tails and look at that beta change I love it do you want to just like come up here and flip a couple wonderful head yeah flip and then I'll update it yay he does so much for us we really appreciate you and all the head ta teams okay flip let's go oh another heads I in fact think that this thing does have higher probability of heads that's why I chose three I was trying to set you up okay o another one yeah let's keep flipping one more let's do one more for good for good nature ooh it Tails okay so in total how many times do we flip it we flipped it four five six times we saw four heads we saw two taals unfortunately we have to add one to each of those to get the beta parameters and then you get this probability distribution we have a belief it's beautiful you can ask expectation question you can talk about variance you can ask what's the probability that the true probability is between 05 and 0.9 by integrating you can ask all these questions just like with any other random variable you guys are wonderful fall on the plot and that's just all I have to say Okay so I also just want to show you a word problem that I think is interesting before being tested a pill is believed to work about 80% of the time then we do a real trial on 20 people in this real trial it works for 14 people and it doesn't work for six what is your no belief that the drug works this is a problem that you could approach in a few ways before today in CS 109 this is all you could do you could say I don't know how to incorporate that 80% but I do know how to talk about 14 out of 20 patients being successful with the drug and that gives me a point estimate for probability but now you can come up with a beta the only thing is it doesn't give you a prior in a format we've talked about the prior is just saying 80% and can I give you three different priors that match that claim here's one prior that matches 80% I imagine 100 trials 80 of which were successful here's a different PR prior I imagine 10 Trials of which eight are successful and here's a different prior I imagine uh six trials sorry five Trials of which four are successful all of these are ways of representing 80% but what's the difference this is very confident this is medium confidence and this is minimal confidence and you'd have to make a choice you'd have to say do they mean 80% and I really should trust them or do they mean 80% and I want to trust them just a little bit and the less you trust them the more the data will dominate your your belief and sorry the higher these par the less the data will dominate and the lower these parameters the more the actual observed data will dominate so in this question 80% needs to be translated into a prior three good choices actually there's no wrong answer who wants this one who wants this one and who wants this one they're all right answers I tend to like priors that are a little bit less assuming I like to have my data speak for itself as much as possible but it really depends how much I trust these people people whoever tells me 80% like if it's will I'm going with the first prior like whatever you say I'm going with it but you know if it's somebody who I don't know really well that's the prior I'm going with you can see why there's a division some people in probability Theory are like what you can't be so subjective anyways so if you chose your prior we now have a way of representing an 80% belief then what's your posterior you don't have to go all the way to Bay theorem you could and if you did go all the way to Bay theorem you would end up deriving this you would end up deriving that your posterior was your prior parameter plus number of observed heads and your prior parameter for number of tals plus observed tales and you would just add those in and an interesting thing if you plot out this prior and you plot out your posterior they both tell similar stories but you've become more confident as you saw more information you can also talk about the expected value you can say hey this is a whole random variable but maybe I just want to give one number for probability and you can do that you can say what's the expectation of this random variable and you could say7 now I want to point out a really weird thing about the beta expectation is a way of taking a beautiful random variable and collapsing it into one value it makes me sad because you've lost so much information there's a different way of taking a whole beautiful random variable and collapsing into one number called the mode and they're different things expectation is like your weighted average the mode is whichever value has the highest probability whoa those are two different things so the mode is the highest point whichever x value has the highest point in the PDF and the expectation is just your weighted average of your PDF often they were the same in almost all cases we've seen before they've been the same but in this case they're actually different the mode is actually number of heads divided by number of heads plus tails and uh so if you did your mode and your mean they're slightly different but if there is one thing you took away from this is that single numbers are boring ways of representing probabilities and distributions are so much richer they capture so much more than single numbers questions comments concerns does the universe change no but your understanding of it does okay so next question for you guys which video are you more likely to like so now that you know about betas we can think about these as coin flips this is a coin that's been flipped 10,50 times and this is a coin that's been flipped 10 times we could just think about the probabilities as frequentist or we can think about the probabilities with beta distributions and if you thought about the probabilities with beta distributions this case I'm using that fancy LL prior so I imagine one heads and I imagine one Tails this one look at this beta distribution what's happened it's just like a straight line if you see enough evidence eventually the beta distribution just looks like a straight line at the true probability so this one we know it's like a 99.9 video but this one we haven't seen that much information so we have to hold out the belief it's a 6 video or the belief that is a08 video and so there's a whole distribution there's a representation of uncertainty now if you want to choose a video that's a cool algorithm wouldn't you like to know an algorithm for choosing this video now at the moment what have I told you I a way told you how you can represent your knowledge in a more beautiful way but I haven't told you how to compare this beta with that beta now what if you guys had to invent that what if you had to invent a way to decide if this video is better than that one you can say what's the probability that I'll like this that what's which video has a greater probability of that I like it wait for each video I can calculate what's the How likely is it that my probability of liking is greater than 0.9 so I could say this one you know it's 100% that I'll my chance of liking is point greater than 0. n and here I can say it's not 100% that my chance of liking is greater than 0.9 it's just whatever is under this curve okay I have one last beautiful thing for you guys I'm done with the beta I'm not done with the beta I'm done setting the foundation of the beta I'm start ready to start playing I'm ready to now use the beta to do cool things but before I do that if you guys have any other beta questions shall we can I ask please yeah yeah yeah that's all I do you remember my experiment on like uh the believe that the child is not being born today um Can can you use that to the beta to solve that like say you had a believe of 18 days um and then by day night the child has not been B I was just thinking the cont of you're really on to something can I hold my very last slide is talking about this connection but you're on to something which is in that world we were thinking about a random variable as this underlying belief which could take on many values and the beta is going to start making us do that in lots of cases so yes you're that is the same mindset in both those problems and could we have multiple Bas in such a way that places have your emphasis on the more recent ones I guess um whoa like a recency bias yeah you just invented a new random variable congratulations you can name it after me no I'm just joking you can name it after yourself you actually can't name after yourself someone else has to name after you I'll name it after you no I'm just joking um uh that's a really nice idea and why would you want to do that though is that because you assume that the probability might be changing potentially there's some situations where that's the case hey flipping this plate the probability is not going to change there's no reason that one old experiment is less valuable than a new experiment but other things could change like the probability of a hurricane that might be a moving distribution and what I would encourage you to do if you want to go down the path of inventing this random variable is just try formalizing how you think like this particular problem you're solving my probability is changing can I make an assumption about how it's changing and that will lead to a different sort of random variable over your belief and probability in fact you'll probably have a model OKAY fantastic you guys are asking good questions have you guys heard about Alpha go they were the algorithm when humans really for the first time um well one at this board game called go and if you don't know this board game called go it's this huge board game was thought to be the most complicated board games that humans play and you really need intuition to be able to win at this game um and then this group called Deep n which is one of the big AI Labs not too long ago came with an algorithm that could win at the world's most complicated board game an interesting thing that they did is they they did mix deep learning but they also mixed deep learning with core reasoning about probabilities and really the sort of beta distribution idea that we've been talking about now there's this whole world called multi arm Bandits and it's a really fancy name for something that's kind of simple to describe a multi-arm bandit I think is best described using this scenario you have two different drugs drug a and Drug B and you need to be administering them to patients and you don't know how well they both work and as you're administrating you're doing two things simultaneously you're giving drugs and you're learning about the drugs and that's what a multi-arm bandit is this is arm one this is arm two the Bandit makes it sound ridiculous um you could have more than two drugs like maybe there's six drugs you're choosing between and every time a patient comes you have to choose one and you're both doing it to explore which one's the best and to take advantage of what you've already learned so far isn't that an interesting problem do you guys want to play okay I need another volunteer to come up and play uh you're going to or actually you know what you're all going to play I'm going to pull up this game and the way this game works is there's two drugs and we have to make decisions and just to add the stakes I'm going to assume that these drugs are for uh let's just say they're for Pokemon so we don't have to think about anything grim and your Pokemon are going to live or die let me just open a new terminal so it's cleaner python can you guys see this okay in the back there's two drugs your first patient Walks In A or B you're like what I don't know what's the prob of A and B that's the beauty of this you don't know you have to make a choice you're like this is an awful awful game already Okay who wants a who wants B just yell I heard a lot of B's we did it yay fantastic our Pokemon lives and then another person comes a or b a a why do you want a obviously B worked a is a better grade yeah why would you want a why you have just curious curious no curious is right um you know there's a possib we should be learning about our drugs as well I'm doing B oh I immediately regret it okay your curiosity was good but it was possible that a was perfect but now I've tried B twice it worked once and it failed again who wants a and who wants B now just yell a everyone wants a and the intuition is yeah I have more information about B but I haven't explored a at all it might be way better and I play a yes and now who wants a or b a fantastic oh a or b b a b b b oh my God I'm out of control I'm just making decisions without any sort of reasoning do a bunch of A's in a row yeah you could do a bunch of A's in a row you can do a bunch of B's in a row and then you can go back and like try and estimate and make better decisions from here on out there's so many contexts where this game is important and it's not just about drugs there's lots of things like um if you're trying to learn how to make decisions under uncertainty even if it's something small like you're trying to give somebody a nudge on dualingo and you're trying to decide if you give a nudge or not it's this game this game exists in so many sorry A nudge is like hey hey have you studied Spanish lately you know they do that they have this whole paper where they use this algorithm I'm just about to teach you so this game we just played it is there a principled way of playing this game and people have done a lot of research on this and it's still out for debate there's different people who have different ideas of how you could play this I'm going to set up a particular context you've tried B five times you've tried um oh sorry if you've tried B five times and we got two successes and three failures we have a formal way of thinking about the probability that b is successful uh and you can talk about expectations we can talk about the probability that the true probability is greater than some number and actually I just want to talk about this one for a second just to get us warmed up to this problem if x is a beta because I've seen I tried drug B five times I got two successes um and I got three failures I can set up the beta you're like why three and four oh right I have to add one to success and failures what happens if I ask you what's the probability that the true p is greater than 6 well then that's asking the probability that my random variable is greater than 6 which we know is one minus the probability that the random variable is less than6 which means you can do one minus the CDF of the beta and then you're just like oh hey I don't remember what the CDF of the beta is you go over at your favorite course reader and you're like there's the PDF and there's a hey if you look at our other continuous random variables they often have this thing called a CDF that's probably random variable is less than a value and the beta doesn't have a closed form a little bit like the normal distribution is the game over no the game's not over we just have numerical approximators so you know if I need the beta CDF I don't use an equation I go to Python and python has a numerical way of telling me the CDF of a beta so anyways you could do one minus you know stats. beta. CDF you put in 6 for x and you put in your two parameters and you'll get a number back okay few so even though there's no closed form for the CDF I do want to point out that we just use Python which uses a numerical approximator okay which leaves us with this game we call it I mean it's got this awful name it's called the exploration exploitation trade-off that's that's this multiarm Bandit where you're trying to choose between a and b and and philosophically you're choosing between going to the place that you've been to the most and you know have the most information or going and learning more about one of your different arms or drugs if you're using that metaphor there's as I said this is not a closed problem there's still different people debating on how you could solve this drug problem one algorithm is this thing called upper confidence bounds which is for each drug you keep a probably distribution over its success and then you think about like an upper bound of confidence you set some threshold maybe like a standard deviation or two standard deviations and you try and choose uh drugs that have the higher upper confidence that's one way of doing it but then somebody not too long ago wrote a paper that pulled on some math from a little while ago and said wait a second there's this other algorithm that works insanely well for ch using drug a or drug B here's how it goes you've been playing the game for a while where you can have drug a and you can have drug B why do my a and Bs look like graphs because we're using betas you know I did number of successes number of failures I got the beta CDF and if you plot them you get these two things so it's like drug B we've tried more drug a looks a little bit better but we haven't tried it as much so that's the state of the game how do you choose which drug to play next and somebody not too long ago came up with this wicked simple idea take drug A's PDF and sample from it you're more likely to get a number in the high density regions and less likely to get a number in the low density regions so let's do this let's say you randomly sample and you get this value and that's going to be my a sample for B you sample from B and you may just happen to choose a sample over here it's not that likely but when you sample you can get any value it's just more likely to get them in the high probability regions you know if you do a gaan samples you're more likely to get something near the mean if you do a sample from this beta you're more likely to get something in the high probability regions so Step One is choose a sample from each drugs beta so here I got a and that was like equal to 5.58 that's my sample for drug a a and my sample for drug B was equal to 42 here's the crazy thing we're halfway through an algorithm the next step in the algorithm you know which drug we choose not the one that has the higher area under the curve at any point just whichever one had the higher sample and they would say you choose drug a here when you're making a choice you take your betas you sample from them and you select the drug with the higher sample and the argument was this does two different things it balances the fact that if you're really confident drug is good you'll always sample from that high probability and if you're really confident is better you'll just always make the right choice but when you're unconfident it does a beautiful balance of exploring and taking advantage of which one it already thinks is better people are arguing that this is in some context the best algorithm but there could be better ones you could invent one in fact there's a one9 student last quarter I taught this who said if you always choose a drug such that if the probability of drug a beta is greater than the probability of B I choose a and the probability of B is greater than a I choose B and they they figure out this inequality and then that's how they made their choice they claimed to me that this is better than Thompson sampling I was like o that's kind of cool um and maybe they're right what I will tell you is you guys get to play so if you look at problem set 4 The Last Problem on problem set four is to play exactly this game you're going to write a function you'll get a history of all the drugs that have been given and whether or not they worked and then you have to return either A or B and when when you run one game here I'm always choosing a and you'll get a score of how well you did if you run test agent you'll get a score over multiple trials I want you guys to implement this Thompson sampling which will be pretty easy now that you know what a beta is but feel free to try and come up with a better algorithm if you feel so fit okay so can I summarize today you learned about beta a beautiful way of representing probabilities and then we used it for a new randomized algorithm it's the distribution for probabilities it's got this beautiful formula it's actually the very last distribution I I plan to talk about and so you can imagine it is a new distribution to add to our whole pile of distributions we have so far if there's one philosophy that I really wanted to drive home it's that in life we often convolve things into a single number but it's so much more elegant if you can keep a whole random variable which has a whole belief distribution because then you're able to represent your uncertainty and if you can represent your uncertainty you can do things like Thompson sampling you can make better decisions under uncertainty if you can represent what you don't know I feel like this doesn't represent what it doesn't know but the beta really does we talked about this at the beginning of class and that confidence and a probability is something we've now gained with the ability to articulate beta so somebody says like my leg itches when it rains they're probably 08 that's close to a uniform you like that sounds like a pretty useless uh probability but this one we could have a formal way of talking about the beta distribution that it comes from and we can say that that second one is more confident and we have language for that and then I want to leave you with this other idea we talked about using probability as a random variable a probability you can think of as the parameter to a binomial it's like the parameter to this binomial what was the thing that was unknown that we allowed to be a random variable and you can do this for any parameter for example a pan you could say I don't know the true rate and I would like to estimate the true rate and you can say what's the belief distribution in the true rate given that observed sum history and maybe that's the more interesting thing and you can talk about if you're like taking an eye disease like we did in section a while ago and you see some count of cells instead of just saying I think this is pan you can allow for it's a pan and I've only seen five cells I don't know what the true average is and by having a softer belief if somebody asks you did this person get better or worse you could make a better decision about that and so my bigger point is you could take any parameter and allow it to be a random variable and that will be a more elegant way of expressing it and that was related I think to the question about baby births before which is that really taking all these Concepts and making them random variables will give you much more powerful ways to talk about likelihoods thank you guys so much if you're taking exam tonight good luck if you're not taking exam tonight definitely don't talk to anyone about the exam you took uh have a wonderful wonderful day come back on Friday we'll continue this great topic in cs19 I'm rooting for all of you guys I'm thinking about you often have a wonderful day