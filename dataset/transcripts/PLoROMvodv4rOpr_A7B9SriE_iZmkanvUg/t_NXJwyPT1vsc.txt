good afternoon CS 109 how are you guys doing today oh my God it's so good to be back as you guys know on Sunday night I got very very sick and I continued to be sick into Monday um it wasn't coid it wasn't the flu uh it was something I picked up for my daughter so it goes uh but I feel so much better now and and thank you to our wonderful ta teams I you know on Monday morning I thought we were going to councel class I was just like I'm not feeling right let's see how I feel and then by Monday midday I knew there was no chance I could teach so around that time I got in touch with the TA teams and there's one ta I've got some time Chris I think I can do this so we were going to cancel class and we're just going to not be able to see that material uh and the whole class will be pushed back and fantastic man we have such a wonderful ta team I appreciate all of them so quick Round of Applause for our wonderful T someone looked at our course they like I have never seen so many office hours uh from a class and that's because our Tas are doing like the extra mile I've seen it in lots of places where they're just staying late to help students on the for the nice messages they post we have a really special team and you guys make my job so wonderful good people to work with um I have so many things to talk about before we jump into material the first one is I just want to make sure we're grounded and where we are we talked about counting Theory we talked about core probability we talked about random variables we put lots of Random variabl together and now we're in a section of cs19 where we talk about the beautiful theories that everyone should probably know we learned about beta distributions and I hope you guys now agree everyone really should know about beta distributions um and then we talked about adding random variables how that led to Central limit theorem and how the central limit theorem really inspired really nice understanding of sampling and today we're going to take that a step further and we're going to be learning about bootstrapping and on Friday we'll talk about algorithmic analysis I did also want to mention the midterm because I was sick on Monday I didn't get to talk that much about it and there's not much more to add um one small thing to add you guys have already seen the distribution but have you noticed how the distribution really looks like it's baited distributed hm peculiar that's not that important right now there was this small misconception of oh man if I got um you know 50 on the midterm does that mean I basically failed cs19 and the answer is no I asked a pretty hard midterm with very real world problems like all those problems actually had correspondence to the real world if you were in the real world someone might give you that problem and if you solved it it would be a big deal so if you could solve all seven of those problems that's amazing fantastic like just keep doing your thing and if you could solve all but one of those problems man that's amazing too and if you miss two problems that means that you could do five out of seven or four out of four out of six real world problems that's really rocking you guys are making good progress um and there's a lot of different versions of you guys have really impress me as a class to say and I did want to drive home just well okay I'll get to this in a second I did want to drive home this point and you guys uh know probability well enough to understand what I'm trying to say here three random variables G is your grade in the class s is the score you got in the midterm why did I keep hitting the wrong button and D is the difficulty of the midterm and what am I trying to say with this equation probability of your grade taking on the value L little G is equal to the probability of grade taking on the value l g given D equals D what am I trying to say here yes dependent of how difficult yeah exactly all I care about is what you guys know I I ask real world problems that are complicated you know to give you the scenario um but uh asking a harder exam doesn't should not change your belief in the difficulty and that was a hard exam um and then there's one other policy that I need you guys to know about which is that I really appreciate that exams are a bit stochastic and sometimes people walk into the midterm and maybe they weren't as prepared did you have a bad midterm it's fine great still in your control for lots of of reasons one is that problem says count for a lot one is that there's this optional contest which we'll talk about in a second but also I have a policy of always looking at people's final exam scores and if I look at your final exam score I look at your midterm score I was like that's pretty substantial Improvement between the two I'll recognize that the final exam score is cumulative so you've showed me that you learned I don't necessarily care what you knew at the mid quarter I know care about what you know at the end so if you use this midterm as a diagnostic and you can improve and you can show that Improvement in the final you don't have to get an A+ the final for this to kick in um but if you can show Improvement then I always recognize that cuz I appreciate people working hard and people trying to improve themselves what a beautiful thing okay another quick announcement if you want to improve yourself one of the cool things you could do is go check out the cs19 problem set party you go to the pet app uh and at 7:15 there'll be a little notification that goes out if you click on it we'll try and put you with like a group of people or another person in class and you guys can just like either have a social moment or you can teach each other something or you can just like commiserate about something All is fair uh and this is not that important but I asked our AI overlords what do students at Stanford learn together at a pet party look like and this is what they gave me back I'm not going to interpret it but I just thought that was interesting okay and then finally as you guys know one of the reasons that CS 109 great still under your control is because there's lots of ways of showing us that you know probability one of the ways is to express what you've learned in probability about something you care about in your own life and that's one of my favorite ways that you could express it totally op and optional in the sense of the word that if you don't do it you'll get the same grade as if it didn't exist but if you do do it this contest what a cool thing all the details on the website okay we're going to learn something really really really cool but I need to motivate it I need to give you could you grab me a glass of water okay thanks I guess I haven't been talking for a couple days I want to motivate it by the end of today's class you should be able to answer problem that that looks like this and at first it doesn't seem that important but let me tell you this is one of the more profound questions you can ask in science okay imagine you have two different learning context and you want to figure out is one better than the other so you have a certain number of people do learning context a and you have a certain number of people do learning context B one of the first things you do is for each person you measure their outcomes and then you take the mean and you say in learning context one the mean was 3.1 and learning context 2 the mean was 2.4 and then I asked you this question question it says is this difference in means of 7 meaningful and how confident are you in the claim that are you in the claim that they're how confident are you in the claim that group a is in fact s points better than Group B it doesn't seem that meaningful it seems nice to know right like you should be able to do that but it doesn't seem so critical but the reason it's so critical is this is the classic SCI test if you ever want to write a science paper in almost any discipline whenever you make a claim you have to talk about the probability of your confidence in your claim a thing called A P value so if you want to do biology or chemistry or physics or computer science and you want to do maybe uh uh computational education anything in that space if you did an experiment and you came up with a result and that result has a claim you have to associate a probability with it and today not only will you be able to associate a probability with this most classic sort of result of differences and means you should be able to talk about a probability of any claim that you could make in a scientific paper how cool does that sound who wants to know how to do a P value yeah okay bear with me because we're going to get there by the end of today's class and actually we'll get there by you know the middle of today's class but first a little bit of a review this whole story starts with the central limit theorem the central limit theorem what a beautiful thing if you take different and un IID random variables and you sum them up no matter what IID random variables they are uh and um as long as n is large enough it will always converge to a normal the sum will always converge to a normal and there's another version of this which means if you take that sum and multiply by 1/ m AKA you take the average the average of IID random variables is always normally distributed and that is a powerful thing that showed up in the world of sampling remember sampling you have a population but you can't get numbers from every single person in your population so you talk to a subsample of them and you know new numerically and in notation we'll represent our sample as a list of random variables we'll think of them all as IID they're independent but they're pulled from the distribution of the population so if this green is the population distribution we're imagine we're get 200 samples from this population distribution because of the central limit theorem some beautiful things come out first of all if you have a sample the mean of your sample is unsurprisingly take all of them add them up divide by n we learned that a long time ago in like sixth grade what you might not have learned about in sixth grade though is if you want to know the variance of your sample you can estimate that and it looks so much like the equation for variance except for this cheeky n minus one it's so cheeky go check out lecture to learn why there is that n minus one but basically if you don't have that n minus one because you're estimating uh expectation or because you're estimating the sample mean you'll get this wrong uh you will have a biased estimate and then finally this very CS 109 in sight sample mean is a random variable and that makes sense every time you take a sample and get a number it's going to be different so even though you get a value it'll take on different numbers probabilistically it's a random variable and because of that you can ask questions like what's the standard deviation and I've told you nothing about the underlying distribution and even though I've told you nothing about the underlying distribution I can tell you how you could calculate the standard deviation of its mean that's insane and it all comes from the central limit theorem because the central limit theorem tells us that the variance of the average of I ID random variables is a particular square root of the true variance divided by how many things you've added up um then we can know what is the variance of the standard deviation of the sample mean if any of this is new certainly review Monday's lecture oh there is this really cool example that did where he actually took all the times it took people to complete the problem Set uh problems and then for each one we calculated the standard mean and also the standard deviation of the standard or standard deviation of the sample mean I want to just point out one more thing we're talking about statistics here right like you had a sample and the two statistics that we could talk about particularly for this sample is what's the mean of the sample we could talk about the variance but often we write error bars which is the standard error and standard error is just that um standard deviation of the sample mean and so the standard deviation sample mean that's what error bars are those are just statistics so if you took any one number if you expand it out there's a whole distribution underlying um and uh I did want to just highlight that we're talking about statistics not about the underlying distribution am I making sense okay anyone curious about what that distribution is this is how long it took people to do the a medical diagnostic problem on the problem set and you're like we all feel for these people respect uh and but what distribution do you guys think this is you guys curious I'm curious too I don't think anyone knows I think it might be Airline which is the sum of exponentials so it's like there's five Concepts you need and it's amount of time to get concept one plus amount of time to get who knows could be Airline could be Gumble which is a Max of exp or or Max of different random variables we could talk about this offline it's really not important right now but the important part is to keep reinforcing in your minds the difference between a statistic about a random variable and the underlying distribution lots of people care about statistics but if you could walk out of cs19 caring a little bit more about the underline distribution my heart would be so filled oh yeah okay Airline versus Gumble not that important right now but what about Bhutan on Monday we left with this deep mystery we were making a report for the government of Bhutan and the government of Bhutan had asked us can you report on the happiness of our people so we took a sample of 200 people we reported the average happiness and then we reported the sample uh the variance of the sample that we got of the 200 people and we used this equation where you use n minus one to make sure there's an unbiased estimate fantastic and then we showed it back to the king of Bhutan and King Ban's like what are you doing there's no air bars there we're like oh oh yeah of course so Monday's class we're like we're going to add some error bars and first of all adding error bars to this estimate of the mean was really straightforward we would just use the fact that this a mean comes from the central limit theorem we know it's going to be Gan we know that its particular variance is going to be S Sid by n and the standard deviation of our estimate should be this value we've got error bars and we go to the king of Bon we like we got air bars the king of Bon's like no you don't you have error bars on one of your statistics what about your error bars here uhoh and you're like huh well we got these error bars because xar was the sum or is a the average of ID random variables Central limit kicked in we could know its variance and you're like is this the sum of IID random variables and you're like ooh I don't know you're like squaring things and then I'm not sure this is actually going to turn out to be gy and it turns out if you went down this path and tried to figure out eventually Central limit theor applies here it turns out it doesn't you can't just use our old trick so what I'm going to teach you is a general trick anytime somebody wants you to know about a distribution of statistic anytime somebody wants you to know P value for science hypothesis we're going to use this one most beautiful randomized algorithm which is called bootstrapping and it's one of my favorite randomized algorithms I think it it would show up in every probability class if people knew how to program because it is such a powerful tool for understanding the underlying probabilities particularly from data I think every data science class would teach it every probability class would teach it but not everybody knows python the way that you guys do bootstrapping is going to be an algorithm and it's going to solve two separate problems if you want to know about a distribution of Statistics like you want to know what's the variance of my standard uh de or of my estimate standard deviation you could know that for any statistic and the generalization of that is you can calculate these most important things for science called P values and it's going to take advantage of the fact that you have computers and if you ask your computers to work hard they can figure out these P values for you and it's just going to take a little bit of probably Theory to get there so let's go back to that ch we had with the king of Bhutan the king of Bhutan said estimate the variance of happiness in my country and we gave the king of Bhutan a number we said the variance of Happiness was I'm going to make this up because I can't remember but 420 or something like that standard deviation would be square root and the king of Bhutan is what is the variance of your estimate what are those error bars or the standard deviation of your estimate so you want to know standard deviation so you could give these error bars but that was hard to do and we don't have a solution I'm going to give you a simpler way to come up with the solution I'm going to tell you the happiness of every person in Bhutan that's right I'm going to let just cheat a little bit and you're like once I know that do I even need to know the standard deviation of my estimate and like no you wouldn't need it we're cheating because obviously we're not going to talk to every person in Bhutan but imagine we had we've talked to every single person in Bhutan and after we talk to every single person in bhon what do we have you could say we have a histogram and on the x axis is people's happiness values which are obviously numbers between like one and 10 uh and on the Y AIS you could think of this as a histogram but better yet if you normalized it this should be the probability Mass function so you should say the probability that the happiness of some person equals little H where this x-axis is little H so my question for you is I give you the full probability Mass function of happiness in Bhutan and now I ask you this question can you tell me how bad was my estimate 420 for variance and particularly I got this estimate after talking to 200 people that 200's important you know if I got my estimate after talking to 10,000 people maybe I should be pretty confident but after talking to 200 people I should have some room for doubt in my number this is a hard question to think about but I want you to figure it out because if you could figure it out then the whole rest of this lecture is going to flow like water in a beautiful Canyon so let's see if we can figure it out how could you estimate how bad your measure of sample variance was if I gave you access to everybody in bhuton yes question expect value of sare difference uh I'm going to let you guys I don't have the answer yeah you guys are going to think about it that was a good proposal answer but think think about it what would you do there's other ideas and think about you can use computers as much as you want imagine you have a laptop which is as powerful as your I don't know Smartwatch okay good fantastic think about it let's see if we can figure this out let's vent some cool stuff so how are we going to get this estimate if people have questions if there's something unclear just raise your hand one of the T will come and answer your question okay yeah go talk about with the person next okay thank you it pass is thanks man app if you have any questions raise your hand we'll come answer okay let's do this and if I could focus everybody on one part of today's lecture it would be this one because if we can really crack this and understand what we're doing here I appreciate the why is not as deeply motivated but if you can understand the mechanism then we'll be able to follow the rest of the lecture so let's make sure we take the time to get this right just to make sure we're all on the same page variance is the measure of spread so the king of Bhutan doesn't just want to know average happiness they want a statistic of how much happiness spreads because if that's low then everyone has close to the average but if it's high then you'll have some really happy people and some really unhappy people so that measure of spread is something the king of Bhutan wanted but because we only talked to 200 people we don't have the variance we have a thing called the sample variance which is our estimate of spread based off of just talking to 200 people it's not going to be the right number we only tou to 200 people and as such we want to know how much this number would have changed if we talked to a different 200 people we want some measure of how much this number is changing and we're getting meta I appreciate how meta we've gotten you variance and now we asking for variance of the like or if you're into square roots standard deviation the standard deviation standard incredible questions clarifications let's talk about things before we talk about ideas yes yeah so this is the meta part that I don't fully get I think the So when you say the standard deviation of the sample variance what are we measuring the spread around are we measuring the spread around a mean yes this should be around the mean oh the sample variance sample variance is an unbiased es because we got that n minus one in there it turns out whatever you get for sample variance is what we call the mean of the sample variance so it's it's around the number you got so if the number you got when calculating sample variance was 420 this will be the standard deviation around that 420 long story short does that answer the question awesome other questions yes is our sample is our sample variance is that considered a random variable yeah it is that's a really good point so it's a random variable so underneath the hood it's going to have a distribution what does that distribution look like have you guys ever seen a distribution of variances oh my God today is a first in your lives can I tell you what it looks like I didn't plan to do this but I want to I'd like to tell you what you've never seen a distribution of variances oh man okay well first of all what's the distribution of means look like it's gaussian because of central limit theorem distribution of variances it depends what the variance is sometimes it looks like this sometimes it looks like this it can depend but notice a big difference between means and variances means can be negative variances can never be negative this is not gaussian but anyways you asked a good question and then I went on a total trade is variance is sample variance this thing a random variable you bet it is and it's got a distribution we just never saw it before today yeah at the beginning of class you said that the way that we worked out the mean variance doesn't work for the way that we work out the variances variance can you clarify that yeah this is your sample mean and this is its distribution if you took 200 different people you would get a different sample mean it will vary around what number you calculated and it's going to be a gaan like if you played 10,000 times the game of getting 200 people getting their sample means and plotted it you would get a gaussian because cenal limit theorem because cenal limit theorem we know exactly what's the variance of this Gan that's not a gan Central Li theorem is not our friend today well it's always our friend it's just not the friend that can solve our problem okay one more question I do need to jump into things use like like some sort of involving be able to avoid using strap to answer this question I want to avoid that because there are shortcuts that people have so okay let me just generalize this question there are shortcuts to several of the questions I'm going to ask you today where somebody might have done some math to propose an answer to just that question what I'd like to teach you today is a way to answer all of the questions so a much more General method so yes there are ways you can circumvent bootstrap basically for any problem but bootstrap is like your Swiss army knife tool and if you can Master this tool then all these problems you don't have to learn a Kai Square test or a t test or all these different mini tests you can just use the power of python and your understanding of probability it's a beautiful thing it's like the most ts19 thing in the world I'm so excited okay so now we know what we're doing how could we do it and I am looking for pretty simple ideas so if you had access to all of bhutan's Happiness values my idea is is there some way you could possibly see the distribution of your sample variance whoa Insanity not possible maybe it is possible yeah you could repeat 10,000 times let's start with that okay so yes we're going to repeat 10,000 times what are we going to do 10,000 times though okay an idea [Music] um and then because we have the whole distribution we could just recreate talking to 200 people I mean we're trying to understand how wrong we worth 200 people so we should take 200 when we're trying to understand this so we're going to pull 200 random people okay and then we calculate sample we using that very nice formula we had for Monday's class and we've done this 10,000 times that's going to give us 10,000 different estimates for sample variance guess what happens if you took all those 10,000 things and made them into a histogram you get to see your own standard the distribution of variant that would come from talking to 200 people fantastic that's on fire that's that's awesome so does everyone I want to pause here this would work but we're missing one step how do we then get the standard deviation of sample variance at this point we've got our whole distribution from 10,000 times of repeating my experiment after repeating my experiment 10,000 times every single time I got a value and if you histogrammed it you would get the whole distribution of sample variance maybe when you talk to 200 people you got this number maybe when you talk to 200 people you got this number if you got crazy unlucky you might get this number but the probability will be governed by the distribution once I have the whole distribution it should be easy to get a statistic like standard deviation once you do this you have the whole distribution and once you have the whole distribution you can just calculate standard deviation man that's crazy like I really appreciate that I have pushed us all I may just think about standard deviation of variant this is insane but I want to pause and see if there's any what's confusing about this here because if it's confusing to you it's confusing to somebody else yes I'm confusing about the value of when you do one of those Loops what you take example is the value of the random VAR a random variable a value in itself or distribution in itself I know the old ad was it's a sample and a sample is interesting we often write it as a random variable but it will be a number when you calculate it like when you run this Loop in your computer you'll get a number but if I were to write this in an equation I'd probably say Like You Know sample one then you can say sample two but this time it's a sample of your sample variance but does that make sense so they will be numbers like when you run this in your computer you're going to get 10,000 numbers it's 10,000 different like values and they're going to be IID pulls from your sample variant you get 10,000 IID pulls from your sample variants so you have you're basically estimating the pmf of the of squ by yeah that that's exactly we estimating the probability Mass function of s s and that is giving us all the information we want to know about s s yes an idea um why would it not be a normal distribution then if it's I good question not everything that's IID is normal are things that are added together U like if you add up IID random variables that's normal if you average IID random variables that's normal but the equation for standard variance doesn't lead to something that's normal and one thing I could also point out too is that variances can't be negative and you know normal distributions have no limits on what values they can take on yes from these 10,000 variances how do you calate the same deviation ah so once you have 10,000 Things you've got this histogram and then you can use your classic variance from the midterm equation where you just take you know expectation of X squ div expectation of x^ squ being a square rooted or you can use your friend Python and say like np. variance and then you just put in your samples and it'll give you the variance why does it matter that we know the true distribution if we're just pulling samples anyway to my next Insight okay but let me be clear about what we've done so far if I gave you access to every person in Bhutan we can now talk about how wrong we were when canceled the full variance and we could talk about that by expressing the full distribution of sample variance but your question is why do we need access to everybody in Bhutan and it's important because we don't have access to everybody Mutan that kind of breaks the whole scenario we'd like to be able to do this with only access to our 200 people I'll take one more question before I jump into the next part uh is is there maybe like just an established like how much you have to we can talk about the S line but that's it depends a little bit okay so where we are is 10,000 times take a mock sample talk to a mock 200 people calculate the sample variance now you've repeated your experiment 10,000 times and because you've repeated 10,000 times you can think about how wrong any one experiment is because you can think about you know how different it could be from the true variance so here's my crazy crazy claim so you guys are halfway through this wonderfully complicated and beautiful idea called the bootstrap so what we've talked about is the first idea that if you want to know about some statistics just repeat many times and recreate the experiment as good as you can calculate your statistic then you'll have 10,000 versions of it and that's the full distribution that's the first half the second half is a bit of a leap of faith we don't have access to everybody in Bhutan what we have access to is fewer people imagine say we had access to 1 2 3 4 five six seven eight people if I histogrammed this and then normalized it we can think of this as you know a probably an estimate of probably Mass function you know what's my estimate at this point that somebody's happiness is 90 well I saw one out of eight people with 990 so you know maybe we'll or maybe there's 10 here H anyways I saw close to one out of you know 10% of people with 90 happiness so I could estimate that's probably somebody has happiness 90 never saw somebody with happiness 91 so that's not possible I saw two people with happiness 92 uh just one person with 93 and I saw a whole bunch of three people with happiness 94 so this sample we can represent it as a histogram and that histogram has a nice analogy with a probability Mass function because a normalized histogram is a pretty nice approximation of the probability Mass function from your data somebody at Stanford not too long ago I don't know what they were doing but they had this wacky idea they said if I don't know all the people's happiness in Bhutan and all I've got are these samples then this probably Mass fun function is a pretty good approximation of the true probability Mass function of all the happiness of people in Bon and people are like what that's crazy yeah he's like the distribution you get from the histogram of your sample is a pretty good estimate for the true underlying distribution crazy the first time I saw that I was like I like nope that's not right turns out it was right and this guy got like all these wordss for figuring this out but you know if you go back to our true distribution of Happiness if we see in 100 samples you know six people with happiness two what's our best estimate for the probability that happiness equals 2 well according to the very first definition we had of probability we had 100 samples and let's say we got seven people with happiness equal to two therefore our best estimate for the probity that happiness equals 2 is about 7 over 100 as 100 increases this will be a better estimate but you know based on this underlying assumption it's not that crazy extension to say well if you extend this to happiness equals 1 happiness equals 2 Happ equals 3 you get to the conclusion that your samples pretty good estimate of the true underlying probabilities and then he put those two things together because now we've got some peanut butter and we got some jelly and we're going to make a delicious sandwich so what's the peanut butter is that we could estimate our distribution of something like sample variant by repeating a whole bunch of experiments and now that jelly is if you only have 200 people pretend that's all of Bhutan consider that the probably Mass function and when you get 200 more people you're going to pull from that probably Mass function from the original 200 people insane let's make that a little bit more graphic this leads to the bootstrap this is our beautiful peanut butter and jelly sandwich bootstrap goes like this you are going to estimate the probability Mass function using the sample so you start with your 200 people from Bhutan Step One is take those 200 people and make your histogram and then estimate your probably Mass function from the histogram then 10 10,000 times we're going to do this pull 200 people and calculate the statistics we cared about and then we have 10,000 draws from Arch statistic okay now how do you pull 200 people from the probity Mass function I think that's the interesting thing by the way for now let's start thinking about estimating the mean we know the central limit theorem will tell us the right answer but this will be a nice warmup to the bootstrap we'll then do something more interesting here's how you could get the bootstrap to estimate how wrong your mean was so you estimated mean you're probably a little wrong how wrong were you here's what the bootstrap says first of all you gave me 200 people the first thing I'm going to do is I'm going to take those 200 people and I'm going to build a probability Mass function it's going to look like this here my happiness scores go from zero to like I don't know 120 but anyways you take all your happiness scores you histogram them and then you say that you know the probability somebody gets 61 it's the number of times I saw 61 divided by the number of samples I had in my data set insane according to this guy at Stanford not insane so now we've got a madeup probably Mass function an estimated probably Mass function if you will and the next thing we're going to do is say that's Bhutan that's all the happiness of all the people and once we've assumed that and that is an assumption then 10,000 times we're going to do this draw 200 samples from this probably Mass function then we're going to recalculate the mean and then we're going to save it so let's draw our 200 samples recalculate the mean from these 200 samples so sorry I squiggled drawing 200 samples but you get the point right you draw 200 samples they're not exactly the same blue distribution and you take the mean of those 200 samples and I'm going to add it to a list of means I've done my Loop once you guys ready for me to do it again next time through the loop I pull another 200 people from bhuton but of course I don't have all of Bhutan instead I'm going to use my estimated probability Mass function insane but beautiful at the same time and once I do this then that red is going to be my 200 pulled people I recalculate a new mean from my 200 pulled people and I add this to my list I now have two estimated means were the same no you know when I pulled each time when I pulled 200 people I got a different 200 people so when I took their means I got different numbers they were pretty similar which is a good sign if they were really different that's a bad sign for how well we're estimating the mean if we do this 10,000 times I'll end up with a list of size 10,000 and the crazy thing about bootstrapping is that it says this is the distribution of means cool or what okay of course it's not that cool who cares about distribution means it's cool when it gets to science so if your original sample is like only 200 for example then if you're redrawing a length 200 sample from that sample is everybody in that SLE think about it as every time you withdraw it's with replacement so it's not just every time I draw a person from this probably Mass function the probably Mass function doesn't change okay it's not like one person gets removed so every time I draw it's from the same proba mass function so for example I could possibly draw 200 people with that happiness it's unlikely but possible good question yes how confident can we be that this is because like what if my 200 sample let's say this is to just like really unusually happy people that just mess up our whole process yeah it turns out that there's a lot of proofs that show that this converges very quickly to the right answer so at the point where you're at 200 it's possible that something out of you know distribution would happen but very very very very unlikely and people trust this immensely because there's a lot of evidence behind it yes is there a minimum amount of people we need to sample I'm like what if you sampled only like 10 people I've never seen somebody attempt this when you had fewer than 200 samples to start with so that's a good question but you probably probably people have done it with like a 100 but I've never needed to yes just clarify work out a new need from sampling this original sample and you distribute that new be that you yeah every time loop I get brand new people and a brand new mean so I'll end up with 10,000 brand new means yes on like if you had say only 200 200 people do SLE 200 it's a survey dat set so I'm really struggling to understand how it replaces itself yes so um let's say there's five samples and I'm going to resample five from that how's that sound can we start with that and then we'll extend to 200 so in my original sample let's say it's binary it's zeros and ones few and in my original sample I only had five people what am I doing bootstrapping for well anyways there was two people in my original sample who had a zero and three people who had a one so I'm going to say two out of five people had a zero uh and three out of five had a one those are probabilities now when I pull five new people it's possible that my five every time I pull a person it doesn't change this distribu so now I'm going to draw people first person I pull is a zero that could happen right I'm going to draw four more people next person is a zero that can happen next person I draw is a zero that can happen every time I'm drawing with this constant probability so there's always a two fths chance of a zero and I could go and I could pull five zeros so even though the original distribution did not have five zeros when I pull five times from the uh imagine proba Mass function I could get zeros so you could see something that was not in the original distribution yes if like of the original pmf one of these happened to be zero so like wouldn't that zero carry on to the all the rest people you pick like You' never have another 61 for example if that was zero and the original came sorry oh yes so if there is some value and you never see a person for that value what do you do school two schools of thoughts one school of thought says that's a zero it's not possible didn't see it in 200 not possible and there's a bean school of thought which is like maybe we can do some little pla smoothing here and we can like add in some uh observations about thing so there's people who get really fancy about it but um for now we're just going to say yeah you didn't see in your sample not possible after the in the list you said it was like it's a good thing that they were similar to each other isn't it doesn't it like make sense that they would be each other because we're pulling from the same thing yeah and in fact because these are me means not only does it make sense but we can know everything without even having done the bootstrap because the central limit theorem tells us that the distribution means will be gaussian and we know that its mean will be expectation of X and we know that the variance will be equal to um the square root of the distribution of the average of IID random variables so that's going to be the square root of n * Sigma did I get that right n time uh okay 51 Central limit theorem says if you average n random variables it will be gaussian and its variance will be Sigma squide n and so the average will be gaussian and it will follow that distribution and if you looked over here at slide 51 you if you looked at this distribution it would be gaussian and its variance would be the true variance of the random variable Sigma squ / n and then you can ask questions like what's the probability that your true mean is in the range 81 to 85 but to be clear after we've done our 10,000 samples experiment if I want to answer the question what's the probability that the true mean is in the range 81 to 85 how could I do this using my 10,000 means so to be clear after bootstrapping I've got 10,000 versions of the sample mean how can I answer the question what is the probability that the actual mean is in the range 81 to 85 I want you to talk about with the person next to you but before you do that as the person next to you is there anything confusing about this if you guys got a good question keep this wonderful wonderful conversation going because I've really appreciate all the questions so far so what's confusing and then how could you answer this question using your 10,000 samples e I take 40 more seconds okay so as we mentioned one answer to this is that you could take your underlying Knowledge from the beautiful expression of nature that is a central limit theorem that says if you ever average random variables it will always be distributed as a gan amazing and not just any gan gan whose mean is equal to the true mean of the things that you averaging together and whose variance is equal to the true variance of the underlying random variable divided by n because of that you can know this distribution just by first estimating the sample variance dividing by n and then you could know how much that this thing has a spread you could estimate the the expectation of this by just calculating xar it's a beautiful thing and then you can calculate this but there's an easier way if we've just bootstrapped and we have 10,000 samples from this distribution of the sample mean there's an easier way to answer the question what's the probity that the mean is range 81 to 85 did anyone come up with that easier way yeah by counting just by counting but tell me more um just count the ones yeah I want you to guys start seeing lists and imagining probably distributions can we start doing that you see a list anytime in life you're like going to be in cs1 XB and they're like here's a list and you start seeing probably distrib is like what did Chris do to me anywayss if you see a list especially if there's samples I want to see a probably distribution and then your claim of counting is very good you said take this list and say what percentage of things in this list are in the range that we cared about and that's a good estimate for the probability that something drawn from this random variable would be in that range I have so much appreciation for how deep this lecture is going and I really appreciate how hard you guys are working to follow this not easy stuff but powerful important stuff that leads to a tool that you'll use for hopefully the rest of your scientific lives Okay so we've answer this question I've set the stage we should be able to do this I now want to add error bars to this report to Bhutan before we take this and start to do p values for science so how do we take this and get standard deviation of this estimate so we got 400 something close to 450 was our estimate for the variance of happiness in Bhutan but that estimate was wrong bootstrapping tells us how wrong it might have been yes why should we trust bootstrap just as much as the central limit theorem do you have like uh like controls to like test how fast the approximation is working and yeah just in like the central limit theorem how there's both um mathematical evidence people have actually done proofs to show that this converges to the right thing as there is a lot of empirical evidence so for both those reasons we trust the central limit theorem and for both those reasons we trust the bootstrap and we should let me see if I can pull up some experiments showing you how quickly it converges okay if you want to figure out standard bar error bars for estimate variance we're going to use the exact same algorithm it's just we're going to place these two things with variance in the loop instead of means we're going to calculate variances so we're going to repeat 10,000 times first well first before we repeat 10,000 times we're going to estimate the probity Mass function from our sample so we took our 200 people said that's the distribution of happiness in Bhutan then 10,000 time we pulled 200 new people from that proba mass function and then this is where it deviates from these 200 people that we just pulled don't calculate the mean we're talking about the distribution of sample variance so so let's calculate the sample variance if you calculate the sample variance you know we've got an equation for that maybe this time you get 4727 we're going to repeat this 10,000 times so the next time we might get we will get 200 different people and this time when we calculate the sample variance from those 200 people you'll get a different number and if you repeat this 10,000 times you'll have 10,000 different estimates of the sample variance and when you see a list what should you think prob okay let's try that again when you see a list what should you think yeah if that is a list of samples that it should be a probability distribution in your mind and the way you could get there is you could think list then go histogram the normalize histogram because of this you know first definition of probability that histogram is going to be a probability Mass function so if you want to see it as a graph that's how you do your translation but a list is a distribution so so now we have a distribution it's not talking about particularly the variance of Happiness it's a distribution of or sorry this is the full distribution of things we could have gotten from our sample variance like in one experiment we could have gotten this number in a different experiment we could have gotten this number in different experim we could have gotten this number after 20,000 times this is all the different numbers we think we could have gotten from asking 200 people their happiness and then calculating stample variance and then if we were to plot it you would get those that whole list would give us a distribution and you can calculate the standard deviation from this distribution Insanity yes question how in the beginning we talked about the spread around the number that we had originally calculated yes so I just wanted to relate relate that to this sort of you know whatever number we're coming out of from this distribution so before we did all of this you could have just taken your sample and calculated the sample variance and you have one number so you have the one number which is the bar that we were putting in our report and now we have these 10,000 numbers and that will give us the in this case they'll just give us the error bars for that bar I don't one thing I would mention if you took all of these 10,000 samples and you calculate the mean of them you would get something exceptionally close to that original number you calculated so when you just took your 200 people and just calculated sample variance if you took the mean of this distribution it'd be basically the same because it was an unbiased estimate unbiased estimate by doing the division by n minus one I don't understand how do we like why does the minus one make a difference oh there's a deep deep answer to that let's talk offline because it'll it'll go long okay craziness the beautiful part of this is we can now put error bars on our report to the king of Bhutan I'm going to give us a pedagogical pause I want people to come ask me questions there in two minutes try and crystallize what we've learned so far uh and I'm going to leave the bootstrapping algorithm up here it's a beautiful powerful thing it's not that many lines of code and it's going to let you do some real magic with probability so take two minutes think about life ask some questions come find me uh and then we will continue this wonderful conversation yeah yeah because it's like we're trying to talk about how bad are estimate when we when we talk to 200 with these people so that's why it should always be 200 if we you know if you had 10,000 if we had sample 10,000 people you'd expect our sample variance the variance of our estimate would be very small talk to so many people that like if you talk to 10,000 different people you probably get a pretty similar number um so it does matter how many people you talk to that will change how you'll change your error bars yes no you always the exact same number always exact same number good question e spr EX such question such conversation I'd like to repeat two things that came up in conversation first of all I appreciate that I first made you think about sample variance and then we're measuring the spread of sample variance itself it's like you're talking about the variance of variance and then I promised somebody in questions I'll never make you go one level deeper it'll never be the variance of variance of variance the other thing is you know people some a really good question is what are we doing here can you just restate what we're doing here I feel like that's a nice way to come back from the pedagogical pause people everywhere in life are are giving you statistics and anytime somebody gives you a statistic they should tell you how wrong they think they are and in science this is a must in in news it's not always a must but it really should be some statistics is easy to know how wrong you are a sample mean it's easy to know because of central limit theorem but that's very much a special case most statistics that get reported to you that are not sample means there's no good language for talking about how wrong you were sample variance is not sample mean it's just my first example of some statistic that we could be reporting for which there's no good language for talking about how bad your estimate was and we really want to talk about how bad our estimates were because as we know from CS 109 those who can express how wrong they are make better decisions and so anytime you see a claim in a newspaper about a statistic anytime you see a claim in science about statistics you should always ask yourself how wrong could they be and there's lots of things that could lead to this source of error like if you only talk to 200 people you might be pretty wrong if you talk to 10,000 people maybe you're less wrong maybe I have more confidence in your claim but you should be able to give me in the language of probability how confident you are in your claim enter the bootstrap the bootstrap will allow us to talk about how confident we are in any statistic even if it doesn't follow the central limit theorem it's going to blow past just being able to talk about how wrong we are for sample means okay so this wasn't too many lines of code but I've got good news for you guys we can make it less you don't have to like if you write five lines of code nobody be like that was way excessive um but there is a way to do this a little bit more efficiently if you don't follow the more efficient one that's not a problem but maybe by showing you the more efficient one it might give you some cool inspiration or some cool insights the idea is if you are told I've got some samples from those samples build a PM and then pull K new samples from that we've already seen how you could do that you could build your histogram you could normalize it and then you could Loop K times and pull from that probability Mass function or you could do this you could say choose K things from these samples with replacement it turns out if you don't put this with replacement you get completely the wrong thing actually going back to this example if I say I have these five things choose five things without replacement you'll get exactly two zeros and three ones every time that's not what we want sometimes we want to get five zeros but we want to be driven by this probability Mass function but if you put replace equals true and I say pull five things from these five objects two zeros and three ones with replacement the first time it'll choose one object from your five and the next time it'll choose one object from the five but it could still be a zero you could still draw five zeros if you pull with replacement with replacement means every time you take a sample you leave it in there so that the next one could be that exact same sample and for those of you who are curious you could prove to yourselves that this is equivalent to build the pmf then draw samples from that probability Mass function draw case samples so there you have it a very very very fast way of doing the sample and replacing let's talk about how this up dates our OG bootstrapping so this is a bootstrapping we had before first you estimate the probabbly mass function then 10,000 times you repeat your experiment in the experiment you draw 200 people from Bhutan you calculate the statistic you cared about and then you have a distribution of your statistic so now I don't know why I have that photo there forgive me uh but it's very inspiring maybe because we're feeling inspired now we don't actually have to explicitly make the prob Mass function the sample as a list list is in fact the probably Mass function and if we choose 200 items from this list with replacement that's the same as first construct the probably Mass function and then draw 200 samples from that constructed pmf it is equivalent to just pulling 200 things from your original sample with replacement now to be clear if there's only one of these that you understand I want it to be this one because that's where the theory deres from and this is just the programming shortcut but if you're really excited to think about why programming shortcut is correct I would encourage you to do so because I do think it will just reinforce some fundamentals if you're curious the rest of the algorithms exactly the same yeah what are we cutting out like what's the shortcut so in the first one before we do 10,000 steps we actually construct a physical probably Mass function yeah and now we don't have to construct the actual probably Mass function we just keep have a list of original samples around and then we sample from that with replacement crazy okay we have to code this we can't talk about this in theory anymore we've got to see some code are you guys ready okay I have a world for you that's going to put this to the test I'm going to make a random country and that random country is going to have a thousand people in it uh and sorry and it's going to when you call when I make this random country I'm going to know the true variance of the people in the country because I made the country and then I'm going to give you a sample of Happiness from it so I know the right answer because I made the country don't use this okay just use your sample and your question is from the sample can you guess the right answer but can you also Express how wrong you might be in your guess and so we're going to bootstrap we're going to repeat 10,000 times and what are we going to repeat bootstrap that VAR yeah one resample a new group recalculate the stat we care about now in this case we're talking about um the the variance so what we should the cat the stat we care about is going to be the sample variance in this case okay how do we resample a new group one option would be to say like probably Mass function equals create pmf from this list of 30 people and then we could try and pull 30 people from pmma we could say take that pmf and give me 30 people from it that's what we could have done but I am going to try and use the programming shortcut in the programming shortcut instead of doing this I'm just going to do np. random. Choice and then I'm going to say take my original sample from them we're going to choose people and replace is going to be equal to true let me just print this out and let's just look at it for one time through the loop and then we can think about our lives you guys ready for it okay one time through the loop I got 30 people and that's their number that's great that's not the end of it I'm supposed to recal calate the statistics so in this case calculate sample variance with the new sample so I have a function which does what we did on Monday's class and I'll call that s squ or something uh and then I'm going to put that into my list and now when I run this 10,000 times I'll end up with a list of 10,000 numbers for my variances uh and if and then I'm going to I have a little histogram plot of it oh and look at my variances isn't that kind of interesting and once you have this you can talk about lots of things I have my whole distribution variances I can be um so the true variance was 24.7 my estimated variance using sample variance was 24.6 so I was a little bit off uh and well actually I was lucky to be that close because in fact the standard deviation of the statistic is six so you could be really far off so if somebody reports to a 24.6 they got a little bit lucky they could have reported anything from like a 20 to a 30 um for this particular number okay so at this point bootstrapping allows us to get something like this which says we can talk about how wrong we were in any statistic we care about could be sample variance could be something more interesting uh and really it's allows you to talk about probabilities of Statistics using code it's a beautiful thing quick history why is it called the bootstrap because it's like the idea of bootstrapping comes from this metaphor of picking one up from your own bootstrap so imagine you're lying down and you have to grab your boots to get yourself up sounds hard right and that's why they call the bootstrap is because this assumption that the true underlying distribution is simple or equal to your sample seems as hard as pulling yourself up from your bootstrap and it's crazy that it works out um and so that's why it gets this name bootstrapping and it was invented here at Stanford in 1979 by this guy who's still a professor at Stanford and he won a national science medal for inventing the bootstrap I don't do celebrity look lights uh for for colleagues so what I did do is I let the internet do it so starbyface.com gave me somebody I don't know but anyways Bradley Efron invented the bootstrap here at Stanford what a beautiful thing and it works for any statistic but there is a big as tricks your sample have to be IID and the underlying distribution has to be one that doesn't have a long tail so if you guys remember the climate change problem you explored longtail distributions for things that are longtail it turns out that this can break down which leaves us with the most important question I claim that this can answer a crazy important idea in science which is you made a claim you had group a it had its mean you had Group B and you had its mean and from those two things you calculate a statistic and that statistic was the difference between those two groups can you talk about how wrong that statistic could have been there's two different ways of talking about you can calculate the variance of that statistic and we can do that in exactly the same way we did before but I do want to introduce you to this idea of a null hypothesis that's been in the history of science for a very long time when comparing two groups people often think about what's the chance of seeing a difference this big if my two groups were the same the null hypothesis says you had two different groups but they're not actually different and any statistical difference you saw is because you didn't do your stats right no I'm just joking it's because you didn't have a big enough sample and everyone has been calculating the probability of this null hypothesis the probability of this null hypothesis has a particular name it is called the P value and bootstrapping gives us a very nice and simple simple way to think about the probability of the null hypothesis it starts out with this crazy idea so you have two lists right and you want to know how likely it is that this calculated difference in means is Meaningful and the way we're going to do that is we're going to imagine it's not meaningful we're going to imagine the null hypothesis in the null hypothesis you had 20 people in group a and 20 people in group b and they're all pulls from the same group there's no difference between group a and Group B you just got 20 samples from student population and 20 other samples in student population you called one group a and Group B and that was totally meaningless that's the null hypothesis world in the null hypothesis world the true probability Mass function is the concatenation of the people in population one and population two so if you looked at the null hypothesis world if you had these numbers for group one and these numbers for group two the null hypothesis world is put all those numbers in one big bag and that's the distribution of students and you just happen to pull 20 and call it group one and you just happen to pull 20 and call it group b or two questions about the null hypothesis it's a weird concept once you know the null hypothesis the bootstrapping will come nicely have you guys seen this before can you nod your heads you seen null hypothesis in other classes some folks but it's new for other people okay so the idea is in the null hypothesis everything comes from one distribution you just call this group a and you just called this group b there's no statistical differences between these IID samples it's just you pulled too little and you saw a difference in means so in bootstrapping here's what we do we make the universal distribution by taking population one and extending it with population two I make a list which has all the people from population one population 2 and that is the probability Mass function of the universal distribution 10,000 times we bootstrap and when we bootstrap we calculate the exact same statistic that we calculated in our science claim we get a group of people and call them group a or in this case group one we get a group of new people and call them group two and they're all being pulled from the Universal population so 10,000 times we take random people call them group one random people call them group two and then we calculate the mean of each of those groups and we look at the difference in means and then we just add it to our list so we'll add up 10,000 differences in means you could count how many of them are bigger than your observe difference in means some people do that but I actually want to look the full distribution of differences and means in this null hypothesis world so you guys ready for this Ready or Not Here Comes so 10,000 times we make scientific experiments with group a and Group B 10,000 times we calculate the statistics this time it's not sample variance that we're calculating the statistic we're calculating is the difference in Sample means that's sta statistic as well and that statistic if you look at it you know in the null hypothesis it's very likely that the absolute value of the difference in Sample means is close to a zero because they came from the same distribution those two sample means are very likely to be similar to each other but even if you pulled 20 samples from one group and 20 samples from another it's still possible that or sorry if you pull 20 from the same group and another 20 from the same group it's still possible that they have different means and we can calculate exactly what's the probability we can say using bootstrapping we know the full distribution and the absolute value of the difference in Sample means and the probability that under the null hypothesis you would have seen a difference in means this big is what is the probability of seeing a number in my distribution greater than the difference you observed and this probability you can calculate you have the full distribution you could just sum up all these probabilities from your probability Mass function of your statistic and you say the P value the chance of seeing a difference this big or bigger based on the null hypothesis is 0.008 and if you know the famous science claim if you have P value less than 0.05 it gets accepted into science which is its own problem so the idea here every science result needs a P value so a lot of science results are statistics I had two groups I calculated their means and the difference in means means the effect size is 7 that statistic we need to know how bad it is we could just look at the variance of that statistic but in science we often look like what's the probability that you could have seen the statistic assuming your groups were exactly the same bootstrapping what an incredibly powerful tool it works for so many different questions you could ask it allows you to use your computer to run 10,000 simulations incredibly quickly to understand distributions of any claim you're making if you can understand the distributions of any claim you're making you can talk about it more probabilistically it makes this insane assumption which we're still going to dig a little bit deeper into which is that a great assumption for your underlying distribution is just the histogram of your samples questions before we jump into I do have one food for thought to leave you with though this is the most important takeaway is what I've got up right now yes say the P value is the probability that under the null hypothesis therefore everybody is coming from the same distribution that you would have seen a difference in means this big or bigger or a different or whatever statistic you claimed so I claimed that my difference in means was greater than 7 that was my claim so you would have seen a claim that strong or stronger under the N null hypothesis what's the probability of seeing a claim that strong or stronger in this case my claim is the absolute value and the difference and means is 7 and you guys will practice this in section yes how did you make the universal good question this beautiful line of code I could have even done it without the Deep copy U but I just wanted to keep my population around these two lines of code I created a list I put everybody in population one in it and then I added everybody in population two in it that is the universal distribution good question okay you guys are wonderful this is one of the harder classes to follow on thank you guys so much for working so hard I tried my best to make it as clear as possible you will get to practice this in section you'll look about corgis on Islands it's a good time have a fantastic time in section so wonderful to see you see you guys back in class on Friday