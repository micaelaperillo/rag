good afternoon cs19 how are you guys doing today fantastic that's what I like to hear um we have a wonderful wonderful class ahead of us we're going to learn a very critical idea once again we're going to be learning about continuous random variables this is cs109 before I jump into things I this is a random photo of my baby but I was just like heart melted and I just thought I would share which is really not the important thing though maybe the important thing is it's a Friday so I like to start Fridays with just a nice story from Life um and the story I was going to tell you is actually not related to this photo um though I guess the short story is like my day starts normally at six again this morning I started at 5 45 a.m I like feed the baby I dance party with the baby this is like such we do she calls it Yoda but she means yoga into like we're gonna do our stretches it's a fun way to start I recommend it anyways but the story I was going to tell you guys today was actually an interesting story from my own life um you guys may or may not know this but I am legally blind in one eye and the story behind that is quite interesting uh when I was 11 years old I was living in uh Kenny at the time and I I believe I was with my parents and they were like pointing something out and I was like should I look out of my good eye or my bad eye and my parents like what like you're not supposed to have a good eye in your mouth I thought everyone had one uh and so I was like yeah I can't see on my left eye and they're like we should actually probably look into that um a long story short something happened to my left eye it was a disease and not contagious don't worry but the thing that happened to my left eye was gonna happen to my right eye and eventually a doctor in Nairobi figured out exactly what it was and and they figured out how to get me the solution it was a little late for my left eye though because it'd been bad for a long time but then at one point my vision my right eye went as well but because this doctor had figured out what had gone wrong they gave me the solution which is an injection into the eye which is not the most fun thing but you know I get to see because of it uh he was able to give me that solution exactly when I needed it so I was able to keep Vision in my right eye and I can see just 2020 out of my right eye and you know on some level in the left eye continues to be a pain because it's been so long without being treated it just like causes all it's my problem child I um and despite the fact that this has been something I've had to deal with my entire life and of course it'd probably be more fun to see out of both eyes and there's always the risk that I will go blind it has been the most wonderful silver lining in my life and I don't know how to express it but I'm going to try there is something about being a middle schooler where it's hard to appreciate life like you just like oh middle school is hard but I had this weird experience at Middle School where I was like whoa I'm supposed to not be able to have one of these primary senses and yet I do and so I have this appreciation that was a big part of my life uh when you know I there's a lot about middle school not to appreciate and then there's other silver lines that have come from it I certainly feel like I I really do a lot of things much better and a really small Silver Lining is I came to Stanford and of course there's doctors helping me to make sure it doesn't happen to my right eye and to keep track of the left eye and there's this time when this doctor is about to do surgery on my eye he's doing like a pre-op he's talking it's like oh what'd you do I'm like oh you know I'm a uh I was a PhD student at the time so I'm a PhD student he's like oh what do you study I'm like I study um artificial intelligence like tell me more and then of course because the Stanford we started a collaboration we've written like three scientific papers together we just like have a good time we like nerd out about eyes and and probability and it's just been the most fun Stanford experience so there's really the strange disease I have somehow been a nice little light in my life and I think one day my vision might just go and I still believe when that happens I'll still feel like okay that's the cards I've dealt and it's been such a blessing in such a lot of different ways so anyways that's my Friday story fruit of the random tree as my friend would call it and that's the only connection I have to cs109 I have a hook for you guys today this is an extension of a problem we thought about on Wednesday so on Wednesday we learned about the poisson distribution and we can ask ourselves what's the probability of certain numbers of earthquakes within a year but there's a different spin on that problem it was probably more relevant to us we want to know what the probably at Stanford of an earthquake within the next four years and as that slight difference spin will lead to a different answer it's going to force us to understand continuous uh probability uh problem probabilities over continuous space okay um oh quick question does anyone know what this is a photo of yeah at Stanford and there's like mem2 but it's got this weird tower and this is like from the front of the quad and it's got this this strange shape to it and that's what Stanford looked like before 1906 when there was a magnitude seven point Earth eight earthquake which took down this Tower and took down this gate at the beginning of Stanford okay well we're going to want to be able to answer questions like that but of course we have to learn some new things to get there so let's learn some new things and it's going to build on some old Concepts we've had certainly we're in this part of cs109 or one of the core things for you to learn is this idea of random variables and the first random variable we learned was the binomial random variable it's a metaphor that comes from coin flips imagine if you have n independent coin flips every coin flip has the same probability of being heads the random variable is going to represent the number of heads you got in the more General story it's the number of successes within an independent trials such a useful thing that we've called it the binomial random variable as soon as you define something to be binomial random variable you inherit a probably Mass function exploitation variance we've gotten very good at this it also has like the little sister the Bernoulli random variable which is like a binomial with just one coin flip more useful for proofs later on then on Wednesday we bumped it up a notch we said let's learn a new random variable we learned one of the most beautiful interesting natural random variables the poisson random variable which says if you think about a fixed amount of time what's the probability of getting exactly K requests and the magical story from Wednesday and if you missed Wednesday class that's an incredible one to go check out it's that if you just give me an average number of equate of requests per minute because of the poisson process and all the things that we can derive with mathematics we can know the full probability Mass function for the number of events within one fixed time frame that's so much that you get from so little if you just tell me a rate you immediately inherit this beautiful graph um and all of this is on the course website you know we have all these random variables that we've learned about today's goal though is to change your understanding of random variables from I'm going to drive them one at a time to let's say somebody tells me about a new random variable can I learn it quickly and can I incorporate many random variables into my vocabulary So today we're going to learn not one random variable not two random variables but we're going to learn one two three four random variables in one day the learning goal really is then how can you learn a new random variable one of the points of random variables you don't have to redrive all the math to use it if somebody says this is a random variable you get to inherit all the math that they've done and I want you guys to be able to work with random variables that you haven't derived and let me give you a very real situation from your future U has gone deeper into computer science you are learning more you are thriving having a great time and learning about servers well a big thing for servers is how long a request has to wait in a waiting area area before it gets served and if you learn about it one of the most popular algorithms is this md1q and in md1q if you learn about it they talk about how long a request is going to be in the queue and they talk about it as being distributed as a Borel with parameter mu and 0.2 and at this point you're like I took 109 and they never taught me the Borel hopefully what we teach you at this point isn't every single distribution but rather how to learn new distributions quickly so if you looked up the Boreal Distribution on Wikipedia it would give you all this information and from this information it would give you all the most critical things and after 109 I want you to be able to read this Wikipedia page and know exactly what you need to be able to follow along the conversation about the md1 algorithm what you really need to know is the story what leads to it that's the equivalent of a binomial is n coin flips so a boreal has a story you should understand that and then you want to understand these equations too a probability Mass function that's the relationship between the values the Boreal could take on and its probability you want to know the mean and the variance and Wikipedia gives all those to you you might want to go drive them yourself but more likely than not you just want to understand this algorithm and you might be using these equations without derivation so does that sound good there is a learning goal for you guys future you is going to be so appreciative that you uh worked on the this learning goal today okay sound fun everyone's curious about servers now aren't they okay good times so this is our goal for today we're going to flesh out all of these random variables you already know a Bernoulli and binomial but I'm now going to teach you uh or in Plus on but I'm not going to teach you a geometric and a negative binomial and then we're going to learn an exponential ready for it we're going to do two quickly and your goal is to incorporate them into your vocabulary random variables so that we can start to solve problems okay geometric random variable if I could give you a metaphor imagine a Pokeball if you don't know what a Pokeball is it's unrelated to the food it's like this little thing that you throw and you catch a Pokemon and you throw it and you might catch a Pokemon or you might not so you might have to throw a whole bunch of pokeballs before you catch a Pokemon if that's not working for you then how about this a geometric random variable is one that's distributed as a geo with probability p and here's the narrative it's the number of independent trials until your first success p is going to be the probability of success on every single try so the one way of reading this is coin flips it's like a binomial says you have n coin flips how many heads did you get a geometric says how many times did you have to flip that coin until you got your first heads it solves a slightly different problem though related so you might say like you know how many um how many server requests do I have to send before one lands or how many pokeballs do I have to throw before I get a Pokemon it can take on the values one two three up to Infinity has to be discrete because you can't flip a coin 2.5 times and why can't it be zero a lot of our other random variables could be zero what's wrong with making this one zero how are you going to get of heads if you flip the coin zero times come on not gonna work so very good point can't be zero I am going to point out this Pro tip if you're learning a new random variable thinking about the values it can take on is such a grounding way to get yourself oriented and think about why can't it take on 2.5 why can't it take on zero so as soon as you buy this story you could then go and drive it this is one you definitely could have derived yourself you know what's the probability that it takes you n coin flips to get ahead well that means you've got n minus 1 Tails followed by head you could have derived this probably Mass function it would have been a little bit more annoying though to derive expectation and variance maybe expectation is not so bad but variance certainly would have been quite a lot of work if you wanted to drive it from scratch so I'm giving you a brand new random variable and anytime you feel that you can match this narrative you have these three tools you can work with does that sound good because I'm not going to stop there I wrote it down over here so you can follow along I'm going to introduce you to one more before we start solving problems you're like I don't care about catching one Pokemon I want to catch them all so the negative binomial that's awful it's how many independent trials not until one success but until our successes so it's like how many times you have to flip a coin until you get r heads and there's some problems that really nicely fit this narrative again we're gonna have the coin metaphor where p is the probability of success on each trial they're all independent every trial has the same probably P of giving you a heads in this case what's the problem that x equals n well if you say like five here you're saying what's it probably took five coin flips in order to get our successes hopefully R is something like three less than five well you have all these different places where you can put your successes you have the probability of success the probability of failure um and you know you could go and think about driving this but the point of today's class is to be able to use something that someone else's drive for you so as soon as somebody gives you a random variable you have the valid numbers it can take on you have the probability Mass function that's the relationship between assignments and probabilities and you get expectation and variance okay now do you have to memorize all these no cs109's midterm and final will be open book anytime in the future when you need to go references they will be somewhere and for actually one of the places uh one of the places that you can find them if you go to the course reader I made this section called random variable reference and you can just go see each of your favorite random variables and you can be like oh hey um that negative binomial here's what it looks like you can put in different values for r you can put in different values for p you can see the probably Mass function expectation variance you don't have to memorize them you need to know conceptually what all these things are you have to know what pmf is expectation variance and you need to know how to match the real world to the stories that it tells does that sound good yes subscribe again ah so there yes let me try and tell you the story uh and talk about how they're different in a binomial you declare ahead of times how many times you'll flip a coin you say I'm going to flip it 10 times and I care about how many heads it's a different situation for the negative binomial negative binomial says you're not going to just do 10 you're going to keep going and you'll keep going until you get r this number counts number of successes this counts trials until successes so they're both talking about coins they're just counting different numbers they're representing different values uh based on those coins yes oh that is such a good question I think it has to do with the probability Mass function because it has um binomial coefficient in it but let me double check I'm pretty sure that's it but I haven't checked that I think I asked that question myself like 10 years ago I can't be positive that's exactly it uh would you mind double checking let us know if I got it wrong cheers okay question exactly the probability that we're covering the probability of like with success so in this case you tell me the probability of a heads so the parameters are what you tell me and what I'm calculating are these things so you tell me what's the chance of getting ahead and I tell you what's the chance of a certain number of Trials until our successes so you know this probability Mass function if you see probability let's say x is a negative binomial x equals three that's a probability question it's asking what's the chance that the trials until our successes takes on the value of three good question and it's assuming that X was defined and when you define X's you had to say two things you had to say how many successes are you looking for so I'm looking for say like two successes that's r and you have to say the probability of success on every single child if it's a coin maybe it's one half yes it's very deep reason why the expectation and variance of the negative binomial are exactly our times the expectation experience of the geometric random variable there is a deep reason we're going to get into the derivation uh at some point but just to give you a little bit of a hint if x is a geometric let's say x i is a geometric you can think of Y which is a negative binomial you can say Y is the sum of X I's so it's like time until your first success plus time until your next success time will tell you so it's a sum of random variables and because it has this property lots of parallels will show up but if you didn't follow along on that not that important but it would be helpful if you want to do derivation more questions I love these questions this is great yes the value of R here it takes a maximum value of anything yeah it kind of flips a little bit I would say n takes on a maximum value of R because R is how many successes you're looking for oh wait sorry sorry um no n must be larger than R sorry R is how many successes you're looking for n is your number of Trials number of Trials must be greater than number of successes second equator or greater than equal it could be greater than equal to like if you're looking for let's say R is three I'm saying how many trials until three successes n is how many trials I ran and it could be three it could be three you're just like success success success drop mic I'm out of here totally possible okay now the interesting thing here is I'm going to give you some problems they're going to be using some combination of binomial poisson geometric negative binomial and I want you to see if you can find the story that you think matches um if that's interesting to you okay and certainly I want you to know that you can visualize these you can use these equations a little gift from the TA team to you okay let's start with dating at Stanford person you date has a 0.2 probability of being someone you spend your life with Wow wonderful I made that number up what is the average number of people one will date and then what's the standard deviation and of course recall that the meta goal here is to think about what steps would you take to answer a question like this practicing the art form of taking a question finding the random variables and then using the proper equations associated with those random variables so talk about what the person next to you you have a point zero zero zero zero zero one probability of that person being the person you spent no I'm just joking just talk about with the person next to you something okay now you might be at the point where you're plugging in equations and if you've gotten to that point you win right just basically you could use there's all those equations I've written are in Python you could just plug it into a calculator the goal is can you get to the point where you know the equation that you're supposed to be using as I said almost always we're going to be defining random variables when we see new problems and this time I helped us out I'm going to say there was a pretty clear random variable in this question which is the number of people that you're going to date until you find the one so that's the random variable I Define but the next step should often be tell me about that random variable it may be one we've never seen before and you have to derive the probably Mass function from scratch but ideally you can declare that it fits one of these narratives did somebody find a narrative that they thought fit nicely find the number of people you use model as a geometric okay I very much agree what's the probability of success on every trial you must give that to define a geometric okay its number of coin flips until you get your first head and we're just going to say you have a probably 0.2 of getting heads on every coin flip now as soon as you've done this then you can answer these questions what's the average number of people one will date What's that question asking saying what's the expectation of x and at this point you know it's a geometric and you can just look up the expectation of a geometric expectation of geometrics is going to be 1 over P so it's going to be one divided 0.25 fantastic so 1 divided by 0.2 and then the next question is what's the standard deviation so like what's the square roots of the variance of x and then again we can say you know what is the variance of a geometric random variable it's 1 minus p divided by P Squared and the standard deviation is just going to be the square root of that variance so did you have to derive that this is the equation for people that you date no you just recognize that this is another instance of the story we've already learned so fantastic the learning goal is really this then this then Define the question and then you'll be able to look up your equations let's take this for a spin okay another one that's worth thinking about this is actually an interesting one sent to me by a student who once took cs109 Justice Breyer who is a Stanford Alum was on the Supreme Court and they had this question about whether or not a jury selection was biased and how people chose the jury selection and particularly they were thinking about whether or not a minority group was represented enough on a jury so somebody was saying this jury was selected unfairly because of it was completely white and so that was what they were discussing and it was coming from a particular Community where they knew the demographics of the community Justice Breyer hypothesized a scenario involving um you know well a thousand balls 60 are blue and 940 are purple so that imagines the the demographics from which people were selecting a jury if you select 12 from this earn what is the probability of getting all of them being one particular color uh Justice Breyer then says something like you would expect something like a third to a half of all juries to have at least one minority person on them and they said looking at this uh particular region and looking at their history of juries they've been clearly choosing them in a biased way interesting Supreme Court involves the Stanford alumni and it involves some probability so I suppose my question for you guys is sorry he says something he invoked sorry I I didn't okay he invokes the binomial theorem he says in his defense he actually said this can be represented as a binomial random variable so can we do that can we represent the number of people on a jury who are coming from the minority population as being a binomial random variable so it's a x equals number of people from minority and he's claiming that or this is why Y is distributed as a binomial in a binomial people number of people on a jury in a binomial have to give an n and you have to give a p in this situation set up in front of you can you guys figure out what n is and what p is I'm just going to give you guys a hot minute to think about this think about it for a second and then we'll think about together okay hopefully thinking about this you understand that he's talking about the number of people on the jury so it's like you have 12 coin flips and he's saying every coin flip you have a certain probability of choosing somebody who's not from the white majority in this particular region so what's the probability here of getting somebody who I guess he has this story of uh a thousand and sixty are from a minority so the probability of any one person being chosen uh who is a minority is 60 over a thousand you can then ask the question what is the probability that y equals zero and I believe I wrote this up I love writing things up it's so fun when we get to do that oh my computer is being slow today not scrolling wow we're already onto machine learning that's exciting Cherry selection okay so I'm going to simulate this you know we're going to flip 12 coins and what's the probability that they all come back purple is the question that he's posing in his Supreme Court guess it's possible to come back all purple but uh it's certainly not that likely so this was the defense's argument you're like it's just like it just happened by chance we were choosing all these juries and they just always came back all white but then you can look at the distribution of their juries and it doesn't fit the distribution it should have been now this is the answer that uh Justice buyer talked about prob it's a binomial there's 12 coin flips every probability every coin flip has a 60 over a thousand chance of coming up as in his metaphor a blue coin and he says what's the probability of X being greater than one and you can solve that as 1 minus probably that X is zero and we can just use the prime minimum pmf and it says about 52 percent of juries should have at least one person who isn't from the majority class now if you just look at two juries it'd be really hard to talk about bias but they looked at all the distribute all the juries in history and they said it's way way less than 50 okay there you go there's a jury that's not all white and you imagine about 52 percent of juries would look like this so very interesting very interesting that he referred to the binomial distribution he was wrong with his probability he said a third to a half but really it should be over 50 which went you know like they got some bad math in a Supreme Court decision kills me okay yes question I'm so glad you asked that okay I'm gonna just pause and talk about that for a second the binomial distribution here is not a perfect story because in the binomial distribution every time you flip a coin you have exactly the same probability of getting heads and this isn't quite the case because after you've flipped a coin here you now only have 999 people to choose from this probability will change not very much because when you that dinar becomes 999 it won't be that different but it will change over time which breaks the Assumption the binomial so the binomial distribution is wrong but if you guys were curious one thing that we don't go deep into in cs109 is there's this other random variable called A hypergeometric and A hypergeometric allows for exactly this sort of change in probability where every time you pull a ball out of an urn your probability of pulling that color decreases slightly if you're really curious to learn about hypergeometric you would make my day and then you could go learn about a hypergeometric put in all the parameters from this problem you could get the hyper geometric probably Mass function and look at the answer you get using the correct random variable you get 0.5261 and using the binomial which is a slightly wrong wrong assumption you get 0.5241 what's the takeaway from you guys there binomial does assume probably stay constant so you were right in recognizing that this was violating it the next takeaway is if you violate that assumption just slightly you're going to do just fine um and then the third one that the world is filled to the brim with one around wonderful random variables and someone in this class may discover their own because maybe you'll be doing some research or starting a company and something interesting will come up and you're like huh no one's ever talked about this particular random variable and then you'll have your own and you can name it after me no I'm just joking you should you don't get to name it after yourself someone has to do that uh so like you would you wouldn't call it like I don't know maybe discovers one he wouldn't call it distribution someone else is like not that important geometric random variable because what is it's really it's not that related to the geometric right it seems like a hyper binomial would have been a much much better name and that I'm curious about too I'm gonna check us out and tell us why is it called the hypergeometric it's nothing to do with the geometric hypergeometric looks a lot like a binomial and basically nothing like a geometric so I these people should just name it after themselves so okay uh long story short you can declare a random variable if you declared a binomial random variable with these particular parameters you wouldn't just know the probability of getting a jury with zero people you would know the whole distribution so here's the problem zero here's probably getting one person probably getting two people probably getting three people you can certainly look at all the juries that have zero people and say that something's wrong but you could also use all this extra information that you have to go deeper if you're interested okay we got the demo I'm going to keep throwing problems at you so we can practice taking the real world and finding the random variables my next one comes from Bitcoin mining if you guys haven't heard of bit behind my I do not know where you've been living but maybe you don't know the algorithm for Bitcoin mining the way the Bitcoin mining works is they're going to give you this hashing algorithm called Shaw 256 and they're giving you a chunk of data and then you get to choose a bit string and when you put these two things through shot 256 it should give you a number back shot 256 is going to give you a number back that you should interpret as basically random zeros and ones but you win you mine a Bitcoin you get I don't know what that's worth twenty thousand dollars now I think you get like twenty thousand dollars if for a particular challenge you're able to produce uh assault that leads to a um a random looking series of bits that start with G zeros so if G was one you can imagine like every time you try a number you'd have a 50 chance of mining a Bitcoin but if G is larger you'll have a smaller probability and we're just going to think about that a little bit you might be able to solve some of these problems just straight but I do want to challenge you to think a little bit about random variables but sometimes you don't need a particular random variable sometimes you can just solve it straight real problem from a midterm in case you're curious okay the first one what's the probability that the first thing you try will produce a bit string which starts with G zeros so it's basically asking if you Generate random zeros and ones what's the chance that your random zeros and ones start with G zeros lots of ways approaching this one certainly you could do this one without a random variable but but just to show you what looking at the world like is like three random variables let's give it a shot in fact I'm not going to push you to too much to think about this one because I think a lot of you guys can just think about look at this and say the probability is one half to the power of G the chance that you produce a random bit string that starts with G zeros is a chance that you get a zero followed by a zero followed by a zero since each one's independent you can just imagine multiplying those probabilities but I did want to show you guys being super formal and finding this in terms of random variables so I'm going to say x is my number of zeros in the first G bits and in my world now every bit is a coin flip it could be a one it could be a zero X is going to be the number of zeros in the first few bits and therefore because it's the number of heads and coins or G coin flips it's going to be a binomial where n is going to be equal to G so the number experiments is given to us as this number G and the probability of getting a zero on every experiment is 0.5 and then this question is just asking what's the probability that the number of zeros in the first G bits is equal to zero and I can just use the binomial probability Mass function which leads to this thing that people could have derived without a random variable okay just a little bit of warm up how about this one this is one where it'd be super hard if you didn't know about random variables I'm going to give you guys a moment to think about what's the problem that you'll need under a hundred attempts to mine two Bitcoins this answer we're going to call probability a that's the probability of mining one Bitcoin on any attempt so it's like a slot machine every time you pull the slot machine this is the probability of you winning my question is what's the problem that you'll need less than 100 pulls to get two Bitcoins questions about what I'm asking every bit is going to be a zero one and you get a Bitcoin only the first G bits are all zeros why can't you just like enter here oh because you don't get to make the bit stream you get to like basically pull the shot 256 lever and it's going to give you back a bit stream equal to oh man I was just like I made this example I brought it into slides today and that should have said the probably that x equals g because if G is the number of zeros you want to have G zeros oh man and then I have to do all my math again but guess what this is not going to be G choose G and it's going to be one half to the power of G times one half to the power of zero this only works out if G choose G is equal to one but guess what if you have G items and I say choose G items how many ways can you do that yeah good times okay so that does that one that was a great question that was a typo on the slides this should have been equal to G question for you guys what's the problem you'll need under a hundred attempts to mine two Bitcoins I'm going to give you a whole whop in two minutes to thinking about this don't try and give me the number but try and do the process Define the random variable uh tell me what the questions asked in terms of random variable and then we'll just think what equation do we want to use okay go for it okay I want your guys's answer to start with this these three words you can choose why if you don't like X but I want to start with let X be and then I want to define something that the problem's asking about and it's asking you know um 100 attempts to mine two Bitcoins I want X to be some number that that question is referring to anyone who hasn't said anything they're like I want to share I want to tell the world yes be the number of Bitcoins behind versus 99 cents it was probably you need under oh that would definitely solve it oh my gosh that's such a good way okay X be the number of Bitcoins mine uh in the first you say a hundred what was your 100 or 99 at any times uh okay 99 number of Bitcoins mine in the first 99 steps this is interesting okay and then what's the problem what's the question asking like now let's write the problem the probably a question like is this asking the problem that X is the number of Bitcoins minus first nine nine steps is it probably that it's asking the probably that x equals greater than or equal to two okay you guys let's think about this for a second X is is a good answer slightly different than how I approach it but I think you might actually get to the same answer let's double check let X be the number of Bitcoins that you mine in your first 99 steps so you're saying I'm going to flip why not a hundred s under 100 okay so I'm going to flip 99 coins uh every coin has uh every coin has a probability of coming up heads of that we've got PA and you can say what's the problem that X is greater equal to so then you say x is a binomial like n equals 99 and P equals PA probably X is greater than two Bitcoins or two or more um exactly two Bitcoins yeah but if you find more than two Bitcoins in 99 attempts and that means you get to two Bitcoins before and I think I buy that so I I agree that has to be greater than because you could get more than two Bitcoins and you want to count that I buy that that works it's a different way than I thought about it but I actually do think this will get to the same answer did somebody have a different approach for this did you have a different random variable declared yes until two Bitcoins okay then what's the problem asking is asking the probability that X that X is less than 100. the x is less than 100 okay and then finally what is X the big reveal it's uh it is a negative two successes okay where R equals two and what does p equal I think it's one it's one half to the power G it's the thing we defined in in problem a this is how I approached it and then you can use probably that X is less than 100 you can just use the negative binomial equation uh and I think this also answers the question of why negative binomial gets its name because I do think that is this relationship that people are referring to in the name but I think these are two different solutions to the two different good solutions to this problem yes yeah okay um and and this should say two Bitcoins so I've typed over there um so let's talk about this your question is number of attempts until you get to two Bitcoins X can't be zero good point also X can't be one you can't have one trial uh technically this this is a more elegant solution but technically the probability of zero is zero and the probability of one is zero so you'd just be adding two zeros to this which would get you the same number but I think this is a much more elegant way of writing it good good shows them Insight yes because if the number of tries until you get two Bitcoins if you pull it once and you get two Bitcoins like what it's time to be alive just like retire from Stanford enjoy your new yacht okay why is the the why does the Sun go up to 100 instead of 99 sloppiness they let you become a professor even if you get off by once okay um and certainly I really appreciate so two different approaches totally fine and two very good ways of seeing a problem and recognizing the math behind it for the expanded answer for the binomial would it just be the sum of that after like when X is equal to two that's such a good question how would I actually do the next step here I wouldn't do the probably two plus three plus four plus five because that feels onerous I would do one minus the probability that x equals zero plus the probability that x equals one and it says the probably that X is greater than equal to two so these are the only two cases that don't count and this seems like less work to do but good question okay I was going to give a pedagogical pause this is your chance to like summarize what we learned about we have long lectures I want you guys to have a break so take a moment if you guys have questions please do ask me otherwise try and summarize we've talked about four new four random variables at this point try and see if you can get your head around what they all mean okay yeah okay do you guys like the pedagogical positive do you guys like having a moment just to relax in the middle lecture you're not okay yeah they're long lectures just so much probability to know uh we get to have a wonderful conversation right now we are at a beautiful point where I really think I could give you any discrete random variable and you could run with it you could probably read it use this probably Mass function and start to solve problems and you could really quickly go from knowing four discrete random variables to knowing hundreds you have the ability to learn new ones that's what really matters but you are missing something and it's that not everything in our world is discrete so if you're working on problem set two for example one of the things that you're doing is you do this estimating the location of a phone based on the distance to a cell phone tower I think that's the very last problem but that assumes that you can take a two-dimensional world and discretize it and think about all the locations as being discrete squares but we know that the real world is not discrete it's in fact continuous and be great if we can start to think about this continuous space and the simplest example I can give you of the world not being discreet is this very humble python function called random and it exists in every language random if you the base of a lot of random number generators is a continuous number between zero and one if you call random you might get 0.11234567 8 9 10 11. but there's a reason that this is so hard to reason about in these random variables like consider binomial you can ask what's the probability of getting a one back you can ask what's the problem of getting a two back but let's see if we can call random so I think math.random and I will make this much bigger you know if you were generating something with coin flips and you talked about number of Trials you could ask the question what's the probability that this would return us back a two if it's simulating the coin flips if this was simulating coin flips you could ask what's the problem give us back a three oh oh it's random random not random forgive me the problem when we get to the continuous world is this is certainly a random variable it's going to take on a value and it's going to take on a value you know with different probabilities but we it's hard to reason about what's the chance of getting exactly this number and especially if you allow this number to keep going to infinite precision I've become so painful to think what's the problem of getting exactly this number so even though continuous is at the end of the day not going to be too hard there's this one itch we have to scratch so let me give you another version of that same story let's say the average rate of earthquakes is one every 100 years using a poisson we already have the language to talk about the probability of different numbers of earthquakes in a year you can say what's the probability of two earthquakes in a year you can talk about the probably three earthquakes in the ear but our language breaks down when we start to talk about how long until the next earthquake like if you ask the question what's the probability that it's four days until the next earthquake this really awful bug shows up when you say four days do you mean four point zero zero zero zero zero zero zero zero zero zero zero zero zero zero zero zero zero zero zero days and if the earthquake shows up one billionth of a second later that doesn't count as being four days time when you think about amount of time until an event is continuous and it gets so hard to think about a probably Mass function in the continuous space now riding the bus is a fun thing I thought this would be a fun little ride to bring us from the discrete to The Continuous world and to really illuminate what I'm talking about we've thought about this problem while waiting for the Marguerite imagine you're running to the bus stop and you don't know when the next bus arrives you have a distribution of probabilities for when the Bus shows up you show up at 220 what's the probability that you wait less than five minutes so um I think you arrive sorry you arrive at two o'clock yeah 215. you arrive at 2 15. and you want to know what's the probability wait less than five minutes forgive me so if you arrive at 2 15 how do you think about the probability that the bus arrives at 217 and like infinite Precision seconds ah gets so hard to think about but here's a hackier thing we could do imagine this is two o'clock and this is 205 uh and this is 210 and everything here is a five minute chunk if you could represent time not as a continuous but time is broken up into five minute chunks then this problem becomes a lot easier to think about you know this is the probably that the Bus shows up between 2 and 205 205 and 210 210 and 215. uh if you show up at 2 15 the chance that you wait for less than five minutes is just going to be the probability that the Bus shows up in this five minutes section does that sound good but time isn't broke up into five minutes sections is it can we break it up a little bit more and start to reason about this probability if we made time a little bit more fine-grained okay let's break it up into time being 2.5 minute sections if you break time into 2.5 minute sections your belief of when the bus will show up it gets a little bit smoother and the width of every single belief becomes a little bit less because this here is representing you know between 15 minutes and 17.5 minutes and this is representing 17.5 and 20. this is discrete we can this is a sort of probability that we can absolutely reason about seems totally fine if you want to know probably wait five minutes you just add the probably that the Bus shows up in this 2.5 minutes to probably Bus shows up in this 2.5 minutes those of you guys who are fans of calculus might see where I'm going this like really to be honest with time we shouldn't allow time to be 2.5 minute sections we should make it smaller and then we should make it smaller and we should keep making our intervals of time smaller and smaller and smaller until they're infinitely small and if you did this you would basically have invented calculus again and you'd be particularly inventing this idea of integrals an area under the curve you know your buckets become smaller and smaller and smaller and your question no longer becomes the sum of the values of each of those buckets but rather it becomes the integral under this new curve that you've gotten as your buckets became infinitely small this area is called the integral and this new curve that you got when time became infinitely small is no longer a measure of probability but it's the derivative of probability and those words strike fear in some people's hearts but for other people you're like oh what a happy place it's going to be a happy place for all of us uh so as probability you know as our interval got smaller and smaller and smaller eventually you'd no longer have a problem you have how much is the probability changing when I take an infinitely small step in my x axis this leads to the most critical idea you need to understand to get continuous random variables and once you understand this idea the rest will come quite naturally but this is going to take a second to get used to when we talk about a continuous random variable like this one for example that can take on values with infinite precisions we can no longer ask the probability that the random variable takes on a precise number instead we represent our probably Mass function using this other thing called a probability density function the probably density function is the derivative and if you want to find a probability query you're not just going to be looking up from a probably Mass function instead you're going to be integrating under a probability density wow and it's going to be just fine uh I want to just go over notation really quickly this probability density this derivative is the thing that's the most important thing to know for a continuous random variable just like the pmf is the most important thing to know for a discrete random variable okay integrals you're going to have to do them but they're loving not scary and here's one of the ways I talk about integrals in cs109 you really know need to know the concept of integral you need to know when you need an integral there is wonderful calculators out there who can do the integrals for you you don't need to memorize all the integral equations you just need to get the concepts you have to get the concepts of a derivative and the concept of an integral that's what it looks like to be a modern mathematician integrals ask allow you to take a curve and answer the question what's the area under the curve so if this is your curve then integral under that curve between A and B will be written with that notation and it will represent what is the area under this curve if this is the integral then this line is the derivative of that same integral okay so if you ask the value of this line would be what is the rate of change of my area at exactly that point if this is a review for you I would recommend just go watch a Khan Academy video on integrals and you'll find it just understand what an integral is because you really want to understand what integral is coming into cs109 so back to this question my claim is if you really could represent a belief distribution about when the Bus shows up the best representation would be this derivative of probabilities that we call the probability density function and if somebody gave you that to answer this probably question we would just be finding the area under the curve between the values 15 and 20. this is a little abstract so we're going to make it a little bit more concrete by learning about two useful random variable types couple things to note to give us some intuition if you take a probably density function and you integrate between two points you're asking the question what's the problem that this random variable takes on a value between a and b and since that's a probability it should be a number between 0 and 1. also if you say this is the derivative of the chance that this continuous random variable takes on a value and you integrate from all the possible assignments from negative Infinity to Infinity that's like what's the chance that the Bus shows up between negative Infinity seconds and positive Infinity seconds you're like one I guess assuming that the bus ever shows up which maybe it won't but assuming that you're just talking about time until something happens it will be one so this is a question that I want you guys to all have baked in I'm going to ask it to you one other time in this class and when I ask you what do you get when you integrate over probably density function I want you guys to just yell out this a probability can we try it out what you get when you integrate over a probably density function oh fantastic okay so the probability density function isn't a probability itself is something that you can use to calculate a probability probably density functions they're the how probability is changing at a certain point in time it's the derivative so if it's flat that means you know the probability is just increasing the same amount of time as you increase more area into your query if it goes up versus it goes down which of these three do you think represents the belief that a bus is more likely to arrive close to 3 pm so this is 2 on the left hand side and this is 3 P.M on the right hand side so this is 2 p.m 3 P.M 2 pm 3 P.M which of these says the bus is more likely to show up at 3 pm I like shouting we're just gonna do a little bit more shouting can we all just Shout hey yeah in this one it says you know probably density is relative likelihood because the derivative tells you how much you'd be contributing to an area here the derivative is high over there and low over here and that means that this is relatively a more likely space this means any time is equally likely the bus could just as well show up at zero minutes at 60 minutes and this is a different distribution that says it's not equally likely it's way more likely to show up at say like 10 minutes and less likely to show up at other points in time so the main takeaway from this slide is that probably density function it's not a probability you'd have to integrate under it to get a probability but it is a relative expression of belief it does turn out that if you compare probably density is this meaningful and I will formalize that for you on Monday but I just want to point that out now okay probability density is not a probability rather it is the derivative of probability and therefore it has units of probability divided by units of X in our case this was time so if you look at the probability density at a certain point you might get that it's 0.05 and that would be like the units would be probability per minute it's not a probability itself you'd have to integrate it to get probabilities one Cheapo way to integrate is you just look up a value and you times by a width you get a rectangle and if you get a nice approximate rectangle then it's a fine approximation of your integral so if you look up one of these values multiply it by a width of say two minutes then you would get something that looks like an area under the curve and something that looks like a good approximation of a probability oh here is a wild thing which is totally possible here is a probably density function for when the Bus shows up what am I claiming here I'm claiming I am positive about the bus that's showing up here is not showing up here all of the probability area under the curve shows up in this point five minutes but as I mentioned f of x is not a probability it's rather the derivative of probability and I want to point out that that means that f of x can be a value greater than one our probabilities are greater than one are probably derivatives ever greater than one yeah yeah it's totally possible especially if like the width here is less than one that would allow the height to be something greater than one anyways another major takeaway is just that there's probably density is not a probability it's the derivative of probability at this point I hope you guys are feeling more comfortable with a probably Mass function it's the most important thing to know about a discrete random variable it relates values that your discrete random variable could take on with the probability that it takes on a value the analogous idea for a continuous random variable is not a probably Mass function it's a probability density function and it is the derivative of how probability is changing at a particular assignment because it's not a probability we use this little F to represent this probability density and it's the most important thing to know about continuous random variable this is like complete information about your discrete random variable and this is complete information about your continuous random variable and but they're both the representation of the relationship between values the random variable could take on and How likely it is to take on those values okay and you can read a little bit more about this definition I'm going to give you a problem it's actually a really cool physics problem but I'm just going to give it to you as a straight continuous random variable X is a continuous random variable and I'm going to give you the probability density function the probability density function for this continuous random variable has this beautiful equation which if you graphed it out looks like a semicircle I'm also going to run a simulation where I get a hundred thousand samples of X and I'm going to show you the histogram my question is how would you take this information and calculate the probability X is greater than zero and let me give you three ideas and hopefully this builds some intuition the first idea the one that I've been kind of hammering is that this is complete information because you can always integrate under it to get a probability so my first solution is you can say the probably that X is greater than zero is the area under the curve of the probability density function from 0 until Infinity but since it can't take on values greater than 100 it'll be the integral from 0 to 100. so you could just integrate this whole puppy and you'd be like I'm going to integrate you from 0 to 100 don't forget your DX over here and that's not wrong but while that is one approach I want to show you simultaneous approaches that maybe will give you some insight you could also look at all of my samples and you say how often were my samples greater than zero and if you did that instead of getting as integral from 0 to 100 you get a sum from 0 to 100 of my histogram that'll be approximation won't be as correct but it'll give you a number that's just about right and this is just for humor a third one is you can no semi-circles realize that this is defining a semicircle and knowing that the area on the right hand side has to be equal to the air on the left-hand side and you're just like well probably X is greater than zero is one half this is just supposed to be a toy problem to get practice with probably density functions if you guys are curious where this comes from it comes from quantum physics and there they consider random matrices and then every element in the random nature you can see is like background noise and they want to know what's the probability that if you chose an eigenvalue of that Matrix that would be greater than zero turns out that whole thing got rephrased to the random variable problem that we just solved but that's not that important right now I just thought it would be fun to share okay what do you get if you integrate over probably density function you guys got it that's awesome okay so now we have to learn two new random variables the uniform and then we're going to learn the exponential the uniform is the probability random variable for a number which is equally likely to take out a value between a lower bound and an upper bound so it has two parameters Alpha and beta Alpha is the smallest value you can take on beta is the largest value it can take on that random I showed you over here it's a uniform the lowest value can take on a zero and the highest value you can take on a zero the most important thing to know about a continuous random variable is it's probably density function which you can use to solve probability questions and it says how relatively likely is your random variable to take on some value Little X and for the uniform it's constant it's 1 divided by the size of the range so the max minus the Min in the case of the random I showed you this is just going to be 1 divided by 1 minus zero so it's saying the probability density is one in all locations and it's zero otherwise if you had to graph this out it would look like a flat line where below Alpha you can't get anything above beta you can't get anything and it's equally likely in between that area a couple properties you can know the expectation if you have a uniform you can know the variance so if you ask what's the variance of these numbers you got right here then I would just do 1 minus zero so that's one squared divided by 12. the variance of these numbers is 1 12. now you know okay so if this is my bus and my belief about when the Bus shows up is uniform in the range 0 to 30. then what is the probability of wait less than five minutes well I'm going to integrate from 15 to 20 that's my favorite range I care about over the probably density function the probability function is just going to be 1 divided by 30 minus 0. when I integrate this constant just becomes an X if you look at a wolf or malfo you're like what's this integral it would just give you that it's x divided by that constant and then I evaluate the range 20 to 15 and when you do that you get 5 over 30. which makes so much sense if it's equally likely at all points and you wait for five minutes it's equally like to show up at any time within 30 minutes then your probability of it showing up in those five minutes is 5 over 30. yes [Music] it is not it's a probably Mass function so the question is is this also a probability density function if not because it's actual probabilities and probably density functions they're going to look like this oh where their derivatives probabilities and notice how there is no gaps you know we're going to define the derivative probability at every single point whereas then probably Mass function there should be gaps it should be more like a bar chart you want to find the probability of something being less than five then also you kind of add up okay I'm with you so you're saying like you still do something similar to an integral if you want to know probably less than five you would add this to this to this to this this it's kind of like you're doing an integral and that's the Deep parallel yeah if you're doing the probability that the discrete random variables in a Range you're adding if you're probably continuous random variable range you're doing the continuous equivalent of adding which is integration yes foreign world in the continuous world only probably density functions good question okay I want to introduce you to one final random variable before we call this a day and it's the last one look at what a day we have had we're going to be learning about the exponential the exponential is a continuous friend of the poisson I think of them as best friends I think they grew up together they had such a good time together they're so similar in so many ways but they've got their own personalities so we're going to be thinking about an experiment that lasts a certain duration until you get a success an exponential random variable is going to be the time until a success and when you talk about the time until you get a success if you declare it to be an exponential you would write it like this you say the time until my success is distribution exponential and it takes a parameter Lambda why does it take a parameter Lambda that reminds me of the poisson poisson was you know the number of events in a fixed time frame when there's a poisson process exponential is also during that poisson process it's like those Uber drivers are showing up or those requests are showing up and this is the number of time until the next Quest shows up so if the poisson says you know you have fixed time how many events are you going to get in that fixed time the exponential says how long until your first event so if you declare something to be an exponential uh for example you have time until your next earthquake or time for requests to reach your web server or time until the end of a cell phone contract time until is the keyword for an exponential poisson was number of events in time and exponential is time until they're very good friends the probability density function is given by this beautiful equation Lambda times e to the power of negative Lambda X Lambda is the average number of events within one unit of time and if you were to draw it out it has this curve which exponentially decays and there's where its name exponential comes from you I'm going to give you the expectation and I'm going to give you the variance so as long as you can recognize something as an exponential you inherit all three of these things for free you're like I like free stuff awesome let's try this out at beginning class I said follow along and we'll be able to answer the question what's the chance that I'll be four years uh until the next big earthquake at Stanford here's the information I'm going to give you I'm going to give you Lambda it's the same Lambda as a poisson that's the average number of earthquakes per year the average number of earthquakes per year in California is 0.002 so 0.002 earthquakes per year and that's your average rate what's the probability of zero major earthquakes in the next year you could solve this using a poisson because of the zero um all right sorry yeah what's the probability of zero or that it takes a whole year until the the next earthquake but this you can also Express as an exponential and I would challenge you to try and express this as an exponential think about it I'm going to clear up the board though we're going to just look at the answer in a second okay if you wanted to make this an exponential you would say uh uh well you click okay sorry this is the poisson version you could say x is the number of major earthquakes next year you define as a plus sign you say what's the probability that X is zero you could use your probably Mass function what if I ask what's the probability of a major earthquake in the next 30 Years now you could set up a different poisson which are the number of earthquakes in 30 years or you could approach it as exponential a lot of times you'll have a choice between exponential poisson but a lot of problems naturally lend themselves to exponential better my question is what is the random variables here so probability of a major earthquake in the next 30 Years instead of talking about number of earthquakes in 30 years I'm going to let y be years until the next earthquake now the question is just asking what's the problem that X is less than 30 but because I Define it as how much time until the next event now why is an account of events instead of Y is time and in this case it perfectly fits the story of an exponential which is the time until an event so the time until event I'm declared as an exponential you have to give the rate of events per unit time and then you immediately inherit that the probability density is equal to that beautiful equation you could substitute in Lambda in which case the probability density function would be this beautiful equation and there's an e missing here though now what's the problem that Y is less than 30. that's all we have to do and up till now these questions have been just plug and chug but for a hot moment this won't be just plug and chug because is the probability density function a probability it's a derivative of probability if you wanted this one we have to solve this integral it's the integral and the range of the values we care about over the probability density function that gives you the probability that y will be in the range of 0 to 30. let's go there okay you need to know this integral review you need to go the integral of e to the power of c s is equal to 1 over c e to the power of c x e is such a beautiful thing to integrate in which case when you took this integral you would get uh you know Lambda times 1 over Lambda e to the negative Lambda um and you would inter evaluate this in the range 30 to 0. once you have the integral you just plug in 30 into this number subtract off plugging 0 into this number and you would get 0.06 . who looks forward to doing in an integral every time you have to do a continuous random variable problem well I was like yes awesome um okay um I just want to show you one mother question and then I'm going to show you a beautiful thing about exponentials that will make you tear up it's so beautiful why is the number of years until X earthquake um what if I change my question to the expected number of years until the next earthquake so now I have the same y it's still an exponential but I'm no longer asking what's the probability that you get an earthquake the next 30 year instead I'm asking what's the expected number of years in which case you would just use the expectation of this new random variable you just plug in that formula if I ask you the variance of years until the next earthquake you would just use the variance formula okay standard deviation yeah exactly you just say here's my exponential and I want the variance I get that and then a standard deviation is just going to be the square root I'm just looking up this formula like why do I know that this is the formula that's because if you look at your exponential that is the formula for the variance of an exponential now I want to leave you guys with hope so I want to talk about how you can solve these problems without integrals I'd like to introduce you to a great new friend who you can bring on your wonderful probability Journey with you welcome everybody to the cumulative density function it's not a probability uh it's not a probability density it's a cumulative density and it's not right in PDF it's written as a CDF and it's a special thing the CDF which we write as a capital f represents the probably the random variable is less than the input to the CDF so this is a function if you put in a 0.5 to this function it will return you what the probability that your random variable is less than 0.5 so it's a function that's where the F comes from and if you learn how to use a CDF you may never need to do an integral you may need to know what an integral is but you might not need to use it it has this shorthand I will often try and just write it using the normal notation okay it's a function you put in values and it gives you back probabilities particularly the probability that your random variable is less than that value here's the CDF of an exponential so it's got this nice closed form equation you could have derived it you could say I want to derive the probability that X is less than Little X you could start with the integral over your PDF in you know plug and chug and when you're done you'll have derived that the probability that X takes on the value less than Little X is this number but how could you use that let's try answering a few questions using both the PDF and the CDF so this is a plot of the CDF of my exponential and this is a plot of the PDF sorry it looks like there's a little slideshow decide to give me a little bit of excitement for a second there what if you want to ask the probably the x is less than two there's two ways of solving it you can solve it using the PDF and you can solve it using the CDF if you wanted to solve it using the PDF you'll do the thing that we've said like a hundred times in this lecture you would take the integral from 0 up to two under this curve you would use a integral but can you solve this just using the CDF recall that the CDF is defined to be the probability that X is less than whatever your input was what would you put as an input just yell at me yell at me confidently yeah it's two if you just put a 2 into the PDF you look up this value and it directly answers your question if you just put a 2 into the formula for the PDF of an exponential you would just have to put in Lambda and your 2 and you would get a number and you would get the same number regardless of how you solved it now obviously it's good for answering questions when of the form probably X is less than something but what if probably is greater than one again using the PDF we can calculate the integral calculate the integral from 1 to Infinity under that curve go or is there a way that we can use this beautiful friend the CDF to solve this problem one minus yeah if you just look up the value at one it'll give you the probably the x is less than one if you want the probably X is greater than one you just do one minus that value you're done and you didn't have to integral like look at this you're laughing you're having a good time the person is doing this tears the person using the PDF tears all the way and the person uses CDF just having a blast but then the PDF has their Revenge because obviously this question is easier to solve with a PDF the new question is what's the probably the random variables between one and two and here the PDF just like I'm going to integrate like I always do what does the CDF do an idea subtract subtraction you look up the value at 2 and you look up the value at one the value at 2 is the probability that X is less than two and the value one is probably the x is less than one if you take the probably that is less than two and subtract off the probably that's less than one it's like you're taking this integral and you're subtracting off this bit which just leaves you with the purple bit in the middle CDF can solve all of these probability questions which leads me to the final question of today what's the probability of a major earthquake in the next four years well it's an exponential but I'm going to use a CDF I'm just going to ask what's the probably this lesson four it's a CDF of four I'm just going to plug in this nice little equation and you get that there's a 0.008 probability of a major earthquake in California in the next four years I'm feeling lucky hope you guys are too that's the end of today's class have a fantastic week if you have more questions come ask me afterwards and see you guys back in class on Monday