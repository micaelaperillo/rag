good afternoon cs19 how are you guys doing today okay let's try how are you guys doing it's the end of the quarter we've made it in fact actually that is one of the things I want to say is at this point you guys have worked so hard to do those p sets the pets is the biggest chunk of work in CS 109 uh and you guys have done it so congratulations on making it through this wonderful milestone in CS 109 and if you're taking that uh grace period then I guess you're very close to being at that point and just imagine as soon as you hit submit I'm like you rock congratulations um another quick quick announcement do you guys know that today's the last class it's our finals lecture this is it and after this we go our ways of course we'll come back together for the final exam uh but but this is it for actually coming to Nvidia for lecture except there is an optional review session uh our wonderful head ta is going to be teaching review session it'll be uh this Friday Friday and we're going to use the same class time so that we can make sure that the recordings end up so even though this is the last regular cs19 if you showed up on Friday you would learn something cool or review something cool rather okay and today uh I have a nice little conversation about where do I think futures of probabilities could be going and what do I think could be relevant for you all what classes could you take afterwards and then just a little bit of reflection of where we've come from before we jump into that any questions about Logistics you guys found the place where the practice final exams and then on that note let's jump into things so you know where are we in class we're at this point where we have made it through all the different parts you know we started at the beginning with counting we went through probability fundamentals learned about single random variables got into problemistic models then got into uncertainty Theory before we built upon that foundation and talked about artificial intelligence if there was one takeaway from today sorry to interrupt you if there's one takeaway from today is I just want you guys to walk out feeling oh my gosh there's such an abundance of important problems that I can work on you know there's a a a whole world of wonderful things that we can do and this is just the beginning of your own journey and if I had to add another learning goal today it would just feeling that yeah actually I worked really hard in CS 109 and the person who works on these interesting problems could be me and I want you guys to all see that potential in yourselves so that's where we'd like to go I'm going to tell you a couple quick vignettes uh and one of the goals of this is just to give you a little bit of my story of how I got into research and working in my own little corner of probability Theory I also wanted to tell you that because I have a very interesting flavor of how I do research and it almost always starts with real word problems that I care about but then I still get to play in the world of computer science research I think a lot of people look at research and like oh if I want to contribute to human knowledge I just pick a problem like P versus NP and that I go sit and I work on it for a long time by the way you could do that if you solve it definitely call me uh first no I'm just joking but for me in reality it's actually looked quite different it often starts with hey there's this thing I really care about and if I solve this I think I could do something neat in the world oh no there's not a solution for it great I've learned these tools could I use these tools for this thing I care about I have a very short vignette to start with before we jump into a longer story I had this problem that started with the problem set app you know we have a bunch of people who are writing probability Solutions and to train Tas I wanted to say hey we've got 300 Solutions can you give me the 10 most representative so that the TA can just see classic examples different ways that people are approaching this problem so you know we could think of it like this you know you have 300 I didn't have time to draw 300 dots but imagine I drew 300 dots and the goal is just choose 10 of them that to be really formal I want the 10 that if you were to take the distance of every other assignment to its closest dot you'd minimize those distances the sum of those distances uh and one thing you're allowed to do is you can say for any two assignments tell me how similar they are we do have a function for that we can take two chunks of text and talk about how similar they are it's just doesn't always obey the the promise that that distance will be what we call ukan so if you want to know the distance of between two chunks of text you just kind of have to call this function does the problem make sense we went to go do this and it turns out to be an n s algorithm you know for 300 that's not so bad but sometimes we want to do the same thing for classes which have 10,000 students or code in place has 18 million students and we want to help them solve this same problem and 18 million squared was not a good time and we were thinking about okay can we just do this faster because we just want those 10 most represented things like must there be a a faster way I'm going to just choose one part of this problem and I want to talk about how CS 109 actually has the secret to how you could turn this from an N squ algorithm into o of n log n algorithm what insane okay so here's the the simpler version of this problem you don't need to choose the K centroid points just choose one choose the single point that's closest to all the other ones a single answer that's most representative of everyone in CS 109 and you know one of the ways you could do this is if you want to see if this is the closest point to every single one you can compare it to every other answer if you want to know if this is the closest to every other point you can compare it to every other answer uh that's going to be n squ but here's a really really cheeky simple little uh idea do you guys remember earlier in class when we talked about this problem of unknown drugs and that you want to both understand which one works well and you want to be most useful for people as you go did you know you could use that same algorithm in all sorts of wonderful places including if you want to figure out which assignment is closest to each other's think of it like this way every single candidate assignment could be thought of as one of your drugs wait that sounds wrong but you understand what I mean uh each of the solutions is a candidate for being the closest to everybody's but my claim is if you think problemistic you don't have to do all the work you can think about every time I do a comput ation it's like a trial it's like you're going to choose one of these candidates and you're going to experiment and instead of doing N squared experiments maybe if we think probabilistically we can get away with doing less so like maybe you've run two trials of this one four Trials of this one four Trials of this one and two trials of this one every time you run a trial you get two distances or a distance rather uh and after you've run those trials you can have a belief distribution about the average distance and after you got belief distribution let's say say this is your belief distribution for the average distance for this uh this potential candidate this potential candidate this potential candidate and this potential candidate now your task is well which one do you want to sample next and guess what you don't have to go through all n squ before you're like I definitely know it's not this one and I definitely know it's not this one maybe my next trial could be between these two and eventually the toms and sampling algorithm tells you yeah we're done here we don't really need to keep triing to figure out which one's the best now it seems like that would be something that would help but like maybe would get the wrong answer sometimes but it turns out like if you set your threshold to be like I want to be 99.9% confident that you're getting the right answer you can still get this n Square down into o of n log n how totally dorky is that which is like much more uh uh much more csy than a lot of my research but I don't know maybe I just wanted to tell you the story of like cared about this problem we learned about something in cs19 I happen to be teaching CS 109 when I was caring about this problem we just talked about about Thompson sampling um and there's all sorts of problems where just if you just use Thompson sampling it's better Thompson sampling falls under a bit Cate bigger category of multi-arm Bandits it's a very fancy way of talking about what we learned in cs19 but there's just all these algorithms where the inner loop would just be way better if you thought a little bit smarter under uncertainty why I think that's interesting to say because like hey you guys could have done this like if you'd seen this algorithm and You' just thought I wonder if we took some probability Theory this is totally in the realm of what somebody in CS 109 could do which is pretty cool and the other thing is do you guys ever feel like all the problems must be solved like everyone must have solved all the problems and we're just left with P versus NP and that's 100% not the case there's all these problems that people just don't know are out there uh and I just happen to Sol stumble into this one because we wanted to be clustering people's Solutions in the problem set up okay so I'd like to tell you some more vignettes uh and I'd tell you you a little bit about my research this seems like a good chance to tell you about some of the things that I do um and when I tell you about some of this research I want to talk about some of the themes that you might see showing up one of the themes you might see showing up is hey we talked a little about deep learning that was very exciting but I also want to think a little bit about the theme of probalistic modeling uh and then one of the themes in CS 109 that's kind of interesting is when do you represent things as single numbers and when do you represent things as random variables or if you want to use different terminologies distributions versus Point estimates you guys want to go on this little journey our last little journey well let's do it okay um and as I told you I'm going to now tell you maybe the the broader thrust of my research but you'll see that that little vignette I gave you is really emblematic of how I've found all these problems that I thought were interesting to work on that you could have found and you could do cool things too uh and a lot of it for me always starts with application and then ends up to some cool Theory thing there is one application I care so much about like if in my life I could move the needle a little bit in this application I'd feel so good and it's this quality education Gap that exists in our world you know there's all sorts of people who don't even get access to education but if you throw in like quality education the sorts of wonderful learning experiences that we've all had access to how great would it be if like everyone in the world could have as great an educational background if they so choose uh and you can tell that story in terms of like traditional statistics like who gets to go to university but you can also tell the story of like you know people who want to get retrained uh because they want to find new jobs uh and even specifically you could talk about the story within the world of computer science uh there's so many Learners out there who would love to get access to the ability to learn things there's all sorts of reasons to believe that we might be able to move the needle uh people have access to technology that didn't exist before uh as you may guess like you know certainly more than half of the world has access to a smartphone and that number is growing pretty quickly so as we have technology in people's hands can we actually move this needle we also have other reasons to be excited that maybe we'll be able to move it is the data we've got is pretty unprecedented um there is places like code.org where a bunch of people are learning to program and to give you a sense of that here's a little picture of all the K12 students so between kindergarten and Senior year students uh in high school or in in the United States and this is the fraction who have tried code.org a huge amount of people um and by the Numbers they've had 42 million unique enrolled students from 180 uh countries uh and they have half a billion hour of code sessions uh and a much smaller number of papers published with our lab but this is a very interesting amount of data like could we actually learn wonderful things about the learning process from this data I don't know but that would be pretty cool um and then the final reason to feel some hope is there's tools that exist now that didn't exist for the thousands of years that people have cared about education well maybe they cared for it about it for even 2,000 years uh but in those years they did not have access to some of the things we have like you know when I was your age speech recognition wasn't possible I was told it was an unsolvable problem I wouldn't see the solution in my academic Lifetime and now we have it all in our phones uh so we have this very wonderful intersection we've still have the clear societal need we have all sorts of new data sets uh and we have this this Renaissance of great ideas and new tools that exist there and my hope is that somewhere in this mix we'll actually be able to move the needle that would be so neat there is one problem that's been pretty sticky for me you I've been a teacher for a long time I was also a ta uh my parents are teachers man like education is like the family business I suppose and it hang out with teachers enough and they'll start complaining about grading because it's a lot of work and one of the ways of telling the stories of how maybe we could make a small Improvement on high quality education maybe we could help teachers by improving our assistance when they're trying to give feedback feedback is important but it's very very labor intensive we could talk about this story of let's give feedback in lots of different domains maybe it's middle school math maybe it's people learning how to program maybe it's people who learning how to program cool things like pyramids um this is really random but the US government publishes all the immigration tests which is very very strange but you know it's public data so it could be like people trying to uh pass the US citizenship test um or maybe it's like somebody who's just doing some open play in all these domains students produce wonderful work but it's easy to produce that work and hard for teachers to give feedback chapter zero in our story is going to be like oh man when I was a PhD student and I was just starting simple uh we I you know I found a friend who worked at this startup at the time called Con Academy and he said they have this problem they see students but they based on their history they'd like to be able to understand the students better but they said they had trouble doing this so they gave us a big data set we're like okay can we try and understand people a little bit better so we would take their past we built a little bit of a machine learning model and we' try and predict their future we built a model that got pretty good at this it's an old problem hey this is me when I was a baby and this is when the problem was first posed people have been thinking about it for a long time but since I had access to these new deep learning tools we could do a really cool job of modeling it we built a big neural network first one for education and it worked pretty well we were able to predict uh student Futures you want to be high on this graph uh way better than their baseline or even kind of the the Forefront of what people were doing at that time we then took our model we're like hey can you tell us about 8th grade math and it figure out all these cool things it said here's how eth grade math is uh set up this is like you have to figure out how to solve the x axis of an equation before you can figure out solving y but the slope is the center point of all these Concepts uh and is a good time and then we started to do cool things like can we do optimal teaching and by Optimal teaching I'm like can we figure out exactly what you know and what you need to learn next so like based on your past I'm like you definitely need to work on uh figuring out square roots uh and there's reason to believe that if you could understand students and you can make good decisions under uncertainty for students we could get people to know more faster and this was fine but it's chapter zero for a reason I have a baby now I didn't at the time but at the time I could imagine having a baby and I thought when I do have a baby and she leaves in the future of Education I don't want her to solve just simple correct or incorrect problems uh and that is exciting you know I want her to be doing more open-ended work I want her to be engaging with exciting thought-provoking problems not just you know solve this uh multiple choice question now while that's what I want it turns out it's a lot harder to be able to understand students in open-ended domains like for example you'd imagine coding when you're writing a few lines of code it can't be that hard to give feedback but it turns out it's tragically hard and if you go to some of the like the best coding learning experience online um they'll tell you things like uh all they can tell you is you're missing a line that I know is in the solution and it's just not the sort of deep feedback that we want so we're like okay let's work on that problem and to pose a little formally the problem looks like this imagine you have a task of students working on imagine you have the student's work itself can you fill in a rubric and that rubric is a bunch of bullying decisions about what feedback to give the student I was like okay that sounds fun let's jump in it uh we had a bunch of Stanford Tas label this for a whole a whole bunch of submissions uh from 106a and code in place we learned a bunch of things from looking at this problem first of all can't we just use some core conditional probabilities turns out you can but you know this F1 score which is a measure of how well you're doing you don't get that much lift on F1 score this is what humans look on that measure of how good you are at filling these rubrics humans are great and conditional probability is just not that good good well deep learning is just got to be the solution to everything right so we have all this data from code.org can we just use some deep learning I also wondered can we use some Dynamic analysis you know actually one of the fun little sites we went on to is how creative can we get what if we didn't just look at the code what if we looked at something more interesting do you guys want to just have a Moment of Zen and appreciate half a million people learning to code their very first program prog and watch it visualized uh in this graph can you guys see this can you see there's a pink dot okay that pink dot is students and see that big circle the big circle means half a million students all these pink dot students are starting with blank code and they're trying to write a feline program here is the solution so you can imagine they're trying to get to that bottom right corner uh can you guys see these little black dots maybe not can you yes it's like the distribution of yeses goes from pretty high to like a little bit um anyways there's these black dots which are intermediate work let's watch them go this is a dance of half a million people trying to write a FIV line program most people do pretty similar thing first but then you have the first splits and this big groups kind of making a good progression but like uhoh those guys are going the wrong way and the people go the wrong way are very likely to then go even more wrong ways now at this point we've got our first group of students making it Yay good job you solved the problem um but then you're you're left with you know couple hundred million people who are still trying to write that five line program there's a bunch of things to take away from this certainly the observation that people who make mistakes are more likely to make more and more mistakes and the other thing is a moment of appreciation can you appreciate that struggle and that grit like some people in this data SP spent more than 12 active hours of work just trying to write a FIV line program the feline program I will tell you has no Loops is move turn left move turn right move that is hard for people and they did not give up like so yes respect to you guys all of you guys have our total respect and these people these people are like I've been working on this feline program for like three hours and I just made it like little tears are welling up in their eyes and they're feeling like I can do it but maybe there's something in this process of how people solve the problems that can help us out so we can jump into this we can can say we can jump into every single student who's written move move turn left and maybe there's some temporal Dynamics for students who have written that program that tells us what they should do next so can you guys give some feedback here student has written move move uhoh that second move crashes turn left what would you want them to do next would you want them to do move turn left turn the T nothing to a turn right or add another move forward afterwards who wants this one yeah that's like the nice teacher of us who wants this one some people just want to watch the world burn so we kind of have this idea that yeah yeah they should they have a bug they should get rid of the bug if you look at what people like we have you know millions of people who have made this exact mistake most people who make this mistake go on to try this next so it turns out the crowd's a little bit unwise so if we want to get into probability we have to think a little bit more deep than just can we use conditional probabilities one of the things we thought about at the time was like well traditional conditional probability asks condition on somebody making this mistake what do they do next but I don't want to condition on condition on them making the mistake because that's all the people who are having misconceptions I would like to be able to ask a conditional question conditioned on the average student and So based on that we came up with this idea of like how could we model what the average student does we said well for the average student you can imagine all the submissions coming at you as a pan process from how appealing it is to the average student and based on this we could say like the expectation of the length of their path will be the sum of one of the expectation of their pan and so you end up with this like pan minimal path that could give you an idea of what the average student would do next from a current state it for any state you can ask what is the pan minimal path next and it gave this really nice problem solving pa uh path and it worked so well for six line programs like with this really cool probability Theory it was really neat we got to title something the paston common path which felt badass what a flex uh but it didn't work really well for problems after six um okay so now it's time to go back to the drawing board at this point I had convinced my PD adviser that deep learning was not a fad and like he finally gave me the green light to go try this deep learning thing and we tried the Deep learning thing tldr it didn't work but we did try a whole bunch of really cool things first we started a regular neural network didn't work then we're like no our neural network needs to be way fancier so we made hierarchal St neural networks we'd take code put it as a tree and we had tree-shaped neural network so you have like a neural network for each node and they would merge together into a new naral network for like the compound node it was so cool but didn't work that well so then we tried this other thing we're like Wella what if we got Triplets of code like I can take all of 106a and I can I can mine oh millions and millions of these triplets where you have the precondition the code and the post condition itself I got lots and lots of these and I'm going to make a neural network that can take a preconditioned code and predict the postc condition is going to be fantastic seemed like a really good idea so we would take a neural network which would encode the precondition uh put it through a neural networks which would translate into encoded post condition then decode it and then it would give us the post condition and we trained this and it felt awesome and we managed to P write a paper but it was basically useless going back to this chart of like how we're doing at grading all of this effort and we made some progress but it just was very far shy Far Cry for humans I went to Percy leang I'm like Percy you know all the neural networks what can we do here and we worked together and we tried to figure out and we still couldn't make progress so you know there's another problem here we wanted to be able to give this feedback but for most teachers you don't even get to look at a huge labeled data set you kind of have to give feedback for the very first time you give the assignment so you really want what we call One-Shot learning like as soon as you give an assignment the first student to hand it back to you you should be able to grade so uh we needed that and we need to be able to verify like deep learning is really cute and it just makes predictions but you guys have been writing problems at six like would you trust all these predictions like I don't know like I don't know why I should trust these things they're giving me probabilities but it could be making mistakes it's not verifiable you can't prove for sure that someone's deserving the grade that they got so we went back to the world of probability we tried to understand why is this problem so hard do you guys want to know the cool thing we discovered all of student work follows the same probably distribution not just some of it not just code not just essays not just poems not just partial Solutions all of it falls the same probably distribution called a zifan distribution and what that means zian distributions on the ranking like the the prop the popularity of like the most common solution and the popularity of the second most common solution so if you take the most common solution this is how probable it is if you take the second most common solution this is how probable it is and every single educational data set that I ever got my hands on when I looked at the log of the rank and the log of the probabilities you always saw the straight line which led to this probability density function which comes from zif distribution whoa that's cool it's like the fattest tail distribution you can ever imagine by fat tail distribution I mean like there's a lot of probability far away from the mean so this is the most probable solution it has a probably like this if I didn't do in log log space you know what this thing looks like it just goes on forever this tail is incredibly large and it just basically says yeah the the most common solution is probable and everything else looks incredibly unlikely and you guys know this is like the the this maybe there's one solution that lots of people come up with but as soon as you're doing something other than the solution you're in that really really really long tail uh uh so that makes it a hard problem and there's also this other problem is you know when we cluster Solutions there is this sharpness which is like two solutions could be really really similar in how they look in their text but mean really really different things like you might just be a couple characters way from the right answer and there's a big difference between those two things so for those two reasons it's hard oh long story short yeah they're all as if want to learn more about it talk to this guy Okay so are we just done no back to the drawing board don't give up we really want to be able to make progress on this problem I was inspired by this paper there was this wonderful paper I told you guys about in the very first class and the reason I told you about is because it was so inspirational to me the inspirational idea was there's this algorithm that can learn from a single example most deep learning you show it 100,000 examples and then it can learn a symbol but this one the very first time you showed a symbol it could learn to recognize other instances of that symbol wow how amazing it did not just for symbols but also for object recognitions it could do all these onot learning problems uh and this is how it worked they did not use deep learning they used beian models instead and the idea was they took a lot of examples of characters and they Ed it to algorithmically create a basian program you know like one of our Bay Nets and the bayet would describe the generative story of where characters came from it's like hey you want to know where this comes from pal well it starts with some primitive shapes those get put together into subp Parts those subp parts get connected and there's some random variable controlling the connection each of these things is defined you know the probability conditioned on its parents just like in our BAS Nets and they would have Productions at the end that would actually be characters and then if you wanted to take a character and predict they would infer into the baset using some pretty reasonable inference techniques not too different from what we did okay I'm going to skip some of these things oh there is some neatness to this not only could you predict but you could also generate you can say like give me more examples of this and the very poor handwriting algorithm would give you more examples so it could do more than just prediction which I also thought was quite cool but really the big takeaway was this they had people try and do the classification task and people are awesome in this case you want to be low in error rate people did a really great job deep learning was doing an okay job and some of the most modern models were being pretty effective but this beijan network did way better than the Deep learning and even did better than humans which is very very impressive on this task and I read this and I was a little jealous happened but I was also a little bit inspired I was like what if we made a beig network of how humans think about their 10line programs and so we did and here's the really interesting insight about a beijan network if I could put into the language that we've learned here's what grading is written as a probabilistic inference task you have a couple random variables one thing you have a random variable for is the code itself so let's say this is representing the code and over here you're trying to predict like maybe their ability and maybe the choices that they made when they were writing this code because if I can look at your code and and guess the choices you made I can give feedback on the choices be like oh yeah that choice to use recursion bad call um and you know maybe at the end of the day if I'm doing grading I might want to get a score out of this and it just turns out this is a very hard probability problem to solve even for humans I see your code and I have to infer choices that is very difficult but the Insight that really came from this paper is that the reverse conditional probability is a lot easier for humans if I tell you here's all the choices somebody has made what could their code look like that is the reverse condition and that is pretty reasonable for humans so uh in this case you know we have the student ability um we have their choices and you have a resulting python code and we made a generative model which says Okay first choose a student ability then based on the ability make some choices like have them walk through the assignment and make some decisions do you do recursion hopefully not but we're going to make some choices for them and then the task was can I write a program that would say what could code look like given those choices and then the simple idea is what if we made a nice little interface so that teachers could write this program so they could say okay in my assignment here's the choices I think students will make and maybe I could write in a way that we can explore the exponential number of choices that they can make and maybe could write in a way that I could describe based on their choices what their output could look like wrote this nice little Library it was called idea to text and you would write each choice as a Class come talk to me if you want to know the details uh but it kind of looked like this we would say here's the decision-making process and every time you make a decision we'll be outputting code that the student could be writing and so after you're done with the decision-making process you've got both their choice of decisions and their solution this code was generative do you remember when we wrote Bas Nets and we hit a program and you would start to see samples a bunch of fake students I had the same thing once we'd written this you know slightly more complicated basian Network we'd hit run and we start popping out madeup students be like here's a madeup student it made some madeup choices and here's the corresponding code and we could run it not one time not 10 times not a million times but a billion times you know students and teachers had not too much trouble describing this generative decision-making process and then we could have a fake data set with billions of students without even having to wait for the first student to show up um and then you know the idea was we did some sort of beian decision-making process or sorry independent thing where you'd say I'm going to make my next choice I'm going be as independent of previous choices as possible um you know come talk to me if you're curious about the details but it was really that we just had a crazy way for people to write the conditional likelihood in One Direction then we did Bas theem to figure out what choices uh a new student had made uh and we got to the point where we can for some code outperform humans which was crazy to me I thought we had given up on this project but um you know the student who led this thing got paper W it was a good time uh and it turns out at this point we're just like having a party cuz we're like we've got this cool little beijan code and we're going to use it on all your homeworks uh you know we did intro maath and stuff like that and it it was working pretty well and this is actually where I got to know that was such a good time man what a party we had in 2019 um now I will note that of course this does hit a a ceiling um didn't work for things Beyond 106a but before we get to that uh you know there's a couple things that we got to do along the way that was quite neat like you could take students who are learning how to draw a pyramid and you could break down their process and so instead of just giving feedback to students on their final solution we could look at how each student got from their empty code to the the final solution we could be like okay this student was at stage one for a long time and then finally jumped to the answer whereas this student you know went back and forth between stages and took a long time to get to the answer um and you know we could tell teachers hey your students here's where they're all stuck on as they're trying to solve problems once we had some data and then finally this is one of the dreams that we're still working on is to actually be able to provide nice feedback to student saying like yes the pr set app says you got the question right but let's talk about your process of how you got to that answer and how can I help you learn a better process so that you're better are able to solve future problems so this is a dream and we're still working on it uh but you know when we were able to give people feedback on their process boy did we see a huge Improvement in both how long they would take but also in exam scores so there's reason to believe if you could pull this off which I have not been able to do so far uh in more complicated assignments we could really really improve learning which was remember the original goal so feedback on process can you guys solve it please call me first no I just go don't have to call me first if you solve let just go tell the world call the New York Times first um now at this point we were having a good time but we still knew that there was this one challenge which we were kind of sucked at which is in CS 106a we would give a midterm and the midterm at this time was something that you didn't have access to a compiler to I think that's still the case yeah you don't have a compiler on your 1 16a midterm which means that people write code but it looks a little bit more like pseudo code it's kind of like in cs19 when we ask for code on midterm like that code doesn't run uh and we're still giving you a good feedback based on that and we really had trouble giving feedback on 106a midterms and to give you an idea of what it looks like to Greater 16a midterm you have like the question that they solve the code that they wrote and a rubric and it's just the code doesn't run but it turns out we managed to pull this off and this time we didn't get into the New York Times and the idea was you know on this task humans are again quite good not perfect though we know that regrade request wof uh but deep learning at this point really wasn't helping even deep learning from 2020 when we applied all our cool basian things wasn't getting us very far when you got to this level of complexity and so we're like can't give up just got to try something new and I guess that's part of it we just never stop trying things uh and the good idea here is why grade one exam when you could grade all the exams we always tried to solve one problem at a time we'd be like we're going to take this one problem we've got 700 Solutions let's do just try and make a model just for this problem that's point we're like that's not enough let's try and write something that can generally solve grading for any problem which sounds harder but it turns out by doing this harder thing it actually became easier so we built a grading system which took in three inputs okay give me the student answer obviously I'm grading that but tell me which question they were grading and tell me the rubric you want me to fill in and then I'll make my decisions I'll understand the student and then I'll make my decisions based off of that and boy did we write a neural network it was like the heftiest little neural network ever cuz that neural network is taking in like over here it's got the question embedding so we'd take the question like write a Python program some questions are easier than others we'd put it through a neural network which ended up with a set of neurons which we call a vector we took the rubric which is like uses proper syntax put that through its own neural network which ended up with a set of activated neurons took both of those things and combined it with this other neur Network that's kind of the same stru this is the same structure as what GPT does obviously not like GPT chat in terms of its capacity because it don't have a billion dollars of training but we use the same architecture cute um and we take the student solution sequence and you put those three vectors together to try and end up with a prediction for how the student would do on this rubric and it worked and we gave it to students and code in place we're like there's a lot of you and we're like hey who wants to take a cs1 6A midterm and like 4,000 of are like sure it's not for grade so like a lot of people are like no I don't want to take a midterm but 4,000 are like yeah I want to take a midterm we're like we can't grade you they're like that's fine we'll just take the midterm anyway so they did the midterm uh this is the people who took the midterm and then we're like hey surprise we could give you feedback but a lot of that feedback is going to come from an AI but some of it will come from a human uh and so he gave feedback to 3,500 students 10% came from humans 90% came from AI we didn't tell them what the feedback came from they we just to be like here's your code here's the feedback that we came up with by the way we just predicted a rubric and then we wrote really fancy text to go with the rubrics and then we did a little bit of cute derivatives we said what is the derivative of your change in your belief of this conditioned on each character and then we could highlight that this is what led to my prediction and we gave it to students and we let them do a thumbs up was this helpful or a thumbs down no it wasn't helpful uh and student students agreed with AI feedback slightly more with the human feedback we didn't just ask students we also asked teachers we did all of our fairness analysis to make sure it worked for different uh demographics uh and yeah it was a good time what a Vibe um okay and we think it it it nicely we didn't have to get too deep into ethics because it seems the model both satisfied um parody as well as calibration which was lucky it didn't mean we had to make a hard tradeoff okay and that's just one example in my world like boy that took like a decade of trying things and getting things wrong but that is just one of the many problems like when I went through this DEC I'm like there's open problems everywhere I think one of the great ones is feedback for teachers so many people are teaching and we're not getting feedback on what is working it's not working but for example Chile and Colombia they both have the system of they have recordings for all of their teachers and they just want to be able to take the recording and give that teacher some automatic feedback um so there's an interesting open problem an interesting problem that we're still working on that we think is really cool is taking transcripts uh and giving feedback to teachers so again in code in place people taught in small groups of 10 and we had 5,000 transcripts of teaching sessions and we're like can we give some feedback to these teachers I was like yeah we did we we did some statistical analysis found times when teachers took up student ideas we found times when people did questions um gave some feedback to teachers and then the teachers who got feed feedback asked more questions and took up student ideas more the students who are the recipients of this teacher feedback recommended the class more and found section more helpful which is a good vibe uh one of the problems that we still find interesting is what if people did really exciting programs like what if they were creative like we didn't tell them we just said like make a cool game and then they made a cool game and now we have to give them feedback you're like my grents are like Chris why are you doing this to me can't we keep life simple I'm like no life is complicated and messy let's go enjoy uh so we're building this algorithm that can learn to play students work to try and separate the difference between this is wrong and doesn't show programming Knowledge from that was super creative and it did something that we've never seen before uh which has been a good time and we keep writing papers about it though that's not yet it's it's almost at the point where we can put in production and we might try it this spring but not sure yet um more than education I think uh one of the folks that we have started talking to recently is the FDA cuz they're approving drugs and you know that problem we talked about earlier they're still trying to figure out how they can do their drug approval process in a more humane way in a way that's more appropriate and there's a bunch of reasons that they don't do it so well right now one is because they don't use probabilistic sampling like come on guys Thompson sampling has been an algorithm for like 30 years now popular for the last 10 at least but the other reason that's really complicated I don't know if you guys know this but when they do their testing they don't do it on random samples of people a lot of drugs are tested on one demographic more than another and an easy one to point to is very few drugs are tested on women of the age where they could possibly be be pregnant because no one wanted to take on that risk and so a lot of these drugs have not been tested on a full population and so they make really bad predictions then in efficacy because sometimes there are differences uh and so trying to help them think through the probabilities has been some interesting ongoing conversation we've already talked about eye test enough but the eye test was interesting just let me tell you one thing about it was like what really was the ey test about it was basically just looking at this being and be like dude that should be a random variable like you're telling my vision as a number but it should be a random variable like that's basically the IB and so maybe if you guys were to think about getting into research maybe that's a nice way to start like I just feel like I walk around the world and everybody's just using numbers when they should be random using random variables and maybe you'll walk around the world be like I'm pretty sure that's a random variable and not a number and maybe that could be a start of a cool little investigation for your guys self uh oh I forgot I wrote this up there yeah definitely Chris I completely agreed no one's done that though uh so okay um you know there's a lot of things that AI can't do uh can't understand Lang well wof social science you can't really do a good job of I can't explain why it made the choices it do it's still struggling to teach humans like even GPT chat like it's very effect like quite interesting but it's not exactly pedagogically inspired there's a whole bunch of things that AI can't do that maybe you could do if you want to apply yourself so what should you guys do next like kind of the point of that story was to talk about you guys not talk about me and I really want you to feel you have the permission to go amongst the world and get amongst the abundance of open wonderful problems out there I think we're all in a little quest to find the problems and the causes we care about I happen to find education as my cause and within the cause of Education I've saw that there's abundance of wonderful problems out there you guys will have your own causes and your own things that you're interested in and I wish you just all the best on this wonderful journey to choose those problems cuz they're all out there they're like hidden under the stones sometimes you look at the world and you're like everything's been solved but then you just take a second to stop and look around you're like no there's so many ways that we can do so much better in the Society of ours now one of the ways is just to go out there and get amongst it some of you guys have started that with a challenge project sometimes you're already on this path to discovery of a problem that calls to you and also other things you can do is take classes cuz that's always a good vibe too and maybe in the classes you'll intersect with new ideas uh that will give you inspiration for your cause and your problems a couple ones I want to point out that you might find interesting you know this class do exist one as an undergraduate it's called decision- making under uncertainty and it is a grad level class but it's kind of like the intellectual next step for CS 109 I've talk to people who' have taken it and they're like this is so fun and you maybe you want to wait till you've got enough maturity to take a grad level class but you certainly after 109 will have the mathematical foundations uh for this class and it's really wonderful one of the things I'd point out about this class and others is that it has this great final project and they give you a whole chunk of the quarter and say okay take an instance where you try out working on a problem and cause that you care about make into a final project and that's so wonderful and you'll get ta support for that you can also take cs221 or cs229 those are kind of the artificial intelligence next steps 221 is technically called artificial intelligence 229 is called machine learning what's the difference these days I guess in like 229 you're not allowed to use a bayet but in 221 you are well I don't know I guess they are very very similar these days but you know 221 you'll talk about more things uh it's a slightly bigger introduction to artificial intelligence but they also I think they're very similar classes they also have this property where the last half of the classes you guessed it choose a project that you find inspiring and work on it so if you took these three classes you've had three instances of trying a problem and finding one that might speak to you now maybe after all that you're like I I want to keep going oh my God there's this class 228 called problemistic graphical models and they will teach you the future ban networks and the future ban networks is wild it's like we can combine deep learning and beijan networks and we can learn structures and do all these Wild Things uh and it is a class I did take and I would say in my life I've never taken a class that was so hard but also I have never taken a class that I learned so much from and actually I'll be honest I stumbled through it at some point I was just like I don't know tired that quarter I took too many units and like at the end I was like oh my gosh and then later I got to my PhD somehow managed to like you know ignore that one class that didn't go so well got into the PHD and immediately started working on stuff that required that class and I'm like oh God so so then I learned it at that point I was like I needed it so then I I went back and I I hope that's not everyone for CS 109 but like maybe one day you'll need it you'll go find that corser like oh oh I get you Thompson sampling anyways um and then certainly if you're just like all these classes have the component where they're both programming and math and I think the programming is a good way to solidify the math you're learning but if you just want to go down pure math there is a pure math path for you it's called stats 200 uh and you get to continue this wonderful process of learning the math in CS 109 uh in in the more pure math Direction what a cool place to be now courses are a cool way to get inspired because I think one of the things that you learn when you have a course is you build your tool set but if there was a takeaway for your future I would talk about intersectionality it's like I happened to do my first research project when I was in 221 I I've done projects before and they all totally like fizzled out but the 221 project totally stuck and it became my first research project so these classes will give you space and they'll give you techniques but the other thing that I would encourage you to work on and and that's kind of this quadrant between now and then is to focus on these other ways that you can find your own little Nook I love this about the world we all have different lived experiences and you know what that means that means you have different insights into pain points in the world than the person next to you we've all seen different things we know where the world could be better and that means you have knowledge of problems that I don't have knowledge of problems and that's wonderful because maybe that's where you'll find the intersection that speaks the most to you in addition to your lived experiences we all have different passions you know like I care about education but I also care about I don't know guitar and uh and frisbee but maybe your passions bring you elsewhere maybe I definitely talk to somebody like I'm So Into ballet choreography and ballet choreography like I want to explore this world problemistic I'm like wow crazy cool so wonderful so you know you've got your lived experience you've got your passion sometimes data can be quite interesting and helpful so maybe you've worked a job um that gave you access to some data set that's interesting and explore all these things and keep looking for intersections where you know when you put a couple of these things together it's like I went to Stanford I learned this tool I have this leave experiment that tells me about this problem and because I worked as an internship that worked on that problem I have access to a data set you might find yourself in an intersection where there's nobody and there's not prior work and that's hard because you're going to have to do something that no one's done before but maybe that's how you get your first step into this wonderful world of research okay that's what I've got you know I I just I love it and you don't have to all do research but I just want you get that feeling of you're closer than you've ever been in your life to that that Frontier of what humans know and that Frontier has more space to take classes but there's also parts of this manifold where you might be able to take that step across the frontier and you're closer than you possibly might imagine the other thing I wanted to do today is it's our last class I was thinking about that I'm going to miss you guys you've been a wonderful class my God I don't think there's ever been a class that's asked more questions in my 10 years of teaching you guys ask so many questions you engaged you worked hard it I will miss you guys all this has been one of the special CS 109s for me and so I did want to take a moment and reflect on where we've gone and how we got here we know about our journey but do you guys remember the very beginning you like came to class oh man and I was like we're going to learn counting and that's where we started and we learn counting and not just you know 1 to 10 but even more we learn sorting combinations uh putting things in buckets we learned all these different rules and Counting was hard um but you know even though you guys were engaging in a very hard thing we're trying to also build a course Community a course Community we like you know we appreciate that we're all people and we're all just trying to do the best we can this was for me really the first quarter that wasn't defined by Co which kind of makes it defined by Co by being the first qu after ago but you know this was a first time of coming together co-president after this crazy thing that we live through um and you guys were both doing this hard thing of learning counting and also this very important work of rebuilding Community uh and part of the rebuilding community that we engaged with was we did that Serendipity problem where you figured out the probability of running to a person we did some cool things we made history class you guys remember I brought in a deck of card and we did something that no one ever done before cuz I shuffled it seven times and shuffling it seven times gives order that we're pretty sure has never ever been seen in the history of world that happened in class and at this point you're ready to learn what a probability was we've just been counting and then you're ready you can learn probabilities and then you know probabilities were exciting but what was really exciting was conditional probability because then you could infer ideas based on evidence you collected um did some cool things played some Monty Hall did some prediction of a zika test did some B theorem where we said okay based off of a medical test result uh we can figure out what your problem is at in your problem set you wrote a general solution to this which is something quite new for CS 109 historically in CS 109 I'd make people solve single instances of Bas theorem but in this class I made you write the code for the general solution I give you like any medical test with its probabilities and you had to figure out for any medical test what was the probability that somebody had disease W that's hard but that's more General and I hope it would my my theory was that by writing the more General thing that you guys would understand this more than any previous 109 and then we bummed it up a notch we're like why do Bas theem with only two outcomes when you can do Bas theem with nine outcomes and you're guys like problem set app why uh we talked about a bull of bat man things were starting to get a little bit more exciting as things got more exciting oh it's got this funny tool tip things that's definitely not that's definitely not but I took a screenshot and somehow I got the tool tips wrong but the the important point was you know speaking of community at this point you guys were getting to the heftier parts of Cs 109 and the TA stepped up we did 50% more office hours than we've done in the past the T are like okay the students are going to work hard we're going to work hard too I've never seen an officeour calendar just like every day a whole bunch of them and that was CU you guys you guys were awesome uh and you were teaching these wonderful sections actually we've had sections for a while now but this is year three of having sections and the sections you guys got to practice going deeper it's like lecture you'd hear the concept section you go a bit deeper and after section went a little bit deeper then on your problem sets you would be doing it on your own and then time for random variables why just have probabilities when you could have random variables and as we now know Chris sees random variables and everything and I hope you too too uh we talked about a bunch of things about random variables like expectation and variance then we start to learn about classic random variables like the binomial distribution oh and we send bits into states that might be corrupted good times we learned about the geometric I love this problem oh how brutal was this problem it's like so simple it's like is that random or is that not random you're like but the geometric is one of the many paths to figuring out that that is not random series of heads and tails uh we use random variables to solve all sorts of neat problems like could we store data on DNA um what's the probability of having earthquakes in a certain number of years what's the probity of extreme weather we talked about the likelihood involved in Bitcoin mins we talked about representative juries in the language of random variables we even talked about love because sometimes Love's what it's all about but sometimes what it's all about is Bloom filters and and all these problems we got to look out through this wonderful new lens but then we hit this problem while we were basking in the glory of random variables there was this hidden issue what about things that are not discreet like the simple humble random function from python but then we went there we're like okay that doesn't scare us we're going to go and think about probabilities in the limits we had random variables that were continuous and we went from probably Mass functions to probably density functions which was a mind trip a whole new way thinking about random variables and it brought in back the big old scary integrals but we learned that integrals are loving not scary they're our friend um and really this class was more about finding when you need to know the integrals than memorizing all the rules of integrals this took us down wonderful paths and allowed us to explore new random variables like the very important gaussian random variable and of course what do you guys get if you integrate over probability density function probility ah yes fantastic um and then you guys took this and you guys solv some cool problems like thinking about climate sensitivity how much our Earth's temperature could change if we double CO2 uh we talked about PDFs you learned about cdfs uh and then we started to apply these random variables I love this one and I hope the T take this into account you guys remember this this was exam scores for the Polish national exam and look how gaussian that looks except for this one part because that's what a passing grade was and that's like this is the nice ta they're like no way man oh look I found a point okay why have one random variable one you could have a whole bunch because so many cool things in the real world invb lots of random variables being random together and we started this narrative in the simple world of thinking about two random variables together and we had these joint probabilities initially there were tables cuz they were discreet we learned about classic multivariable random variable types like the multinomial and then we figured out who wrote this Federalist paper not Hamilton Madison and of course the exciting thing that we worked on through this thing was a general tool to figure out predictions of diseases people have based on a combination of symptoms this really huge problemistic model that you guys work through lots of random variables was too exponentially hard for us to deal with so we built a problemistic basion network you know the idea that led to that great paper that was so inspirational to me uh and not only do we build problem networks you also learned a randomized algorithm called rejection sampling where you could take any problemistic random Network and you could infer any conditional probability you cared about which was a really really cool probabilistic algorithm to get to see in your first probability class at this point we' done some cool stuff and you guys had done some cool stuff cuz you had been doing the hard work at home but it was time to learn the classics you know like some of those beautiful ideas in probability theories and we started with one of my favorites we went back and we thought hey what if I have uncertainty about probability itself and we thought about well let's say I flipped a coin I was uncertain if it's true probability being heads after I observe a certain number of heads and tails could I rethink about my estimation of the probability and in the spirit of 109 that everything could be a random variable we let probability itself be a random variable and after you observed nine heads and one Tails we figured that if you thought of probability as a random variable this is your belief distribution not on whether or not you'll get heads on the next coin flip but in the probability of heads itself the beta distribution what a beautiful piece of Theory and of course the beautiful piece of theory is not just going to live in theory land it's going to help us and it helped us solving this decision that we called Thompson sampling of making decisions repeatedly under uncertainty and as I mentioned at the beginning of class this isn't just something that I teach you because I'm like yeah whatever they should know it's something that I use and it's so helpful and I think it could be a tool you might be able to find applications to in problems that people haven't thought about and you did it you coded up Thompson sampling you made that happen on your problem set app then we learned the central limit theorem we took a couple random variables and we add them up together we're like What if we add up this random variable more and more and more we started with dice we're like okay we're going to add dice up together and we looked at the sum of many dice and started to look like a gaan we're like oh what a coincidence and then we took a beta and we summon it up and it was a gaan and we took things that didn't even look like distributions we summed up lots of samples from them and it always end up being gaussian which led to this crazy idea of the essential limit if you some IID random variables it always leads to a gaussian crazy beauty that exists in our world we then also learned about the crazy beauty that is the bootstrap where you know it's time to think about the theories behind what scientists do when they have to calculate P values and we to think about distribution of Statistics themselves and in the craziest mind trip we were able to find distribution of Statistics Based on data itself using this wild wonderful idea of a bootstrap where we would say okay we're going to take all our data data assume a universal probability Mass function resample and recalculate new probabilities and we' use this to calculate distributions of Statistics themselves and you use this to solve some cool problems like hey should we use mean or medians for Pure grading um what's the result of a Ab test what should we think of as its P value at this point we've done counting we done core fundamental probability Theory we talked about random variables we talked a lot about random variables and probabilistic models and then we got into finish our Theory it was time for our last dance of machine learning we learned about a bunch of different ways of doing parameter estimation we learned about maximum likelihood estimation we learned about maximum a priority and all of these things led to different algorithms that could do our biggest task that we ended our final problem set on which is classification we took three different data sets and we used different algorithms to classify the two algorithm and this is still a little fresh I know some of you guys have just finished like 3 hours ago uh you wrote leg istic regression logistic regression that we learned was like the core idea behind deep learning which is what we talked about last Friday or sorry I guess last Friday was algorithmic fairness and at this point you know you learn two algorithms naive Bay and logistic aggression you implement them we talked about how logistic regression was the Cornerstone behind this great idea which was deep learning we made the important aside say this is really complicated tools and we have to be so thoughtful about how they interact with society and then we're like the world's still changing and I we did this class on just Monday where we said okay now that you guys have learned all this could we understand some of the newest tools of our day like this tool that came out last Thursday GPT and this tool that's only been around for a few months uh Dolly and how those things can use probability Theory to generate images and generate text this is a little funny I did want to bring this up I don't know if anyone's tried this don't tell me if you did anyone curious like has anyone Ed these these gpts the show hands you've tried it out okay now put your hands down because I don't want to know who tried to see if he could solve their homework problems but I did did you try I tried okay okay but for for a class I'm teaching was is totally legit right that's not Honor Code problem and so I was like hey gbt can you help me with my homework I like hell yeah let's do that I'll give you all your Solutions I'm like uh oh I tried giving you all these CS 109 problems and it couldn't solve even the most basic ones like I started with one of the easy ones problems at five which is like well not that easy boy this was a little bit hard to think but fair six-sided dice is repeat like no one's like that was not easy Chris uh six-sided dice rep pulled until you get a sum that exceeds 300 was the probability that it took you at least 80 rules and it was so wrong it did some things that look pretty reasonable like it got dice right it got this uh everything is a potato not a potato right and then everything was wrong I was like uh pretty sure that's wrong but hint why don't you use the central Limon theorem it's like oh yeah the central Limon theorem definitely and it got the expectation of dice right and then it totally got the central limit theorem wrong it gave such a convincing answer it was so convincing but completely wrong I think you need to understand more to realize how it was wrong than to solve it yourself so I just want to let you guys know so people don't feel tempted no I'm just joking can you guys do me a favor class is going to be over next we actually the problem sets are app is basically closed can anyone see if you can get it to solve okay study sorry study definitely focus on your exams you guys don't need to do that but like if you really need distraction which you don't you should study if you need a distraction which you don't then uh if could you find out if you could get a solution to one of one of our CS 109 questions just for fun maybe over Christmas if you're curious It's a little little Challenge and please do let me know because I am quite curious um okay let's talk about CS 109 by the numbers because I think that's kind of interesting you know we had more than 30 major keys to help guide you uh maybe more importantly there's a whole course here with 64 chapters and Counting now uh some of them Dynamic oh this personal challenge just makes me so happy and it's made us so happy just looking at the the fun and wonderful ways that you guys have been exploring probability uh oh and this is so cute you guys my baby started counting this quarter she can like count to 10 I'm like oh that's what I teach and I'm like you know tears in my eyes been so cute so it's just been so fun to both be a father and be your teacher at the same time and if I could end on a few notes the most important one is thank you I just I appreciate you guys thank you to our wonderful T thank you so much thank you thank you well you've been a wonderful new head ta uh thank you guys to all the students yeah for our head uh and then you know thank you to you guys as a class youve just you made our job so wonderful it turns out teaching without students is not that fun uh and it it is because of you that we do what we do and that our jobs are so enjoyable so thanks for that and if I could leave on on one interesting note is you guys live in interesting times and there's a lot of excitement out there and you know there was a moment when people were developing all the fundamental theories of addition and there was a time when people were trying to figure out oh what's a function they were defining what algebra was and people were coming up with ideas that we've studied to this day and you're living in a time that has all that movement again it's scary and it's wild but it's also if you imagine what it would be like to live at a time when people like uh uh were inventing all those core fundamental mathematics from our future perspective that sounds quite exciting in the future people will think about this time and be like wow you live in that time when people are inventing things Chris what did you invent I'm like uh not P ver senp like why you missed your chance uh but what an exciting time to be living and and I do want you guys think there's all these wonderful problems and you live at a time when they're still open and how exciting is that and you're at a wonderful place there's so many tools and resources and and ideas floating around Stanford what a great time to be learning all these things what a great place to be I hope you guys can feel some of that energy and and whatever your future path is be it going into research be it going to further classes be it this could be your last stop in CS and you go apply these things into wonderful other new Fields whatever your future path is just know that we're so appreciative of having you a class that we're rooting for you on your future uh whatever that is and then maybe I'd say don't be a stranger you know you see coo say hi if you see me walking around uh please do say hi I'd really appreciate it because you know now we're going to go on Christmas and and we'll miss you all okay come to the review give a great review on Friday come to the final definitely come to the final that'll be next Tuesday uh and then we'll say yeah um and then you guys all the best and I really mean that uh don't be a stranger have a wonderful rest of your day CS