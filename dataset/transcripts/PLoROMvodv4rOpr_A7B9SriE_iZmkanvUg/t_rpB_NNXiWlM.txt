good afternoon CS 109 how are you guys doing today wo fantastic that's what I like to hear happy Monday I hope you guys had a fantastic weekend and you're excited to come back and learn another great concept cuz again we have a fantastically important concept you guys have probably heard about it before but today you're going to learn all the important details about it the normal distribution which is one of the last major random variables we're going to talk about before we get into the next level of cs19 like there's another level there's always another level where we're going to be talking about probabilistic models um so let's enjoy this wonderful class before I jump into things oh yeah um one big announcement is that problem set Three is out uh and problem set three is going to be largely around random variables uh in fact you the first set of questions are using discret random variables that you've already learned about in the last few ones are using continuous random variables uh which were just finished finishing up our conversation about today I want to highlight a couple fun things that you'll do you know back in the day I used to teach random variables and people would still find it confusing and then once I introduce this problem and it seems to crystallize so much to different people what the different random variables do in this problem you're going to be writing code that simulates each of the random variables so you like simulate pulling a sample from my binomial pulling a sample from your geometric pulling a sample from Pon and the process of simulating okay what is bom it's a bunch of coin flips seems to be very helpful for understanding random variables um there's a lot of problems where your answer should look like Define a random variable tell me its distribution write the question as a probability statement and then solve a whole bunch of your problems will have that uh template some of the cool things you're going to do have you guys ever heard of a bloom filter is this probabilistic data structure that's using a whole bunch of things like for example it's used in Chrome to keep track of malicious URLs and imagine how many different URLs there are in the world and putting all of them into a data structure that says malicious or not malicious that is incredibly difficult thing to do but Google is able to do it on every single one of your computers using the thing called a bloom filter wouldn't you like to learn more about that yes yes yeah great you get to and your problem set whether or not you want to learn about it you're going to okay and then um there's another interesting question we actually got data from the ipcc uh and made a whole problem around it that is based on real predictions on this thing called climate Sensi ensity that's a very interesting random variable climate sensitivity is a random variable that says if you doubled CO2 in the atmosphere what would be the equilibrium state of temperature change uh on planet Earth and so we're going to be thinking about that very interesting random variable on this problem set oh and I love this problem maybe you guys can just look at this no which of these two sequences is random they have the same number of heads and tails but you have to go into your investigative creative space in order to answer this and speaking of creative space one of my favorite things on this problem is we're going to be making some algorithmic art you'll make some beautiful artwork like this uh using a thing called a pretto distribution what a fun time make some artwork learn about some algorithms just build this Foundation of random variables I couldn't imagine a more fun problem set um and just a small note if you want to learn more about the Predator distribution don't forget that there is a chapter about it inside the course reader oh totally not important totally not for grad but if you make some beautiful artwork and you want to share it with the class please do we would all appreciate seeing the gorgeous artwork that you make okay cool that's what I've got yes theine for I'm so glad you asked uh so asked a very good question he's our head uh he asked a very good question when is the late deadline for problem set three and that's such a good question because problem set three goes out today and we want you to have finished before the midterm which is basically in two weeks from now because of that even though the deadline for PR set 3 is not this Friday but the Friday afterwards if you gave yourself an extension it can't go beyond that midterm so the longest extension we give is actually only Saturday Sunday and then Monday and a half day so there's only a three and a half days is the longest extension we'll give for problem set three we want everyone caught up on all their problem sets by the time the midterm starts thanks what a good question I really appreciate it okay fantastic now we are going to be building off some of the great things we talked about on Friday's class and since it's been a weekend it's certainly worth reviewing in Friday's class we started with this simple observation that the random variables we have have the language to talk about the relationship between values and the probability of the random variable taking on those values in the world of discreet random variables where the answers are the values are things like one two and three this made a lot of sense but we got into the continuous World it made a little bit less sense and to give you that idea let's say you had a random variable that talked about the height of babies when they're born and maybe your your random variable you know looks a little bit like this it it talks about this is the most likely height when babies are born and you know there's a little bit of spread to it if this was a discreet random variable and he said like the height of the baby is five you could talk about the probability of that but it got really really weird when you said what's the probability of this baby that was just born and you look at the baby's weight it's a real value like what's the you know weight of a baby let's say it's 10.12 134 and it's real valued so it's going to keep going you know if this is a whole number we can talk about the probability of random variable taking on a whole number but how ridiculous is is it to talk about the probability of a real valued number that a random variable would take on a real valued number so continuous random variables present a little bit of a challenge to formalize that into mathematics what we did on Friday is we said okay let's imagine when a margarite shows up and we had the first intuition to just start by discretizing time we're going to think about the continuous random variable as time but we discretized it to start out with we said what if time was in five minute chunks this makes it more look like a discret random variable than a continuous random variable but we could still solve probability problems like what's the chance that the bus shows up at this point and then we said well we discretized it into 5 minutes but we could have discretized into more fine grained elements and you can see where this is going if you took those discretizations and kept making more and more fine grain event elements eventually you would end up with a smooth curve you get infinitely small buckets and here the values wouldn't be the probabilities and instead they would be derivatives of probabilities that's where we went on Friday what an adventure do you guys remember Good Times we'll be practicing that a little bit today okay we talked about a couple canonical continuous random variables the easiest one that we started out with was the uniform random variable the uniform random variable is such a good time it basically says my random variable can take on any value from A Min and a Max here plotted is min0 Max one and it's equally likely to take on any real valued number between that range so it's just as likely to take on the value 0.5 as 75 um and it gives you this nice little flat uh probability density function fantastic we have things like expectation and variance for it and but what if you wanted to figure out the probability of some range here so you've got a probability density function how do you figure out um a probability question under that so what do you get if you integrate over a probability density function probility yay probability that was exactly it you know in the world of continuous random variables that derivative of probability we call the prob density function so as you took time and you made it finer and finer that thing you're left with we call it the probability density function or PDF and to get a probability answer out of that PDF you would just find an area under the curve and it was equivalent to like as you discretize time you were summing up uh columns and this sum ended up becoming an integral as we enter the world of calculus but at the end of Friday's class plot twist total plot twist we were were working with continuous random variables we had PDF we were doing a bunch of integrals at the end of class I like wait what if we could derive something so we don't have to keep doing a bunch of integrals and we introduce you to the world of the CDF a CDF is ideally a closed form equation for the probability that a continuous random variable is less than some number and if you can Master using the CDF you can solve a whole bunch of probability questions without doing integrals the example from Friday's class was we said well let's say you had this exp exponential random variable and here's this probabbly density function and you want to get the area under the curve between 1 and two AKA you want to know the probability of the random variables between 1 and two you guys were super clever and you came up with this idea that we can look at the PDF value at at two that'll give us the area under the curve under two because that's the probability that X is less than two and we can subtract off the probability that X is less than one and we figured out a way to get the probability without doing any integrals just two quick lookups in this CDF you can derive the CDF for um X itial someone has already derived it for you if you want to know and there you have it that's a whole bunch of review what a good time okay any questions before we jump in let's go because it's an exciting and big day we're going to be learning about the normal distribution would you've heard a bunch uh in your life and now we're going to formalize it the normal distribution is one of the most popular random variables and it's a random variable that describes a probability density function that looks like this and you guys have seen this before can I just see some nods of heads if like just to confirm confirm that sometime in high school somebody has shown you a gaussian distribution AKA normal okay that's a good time a normal distribution has a probably density function that looks like this bell curve um is defined by two things a mean and a variance the mean kind of specifies what is the middle of the be curve and the variance specifies how wide is the bell curve it's used for a whole bunch of things as a random variable we Define something to be a normal random variable like this and as I said there's two parameters the mean that's the middle of the bell curve and how wide it is that's the variance its support is negative Infinity to Infinity so technically you can answer probably question about any value assignment to X we call this the mean we call this the variance its expectation unsurprisingly is just that parameter of the mean and it's variance you guessed it is the parameter you gave it so this is such an interesting random variable it's a random variable you give it the mean and you give it the variance and then it gives you the rest of the distribution and then finally this random variable has a PDF and boy does it have a PDF have you ever seen such a beautiful equation it's such a beautiful equation I wrote it up on the board over here and this is the equation that defines that bell curve that gives you that shape that we all know live learn and love uh the gaan distribution what a beautiful equation we're going to use it today that equation derive defines this this is particularly where mean is zero and Varian is one and if me is zero and variance is one this beautiful set of math describes that orange curve now we're going to talk about the gaussian distribution but it's worth talking a little bit about this guy Frederick Gus who you might have heard of remarkably influential German mathematician he did a whole bunch of things um including invent or popularizing the gaussian distribution um but this is kind of interesting he didn't invent the gaussian distribution gaus isn't the inventor of it in fact it's just that at some point in his life he's like everybody you need to know about this distribution it's so awesome it's so useful for everything to the point where he said that enough that people were like okay we're just going to call that thing the gaussian distribution because he's like the number one fan uh and I'm going to say his celebrity looked like is a late Robin Williams but I've done something I don't normally do in CS 109 normally I give you a story and then we derive the math but here I flipped it I just gave you the math I said here's a gaussian distribution here's the math and the reason behind that is the story for why gausin distribution is a little bit nuanced can we talk about this for a moment why do people care so much about this gaussian distribution one answer you might hear is that it's very common for natural phenomena like if you look at the heights of babies when they're born they tend to be gaussian if you look at the weights of babies when they're born and they tend to be gaussian all these normal distrib or all these distributions that show up in nature seem to be gaussian there's this argument that you might hear that background radiation noise and other forms of noise in electronics often tend to be gaussian that's similar to the first argument natural phenomena seems to be gaussian people might tell you if you take a bunch of random variables and add them up then that's what leads to a gaussian uh and you might even hear an argument something like the sample means are distributed as a gaussian now notice that gaussian and normal I use as synonyms so if I say something's gaussian and if I say something's normal those are the exact same claims okay let's go over each of these that's kind of what they want you to believe it turns out very few phenomena in the real world are actually gaussian a lot of them are very gaussian related for example when people looked a little bit deeper into Heights it seems like maybe a log normal which is a related distribution will be a better fit now most World noise in the world is normal is a interesting claim but it also again seems that most people just assume noise is normal and it's some types of noise we assume are normal but it's not actually normal this sum of many random variables we're going to go deeper into when we get into our theoretical section of Cs 109 but that turns out to only apply when you're summing up equally weighted and independent random variables but if that they are equally weighted independent turns out to be gaussian uh and this fin one actually is true but I want to give you the deeper reason that you see gaussians everywhere and this is a Christ opinion it's this aam's razor claim that often the simplest explanation is usually the best one we're going to enter a next phas in CS 109 where we'll do some problemistic modeling where you have to come up with what you think is the appropriate random variable for something like a data set and sometimes we don't know what the right random variable is like for example let's say you have a data set it describes a single random variable and when you get the histogram it looks a little bit like this let's say nothing about the story of this random variable tells you what it is it doesn't tell you it's a pan it doesn't tell you that it's an exponential but you just have to figure out what random variable it is just by straight looking at it complexity is very tempting you might want to say okay I don't know what this random variable is so I'm going to define a brand new random variable this is the Cris the peach random variable the peach random variable goes like this and it perfectly describes my data but you might not want to do that because it kind of violates this idea of aam's Razor that you should probably give a simpler explanation to how the world works and what people often do is if they want to come up with a generalizable solution they might want to give you a simpler story and it turns out one of the simplest stories you can give is say I'm just going to assume that this is gaussian it's probably not perfectly gaussian but if I assume it's gaussian I can calculate the mean I can count the variance and I can tell the world I think this is gaussian that's generally accepted lots of fields and science do this and it turns that if you're curious there is a deeper reason why that's a pretty reasonable thing to do if you match the mean and you match the variance and you say I want to make as few assumptions as possible beyond that there's a very elegant mathematical proof that says gaan is one of your Best Bets if you want those two numbers to match if you want to come with a random variable that matches the match of the variance and you choose a g skin it turns out this claim is true it maximizes the entropy of the distribution and the entropy is a measure of disorder which is kind of a measure of how little information uh you've put into the Assumption you've made wow that's a really really long way of saying a pretty simple thing is that many times gaussians will show up in your life because people have assumed gaussion because calcian is a pretty reasonable assumption uh in lots of cases when you don't know that much about your random VAR so so many things in the world are assumed gaan that you absolutely need to know them you need to know how to work with them pretty well okay um entropy we'll talk about it in office hours if you're curious about it I'm super into it uh but it's a little bit beyond CS 109 right now okay but there's a final reason gaussians are remarkably easy to use you might see this equation and think that they're hard to use but let me tell you they are one of the nicer distributions that I've worked with and a lot of times when you're doing c s proofs if you can make a gaan assumption a lot of cool things fall out yes that's missing a minus sign where in the exponent minus 2 Oh e to the minus thank you appreciate it okay so my claim is that there's a lot about this formula in some of the rated formulas that actually make it a little bit e easier to use okay let's take a moment and do some anatomy of this beautiful beautiful equation because the Gan distribution like once you've assumed it you immediately inherit that this is the probability density function it's got a lot of moving pieces to it first of all probability density functions are functions where you put in an assignment a possible assignment to your galin and it gives you the derivative of probability at that point so the input is going to be a possible assignment to your G then you have this whole thing which looks really complicated except most of this is just a constant it's really cool that there's a pi in there like beautiful equation uh and it's got a pi and an e what is this gorgeous equation it's got all my favorite symbols in it um this term over here says take that query and see how far it is away from the mean and it's going to be the square of that difference so if you're into Norms that's the L2 Norm um and then here we have the variance showing up twice so so it's like how far are you from the norm somehow modulated by your variance and that gives you your density I don't know if I put the equation in the top right can I show you another way of writing that I think highlights why it's easier to work with this is the same equation but it's written to look a little bit less scary instead of writing e to the power I use this exp which is what you write in Python like if you want e to the power something you do math. exp and exp is the math thing which says e to the power of this uh and it just makes it a little bit easier to read and you can see like oh yeah that term is really the important thing and it's not too scary of term this thing which catches the I is actually just one over Sigma times a constant and sometimes when you times a constant you can just write proportional to because in lots of math the constant will just fall away or if you needed it it would just be two square root of 2 pi that looks a little bit nicer okay you're going to work with it you're going to like it it's a good time uh okay as I mentioned exp is something you should know if you want ma mix math and python um and proportional to is certainly something that I hope you guys saw in previous uh studies before CS 109 okay um I have this hypothetical question what if you had to take the log of this function like if for some reason you found yourself doing a log so many beautiful things would happen this would become inition and the log of this exponential would just cancel each other out and You' just be left with this so if you find yourself ever in the world of logs and normals like little tears well in your eyes because of the beauty that happens okay I've been talking a lot but you guys need to be practicing your normal let's get your gaussian on let's talk about how long it times takes to travel between classes let's say you measure how long it takes you to get from class to or from home to class and on average it's taking you four minutes and from the data you collect you're also able to estimate that the variance is about 2 minutes squared or the standard deviation is um square root of 2 minutes we don't know the distribution of how long it's going to take you it's not coin flips uh it doesn't seem like an exponential so let's say we're going to say I'm going to suppose it's normally distributed you've empirically calculated the meum empirically calculated the variance and now we're going to assume that the whole distribution is normal my question is what if what is the probity you spend more than 6 minutes traveling and that means you're going to be late for class and I want you guys to think about how you would solve this problem uh and then we're going to do it all together okay so how do you solve this problem talk about with the person next to you get your gaussian on okay I am going to interrupt you and I'm I'm sure no one got to the end of this yet um because I wanted us to do it together I'm glad that you guys had a chance to think about it let's do this all together the first step is to declare your random variable as I said this is going to become a pattern for you guys to fill in you say like okay I'm going to declare that X is not just any any random variable it's a normal random variable as soon as you write that then you inherit the probability density function that we've talked about and particularly We Care what's the probability that X is greater than equal to 6 and we know that if you want to know a probability with a random variable you just integrate over that range so this is 6 to Infinity you could do 1 minus um 0 to 6 that would be fine too well actually you'd have to do technically negative Infinity one of the awful things about this assumption that travel time is gaussian is that gaussian technically allows for to take negative minutes to get to class like the Gans defined over the entire range does that make sense like it makes sense mathematically but like does it make sense for you to take negative minutes to get to class not unless you're like Hermon Granger otherwise it's going to be taking positive minutes right anyways aside from that bad assumption so because Gans are defined in the rain to Infinity we going to have to integrate this from six to infinity and we're going to integrate this beautiful equation that says nice work with so we're just going to do this integral um and did anyone want to get the answer to this integral somebody think they did wol for Alpha oh man okay so I told you at some point in CS 109 like integrals they're loving not scary except for this time they're terribly scary it turns out there's no closed answer to this integral that was a cheeky question if somebody did come up with the answer please do see him after class and we'll name the algorithm after you uh certainly oh man wait how are we going to do this we have a probably density function but we can't even solve this problem because we can't integrate under this this is a non-integrable function oh man we're to well this gaussian seems useless yeah it looks pretty but it can't do anything for us because we can't integrate it ah we're going to have to go back to the drawing board do you guys want to go see how you're going to do stuff like this yeah we want to be able to do stuff with gaans okay sad times let's just rally ourselves and be like no we will will not give up we will continue until we figure out how to figure out the probability that we're late for class it turns out there's no closed form for the integral and worse yet there's no closed form for the CDF so in the exponential we have this wonderful CDF but there's no close form for that either sorry can you just Define what do you mean there's no CL form like closed form would be able would mean that you'd be able to write this integral as an equation like you'd be able to write down the answer to the integral like for example like if I say x s if you take that integral there is a close form because you can write this integral as an equation math that's a very good question that's what I mean by close form so there's no closed form for the integral bummer worse there's no closed form for the CDF total bummer but question I don't know if this is like within the scope of the class but why does a function have a close form and why does it not yeah let me see if I can come up with a good example of something that doesn't have a closed form um sorry yeah there's a bunch of things where like the integral is not possible to calculate where it's maybe I I suppose in this one like where did you get stuck it's like you have to do break this up into parts and there's no way to break this up into parts so that you could write it down I wonder if there's a deeper answer though to like what are the family of things that don't have close form integrals I'll be curious about that but um long story short if you try to work on this which maybe it's worth spending five minutes on and you try and say like okay how do I integration by parts uh there's no path that would lead to you be to write down an equation okay I'm going to give you the end of the story and then we're going to get there the end of the story which I've written on the board because it's important I want to have it in front of us the whole time is that even though there's no close form for the CDF there's this magical function fi and with this magical function fi I'm going to give you a way to use a CDF for gaussian does that sound good okay so at the end of the class you'll understand why this magical function f works and you'll be able to use it to solve problems it says that the CDF remember the capital F is the cumulative density function so the probability that your random variable is less than Little X is equal to this numerically calculated thing called fi and F is going to be a function where you put in the difference between the input to your CDF the mean of the gaan and you're going to normalize it by the standard deviation but to get to that final conclusion that there is this CDF that we will be able to use you need to know some of the beautiful properties of normals and that will lead us to be able to drive this the first cool thing about a normal is that if you transform the normal a little bit you'll still end up with a normal and by transform the normal let me give you an example of what I mean mean we have a normal up here and let's say I say that was our normal of time to get to class Y is equal to the normal of the time to get to class plus I always take three minutes for my shower so the amount of time from the start of my shower to when I got to class is y and that's take my normal and add a number that's called a linear transform because I'm just adding number even if I said like some constant multiplied by X and then added that's still a linear transform and a beautiful thing is if x is a gaussian any linear transform you do will lead to another gaussian good times so not only that we can calculate exactly what gaussian it is we can calculate what gaussian it is because we can figure out what's the expectation of this new gaussian and the expectation of the new gaussian is just going to be the expectation of what Y is equal to but because expectation itself is linear this whole thing works out to be pretty straightforward now variance is not exactly linear if you say x is a random variable if you do do ax plus b it turns out that the variance of this transformation drops the plus that doesn't change variance at all but any multiple times x has a squared effects on variance so if Y is equal to ax plus b then the variance of Y is equal to a^2 * the variance of X and this means that if you do this linear transform any lary transform you want it will be a normal and I will know exactly what normal it will be it will be the normal with this mean and this variance okay that's kind of cute but it turns out it gets a little bit cuter so what we have derived so far is that if you do a linear transform the result is going to be normal what I'm going to now show you is a very magical linear transform give me any normal like for example this normal and I can transform it to be the normal with mean zero and variance one you guys ready for it okay if you choose particularly you're going to take your random variable if you multiply by one over the standard deviation and then you subtract off this number that's a linear transform do you guys believe me it's a linear transform we must have trust before we go on so X is a random variable this is a linear transform and it turns out I chose a very special linear transform because when you do this no matter what random variable you started with it will transform it into normal with mean z and variance one so to convince you of this you know this linear transform the multip the multiple is one over Sigma and the addition term is negative mu over Sigma and we can put those equations into here we can say like if we did this linear transform with this a and this B what will this result in well let's try it out let's plug and chug we're going to plug in that for a and that for B and if you plug it in here's what you get in the first term you get a * mu is going to be mu over Sigma and then plus b is going to be negative mu over Sigma hey look what happens to these terms Tada there's zero what happened when we plug in you know one over Sigma for a you get one over Sigma squ time Sigma squ hey guess what happens here you get one no matter what normal you gave me like if you gave me this normal I could choose a is equal to 1 / 2 cuz that's 1/ Sigma 2 and I can choose B is equal to-4 / < TK 24 over < tk2 and if I use that particular a and that particular B if I did ax plus b I would end up with a normal with mean zero in variance one so far this is just cute you're like hey that's cute you take any normal and you can transform it into the standard normal but it turns out it's a little bit more than cute because the standard normal is something that we could do a lot of computations on ah everybody Welcome the standard normal it's like the chillest of the chill distributions if the normal is the the the least entropic distribution that matches mean and variance the standard normal is the most relaxed version it has the simplest values of the prameters mean is zero variance is equal to one mean is zero means it's will have its peak at zero and one means it just won't be that uh thin it won't be that wide what people did these crazy folks is they got their computers out and they said what if we calculate the CDF for the standard normal we can't do the CDF for all um normals but we can do it for the standard normal we can get a whole bunch of computers and just try and do some numerical integration and using some numerical integration we could come up with a big lookup table and that big lookup table will have the CDF of the standard normal and they did that and the world has never been the same sense uh because it allowed us to do a whole bunch of other things now particularly there when they did this numerical calculation they ended up a big lookup table where you could put in something like 1.3 and it would return you back this CDF of the standard normal at 1.3 and they called this lookup table five so what are the two pieces we've got you can take any normal and make it look like the standard normal and people have made a big lookup table for the CDF of the standard normal we got those two pieces what we would like to have is for any normal distribution to know it's CDF but we can put these two pieces together like a delicious peanut butter and jelly sandwich to come up with a CDF for any normal distribution before I do that though any questions on fi which is the CDF of not any normal noral just a standard normal yes um what's the point of converence to have mean Zer and variance one if say we have a problem where in fact mean score like I feel like just losing information you're totally right okay so um you're you know right now we're doing all this work for mean zero and variance one and so far that's doing nothing for our problem here which has mean four and variance 2 there this is like lost information it's this whole calculation is done with the wrong parameters we want the right parameters so you're right the tension is right I just haven't given you the answer okay so when you say Z is kind of like n with m z Etc what does that Tilda basically indicate this one yeah like conceptually what does it mean to say that they're similar oh it's not similar this is is distributed as whenever you see the til in cs19 it means is distributed as so X is distributed as a normal and this is saying Z is distributed as a normal so that tiled doesn't mean approximately it means is distributed as good question because in a lot of other places til is used for approximation okay here is what fi looks like you can print it out people used to print it out actually when I took CS 109 the teacher gave me a print out of f is like here you go people did all this work it's on a piece of paper and I could hold it and love it but that was actually quite useless uh because now computers can store it too but this piece of paper just had the whole numeric pre-computation for five so you could be like hey five of 1.13 you could look it up on this piece of paper and know that it's 0.90 and that five recall CDF of the normal saying so if you have a standard normal the likelihood that its value is less than 1.31 is 949 okay couple things that are cute about F though it's symmetric so if you ask a fi of a negative number that's equivalent to asking the FI or one minus the FI of a positive number um if you do if you just want to know the likelihood that your standard normal is between C and D just like we did with cdfs before you can do the CDF at D subtract out the CDF at C there's a whole bunch of cute things you can do with f okay but this is like Beyond cute it turns out we can use fi to figure out the CDF of any normal you guys want to see how we're going to figure out this by transforming any normal into the standard normal here's what we're going to do let's say F ofx is for not the standard normal but rather a normal we care about say how long it takes to get to class we can take our X and we've got the probability of this U binomial or sorry this Boolean expression and I'm going to subtract mu from both sides If I subtract mu from both sides you know since mu is a constant this is a still a valid inequality do you guys agree and next I'm going to divide standard deviation from both sides that's a fair thing you can do with the left hand side since this is a constant you can divide now I note that variance is always or sorry standard deviation is always positive you can't have a negative standard deviation and you have to be careful when you divide in a less than sign if you could have a negative number but since this is a positive number this is still something valid we can do but the interesting thing about this is over here we have a number this is a number minus a number divide by a number over here we have a random variable it's a random variable minus a number divide by number and it turns out this is in fact a linear transform and it's not just any linear transform notice that over here what I've done is the linear transform that is z if you take any random variable and you subtract off its mean you divide by its standard deviation that was the transformation that we were doing to get Z so when I did this transformation to this random variable I was left with z and that's kind of cool the probability that any normal is less than or equal to X is the same as asking what's the probability that the standard normal is less than or equal to x - mu divide by standard deviation where these are the two parameters of x w that's super cool why is that super cool because now we're answering the question of X in terms of Z and we already know it's the probability that Z is less than something that was just five the probability that Z is less than some number is five of whatever that number is and that's how we get this equation if you have any gaum distribution and you want to know what's the probability that is less than a little X you take that little X you subtract the mean divide by the standard deviation take that number put it through five which is the CDF of the standard normal and that will give you the CDF of your normal and we've learned so many things along the way like what a beautiful Journey it led to this really useful formula but along the way we learned what F was we learned that you can transform a normal distribution and it'll lead to another distribution like what a beautiful Journey we've been on but this is really where it ends so if we go back to this problem what's the probability that X is greater than equal to 6 now how would you solve it again talk to the person next to you let's see if we can actually come up with a way to get a number answer here okay I started up here I said hey what's the probability that X is greater than equal to 6 I don't like greater than equals because the CDF is always saying the probability that your random variable is less than number so whenever I have continuous things and I've got a probability that's greater than I try and convert it into probability that's less than and this is true the probity X is greater than equal 6 is equal to 1us the probability X is less than 6 and I did that transformation because this is what a CDF is telling you this is saying what's the CDF at six CDF is the capital F sometimes you write the random variable you care about as a subscript so it's the CDF of our random variable six at sorry random variable X at the value six and now we just need to know what's the CDF of a normal but we've got it over here it uses this fi which is that cool little thing uh this is equal to 1us 5 of X in this case is 6 minus the mean o where's the mean whose mean what mean is it standard normals mean where the mean come from just yell it out which mean do I mean oh how cute was that I said mean twice okay and then what's the standard deviation that I should be plugging in here square root of two yes don't get confused variance is often what's given as a parameter for the normal but this function wants the standard deviation which is a square root of variance uh and this is equal to 1 - 5 of 2 / < TK of 2 this would be a whole number you could get your lookup table but that lookup table also exists in your computer and actually one of the places it lifts is I made this calculator section in the course reader uh and you know there's a fi so you can put in like two in here and it'll tell you the FI table for two so that's the probability that a standard normal is less than two you can do 0.05 we you know this is not that important right now but anyways we could get two divide by square otk two put into our five calculator and just one minus that will be our answer question is there a liit to the Precision oh yeah you know there is that tells you something deep there's a limit to the Precision about probably questions we can ask about gausset but it's done in a computer and you know how it's done it's done using this really cool thing called Monte Carlo sampling which again we can talk about offline uh but allows it to have the Precision that you expect from a computer that can go really really precise and because so many things use gaussians they spent a lot of time making this a very very very precise lookup table so good question yes look table is there anything different asking like proba X is less than 6 versus X is less than or equal to 6 oh that's such a good question I'm really glad you asked it so the question is what's the difference probably X is less than equal to six so here's my interesting thing so your question is what's the difference between probably X is less than equal to six and the probably that X is equal to or sorry less than six did I get that right so do you agree that this is true you buy this okay let me blow all our minds this equals zero wait what no matter what value you have the probability that a continuous random variable takes on exactly that value is zero think about the baby and the baby being born with like 10.6 1 2 3 4 5 6 like infinite Precision the probability of that infinite Precision number is zero the probability of any exact query is zero and it's only area under a range that leads to non-zero probabilities so isn't that kind of cool fun little side question I hope it gives some insight to some people okay oh you guys are asking this quarter I'm getting such good questions and I really appreciate keep it up everyone okay man this leads to the number one takeaway for today if you're working with a normal distribution very likely you'll want to know probability questions and you're going to use the CDF of a normal the CDF of the normal uses this fi trans this fi lookup table um and this transform to the standard normal uh to solve problems okay and here we are the end of our journey we have the CDF of a normal distribution and you can just use this equation okay as I said looking up in the table is kind of old school if you wanted to there is this thing called stats. norm. CDF that will allow you to do this lookup much faster and again you can also just use the course reader if you wanted to it is kind of interesting though I didn't want to point out this thing that I don't normally point out but I think it's cool this is fi as a function right fi as a function you can put it in a number and you'll get a probability out it's a onetoone function so you can invert it you can say hey if I have 0 705 what input leads to that number and you might want to use that at some point you can you can always do the inverse of five you can the inverse of five says what probability do I put in here that will give me back some number uh oh did I get that sorry you put in your no yeah yeah you put in your probability and you get back a number I just wanted to note that it's an invertible function okay in the course reader okay back to the campus bikes we can't do it using an integral but we can do the transform and if you did the transform you know you would get this which you can then put into the five table and you get that the probability that you'll be late is only 8% you can decide if that's a decision or a risk you're willing to take on your way to class okay let's do a little bit of getting your gaing on some people suggested that we do more examples and I wanted to just give you a whole of examples so here's a new gaussian it could mean anything but let's just solve some problems with it so standard deviation is four because the variance is equal to 16 and the mean is three I put um over here that most important formula that you might want what's the probability that this Gan is greater than zero well if you want to know the probability that it's greater than zero you would just do probably is greater than equals 1 oneus the probability that's less than zero and one minus probability less than zero is going to be equal to so it's greater than Z equal 1 minus the probability that it X is less than zero uh is 1us 5 of 0 minus the mean ID by standard deviation in this case oh the standard deviation in this case we know that the standard deviation is equal to four and the mean is equal to 3 0 - 3 is going to be just three and you'll get five of -3 or 4 and you do one minus that that will be your probability okay if you want to know the probability that 2 is less than x is less than five so you want to do AR range how would we do that and think about it for a second and then we'll do it all together I'm going to give you guys uh 30 seconds to think about this or come up with a question for the class okay any questions come up people are curious about I mean the key here is to realize that this inequality can be broken down to the probably X is less than 5 minus the probably that X is less than two it's the same thing that we did with the exponential distribution last Friday so you know that can be the probably X is sorry X is less than 5 minus probably X is less than two and both of these are just plugging into the CDF of X okay and then finally what's the probability that X absolute value or x - 3 absolute value is greater than six wow you never seen an asle value are you allowed to do that oh yeah you are allowed to do that uhoh question um thinking back to that bike problem right when you're looking at a CDF that right less than two let's say you put in any number doesn't it take into account the positive values that you have a negative time so isn't that a little off or can can we like end the CDF at zero okay so the question kind of comes back to this by problem and you're annoyed by this really awful thing about our assumption so if this is zero so this is X is zero the gaan has a mean of four and then it has a variance of two which means it's going to kind of look like this right something like that but it's going to have all these nonzero values less than zero like there is some probability if you ask what's the probability of taking less than zero minutes to get to class you can put it into your standard normal and you get a positive number back and you're saying is there a way to not do that cuz that seems dumb uh yeah there is you could there's two solutions one is you could calculate the probability less than zero and you can somehow just subtract that off the more elegant thing to do is to realize if you subtract off this you kind of need to increase the probability mass of the rest of the thing so that it still integrates to to zero and then you've invented this thing called a folded normal and there's a thing called a fold normal and that kind of like deals with the fact that sometimes you want normals that can't go negative um and you know we can talk about that offline very cool question what we can't talk about offline what we have to talk about online is what happens when you in absolute value you're like oh man absolute values that seems complicated the idea here is to realize that this absolute value is actually making two different claims there's two different cases that satisfy this absolute value if x is less than -3 so if you put in like5 into here5 - 3 will be8 take the absolute value that's greater than 6 and any value less than -3 will make this equation true similarly any value greater than n so 10 minus 3 will be 7even that's greater than six any value greater than n will also make this true and once you realize that this absolute value equation is actually just one of these two mutually exclusive cases then now you can figure out your probability just by doing cdfs again this is the CDF of your random variable at -3 and this is 1 minus your CDF F at 9 uh and there you have it you can put in the five CDF equation for both these uh you could put into a calculator if you want to and eventually you get okay which leads me to this moment where actually I want to take a pedagogical pause because what we've talked about so far is really important we've talked about normal distribution and at this point I hope you guys have mechanics to work with the normal distribution you either have the relative likelihood or you have the probably that your random variable is less than some number Take 2 minutes think about it before we get on to other cool things you can do with normals cuz there's a lot okay take your moment how to work with a normal but it turns out the normal is useful in many many other cases and I want to give you an idea of some of that breadth so I want to start by an imagine situation and I want want you guys to put on your like hacki as hats and you're going to try and make it through this tough situation I'm going to present you with the tough situation I'm going to present you with is imagine you're doing an exam and this question shows up 100 people are given a new website design X is going to be the number of people whose time on the site increases the CEO is going to endorse your due design if you know if you try this on 100 people if more than 65 have more time on the site than the CEO is going to endorse it my question is what's the probability that the CEO endorses your change given it has no effect well if it has no effect the number of people who are going to spend more time on your site is going to be binomial there's 100 people and everyone has a 50/50 chance of spending more time or less time uh because it has no effect so this is a straightforward binomial question where you're given a binomial distribution and you want to calculate the probability that your binomial is greater than equal to 65 but then you're sitting down for an exam and it says this give a numerical answer and you're like uh what you can write down your binomial probability Mass function a remember that back in the day and then you can sum that from the value 65 to 100 and you can plug in all those numbers add it up and that should be the probability that X is greater than equal 65 and you write this down you're like that's some partial credit and partial credit is a thing um but then it ask for the numerical answer and you're feeling like ah I really want to get a little bit more partial credit got a little bit more time what could I possibly do I'm I'm actually going to jump into the Insight you have you're like first of all we are always presented with moments like this we like I don't know the answer and it's like certainly the most important thing might be to find one Zen you're like ah you know what I might not do the answer but I'm going to try anyways that's the Stanford way and you go back in your mind and you recall this moment in class when you're learning the binom bomal and we were learning the binomial we had this wonderful gon board where we threw all these balls down these pins and because of the binomial distribution we could predict exactly how many balls would end up in how many bins and in this hacki of hacky moments you're like you know what that kind of looks like a normal distribution and if I had a normal distribution getting numerical answers is a lot easier uh because I can use my fi lookup table um what if I got super hacky and I took that binomial distribution and I approximated I just tried to draw like the best markered normal over this binomial so that we could try and come up with a numerical answer how hacky does that sound so hacky we should just try it okay so you know you might want to solve this it turns out if you were to solve this correctly you get the answer 0.018 but we don't have time for that it's on the exam they want a numerical answer approach number two and you know let's say you don't have a calculator that is an important detail here approach number two the hacky approach is we're just going to draw a gaussian and hope it looks like our binomial how hacky does that sound so I'm going to Define why to be this hacky normal that looks a lot like the binomial it's going to have a particular mean and a particular variance and that's our first task as the people who are just guessing and trying to get some partial credit we have to say what mean and variance would lead to a pretty good guess for matching this binomial and you sit there and you're like okay okay I'm feeling the creativity and then it hits you you should like oh binomials have known expressions for means and variances those are equations we've got if somebody tells you the binomial you can use a plug-in equation to figure out the mean it's actually just n * p and there's also an equation for the variance of binomial it's n * P * 1 minus P what if we chose a normal that just match those two statistics so we're going to put the expectation of our binomial that's n * p and we're going to put in the variance of our bomal it's n * P * 1 - p uh so this is 50 and 50 * .5 is 25 so you're like okay I'm going to say why is that particular normal and now I'm going to say the probability that X is greater than equal 65 is pretty much the probability that Y is greater than equal 65 and the probity that Y is greater than 65 is 1 minus the CDF of Y at 65 and we now know what to do with that you just put it into this formula you take 65 subtract off its mean you divide by its standard deviation you get a number which you put into the file lookup table and you get 0.0013 and the person grading you is like wow that's a whole bunch of extra credit or partial credit you got really really close you know it's not exactly the right answer the right answer is 0.18 and you got 0.0013 but you're getting there and you're like oh why didn't I get it perfect is it because this was super hacky and the Galaxy and the binomial are two separate things and you just made it sound like they're the same thing it turns out actually it wasn't such a crazy thing to do after all but you did miss one thing here is a binomial with mual 100 and variance equal to 0.5 and here is the matching normal that you defined look how nice a match that is is that not elegant like that was a good choice I applaud us on our choice uh we actually though did make a mistake and I want to zoom into this section of the graph to talk about this mistake here's the binomial in blue here's the probility of 64 here's a probably 65 here's a probability of 66 we were supposed to be asking what's the probability that X is greater than 65 and so we put 65 into our normal and we got all of this area but we were supposed to include this whole rectangle and we kind of chopped the rectangle and half do you guys see how we did that we only included this half the rectangle we didn't include that half and so there's a whole bunch of things in this rectangle that we didn't approximate very well if we really wanted to be super hacky and legit we should have actually just bumped up this by half a point so that we would have gotten that whole rectangle because we're supposed to getting the probability of less than or equal to 65 which is supposed to include this rectangle that red line should be moved over by half a point if you move that red line over by half a point uh so uh probably Y is greater than oh greater than or equal to 65 ah sorry sorry sorry we want greater than or equal to we wanted all the dark blue which means we need to shift the red line over by half point this way if we said Y is greater than equal 64.5 so we shift the red line over half a step so that you know we take advantage of the fact that we're supposed to include this entire column if you asked this question of why you would have gotten exactly the right answer and in fact the reason we didn't get the right answer wasn't because the normal is a bad approximation of the binomial the reason we didn't get the right answer is simply because we didn't do this little bit complicated continuity correction so it turns out major takeaway you can approximate a binomial which is hard to calculate with a normal and a normal is very easy to calculate in lots of situations we'll talk about when this is valid but if you do so you're approximating a discrete distribution using continuous one and that means when you ask a probability question question you have to be super careful to think about the correction from when you go from the discret world to The Continuous World um I have written down a whole bunch of these Corrections if your discret question about X is probably that x equals 6 in the continuous world to capture that whole rectangle you should do y between 5.5 and 6.5 that will capture the whole rectangle of x equals 6 if you want the probity X is greater than six well that's the same as probably Y is greater than equal 5.5 that allows you to capture the six rectangle and again these are all the different times when you either don't need to include the six rangle or you do need to include the six rectangle anyways there's all these continuity Corrections so you can approximate but when you approximate you have to do a little bit of adding half a step to make sure that the probability question that you ask is the appropriate one for the comparison that tables in your reader you're going to practice it a little bit and that's better done when you do you're practicing this leads us to an interesting situation binomials are hard to calculate we now have two ways to approximate them earlier in class we learned that pan now we've learned about the normal who gets to approximate well here's an example of binomial with 10.04 in this case you can see you know both the pan or the Pan here is kind of a better approximation here's a binomial where the MU or sorry the N is much larger and the p is much more moderate and here if you look this gray Line's not a very good match but the orange line which is the or the normal is a very good match basically the plon approximation is really good when these two categories hold n is large p is small and the normal approximation is great when n is large and the variance is also large and so if you calculate the variance if that's larger than 10 you can use normal approximation and this shows up all the time if there's a choice either is fine um and when you're using the normal you have to do the continuity correction the pon doesn't need it because the pon already discreet the normal is the continuous one okay and here's is a question to practice that this is a real question that Stanford thinks about all the time so you know Stanford has a fixed number of dorms when they admit students they admit people not knowing if they'll come to Stanford and in their Ideal World they admit the perfect number of students so that the people who say yes is equal to their number of freshman dorms is there anyone here who's living in a freshman dorm actually can anyone tell me are we overflowing on freshman dorms like are there freshmen who are living on off-campus do you guys know that happened evgr is happening no evgr a a they maybe try underground healing too so they can yeah man Stanford always has this problem where like too many people come and they have to like once when I was an undergraduate they put them in like a hotel across the street The Freshman were living was a total disaster now they should be thinking I don't know if they're thinking about probabilistically but they should be thinking about probabilistically so let's think about it for Stanford so let's say Stanford accepts 2,480 students every student may come or they may not come and Stanford thinks that the probability that they come is like and if the probability is 68 let's say x is the number of students who will attend how could you answer a question like what's the probably that X is greater than 1745 where imagine 1745 is the number of available dorms so if more than 1745 people come then they don't have enough dorms for everybody if they ask for an actual number there's a few ways you can answer this you could solve this using a binomial every students a coin flip 6 probability of being heads and we want to know the total number of heads that's not wrong but but it's hard to calculate so you could approximate as a pan it turns out pan is a bad choice here though cuz pan really wants P to be very tiny to be a good approximation and 68 is not tiny P wants to be like 05 or something smaller than that the normal approximation though turns out is a very good choice and if you actually sat down and calculated the variance it'd be 540 so 540 is a lot larger than 10 that was our requirement and also n is pretty large 2,480 we want a large n and a moderate variance or sorry a large variance so this is a binomial question but it's one where a normal approximation would just make things a lot easier so we're going to Define approximating normal say why is similar to the binomial we care about its expectation is n * P because that's the expectation of variance and it's variance equals n * P * 1 P because that's the variance of binomial and we can calculate both of those numbers and we can say now we know that y or sorry um sorry Y is going to be our approximating normal the probability that X is greater than 1745 we're going to do a continuity correction say that's about the same as asking what's the probity that the approximating normal is greater than equal to 17455 now we can just solve this you know the probability that a normal is greater than a number it's something that we've done a whole bunch in today's class you just use the CDF so or one minus the CDF in this case and you just plug into the CDF you take in the input you put to the CDF subtract off the gy mean divide by the Gan standard deviation and you get a number so in this case Stanford would feel like hey if we accepted 20480 students students there's a 0.0055 chance that we won't overflow fun fact these are real numbers from a real year uh and then they wrote an actual article because it turned out to be a total disaster they assumed the yield rate would be like 65 and that year the yield rate was like 82% which mean 82% of people were saying yes and they're like putting people people in hotel rooms fun things okay we've already done our pedagogic B but anyways binomial you can approximate it with a gaan I thought that's where we' end but we have some time and I've gotten some super cool or there's so many cool questions about normal and I want to just start showing you a couple more you guys want to see more examples this was a cool question that I got asked by a student have you guys ever heard of the 68% rule fun fact about all gaussians 68% of its probability Mass exists within one standard deviation of the mean always and exactly so what that means is if you take any gin with a mean in a variance if you figure out what's the probability that the random variable is between one standard deviation greater than mean and one standard deviation less that probability is always 68% and the question was is this only true for normal distributions or is this true for all distributions well first of all let me convince you it's true for normal distributions so what's the probability that the distance between your random variable and the mean is less than the variance which is really saying what's the probability that your random variable takes some value between this number and this number we've already broken that up in an earlier problem that's the same as the CDF of the larger number minus the CDF of the smaller number so what's the CDF of any random variable any gaan with a mean mu and standard deviation Sigma evaluate at these points recall that this is now the input to the CDF this is X so if you take that X and subtract off the mean divide by the standard deviation it actually simplifies to just one because here when you take this and subtract off the mean those means cancel and then the standard deviations cancel and you're left with one something similar happens on this side and you're left with five of negative 1 you might look at this and be like uhoh are these two things going to cancel and you're left with the probability of zero they don't cancel because five of a negative number uh is equal to 1 minus 5 of the positive number so you know if you put in a negative 1 into five that's the same as doing 1us 51 if you figure this out if you kept going which you could do using a calculator or you can just use your five table it ends up that there the probability that for any gussian the random variable takes on the value in this range is in fact equal to not 68 but 6826 we didn't put in hard numbers for mean we didn't put in hard numbers for variance and we got this number so whatever your gy is turns out 68% is within one standard deviation does this apply for uniforms just Instinct who thinks that 68% of a uniforms probability will occur within one standard deviation of its mean who thinks nah but why not let's show okay if this is a uniform what's the probability that it's within one standard deviation of this mean exact same formula um but now what's the probability that the random variable is in this range notice in a uniform if you have a range and you want to find the area under the curve what shape is that area under a curve rectangle it's a rectangle so we can skip all the calcul and be like what is the area of this rectangle it's got a width and it's got a height the height is equal to the CDF of the uniform and the width here is just equal to the larger Point minus the smaller point and that's the area of the rectangle and if you solve for this you know um you just reduce you end up with for a uniform 0.58% of its probably Mass within did you guys ever know the 58% rule 58% rule for uniform that 58% of its problem Mass within one standard now you know it's not that important gaussians show up everywhere here's another cool extension idea did you know that gaans are used for for a lot of sports they originally were used in chess but they've shown up in all other sports like basketball so if you want to say what's the probability that the Warriors win a particular game I know we talked about a serious series before but if you want to talk about a particular game a lot of people use this thing called an ELO rating and an ELO calculation which involves gaussians here's how elos work you might have heard about them because they've showed up in a lot of places every team has an ELO score and it's based on its past performance um and we think of that score as being the mean of a normal distribution when they play a game they sample from this mean that's how they play on average but sometimes they play better and sometimes they play worse we think a team wins when the probability when sorry when their ability is greater than the other team's ability invented by this guy called rped ELO and it looks like this it's saying the Warriors you know based on their past performance they have a mean performance of 1657 but when they show up to play they might play Above their mean or they might play below their mean and their ability when they show up on a particular night will be governed by this gaussian the opponents will also have an ELO rating and that ELO rating will be the mean of gaan with the exact same variance they set this per sport in ELO's world and you know when you show up you might outperform your mean and you might underperform your mean but every team is going to get an AB ility on a given night and whoever's ability is larger wins now actually this is kind of awful or I don't know if we should put a value judgment ELO rating showed up in chess then they transferred to sports I don't know if you know this for the longest time this app called Tinder was using ELO ratings to figure out how they were going to be giving matches which like a whole awful conversation we could have about that but anyways the important thing is Warriors have a good probability of winning in this game and let's talk about exactly what that prob this is an interesting thing a is this gaussian AO is this gaussian for the opponent's ability and I want to know what's the probability that this random variable is greater than this random variable that's so different than asking the probability that a random variable is greater than a number you know up till now it's been a random variable and a number and now I've got two random variables on either side oh I promise when we get to Theory section we'll talk about exactly how you could solve this uh with a closed formula but I also want to show you something that we often do with random variables as computer scientists how would you solve this if I didn't tell you a really complicated closed formula for dealing with two random variables in an equal sign for now I'll tell you it's more complicated than just doing something like a CDF so if you didn't have any access to the mathematics for comparing two random variables man how would you figure out the probability that this random variable is greater than that random variable someone has an idea sampling sampling yes we're computer scientist we can always fall back on sampling when everything get hard so here's what we're going to do we're going to repeat 10,000 times and we're going to pull a random variable for the Warriors from their gaussian and we're going to pull a random variable from the opponent from their gaussian when you do stats. norm. RVs it does this thing called sampling it doesn't give you back the gaussian it gives you back a pull from the gaussian so will give you a number just and it'll be governed by this Pro particular probability distribution and we'll take each of those numbers and we'll just compare was that number greater than zero in case We'll add one and we're going to repeat 10,000 times and see how often the pull from this gaussian was greater than the pull from that gaussian which is super cool um by sampling you get 0.748 which according to this ELO model uh is very very close to the probability that the Warriors would win that particular game is there a better way I promise you that we will tell you a better way oh but this leads to one final extension idea that I just think is so neat for computer scientists to think about this idea of a gaussian sample is so interesting like how did how did python do that right when you write this python script so Random has a function called gaus and if you get a mean and standard deviation it gives you a pull from that gaus and by a pull I mean like if you set mean is equal to five and standard is one if you run this 10 times you get 10 different numbers are you curious how did python do that can I tell you let's this the joy of being a teacher I get to tell you when I want to um here's the algorithm that python uses and I love it because it is going to use our Instinct of a CDF it's supposed to be doing a pull where the likelihood is governed by the probability density function it's governed by this beautiful equation here which we know is very hard to integrate here's the steps by step for how it does it step one you are going to pick a number between 0 one uniformly computers are quite good at that any number somebody give me a number between 0 and one I'm glad that you chose that number so let's say you chose like 08 what they do is they do the inverse transfer of the uh CDF they say what number would you put into the CD F that would have given the number between Z and one that you chose so you know maybe you get um that this is 0.9 and you say which value leads to a 0.9 and a 0.1 on in the CDF and it gives you maybe a 1.2 the next time you choose a number between 0 and one maybe you get something like 3 and then when you ask the inverse F question what input to F function the CDF would I have had to give to get 0.3 you get a different number let's say in this case you get .45 that's how it does it I've told you the algorithm I haven't convinced you that it's right and convincing you that it's right I think is quite interesting how much more likely is 1.2 the.45 we would like that relative likelihood to be governed by the PDF well if we think about how likely it is we kind of want to think about like how much vertical space is covered by numbers close to 1.2 if you think about how much vertical space is covered it kind of has to do with what's the slope of the CDF at that point if you think about how much vertical space is covered over here it kind of has to do with what's the slope of the CDF at this point and the slope of the CDF is going to be the derivative of the CDF and you know what the C derivative of the CDF is man the derivative of this thing is that thing it's the PDF it's always the PDF you derive the CDF you ask the slope of the CDF at any point and you will get the probability density function what a beautiful thing so that is the mathematics behind how this actually works and now you know next time you pull a Galaxy and you think oh we learned about that cool algorithm it's called inverse transform sampling if you want to know um I did put this is not something I want you to go over I did put in a challenge if you guys want to think about a challenge between now and next Wednesday here's the thing to think about otherwise just come back in next minut we'll continue this wonderful conversation have fantastic day I can't wait to continue talking to you guys about probability cheers