So let me begin by telling you what a topological ordering of a directed graph is. Essentially it's an ordering of the vertices of the graph so that all of the arcs the directed edges of the graph only go forward in the ordering. So let me encode an ordering by a labeling of the vertices with the numbers 1 through n. This is just to encode the position of each vertex in this ordering. So formally there's going to be a function which takes vertices of G and maps them to integers between 1 and n. Each of the numbers 1 through n should be taken on by exactly one vertex. Here n is the number of vertices of g. So that's just a way to encode an ordering. And then here's really the important property that every directed edge of ges forward in the ordering. That is if uv is a directed edge of the directed graph g then it should be that the f value of the tail is less than the f value of the head. That is this directed edge has a higher f value as you as you traverse it in the correct direction. Let me give you an example just to make this more clear. So suppose we have uh this very simple directed graph with four vertices. Let me show you two different totally legitimate topological orderings of this graph. So the first thing you could do is you could label S1, V2, W3, and T4. Another option would be to label them the same way except you can swap the labels of V and W. So if you want, you can label V3 and W2. So again what these labelings are really meant to encode is a ordering of the vertices. So the blue labeling you can think of as encoding the ordering in which we put S first then V then W and then T. Whereas the green labeling can be thought of as the same ordering of the nodes except with W coming before V. What's important is that the pattern of the edges is exactly the same in both cases. And in particular, all of the edges go forward in this ordering. So in either case, we have S with edges from S to V and S to W. So that looks the same way pictorially, whichever order V and W are in. And then symmetrically, there are edges from V and W to T. So you'll notice that no matter which order we put V and W in, all four of these edges go forward in each of these orderings. Now if you tried to put V before S, it wouldn't work because the edge from S to V would be going backward if V preceded S. Similarly, if you put T anywhere other than the final position, you would not have a topological ordering. So in fact, these are the only two topological orderings of this directed graph. I encourage you to convince yourself of that. Now, who cares about topological orderings? Well, this is actually a a very useful subine. Uh this has been come up in all kinds of applications. really whenever you want to sequence a bunch of tasks when there's precedence constraints among them. By precedence constraint I mean one task has to be finished before another. You can think for example about the courses in some kind of undergraduate major like a computer science major. Here the vertices are going to correspond to all of the courses and there's a directed edge from course A to course B if course A is a prerequisite for course B if you have to take it first. So then of course you'd like to know a sequence in which you can take these courses so that you always take a course after you've taken its prerequisites and that's exactly what a topological ordering will accomplish. So it's reasonable to ask the question when does a directed graph have a top topological ordering and when a graph does have such an ordering how do we get our grubby little hands on it? Well, there's a very clear necessary condition for a graph to have a topological ordering, which is it had better be a cyclic. Put differently, if a directed graph has a directed cycle, then there's certainly no way there's going to be a topological ordering. So, I hope the reason for this is fairly clear. Consider any directed graph which does have a directed cycle and consider any purported way of ordering the vertices. Well, now just traverse the edges of the cycle one by one. So you start somewhere on the cycle and if the first edge goes backward, well, you're already screwed. You already know that this ordering is not topological. No edges can go backward. So evidently the first edge of this cycle has to go forward. But now you have to traverse the rest of the edges on this cycle and eventually you come back to where you started. So if you started out by going forward, at some point you have to go backward. So that edge goes backward in the ordering violating the property of a topological ordering. That's true for every ordering. So directed cycles exclude the possibility of topological orderings. Now the question is well what if you don't have a cycle? Is that a strong enough condition that you're guaranteed to have a topological ordering? Is the only obstruction to sequencing jobs without conflicts the obvious one of having circular precedence constraints. So it turns out not only is the answer yes. If as long as you don't have any directed cycles, you're guaranteed a topological ordering. But we can even compute one in linear time, no less, via depth first search. So before I show you the super slick and super efficient reduction of computing topological orderings to depth first search, let me first go over a pretty good but slightly less slick and slightly less efficient uh solution to help build up your intuition about directed as cyclic graphs and their topological orderings. So for the straightforward solution, we're going to begin with a simple observation. Every directed as cyclic graph has what I'm going to call a sync vertex. That is a vertex without any outgoing arcs. So in the four node directed as cyclic graph we were exploring on the last slide, there is exactly one source vertex and that's excuse me sync vertex. That's this rightmost vertex here. Right? That has no outgoing arcs. The other three vertices all have at least one outgoing arc. Now, why is it the case that a directed as cyclic graph has to have a sync vertex? Well, suppose it didn't. Suppose it had no sync vertex. That would mean every single vertex has at least one outgoing arc. So, what could we do if every vertex has one outgoing arc? Well, we could start in an arbitrary node. We know it's not a sync vertex because we're assuming there aren't any. So, there's an outgoing arc. So, let's follow it. We get to some other node. By assumption, there's no sync vertex. So, this isn't a sync vertex. So there's an outgoing arc. So let's follow it. We get to some other node that also has an outgoing arc. Let's follow that and so on. So we just keep following outgoing arcs. And we do this as long as we want because every vertex has at least one outgoing arc. Well, there's a finite number of vertices, right? This graph has say n vertices. So if we follow n arcs, we're going to see n plus one vertices. So by the pigeon hole principle, we're going to have to see a repeat, right? So if n plus one vertices, there's only n distinct vertices. We're going to see some vertex twice. So for example, maybe after I take the outgoing arc from this vertex, I get back to this one that I saw previously. Well, what have we done? What happens when we get a repeated vertex? By tracing these outgoing arcs and repeating a vertex, we have exhibited a directed cycle. And that's exactly what we're assuming doesn't exist. We're talking about directed as cyclic graphs. So put differently, we just proved that a vertex with no sync vertex has to have a directed cycle. So a directed a cyclic graph therefore has to have at least one sync vertex. So here's how we use this very simple observation now to compute a topological ordering of a directed a cyclic graph. Well, let's do a little thought experiment. Suppose in fact this graph did have a topological ordering. Let's think about the vertex which goes last in this topological ordering. Remember any arc which goes backward in the ordering is a violation. So we have to avoid that. We have to make sure every arc goes forward in the ordering. Now any vertex which has an outgoing arc we better put somewhere other than in the final position. Right? So the node that we put in the final position, all of its arcs are going to wind up all of its outgoing arcs are going to wind up going backward in the topological ordering. There's nowhere else they can go. This vertex is last. So in other words, if we plan to successfully compute a topological ordering, the only candidate vertices for that final position in the ordering are the sync vertices. That's all that's going to work. We put a non-sync vertex there, we're toast. It's not going to happen. Fortunately, if it's directed a cyclic, we know there is a sync vertex. So, let V be a sync vertex of G. If there's many sync vertices, we pick one arbitrarily. We set V's label to be the maximum possible. So, if there's n vertices, we're going to put that in the nth position. And now we just recurse on the rest of the graph, which has only n minus one vertices. So, how would this work in the example on the right? Well, in the first iteration or the first outermost recursive call, the only ca the only sync vertex is this rightmost one circled in green. So there's four vertices. So we're going to give that the label four. So then having labeled that four, we delete that vertex and all the edges incident to it and we recurse on what's left of the graph. So that would be the leftmost three vertices plus the leftmost two edges. Now this graph has two sync vertices after we've deleted four and everything from it. So both this top vertex and this bottom vertex are syncs in the residual graph. So now in the next uh recursive call we can choose either of those as our sync vertex. Uh because we have two choices that generates two topological orderings. Those are exactly the ones that we saw in the example. But if for example we choose this one to be our sync vertex then that gets the label three. Then we recurse just on the northwesternmost two edges. This vertex is the unique sync in that graph that gets the label two. And then we recurse on the one node graph and that gets the label one. So why does this algorithm work? Well there there's just two quick observations we need. So first of all we need to argue that it makes sense that in every iteration or in every recursive call we can indeed find a sync vertex that we can assign in the final position that's uh still unfilled. And the reason for that is just if you take a directed as cyclic graph and you delete one or more vertices from it, you're still going to have a directed asyclic graph, right? You can't create cycles by just getting rid of stuff. You can only destroy cycles. And we started with no cycles. So through all the intermediate recursive calls, we have no cycles. By our first observation, there's always a sync. So the second thing we have to argue is that we really do produce a topological ordering. So remember what that means. That means for every edge of the graph it goes forward in the ordering. That is the head of the arc is given a position later than the tail of the ark. And this simply follows because we always use sync vertices. So consider the vertex V which is assigned to the position I. This means then that when we're down to a graph that has only I vertices remaining, V is a sync vertex. So if I is a if V is a sync vertex for when only the first I vertices remain, what property does it have in the original graph? Well, it means all of the outgoing arcs that it has have to go to vertices that were already deleted and assigned higher positions. So for every vertex by the time it actually gets assigned a position, it's a sync and it only has incoming arcs from the as yet unsigned vertices. its outgoing arcs all go forward to vertices that were already assigned higher positions and got deleted previously from the graph. So now we have under our belt a pretty reasonable solution for computing a topological ordering of a directed as cyclic graph. In particular, remember we observed that if a graph does have a directed cycle, then of course there's no way there's a topological ordering. However, you order the vertices, some edge of the cycle is going to have to go backward. And the solution on the previous slide shows that as long as you don't have a cycle, it guarantees a topological ordering does indeed exist. And in fact, it's a constructive proof, a constructive argument. It gives an algorithm. What you do is you just keep plucking off syncs, sync vertices one at a time and populating the ordering from right to left as you keep uh peeling off these syncs. So that's a pretty good algorithm. It's not too slow. And actually, if you implement it just so you can even get it to run in linear time. But I want to conclude this video with an application of depth first search which is a very slick very efficient computation of a topological ordering of a directed as cyclic graph. So we're just going to make two really quite minor modifications to our previous depth first search uh subruine. The first thing is we have to embed it in a for loop just like we did with breath first search when we were computing the connected components of an undirected graph. That's because in computing a topological ordering we better give every single vertex a label. We better look at every vertex at least once. So to do that we'll just make sure there's an outer for loop and then if we have multiple components we'll just make sure to invoke DFS as often as we need to. The second thing we'll do is we'll add a little bit of bookkeeping and this will make sure that every uh node gets a label and in fact these labels will define a topological ordering. So let's not forget the code for depth first search. This is where you're given a graph G. In this case we're interested in a directed cyclic graph and you're given a start vertex S. And what you do is you as soon as you get to S, you very aggressively start trying to explore its neighbors. Of course, you don't visit any vertex you've already been to. You keep track of who you visited. And if you find any vertex that you haven't seen before, you immediately start recursing on that node. So I said the first modification we need is to embed this into a outer for loop to ensure that every single node gets labeled. So I'm going to call that subutine dfs-loop. It does not take a start vertex. Initialization. All nodes start out unexplored, of course. And we're also going to keep track of a global variable, which I'll call current label. This is going to be initialized to n. And we're going to count down each time we finish exploring a new node. And these will be precisely the f values. These will be exactly the positions of the vertices uh in the topological ordering that we output. In the main in the main loop, we're going to iterate over all of the nodes of the graph. So for example, we just do a scan through the node array. As usual, we don't want to do any work twice. So for ver the vertex has already been explored in some previous invocation of DFS. We don't we don't search from it. This should all be familiar from our embedding of breath first search and a for loop when we computed the connected components of an undirected graph. And if we get to a vertex V of the graph that we haven't explored yet, then we just invoke DFS in the graph with that vertex as the starting point. So the final thing I need to add is I need to tell you what the f values are, what the actual assignments of vertices to positions are. And as I foreshadowed, we're going to use this global current label variable. And uh that'll have us assign vertices to positions from right to the left, very much mimicking what was going on in our recursive solution where we plucked off sync vertices one at a time. So when's the right time to assign a vertex its position? Well, it turns out the right time is when we completely finished with that vertex. So we're about to pop the recursive call from the stack corresponding to that vertex. So after we've gone through the for loop of all the edges outgoing from a given vertex, we set f of s equal to whatever the current label is and then we decrement the current label. And that's it. That is the entire algorithm. So the claim is going to be that the f values produced which you'll notice are going to be the integers between n through one because dfs will be called eventually once on every vertex and it will get some integer assignment at the end and everybody's going to get a distinct value and the largest one is n and the smallest one is one. The claim is that is a topological ordering. Clearly this algorithm is just as blazingly fast as dfs itself with just a trivial amount of extra bookkeeping. Let's see how it works on our running example. So let's just say we have this four node directed graph that we're getting quite used to. So this has four vertices. So we initialize the current label variable to be equal to four. So let's say that in the outer DFS loop, let's say we start somewhere like the vertex V. So notice in this outer for loop, we wind up considering the vertices in a totally arbitrary order. So let's say we first call DFS from this vertex V. So what happens? Well, the only place you can go from V is to T. And then at T, there's nowhere to go. So we recursively call dfs a t. There's no edges to go through. We finish the for loop. And so t is going to be assigned an f value equal to the current label which is n. And here n is the number of vertices which is four. So f of t is going to get sorry t is going to get the assignment the label four. So then now we're done with t. We backtrack back to v. We decrement the current label. As we finish up with t, we get to v. And now there's no more outgoing arcs to explore. So it for loops finish. So we're done with it with in depth first search. So it gets what's the new current label which is now three. And again having finished with V, we decrement the current label which is now down to two. So now we go back to the outer for loop. Maybe the next vertex we consider is the vertex T. But we've already been there so we won't don't bother DFS on T. And then maybe after that we try it on S. So maybe S is the third vertex that the for loop considers. We haven't seen S yet. So we invoke DFS starting from the vertex S. From S, there's two arcs to explore. The one with V. V we've already seen. So nothing's going to happen with the arc SV. But on the other hand, the arc SW will cause us to recursively call DFS on W. From W, we try to look at the arc from W to T, but we've already been to T, so we don't do anything. That finishes up with W. So depth first search then finishes up at the vertex W. W gets the assignment of the current label. So f of W equals 2. We decrement current label. Now its value is one. Now we backtrack to S. We've already considered all of S's outgoing arc. So we're done with S. It gets the current label which is one. And this is indeed one of the two topological orderings of this graph that we exhibited a couple slides ago. So that's the full description of the algorithm and how it works in a concrete example. Let's just discuss what are its uh key properties, its running time and its correctness. So as far as the running time of this algorithm, the running time is linear. It's exactly what you'd want it to be. And the reason the running time is linear is for the usual reasons that uh these graph search algorithms have run in linear time. You're explicitly keeping track of which nodes you've been to so that you don't visit them twice. So you only do a constant amount of work for each of the end nodes. And each edge in a directed graph, you actually only look at each edge once when you visit the tail of that edge. So you only do a constant amount of work per edge as well. Of course, the other key property is correctness. That is we need to show that you are guaranteed to get a topological ordering. So what does that mean? That means every edge, every arc travels forward in the ordering. So if uv is an edge, then f of u the label assigned to u in this algorithm is less than the label assigned to v. The proof of correctness splits into two cases depending on which of the vertices u or v is visited first by depth first search. Because of our for loop which iterates over all of the vertices of the graph g, depth first search is going to be invoked exactly once from each of the vertices. either U or V could be first. Uh both are possible. So first let's assume that U is visited by DFS before V. So then what happens? Well remember what depth first search does. When you invoke it from a node, it's going to find everything findable from that node. So if U is visited before V, that means V isn't yet explored. So it's uh it's a candidate for being discovered. Moreover, there's an arc straight from U to V. So certainly DFS invoked at U is going to discover V. Furthermore, the recursive call corresponding to the node V is going to finish is going to get popped off the program stack before that of U. The easiest way to see this is just to think about the recursive structure of depth for search. So when you call depth for search from U, that recursive call that's going to make further recursive calls to all of the relevant neighbors including V. And use call is not going to get popped off the stack until V's does uh beforehand. That's because of the last in first out nature of a stack or of a recursive algorithm. So because V's recursive call finishes before that of U, that means it will be assigned a larger label than U. Remember the labels keep decreasing as more and more recursive calls get popped off the stack. So that's exactly what we wanted. Now what's up in the second case? Case two. So this is where V is visited before U. And here's where we use the fact that the graph has no cycles. So there's a direct arc from U to V. That means there cannot be any directed path from V all the way back to U. That would create a directed cycle. Therefore, DFS invoked from V is not going to discover U. There's no directed path from V to U. Again, if there was, there'd be a directed cycle. So it doesn't find you at all. So the recursive call of V again is going to get popped before U's is even pushed onto the stack. So we're totally done with V before we even start to consider U. So therefore for the same reasons since V's recursive call finishes first its label is going to be larger which is exactly what we wanted to prove. So that concludes the first quite interesting application of depth first search. In the next video we'll look at an even more interesting one which computes the strongly connected components of a directed graph. This time we can't do it in one death first search.