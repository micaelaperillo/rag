having mastered Computing the connectic components of an undirected graph in linear time let's now turn our attention to directed graphs which also arise in all kinds of different applications now the good news is is we'll be able to get just a blazingly fast primitive for computing connectivity information for directed graphs the bad news if you want to call it that is we'll have to think a little bit harder so it won't be as obvious how to do it but by the end of this lecture uh you will know a linear time algorithm with very good constants really just based on depth first search for computing all of the pieces of a d directed graph in fact it's not even so obvious how to define pieces how to define connected components in a directed graph certainly not as obvious as it was with undirected graphs so to see what I mean let's consider the following four node directed graph so on the one hand this graph is in some sense in one piece if this was an actual physical object made say of a bunch of strings connected to each other and we picked it up with our hands it wouldn't fall apart into two pieces it would hang together in one piece on the other hand when you think about moving around around this network it's not connected in the sense that we might think about you cannot get from any one point a to any other point B for example if you start at the rightmost node in this graph certainly there's no directed path that will get you to the leftmost node so what's typically studied and most useful for directed graphs is what's called strong connectivity and a graph is strongly connected if you can get from any one point to any other point and vice versa and the strong kinetic components then informally are the maximal portions of this graph the maximal regions which are internally strongly connected so the maximum regions from within which you can get from any one point a to any other point B along a directed graph for the record let me go ahead and give you a formal definition although you know this intuition is perfectly valid just regions where you can get from anywhere to anywhere else so we say that the strongly connected components of a directed graph or the secc's for short and as in the unded case we're going to give a somewhat slick definition rather than talking about maximal region satisfying some property we're going to talk about the equivalence classes of a particular equivalence relation but really it means the same thing this is just sort of the more mathematically mature way of writing it down so the equivalence relation we're going to use it's on nodes of the graph and we'll say that u a node is related to a node V if you can get from U to V via directed path and also from V to U and some other directed path I'm not going to bore you with the verification that this is an equivalence relation that's something you can work out in the privacy of your own home so remember what it means to be an equivalence relation it's reflexive that is everybody's related to itself but of course there is a path from every node to itself it also means that it's symmetric so if U is related to V then V is related to U well again by definition we're saying that the paths are mutually the vertices are mutually reachable from each other so that's clearly symmetric by definition and then it has to be transitive and the way you prove it's transitive is you just Pac paths together and it just works the way you'd expect it to so let's illustrate this concretely with a a somewhat more complicated directed graph so here's a directed graph and I claim that it has exactly Four Strong and connected components has a triangle on the left a triangle on the right has this single node in top and then it has this directed for cycle with a diagonal at the bottom so what I hope is pretty clear is that each of these Circle regions is indeed strongly connected that is if you start from one node in one of these circled regions you can have a directed to any other node uh so that's certainly true cuz on a directed cycle you can get from any one starting point to any other place and all of these have directed cycles and then there's the one strong component that just has the one node which is obviously strongly connected what I also claim is true is that all of these regions are maximal subject to being strongly connected that's why they're the strongly connected components that's why they're the equivalence classes of this equivalence relation we just defined so if you take any two pairs of nodes which line two different circles you either won't have a path from one from the first one to the second one or you won't have a directed path from the second one back to the first one in fact the structure of the strong components in this black graph exactly mirrors uh the directed aycc graph that we started with in Red so in the same way in the red four node graph you can't move from right to left here in this bigger graph you can't move from any of the circled sec's to the right to any of the circled secs to the left so for example from the rightmost nodes there's are no directed paths to the leftmost nodes so that's a recap of the definition of Australian kinetic components I've motivated in a separate video uh some reasons why you might care about Computing strong connectic components in particular on extremely large graphs which motivates the need for blazingly fast sub routines uh so for free Primitives that will let you compute connectivity information so you'd love to be able to just know the pieces of a directed graph maybe you don't even know why they're going to be useful but you just compute them because why not it's a for-free primitive so that's what I'm going to give you in this lecture so the algorithm we're going to present is based on depth for search and that's going to be the main reason why it's going to be so blazing when fast is because depth first searched is blazingly fast now you might be wondering what on Earth does Graph Search have to do with Computing components they don't seem obviously related so let's return to the same directed graph that I showed you on the previous slide and to see why something like death first search might conceivably have some use for computing strong components suppose we call depth first search starting from this red node as a starting point what would it explore so remember what the guarantee of something like depth first search or bread first search for that matter is you find everything that's findable but naturally nothing else so what is findable from this red node where by findable I means you can reach it from a directed path emanating from this red node well there's not much you can do so from here you can explore this Arc and you can explore this Arc and then you can go backward and so if you do DFS or BFS from this node you're going to find precisely the nodes in this triangle all the other arcs involved go the wrong direction and they won't be traversed uh by say a depth first search call so why is that interesting what's interesting is that if we invoke DFS from this red node or any of the three nodes from this triangle then it's going to discover precisely this stol kinetic component precisely the three nodes in this circled SEC so that seems really cool seems like maybe we just do a DFS and boom we get an SEC so maybe if we can do that over and over again we'll get all the SC so that's a good initial intuition but something can go wrong suppose that instead of initiating DFS from one of these three nodes on the triangle we say initiate it from this bottommost node in green so remember what is the guarantee of a graph search subroutine like DFS it'll find everything findable but of course nothing more so what's findable from this green node well naturally everything in its own SEC right so the four nodes here it'll certainly find those four nodes on the other hand if we start from this green node since there are arcs that go from this bottommost sec to the rightmost SEC not only will this DFS call find the four nodes in the green nodes strong component but it'll also Traverse these blue arcs and discover the three nodes in the red triangle so if we call DFS from this green node we'll capture all seven of these so the point is if we called DFS it looks like we're going to get a union of possibly multiple secc's in fact in the worst case if we invoke DFS from the leftmost node what's it going to discover it's going to discover the entire graph and that didn't give us any insight into the strong component structure at all so what's the takeaway point is the takeaway point is if you call DFS from just the right place you'll actually uncover an SEC if you call it from the wrong place it will give you no information at all so the magic of the algorithm that we're going to discuss next is we'll show how in a super slick pre-processing step which ironically is itself a called a depth first search we can in linear time compute exactly where we want to start the subsequent depth for searches from so that each invocation gets us exactly one strongly connected component and nothing more so the algorithm that I'm going to show you is Du to Kazar Raju and it will show The Following theorem that the strong kinetic components of a directed graph can be computed in linear time and as we'll see the constants are also very small it's really just going to be two passes of depth for search and again let me remind you that for many problems it's natural to assume that the number of edges is at least the number of nodes because you're only interested in cases where the graph is connected of course when you're Computing connected components that's one of the most natural cases where you might have a super sparse broken up graph so we're not going to assume m is at least n so that's why linear time is going to be M plus n because that's the size of the input and we don't know either M could be bigger than n or n could be bigger than M we have no idea Kazar raju's algorithm is shocking in its Simplicity it has three steps let me tell you what they are first very mysteriously we're going to reverse all of the arcs of the given graph totally not clear why that would be an interesting thing to do yet then we're going to do our first pass our first depth first search and we're going to do it on the reverse graph now the naive way to implement this would be you literally construct a new copy of the input graph with all of the arcs in the reverse Direction and then just run dep for search on it of course the sophis the sort of obvious optimization would be to just run DFS on the original graph but going across arcs backward so I'll let you think through the details of how you do that but that just works you run DFS and instead of going forward along edges you go backward along edges that simulates depth for search on the reverse graph now I've written here DFS Loop and that just means the usual trick where to make sure that you see all of the nodes of of the graph even if it's disconnected you have an outer loop where you just try each starting point separately if you haven't already seen it then you run DFS from that given node I'll be more detailed on the next slide and the third step is just your in depth first search again but this time on the original graph now at this point you should be thinking that I'm totally crazy right so what are we trying to do we're trying to compute these strongly connected components we're trying to actually compute real objects these maximal strongly connected regions and all I'm doing is searching the graph and I do it once forward I do it once backward I mean I'm not doesn't really seem like I'm Computing anything so here's the catch and it's a very minor catch so we're need going to need to do a little bit of bookkeeping it's going to be very low overhead so we'll still have a blazingly fast algorithm so but with a little bit of bookkeeping here's what's going to happen the second depth first search which searches the graph with will in it in its search process discover the St kinetic components one at a time in a very natural way and that'll be really obvious when we do an example which we'll do in just a second now for the second depth aearch to work in this magical way where it just discovers thean connecting components one at a time it's really important that it executes the depth for searches in a particular order that it goes through the nodes of the graph in a particular order and that is exactly the job of the first pass the depth first search on the reverse Gra gra is going to compute an ordering of the nodes which when the second depth first search goes through them in that order it will just discover the secc's one at a time in linear time so let me say a little bit more about the form of the bookkeeping and then I'll show you how that bookkeeping is kept in as we do depth first search so we're going to have a notion of a finishing time of a Vertex and that's going to be computed in the first pass when we do depth research on the reverse graph and we're going to make use of this data in the second pass so rather than just going through the nodes of the graph in an arbitrary order like we usually do when we sort of have a looped depth first or breath first search we're going to make sure that we go through the vertices in decreasing order of these finishing times now there's still the question of in what sense does this second depth first search discover and Report the strong kinetic components that it finds so we're going to label each node in the second pass with what we call a leader and the idea is that the nodes in the same Sten ktic component will be labeled with exactly the same leader node and again all of this will be much more clear once we do a concrete example but I want to have it down for the record right now so that's the algorithm at a high level it's really just two passes of DFS with some bookkeeping but this is underspecified you really uh shouldn't understand how to implement the algorithm just yet so what do I owe you I owe you exactly what I mean by DFS Loop although this you've seen uh more or less in the past it's just a loop over all the vertices of the graph and then if you haven't seen something yet you DFS from that starting point I need to tell you what finishing times are and how they get computed they're just going to be integers 1 to n which is basically when depth first search gets finished with one of the nodes and then I need to tell you how you compute these laders so let me tell you all three of those things on the next slide so the Workhorse for Kazar raju's strong kinetic components algorithm is this DFS Loop sub routine and it takes as input a graph okay so it does not take as input a starting node it's going to Loop over possible starting nodes now for the bookkeeping to compute finishing nodes we're going to keep track of a global variable that I'll call T which we initialize to zero the point of T is to count how many nodes we've totally finished exploring at this point so this is the variable we use to compute those finishing times in the first pass that magical ordering that I was talking about now we're also going to have a second Global variable to compute these things I was calling leaders and these are only relevant for the second pass so what s is going to keep track of is the most recent vertex from which a DFS was initiated so to keep the code simple I'm just going to do all of the bookkeeping in the DFS Loop so but really DFS Loop gets called twice once on the reverse graph once in the forward graph and we only need to compute these finishing times in the first pass on the reverse graph and we only need to compute these leaders on the second paths for the forward graph but let's just keep them both in there uh Just for kicks now we're going to need to Loop through the vertices and so the question is in what order are we going to Loop through the vertices and that's going to happen differently in the two different passes but let me just use some common notation let's just assume in the sub routine that the nodes are somehow labeled from 1 to n in our first depth for search it's going to be labeled totally arbitrary so these are basically just the names of the node or their position in the node array whatever you used do it in some arbitrary order now the second time we run DFS loop as indic ated on the previous slide we're going to use the finishing times as the labeling and as we'll see the finishing times are indeed numbers between 1 and N so now what we do is we just iterate through the nodes in decreasing order and if we haven't already seen node I then we initiate a DFS from it so as usual we're going to be maintaining a local Boolean to keep track of whether we've already seen a node yet in one of the DFS passes now remember the global variable s is responsible for keeping track of the most recent node from which depth first search had been initiated so if I is not explored and we initiate a depth first search from it we better reset s then we do the usual DFS NG G starting from the source node I so for completeness let me just remind you uh what the depth for search sub routine looks like so now we're given a graph and a starting node so the first time we see a node we mark it as explored and just a side note that once a node is marked explored it's explored for this entire invocation of DFS Loop okay so even if this DFS from a given node I finishes and then the outer for Loop Marches On and encounters I again it's still going to be marked as explored now one of our bookkeeping jobs is to keep track of uh from which vertex did the DFS that discovered I get called so when I is first encountered we remember that s was the node from which this DFS originated and that by definition is is the leader of I and then we do what we always do with depth for search we immediately look at uh the arcs going out of I and we try to recursively DFS on any of those although of course we don't bother to do it if we've already seen those nodes now once this for Loop has completed once we've examined every outgoing Arc from I and for each node J either we already saw it in the past or we've recursively explored from J and have returned at that point we call ourselves done with node I there's no more outgoing Arc to explore we think of it being finished remember T is the global variable that's keeping track of how many nodes we're done with so we increment T because now we're done with I and we also remember that I was the teeth vertex with which we finished that is we set I's finishing time to BT because death for search is guaranteed to visit every node exactly once and that therefore finish with every node exactly once this Global counter T well when the first node is finished it will be value one then when the next node gets finished it'll have value two then it'll have value three and so on when the final node gets finished with it'll have value n so the finishing times of the nodes are going to be exactly the integers from 1 to n let's make this much more concrete by going through a careful example in fact I think it'll be better for everybody if you yourself Trace through part of this algorithm on a concrete example so let me draw a nine known graph for you so to be clear let's assume that we've already executed step one of the algorithm that is we've already reversed the graph so that is this blue graph that I've drawn on the slide this is the reversal we've already reversed the arcs moreover the nodes are labeled in some arbitrary way from 1 to n just assume these are how they show up in the node array for example and remember in the DFS Loop routine you're supposed to process the nodes from the from top to bottom from n down to one so my question for you then is in the second step of the algorithm when we run DFS Loop and we process the nodes from the highest name nine in order down to the lowest name one what are the finishing times that we're going to compute as we run DFS Loop now it is true that you can get different finishing times depending on the different choices that DFS Loop has to make about which outgoing Arc to explore next but I've given you four options for what the finishing times of the nodes 1 2 3 all the way up to 9 respectively might be and only one of these four could conceivably be an output of the finishing times of DFS loop on this scen graph so which one is it all right so the answer is the fourth option that is the only one of uh these four sets of finishing times that you might see uh being computed by DFS loop on this blue graph so let's go ahead and Trace through DFS Loop and see how we might get this set of finishing times so remember in the main Loop we start from the highest node nine and then we descend down to the to the lowest node one so we start by invoking DFS from the node 9 so now from here there's only one outgoing Arc we have to go to so we Mark nine is explored uh and then there's only one place we can go we can go to six so we Mark six is explored now there's two places we can go next we can either go to three or we can go to eight and uh you know in general DFS could do either one now to generate this uh fourth set of finishing times I'm going to need to assume that I go to three first okay so again what DFS does what we're assuming it does it starts at 9 and it has to go to Six it marks those as explor then it goes to three it does not go to eight first it goes to three first now from three there's only one outgoing Arc which goes to nine but nine we've already marked as explored so it's not going to re-explore nine it's going to skip that Arc since that that's three's only outgoing Arc then that four Loop completes and so then three is the first node to finish so when we finish with three we increment T it started at zero now it's one and we set the finishing time of three to be one just like we said it was in the example so now we go back now we backtrack to six now we have another outgoing Arc from six to explore so now we go to eight from eight we have to go to two from two we have to go to five from five we have to go to eight eight we've already seen so then we're going to be done with five because that was its only outgoing Arc so then we increment T now it's two and the finishing time of five is going to be two as promised so now we backtracked to two there's no more outgoing Mars from two so two is going to be the third one that we finish as promised then we finish with eight so the finishing time for eight is going to be the fourth node to be done as promised now we backtrack to six we're done with six that's the fifth node to be completed as promised and then finally we got all the way back to where we started at Nine and Nine is the sixth node to be completed as promised now if we were Computing those laders all of these nodes would get the leader nine but again the laders are only relevant for the second path so we're just going to ignore the laders as we're doing this Trace we're just going to keep track of the finishing times so now we're not done so all we did is we finished with the DFS that is invoked from the node n and we found six of the nodes total in that uh depth for search so now we return to the outer for Loop and we decrement I so it started at nine we're done with that now we go down to eight we say have we already seen eight yes Eight's already explored so we skip it we go we decrement I down to seven we say have we already seen node seven no we have not okay seven is not yet explored so we invoke DFS now from node seven seven has two outgoing arcs it can either go to four or it can go to nine let's say it checks the outgoing Arc to nine first now nine we already explored granted that was in an earlier part of the for Loop but we remember that we we're going to keep track of who got explored on previous iterations of the for Loop so we don't bother to re-explore nine so we ski that so now from Seven we have to go go from to four from four we have to go to one from one we have to go back to seven Seven's already been explored so we backtrack now we're down with we're done with one so one is the next one we're completed with and the finishing time of one is going to be seven as promised we backtrack to four there's no more outgoing arcs from four to explore so that's going to be the eighth one to finish as promised and then the last one to finish is poor node 7 it is last so that would be an example of how the DFS Loop sub routine computes finishing times on a reversed graph so now let's work through the second pass on the forward version of the graph using the same example now remember the point of the first pass is to compute a magical ordering and the Magical order against these finishing times so we're going to throw now we're going to throw out the original node names and we're going to replace the node names in Blue by the finishing times in red we're also going to work with the original graph which means we have to reverse the arcs back to where they were originally so those are the two changes you're going to see when I redraw this graph first of all all the arcs will reverse orientation second of all all of the nodes will change names from the original ones to the finishing times that we just computed so here's our new graph with the new node names and all of the arcs with their orientation reversed and now we run DFS again on this graph and again we're going to process the nodes in order from the highest label 9 down to the lowest label one moreover we don't need to compute finishing times in the second pass we only need to do that in the first pass in the second pass we have to keep track of the leaders and remember the leader of a Vertex is the vertex from which DFS was called that first that first discovered that node all right so what's going to happen well in the outer for loop again we start with with I equal to 9 and we invoke DFS from the node 9 so that's going to be the current leader because that's where the current DFS got uh initiated now from 9 there's only one choice we have to go to seven from Seven there's only one choice we have to go to eight from eight there's only one choice we have to go back to nine and then Nine's already been seen so we backtrack we go back to eight we go back to seven we go back to nine and that's it so when we invoke DFS from node 9 the only things that we encounter are the nodes 7 8 and n and these are all going to be given the leader vertex 9 you will notice that this is indeed one of the strongly connected components of the graph we just sort of found it with this invocation of DFS from the node 9 so now we go back to the outer four Loop and we say okay let's go to node eight have we already seen eight yes what about seven have we already seen seven yes what about six have we already seen six we have not we have not yet discovered six so we invoke DFS from node 6 we reset uh the global uh Source vertex s to 6 from six we can go to 9 or we can go to one so let's say we explore 9 from first well we already saw nine in the earlier iteration of the for Loop so we don't explore it again so we don't discover nine now so we backtrack to six we go to one from one we have to go to five from five we have to go to Six and then we start backtracking again so the only new nodes that we encounter when we invoke DFS from the node 6 are the vertices 61 and 5 and all of these will have a leader vertex of six because that's where we called DFS from when we first discovered these three nodes and you'll notice this is another sec of this directed graph so we invoke DFS again now from a n node the N node 6 and what it discovered the new nodes it discovered was exactly an SEC of the graph nothing more nothing less so now we returned to the outer for Loop we go to node five have we already seen five yes have we already seen four no we haven't seen four yet so now we invoke DFS from four again we can try to explore five but we've seen that before we're not going to explore it again so from before then we have to go to two from two we have to go to three from three you have to go back to four and then after all the backtracking we're done so the final call to DFS will be from the node 4 and that DFS will discover precisely newly discover precisely the noes 2 3 and four they will all have the leader Vertex 4 because that was where this DFS was called from it's true we'll go back to the for Loop and we'll check have we seen three yet yes have we seen two yet yes have we seen one yet yes and then the whole thing completes and what we see is that using the finishing times computed from that first stth for search pass somehow the strongly kinetic components of this graph just showed up and presented themselves to us one at a time on a silver platter every time we invoked DFS the nodes we discovered newly were precisely one of the secc's nothing more nothing less and that's really what's going on in this algorithm it turns out this is true in general the first pass DFS on the reverse graph computes finishing time so that if you then process nodes according to decrease ordering of finishing times in the second pass each invocation to DFS will discover one new SEC and exactly one sec so they'll just present themselves to you one per DFS call in that second passes for Loop this is of course merely an example you should not just take a single example as proof that this algorithm always works I will give you a general argument in the next video but hopefully there's at least a plausibility argum no longer does this three-step algorithm seem totally insane and maybe you could imagine perhaps it works at least there's some principles going on where you first compute the right ordering to process the nodes and then the second pass peels off secc's one at a time like layers from an onion one thing that I hope is pretty clear is that this algorithm correct or not is blazingly fast pretty much all you do is to two depth first searches and since depth first search as we've seen in the past uh runs in time linear in the size of the graph so does cause aaju to pass algorithm there are a couple subtleties and I encourage you to think about this and you'll be forced to think about this in the programming project for week four so for example in the second pass how do you process the nodes in decreasing order of finishing time you don't want to sort the nodes by their finishing time because that would take n log n time so you need to make sure that you remember in the first pass that you sort of remember the nodes in a way that you can just do a linear scan through them in a second pass so there are some details but if your intuition is that this is really just double DFS properly implemented that's pretty much exactly right so having spelled out the full implementation argued that it's definitely a linear time algorithm and given at least a plausibility argument via an example that it might conceivably be correct let's now turn to the general argument