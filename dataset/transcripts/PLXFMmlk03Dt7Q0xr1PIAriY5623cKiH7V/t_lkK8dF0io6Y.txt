so welcome to part 2 of our probability review this video assumes that you've already watched part 1 or at least are familiar with concepts covered in part 1 namely sample spaces events random variables expectation and linearity of expectation in this part of the review we're going to be covering just two topics conditional probability and the closely related topic of Independence both between events and between random variables I want to remind you that this is by no means the only source you can or should use to learn this material a couple other sources free that I recommend are lecture notes that you can find online by Eric Lehman and Tom Leighton and also there's a wiki book on discrete probability so conditional probability I hope you're not surprised to hear is fundamental to understanding randomized algorithms that said in the five weeks we have here we'll probably only use it once and that's in analyzing the correctness of the rand contraction algorithm for computing the minimum cut of an undirected graph so just to make sure we're all on the same page first some stuff you should have learned from part 1 of the probability review you should notice sample spaces this represents all of the different outcomes of the ramp coin flips all of the different things that could happen often in randomized algorithm analysis this is just all the possible random choices that the algorithm might make each outcome has some known a probability P of I and of course the sum of the probability is equal 1 and remember that event is nothing more than a subset of Omega Omega is everything that could possibly happen s is some subset of things that might happen and of course the probability of event is just the probability of all of the outcomes that the event contains so let's talk about conditional probability so one discusses the conditional probability of one event given a second events so let x and y denote two events subsets of the same sample space you might want to think about these two events x and y in terms of a Venn diagram so we can draw a box representing everything that could conceivably happen so that's omega then we can draw a blob corresponding to the event X so that's some stuff might or might not happen who knows and then the other event Y is some other stuff which might or might not happen and the general these two events could be disjoint that is they could have no intersection or they might have a non-trivial intersection X intersect Y similarly they need not cover all of Omega it's possible that nothing in X nor Y happens so what we're looking to define is the probability of the event X given the event y so we write probability of X bar y phrased X given Y and the definition is I think pretty intuitive so given Y means we assume that something in Y happened originally anything in Omega could have happened we didn't know what now we're being told that whatever happens it lies somewhere in Y so we zoom in on the part of the picture that which contains a Y so that's going to be our denominator so our new world is the stuff and Y that's what we know happens and now we're interested in the proportion of Y that is filled up with X so we're interested in that what fraction of y's area is occupied also by stuff in X so X intersect Y divided by the probability of Y that is by definition the conditional probability of x given Y let's turn to a quiz using our familiar example of rolling two dice to make sure that the definition of conditional probability makes sense to you okay so the correct answer to this quiz is the third answer so let's see why that is so what are the two events that we care about we want to know the probability of x given Y where X is the event that at least one die is a 1 and Y is the events that the sum of the two dice is 7 now the easiest way to explain this is let's zoom in let's drill down on the Y let's figure out exactly which outcomes Y comprises so the sum of the two dice being 7 we saw in the first part of the property Review that there's exactly six outcomes which give rise to the sum 7 namely the ordered pairs 1 6 2 5 three four or three five two and six one now remember that the probability of X given Y is by definition the probability of X intersect Y divided by the probability of Y now what you notice from this formula is we actually don't care about the probability of x per se or even about the event experts say just about X intersect Y so let's just figure it so now we know Y is it's these six outcomes which of those also belong to X well X as those where at least one that is one so X intersect Y is just going to be the one six and the sixth one now the probability of each of the 36 possible outcomes is equally likely so each one is 1 over 36 so since X intersect Y has only two outcomes that's going to give us a 2 over 36 in the numerator since Y has 6 outcomes that gives us a 6 over 36 in the denominator when you cancel everything out you're left with a 1/3 so just applying the definition of conditional probability to the correct definition of the two relevant events we find that indeed 1/3 of the time is when you have a 1 conditioned on the sum of the two dice being 7 let's move on to the independence of two events so again we consider two events x and y by definition the events are independent if and only if the following equation holds the probability that both of them happened that is the probability of X intersect Y is exactly equal to the probability that X happens times the probability that Y happens so that's a simple an oculist looking definition let me rephrase it in a way that it's even more intuitive so I'll let you check this it's just some trivial algebra this equation holds for the events x and y if and only if this is just using the definition of conditional probability we have on the last slide if and only if the probability of x given Y it's exactly the same thing as the probability of X so intuitively knowing that Y happened gives you no information about the probability that X happens that's the sense in which X and y are independent and you should also check that this holds if and only if the probability of Y given x equals the probability of Y so symmetrically knowing that X has occurs gives you no information no new information about whether or not Y has a curve the probability of Y is unaffected at my conditioning on X so at this juncture I feel compelled to issue a warning which is you may feel like you have a good grasp of Independence but in all likelihood you do not for example I rarely feel confident that I have a keen grasp on independence of course I use it all the time in my own research in my own work but it's a very subtle concept your intuition about independence is very often wrong even if you do this for a living I know of no other source has created so many bugs and proofs by professional mathematicians and professional computer science researchers as misunderstandings of Independence and using intuition instead of the formal definition so for those of you without much practice with independence here's my rule of thumb for whether or not you treat the random variables is independent if things are independent by construction like for example you define it in your algorithm so the two different things are independent then you can proceed with the analysis under the assumption that they're independent if there's any doubt if it's not obvious the two things are independent you might want to as a rule of thumb assume that they're dependent until further notice so the slide after next I'll give you an example showing you things which are independent and things which are not independent but before I do that I want to talk about independence of random variables rather than just independence of events so you recall the random variable is from the first video on probability review it's just a real valued function from the sample space to the real numbers so once you know what happens you have some number of the random variable evaluates to some real number now what does it mean for two randomvariables to be independent it means the events of the two variables taking on any given pair of values are independent events so informally knowing the value taken on by one of the random variables tells you nothing about what value is taken on by the other random variable recalling the definition of what it means for two events to be independent this just means that the probability that a takes on value little a B takes on that little bead probably that both of those happen is just the product of the probabilities of each happens individually so what's useful about independence of events is that probability is just multiplied what's useful about independence of random variables is that expectations just multiply so we're going to get an analogue of linearity of expectation where we can take we can interchange an expectation and a product freely but I want to emphasize this this interchange of the expectation the product is valid only for independent random variables and not in general unlike linearity of expectations and we'll see a non example we'll see how this fails on the next slide for a non independent random variables so I'll just stated for two random variables but the same thing holds by induction for any number of random variables if two random variables are independent then the expectation of their product equals the product of their expectations and again do not forget that we need a hypothesis remember linearity of expectations did not have a hypothesis for this statement about products we do have a hypothesis of them being independent so why is this true well it's just straightforward derivation where you follow your nose I'll write it out here for completeness but but I really don't think it's that important so you start with the expectation of the product this is just the average value of a times B of course weighted by the probability of any particular value so the way we're going to group that sum is we're going to sum over all possible combinations of values a and B that capital A and capital B might take on so that's going to give us a value of a times B times the probability that big a takes on the value little a and capital B takes on the value little B so that's just by definition where this is the value of the random variable capital a times capital B and this is the probability that it takes on that value with the constituent values a and B now because a and B are independent there's probability factors into the product of the two probabilities this would not be true if they are not independent it's true because they're independent so same sum over all possible joint values of a and B still have any times B but now we have times the probability that a takes on the value a times the probability that B takes on the value B so now we just need to regroup these terms so let's first sum over a let's yank out all the terms that depend on little a notice none of those depend on little B so we can yank it out in front of the sum over little B so we have an a time's the probability that big a takes on the value with a leg and then the stuff that we haven't yanked out is this sum over B of B times little bit times the probability that capital B takes on the value little B now what's here inside the quantity this is just the definition of the expectation of B and then what this remains after we've factored out the expectation of B just this other sum which is the definition of the expectation of a so indeed for independent random variables the expected value of the products is equal to the product of the expectations let's now wrap up by tying these concepts together in an example a simple example that nevertheless illustrates how it can be tricky to figure out what's independent and what's not so here's the setup we're going to consider three random variables X 1 X 2 and X 3 X 1 and X 2 we choose randomly so they're equally likely to be 0 or 1 but X 3 is completely determined by X 1 and X 2 so it's going to be the X 4 of X 1 and X 2 so X or R stands for exclusive or so what that means is that both of the operands are 0 or if both of them are then the output is 0 and if exactly one of them is one exactly one of them is 0 then the output is 1 so it's like the logical or function except that both of the inputs are true then you output false ok that's the exclusive-or now this is a little hand wavy when we start talking about probabilities we want to be honest about it we should be explicit about the sample space so what I mean by this is that x1 and x2 take on all values they're equally likely so we could have a 0 0 or a 1 0 or a 0 1 or a 1 1 and in each of these four cases x3 is determined by the first two as the XOR so we get a 0 here a 1 here a 1 here and a 0 there and each of these 4 outcomes is equally likely so let me now give you an example of two random variables which are independent and a non example I'll give you two random variables which are not independent so first I claim that if you think that X 1 and X 3 then they're independent random variables I'll leave this for you to check this may or may not seem counterintuitive to you remember X 3 is derived in part from x1 nevertheless x1 and x3 are indeed independent and why is that true well if you enumerate over the 4 possible outcomes you'll notice that all four possible to bit strings occur as values for 1 & 3 so here they're both 0 here they're both 1 here you have a 0 & 1 and here you have a 1 and a 0 so you get all four the combinations with probability 1 over 4 so it's just as if x1 and x3 were independent fair coin flips so that's basically why the claim is true now that's a perhaps counter-intuitively example of independent random variables let me give you a perhaps counterintuitive example of dependent random variables needless to say this example just scratches the surface and you can find much more devious examples of both independence and non independence if you look and say and a good book on discrete probability so now let's consider the random variables X 1 product X 3 and x2 and the claim is these are not independent so this will give you a formal proof for the way I'm going to prove this can be slightly sneaky I'm not going to go back to the definition I'm rather going to contradict the consequence of the definition so to prove that they're not independent all I need to do is show that the product of the expectations is not the same as the expectations of the products remember if they were independence then we would have that equality can be its product of expectations would equal the expectation of the products so if that's false then there's no way these random variables are independent so the expectation of the product of these two random variables is just the expected value of the product of all three and then on the other side we look at the product of the expected value of x1 and x3 and the expected value of x2 so let's start with the expected value of x2 that's pretty easy to see that is 0 half the time and that is 1/2 the time so the expected value of x2 is going to be 1/2 how about the expected value of x1 and x3 well from the first claim we know that x1 and x3 are independent random variables therefore the expected value of their product is just the product of their expectations so this expectation 0 the expected value of x1 times the expected value of x - excuse me of x3 and again x1 is equally likely to be 0 or 1 so it's expected iOS a half x3 is equally likely to be 0 or 1 so it's expected value as 1/2 so the product of their expectations is 1/4 so the right-hand side here is 1/8 1/2 times 1/4 that's 1/8 what about the left hand side the expected value of x1 times x3 times x2 well let's go back to the sample space what is the value of the product in the first outcome 0 what is the value of the product in the second outcome 0 third outcome 0 fourth outcome 0 the product of all 3 random variables is always 0 with probability 1 therefore it's the value of course is going to be zero so indeed the expected value of the product of x1 x3 and x2 0 is not equal to the product of the corresponding expectations so this shows that x1 x3 and x2 are not independent