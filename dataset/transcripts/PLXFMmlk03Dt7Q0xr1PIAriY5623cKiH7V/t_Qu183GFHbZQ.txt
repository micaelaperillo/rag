in this video we'll begin our discussion of hash tables we'll focus first on the supported operations and on some of the canonical applications so hashtables are insanely useful if you want to be a serious programmer or computer scientist you really have no choice but to learn about hash tables I'm sure many of you have used them in your own programs in the past in fact now on the one hand what's funny is they don't actually do that many different things in terms of the number of supported operations but what they do do they do really really well so what is a hash table well conceptu ignoring all of the aspects of the implementation you might want to think of a hashtable as an array so one thing that arrays do super well is support immediate Random Access so if you're wondering what's at position number 17 of sumeray Boom with a couple of machine instructions you can find out want to change the contents at position number 23 in some array done in constant time so let's think about an application in which you want to remember your friend's phone numbers so if you're lucky your friend's parents were all un unusually un imaginative people and all of your friends names are integers let's say between 1 and 10,000 so if this is the case then you can just maintain an array of length 10,000 and to store the phone number of say your best friend 173 you can just use position number 173 of this modes sized array so this array based solution would work great even if your friends change over time you gain some here you lose some there as long as all of your friends names happen to be integers between 1 and 10,000 now of course your friends have more interesting names Alice Bob Carol whatever and last names as well so in principle you could have an array with one position in the array for every conceivable name you might encounter with at least 30 letters say but of course this array would be way too big it would be something like 26 raised to the 30th power and you could never implement it so what you'd really want you'd want an array of reasonable size say you know ballpark the number of friends that you'd ever have so say in the thousands or something where its positions are indexed not by the numbers not integers between 1 and 10,000 but rather by your friends's names and what you'd like to do is you'd like to have random access to this array based on your friend's name so you just look up the quote unquote Alice position of this array and boom there would be Alice's phone number in constant time and this conceptual level is basically what a hash table can do for you so there's a lot of magic happening under the hood of a hash table and that's something we'll discuss to some extent in other videos so you have to have this mapping between the keys that you care about like your friend's names and uh numerical positions of some array that's done by What's called the hash function but properly implemented this is the kind of functionality that hash tables gives you it's like an array with its positioned indexed by the keys that you're storing so you can think of the purpose of a hasht table as to maintain a possibly evolving set of stuff where of course the set of things that you're maintaining you know will vary with the application it could be any number of things uh so if you're running an e-commerce website maybe you're keeping track of transactions you know again maybe you're keeping track of people like for example your friends and various data about them so maybe you're keeping track of IP addresses for example if you want to know uh who who are the unique visitors to your website and so on so a little bit more form you know the basic operations you need to be able to insert stuff into a hash table in many but not all applications you need to be able to delete stuff as well and typically the most important operation is lookup and for all of these three operations you do it uh in a key based way where as usual key should just be a unique identifier for the record that you're concerned with so for example for employees you might be using Social Security numbers for transactions you might have a transaction ID number uh and then IP addresses could act as their own key and so sometimes all you're doing is keeping track of the keys themselves so for example in IP addresses maybe you just want to remember a list of IP addresses you don't actually have any Associated data but in many applications you know along with the key is a bunch of other stuff so along with the employees social security number you're going to remember a bunch of other data about that employee but when you do the insert when you do the delete when you do the lookup you do it based on this key and then for example on lookup you feed the key into the hash table and the hash table will spit back out uh all of the data associated with that key you sometimes here people refer to data structures that support these operations as a dictionary so the main thing that a hash table uh is meant to support is lookup in the spirit of a dictionary I find that terminology a little misleading actually uh you know most dictionaries that you'll find are in alphabetical order so they'll support something like binary search and I want to emphasize something a hash table does not do is maintain and ordering on the elements that it supports so if you're storing stuff and you do want to have order-based operations you want to find the minimum or the maximum or something like that a hash table is probably not the right data structure uh you want something more you want to look at a heap or you want to look at a a search tree but for applications in which all you have to do is basically look stuff up you got to you got to know what's there and what's not then there should be a light bulb that goes off in your head and you should say let me consider a hash table that's probably the perfect data structure for this application now looking at this menu of supported operations you may be left kind of unimpressed right so a hash table in some sense doesn't do that many different things but again what it does it does really really well so to first order what hash tables give you is the following amazing guarantee all of these operations run in constant time and again this is in the spirit of thinking of a hasch table as just like an array where its positions are conveniently indexed by your keys so just like an array supports random access in constant time you can see if you know there's anything in the array position and what it is uh similarly a hash table will let you look up based on the key in constant time so what is the fine print where there's basically two caveats so the first thing is that hash tables are easy to implement badly and if you implement them badly you will not get this guarantee so this guarantee is for properly implemented hash tables now of course if you're just using a hash table from a well-known Library it's probably a pretty good assumption that it's properly implemented you'd hope but in the event that you're forced to come up with your own hash table and your own hash function and unlike many of the other data structures we'll talk about some of you probably will have to do that at some point in your career then you'll get this guarantee only if you implement it well and we'll talk about exactly what that means in other videos so the second caveat is that unlike most of the problems that we've solved in this course hash tables don't enjoy worst case guarantees you cannot say for a given hash table that for every possible data set you're going to get constant time what's true is that for non-pathological data you will get constant time operations in a properly implemented hash table so we'll talk about both of these issues a bit more in other videos but for now just high order bits are you know hash tables constant Time Performance subject to a couple of caveats so now that I've covered the operations that hashtable support and the recommended way to think about them let's turn our attention to some applications all of these applications are going to be in some sense you know kind of trivial uses of hash tables but they're also all really practical these come up all the time so the first application we'll discuss which again is a canonical one is removing duplicates from a bunch of stuff also known as the D duplication problem so in the D duplication problem the input is essentially a stream of objects where when I say a stream I have kind of you know two different things in mind as a canonical examples so first of all you can imagine you have a huge file so you have you know a log of everything that happened on some website that you're running or all of the transactions that were made uh in a store on some day and you do a pass through this huge file so you're just in the middle of some outer for Loop going line by line uh through this massive file the other example of a stream that I have in mind is uh where you're getting new data over time so here you might imagine that you're runting software to be deployed on an internet router and data packets are coming through this router at a constant extremely fast rate and so you might be looking at say the IP addresses and the sender and you data packet which is going through your router so that' be another example of a stream of objects and now what you got to do what you got to do is you got to ignore the duplicates so remember just the distinct objects that you see in this stream and I hope you find it easy to imagine why you might want to do this task in ious applications so for example if you're running a website you might want to keep track of the distinct visitors that you ever saw in a given day or a given week if you're doing something like a web crawl you might want to identify duplicate documents and only remember them once so for example it' be annoying if in search results both the top link and the second link both LED to identical Pages at different URLs okay so search engines obviously want to avoid that so you want to detect duplicate web pages and only report uh unique ones and the solution using a hashtable is laughably simple so every time a new object arrives in the Stream you look it up if it's there then it's a duplicate and you ignore it if it's not there then this is a new object and you remember it QED that's it and so then after the stream completes so for example after you finish reading some huge file if you just want to report uh all of the unique objects hash tables generally support a linear scan through them uh and you can just report all of the distinct objects when this uh stream finished es so let's move on to a second application uh slightly less trivial maybe but still quite easy and this is the subject of programming project number five so this is a problem called the two suome problem and you're given as input an array of n numbers these integers are in no particular order you're also given a Target sum which I'll call T and what you want to know is are there two integers from amongst these n you are given that sum to T now the most obvious naive way to solve this problem is just to go over all and choose two pairs of integers in the input and check each one separately so that's clearly a quadratic time algorithm but now of course we need to ask can we do better and yes we can and first of all let's see what you do if you couldn't use any data structures so if you were clever but you didn't use any data structures like a hash table here would be a reasonable improvement over the naive one so the first step of the better solution is to sort a up front for example using merge sort or Heap Sort something that runs in nlog and time so you may be asking about the motivation for sorting well again you know one thing is just you know whenever you're trying to do better than n squ you might think of sorting your data somehow helps right you can sort of do it almost for free and and log in time now why would sorting the array up front help us well then the clever Insight is that for each entry of the array a say the first entry now we know what we're looking for to achieve this given Target right if the target for trying to get two that sum to 100 and the first entry in the SED array is 43 then we know we're looking for a 57 somewhere else in this now sorted array and we know that searching a sorted array is pretty easy right that's just binary search that just takes logarithmic time so for each of the N array entries we can look for a complimentary uh entry namely for each X we can look for T minus X using binary search and so each binary search takes log in time so the Sorting up front speeds up this entire batch of n searches and so that's why it's a win so in the Second Step because we do a linear number of binary searches again this is just n the number of searches Times log n the time per search so this is just another Theta of n log n Factor all right so that's pretty cool I don't think you can come up with this n log n solution without having some basic uh facility with algorithms this is already a really nice improvement over the naive n squ but we can do even better okay there's no reason we're stuck with an N log n lower B Bound for the two sum problem obviously because the array is unsorted we have to look at all the integers so we're not going to do better than linear time but we can do linear time via a hash table so a good question you might ask at this point is what's the clue about this problem about this task that suggests that we want to use a hash table well so hash tables are going to dramatically speed up any application where the bulk of the work is just repeated lookups and if we examine this nlogn solution once we have this idea of doing a search for T minus X for each value of x we realized actually you know the only thing we needed the sorted array for was to support lookups that's all binary search here is doing is just looking stuff up so we say aha all of the work here in step two is from repeated lookups we're paying an exorbitant relatively logarithmic amount of time per lookup whereas hash tables can do them in constant time so repeated lookups ding dingding let's use a hash table and indeed that's what gives us linear time in this problem so from The Amazing guarantee of hash tables we get the following amazing solution for the Tome problem although again this is subject to the same fine print about you better use a properly implemented hash table and you better not have pathological data so rather than sorting you just insert everything in the array into a hash table and so insertions constant time so this is going to be linear time rather than the nlog in we were paying before once all the stuff is in the hash table we just do the same thing as in the nlend solution for each X in the array we look for its matching element tus X in the hash table using the constant time lookup operation exported by the hash table and of course if for some X you do find the matching element T minus X then you can just report x and t minus X that proves that there is indeed a pair of integers of Target some T if for every single element of the input array a you fail to find this matching element T minus X in the hash table then for sure there is no pair of integers in the input that sums to T So this solves the problem correctly moreover constant time insertion so that means this first step is going to be o of n time and constant time lookup so that means the second step is also going to be linear time at least subject to the caveats that we discussed on the previous slide so it's kind of amazing how many different applications of computer science boil down in their Essence to repeated lookup operations therefore having a super fast lookup operation like that supported by a hash table permits these applications to scale to Fantastic sizes it's really amazing and it drives a lot of modern technology so let me just mention a couple examples again if you look around or do some research on the web you'll quickly find many more so originally what prompted researchers to think hard about data structures that support super fast lookups was back when people were first building compilers this is a long time ago this is in the 50s or so and these repeated lookups to figure out you know what has and has not been defined before was was emerging as a bottleneck in comp ders back uh in the early days of programming languages and that was one of the early applications uh of hasch tables was to support super fast lookups uh to speed up compile time to keep track of the function and variable names and things like that hash table technology is also super useful for software on routers in the internet so for example you might want to block Network traffic from certain sources so for example maybe you suspect that a certain IP address has been taken over by spammers and so any traffic coming from that IP address you just want to ignore and you don't want to even let it get to the end host to the computer on someone's desktop or to someone's mobile device but rather inside the internet you want to just drop packets that are coming from certain certain senders so what does that problem boil down to well you might have a black list of IP addresses that you're refusing traffic from and then the task face by the router is really a lookup problem so a data packet comes in at some insanely fast data rate and what you want to do immediately is look up is this in The Blacklist or not and if it is in The Black List then you drop the packet if it's not then you let it go through so a very different application is for speeding up search algorithms and when I say A search algorithm what I'm thinking about here is something like a chess playing program so something that does game tree exploration so we've already talked a fair amount about Graph Search in this class but in our discussion of breath first and depth first search we were thinking about graphs that you could basically write down you could store them in the main memory of your machine or in the worst case on some big cluster so maybe graphs you know about the size of the web graph or possibly smaller but in a context of something like a chess playing program uh the graph that you're interested in is way way way bigger than the web graph so what's the graph we care about for a chess PL program well the nodes of the graph are going to correspond to all possible configurations of chest pieces on a chess board so every chess board that you might ever encounter in a game of chess so that's a massive massive number of configurations okay you're never going to be able to write down all of these vertices the edges in this graph are going to take you from one configuration to another and they're going to correspond to Legal move so if you can move a bishop from one place to another place and you get from one configuration to another configuration there's an edge in the graph corresponding to that move now you can't write down this graph so you can't Implement breath first or depth first search exactly as we discussed it before but you'd still like to do graph exploration right so you'd like to have your computer program reason about the at least short-term ramifications of your possible next move so that would correspond to searching through this graph now how are you going to remember in Graph Search a really important property was you don't want to do redundant work you don't want to re-explore things you've already explored that would be silly and might be to infinite loops and so on and if you can't write down the graph even just remembering where you've been is suddenly a non-trivial problem but what is remembering where you've been fundamentally fundamentally that's a lookup operation so that is exactly what hash tables are for so to be a little more concrete you know one way you use a hash table in say a chess playing program is you St take the initial configuration you would sort of imagine trying all possible moves from this configuration and then you try you sort of have all moves by your opponent then you'd have all your moves and response and you would always remember as you were doing this reasoning every chest board configuration you'd ever looked at before and you'd stick it in a hash table and before you go exploring some configuration you look it up in your hash table to see if you've already explored it in the past and if you have you don't bother you've already seen it all right so chess playing programs operate by exploring systematically as many configurations as they have time for you know obviously in a budget of 3 minutes or whatever you don't want to waste any work exploring any given configuration more than once how do you remember where you've been well everything you've explored you stick in a hash table before you explore configuration you look it up in a hash table and see if you've already done it so these of course are just scratching the surface I just wanted to highlight a couple you know fairly different looking applications you know to convince you that hash tables come up all the time and the reason they come up all the time is because you know the need for fast lookups comes up all the time it's kind of amazing how much technology is being driven just by you know repeated fast lookups so as homework I encourage you to just sort of think about you know your own life or think about technology out there in the world and come up with some uh you know guesses about where probably hash tables are making something out there running blazingly fast I think it won't take you more than a few minutes to come up with some good examples