previous videos covered an outstanding algorithm for the selection problem the problem of computing the I order statistic of a given array that algorithm which we call the r select algorithm was excellent in two senses first it's super practical it runs blazingly fast in practice but also it enjoys a satisfying theoretical guarantee for every input array of length n the expected running time of R select is Big O of n where the expectation is over the random choices of the pivots that our select makes during its execution now in this op video I'm going to teach you yet another algorithm for the selection problem well why bother given that our select is so good well frankly I I just can't help myself the ideas of this algorithm are just too cool not to tell you about at least in an optional video like this one the selection algorithm will cover here is deterministic that is it uses no randomization whatsoever and it's still going to run in linear time Big O of end time but now in the worst case for every single input array thus the same way merge short gets the same ASM totic running time go of n log n as quicksort gets on average this deterministic algorithm will get the same running time o of n as the r select algorithm does on average that said the algorithm we're going to cover here well it's not slow it's not as fast as our select in practice both because the hidden constant in it are larger and also because it doesn't operate in place for those of you who are feeling Keen you might want to try coding up both the randomized and the deterministic selection algorithms and make your own measurements about how much better the randomized one seems to be but if you hav an appreciation for brilliant algorithms I think you'll enjoy these lectures nonetheless so let me remind you the problem this is the I order statistic problem so we're given an array it has n distinct entries again the distinctness is for Simplicity and you're given a number I between one and N you're responsible for finding the I smallest number which we call the I order statistic for example if I is something like n /2 then we're looking for the median so let's briefly review The randomized Selection algorithm we can think of the deterministic algorithm covered here as a modification of the randomized algorithm the r select algorithm so when that algorithm is passed an array with length n and when you're looking for the I Oro statistic as usual there's a trivial base case but when you're not in the base case just like in quick sort what you do is you're going to partition the array around the pivot element P now how are you going to choose P well just like quick sort in the randomized algorithm you choose a uniformly at random so each of the N elements of the input array are equally likely to be chosen as the pivot so call that pivot P now do the partitioning remember partitioning puts all of the elements less than the pivot to the left of the pivot we call that the first part of the partitioned array anything bit bigger than the pivot gets moved to be right of the pivot we call that the second part of the array and that J denote the position of the pivot in this partitioned array equivalently let J be what order statistic the the pivot winds up happening to be right so if we happen to choose the minimum element then J's going to be equal to one if we happen to choose the maximum element J is going to be equal to n and so on so there's always the lucky case chance one and N that we happen to choose the I order statistic as our pivot so we're going to find that out when we just notice that J equals I in that Super Lucky case we just return the pivot and we're done that's what we were looking for in the first place of course that's so rare it's not worth worrying about so really the two main cases depend on whether the pivot that we randomly choose is bigger than what we're looking for or if it's less than what we're looking for so if it's bigger than what we're looking for that means J is bigger than I we're looking for the I smallest we randomly chose the J smallest then remember we know that the I smallest element has to lie to the left of the pivot element in that first part of the partitioned array so we recurse there it's an array that has J minus1 elements in it everything less than the pivot and we're still looking for the I smallest among them in the other case this was the case covered in a quiz a couple videos back if we guess a pivot element that is less than what we're looking for well then we should discard everything less than the pivot and the pivot itself so we should recurse on the second part of a stuff bigger than the pivot we know that's where what we're looking for lies and having thrown away J elements the smallest ones at that we're recursing on an array of length n minus J I'm looking for the IUS J smallest element in that second part so that was the randomized selection algorithm and you'll recall the intuition for why this works is random pivots should usually give pretty good splits so the way the analysis went is we showed that each iteration each recursive call with 50% probability we get a 25 75 split or better therefore on average every two recursive calls we are pretty aggressively shrinking the size of the recursive call and for that reason we should get uh something like a linear time bound we do almost as well as if we pick the median in every single call just because random pivots are a good enough proxy of best case pivots of uh the median so now the big question is suppose we weren't permitted to make use of randomization suppose this choose a random pivot trick was not in our toolbox what could we do how are we going to deterministically choose a good pivot okay so let's just remember quickly what it means to be a good pivot a good pivot is one that gives us a balanced split after we do the partitioning of the array that is we want as close to a 50/50 split between the first and the second parts of the partitioned array as possible now what pivot would give us the perfect 50/50 split well in fact that would be the median but that seems like a totally ridiculous observation because we canonically are trying to find the median so previously we were able to be lazy and we just picked a random pivot and use that as a pretty good proxy for the best case pivot but now we have to have some subroutine that deterministically finds us a prettyy good approximation of the median and the big idea in this linear time selection algorithm is to use What's called the median of medians as a proxy for the true median of the input array so when I say median of medians you're not supposed to know what I'm talking about you're just supposed to be intrigued now let me explain a little bit further here's the plan we're going to have our new implementation of choose pivot and it's going to be deterministic you will see no randomization on this slide I promise so the high level strategy is going to be we're going to think about the elements of this array like sports teams and we're going to run a tournament a two- round knockout tournament and the winner of this tournament is going to be who we return as the proposed pivot element then we'll have to prove that this is a pretty good pivot element so there's going to be two rounds in this tournament each element each team is going to first participate in a world group if you will so there will be uh small groups of five teams each five elements each and to win your first round you have to be the middle element out of those five so that'll give us n over five first round winners and then the winner of that second round is going to the be the median of those n over five winners from the first round here are the details the first step isn't really something you actually do in the program it's just conceptually so logically we're going to take this array capital A which has n elements and we're going to think of it as comprising n over five groups with five elements each so if n is not a multiple of five obviously there'll be one extra group that has size between one and four now for each of these groups of five we're going to compute the median so the middle element of those five now for five elements we may as well just invoke our reduction to sorting we're just going to sort each group separately and then use the middle element which is the median it doesn't really matter how you do the Sorting because after all there's only five elements but you know let's use merge sort what the heck now what we're going to do is we're going to take our first round winners and we're going to copy them over into their own private array now this next step is the one that's going to seem dangerously like Che cheting dangerously like I'm doing something circular and not actually defining a proper algorithm so C you'll notice has length Over N over five we started with an array of length n this is a smaller input so let's recursively compute the median of this array capital c that is the second round of our tournament amongst the N over five first round winners the N over five middle elements of the sorted groups we recursively compute the median that's our final winner and that's what we return as the pivot element from this sub routine now I realize it's very hard to keep track of both what's happening internal to this choose pivot sub routine and what's happening in the calling function of our deterministic selection algorithm so let me put them both together and show them to you cleaned up on a single slide so here is the proposed deterministic selection algorithm so this algorithm uses no randomization previously the only randomization was in choosing the pivot now we have a deterministic sub routine for choosing the pivot and so there's no randomization at all I've taken the liberty of inlining uh choose pivot sub routine so that is exactly what lines 1 2 and three are I haven't written down the base case just to save space I'm sure you can remember it so if you're not in the base case what did we do before the first thing we do was choose a random pivot what do we do now well we have steps one through three we do something much more clever to choose a pivot and this is exactly what we said on the last slide we break the array into groups of five we sort each group for example using merge sort we copy over the middle element of each of the N over five groups into their own array Capital C and then we recursively compute the median of C so when we recurse on select we pass it the input c c has n over five elements so that's the new link that's a smaller link than what we start with so it's a legitimate recursive call we're finding the median of n over five elements so that's going to be the n/ 10th order statistic as usual to keep things clear I'm ignoring stuff like fractions uh in your real implementation you would just round it up or down as appropriate so steps 1 through three are the new choose pivot sub routine that replaces the randomized selection that we had before steps 4 through 7even are exactly the same as before we've changed nothing all we have done is ripped out that one line where we chose the pivot randomly and pasted in these lines one through three that is the only change to the randomized selection algorithm so the next Quiz is a sanity check that you understand this algorithm at least not necessarily why it's fast but at least just how it actually works and it only asks you to identify how many recursive calls there are each time so for example in merge sort there's two recursive calls in quick sort there's two recursive calls in R select there's one recursive call how many recursive calls you have each time outside of the base case in the D select algorithm all right so the correct answer is two there are two recursive calls in deselect and maybe the easiest way to answer this question is not to think too hard about it and literally just inspect the code and count right namely there's one recursive call in line three and there's one recursive call in either six or seven so quite literally you know there's seven lines of code and two of the ones that get executed have a recursive call so the answer is two now what's confusing is that in the Rand couple things first in the randomized selection algorithm we only had one recursive call we had the recursive call in line six or seven we didn't have this one in line three that one line three is new compared to the randomized uh procedure so we're kind of used to thinking of one recurs call using the Divine and Conquer approach to selection here we have two moreover conceptually the role of these two recursive calls are different so the one in line six or seven is the one we're used to that's after you've done the partitioning so you have a smaller sub problem and then you just recursively find uh the residual order statistic in the residual array that's sort of the standard divide and conquer approach what's sort of crazy is this second use of a recursive call which is part of identifying a good pivot element for this outer recursive call and this is so counterintuitive many students in my experience don't even think that this algorithm will halt sort of they sort of expect it to go into an infinite Loop but again that's sort of overthinking it okay so let's just compare this to an algorithm like merge SW what does merge sword do well it does two recursive calls and it does some other stuff okay it does linear work that's uh what it does to merge and then there are two recursive calls on smaller sub problems right no issue we definitely feel confident that merge is going to terminate because the sub problems keep getting smaller what does deselect do if you squint so don't think about the details just a high level what is the work done in deselect well there are two recursive calls there's one's in line three one's in line six or seven but there's two recursive calls on smaller sub problem sizes and it does some other stuff does some stuff in steps one and two and four but whatever those aren't recursive calls it does some work two recursive calls and smaller sub problems it's got to terminate we don't know what the runtime is but it's got to terminate okay so if you're worried about this terminating forget about the fact that the two recursive calls have different semantics and just remember if ever you only recurse on smaller sub problems you're definitely going to terminate now of course who knows what the running time is I owe you an argument about why it would be anything reasonable that's going to come later in fact what I'm going to prove to you is not only does this selection algorithm uh terminate run in finite time it actually runs in linear time no matter what the input array is so whereas with r select we could only discuss its expected running time being linear we showed that with disastrously bad choices for pivots R select can actually take quadratic time under no circumstances will deselect ever ever take quadratic time so for every input array it's Big O of end time there's no randomization because we don't randomly do anything and choose pivot so there's no need to talk about average running time just the worst case running time over all inputs is O of n that said I want to reiterate the warning I gave you at the very beginning of this video which is if you actually need to imp implements a selection algorithm you know this one wouldn't be a disaster but it is not the method of choice so I don't want you to be misled as I said there were two reasons for this the first is that uh the constants hidden in the Big O notation are larger for D select than for R select that will be somewhat evident from the analyses that we give for the two algorithms the second reason is recall we made a big deal about how partitioning Works in place and therefore quick sort and nor select also both work in place that is with no uh real additional memory storage but in this deselect algorithm we do need this extra aray C to copy over the middle elements the first round winners and so that extra memory as usual slows down the Practical performance one final comment so for many of the algorithms that we cover I hope I explain them clearly enough that their Elegance shines through and that for many of them you feel like you could have come up with it yourself if only you'd been in the right place at the right time I think that's a great way to feel and a great way to appreciate uh some of these very cool algorithms that said linear time selection I don't blame you if it you feel like you never might have come up with this algorithm I think that's a totally reasonable way to feel after you see this code if it makes you feel better let me tell you about who came up with this algorithm it's quite old at this point about 40 years from 1973 uh and the authors there are five of them and at the time this was very unusual so Manuel Blum Bob Floyd Von pratts Ron mest and Bob tarjan and this is a pretty heavyweight lineup so as we've discussed in the past the highest award in computer science is the ACM Turing award given once each year and I'd like to ask my algorithms classes how many of these authors do they think have been awarded a turing award I've asked it many times the favorite answer anyone's ever given me has been six which I think is uh in spirit should be correct strictly speaking the answer is four so the only one of these five authors that doesn't have a touring award is Von Pratt although he's done remarkable things spanning the gamut from co-founding Sun systems to having very famous theorems about uh for example testing primality but the other four have all been awarded the touring award at some point so in chronological order so the late Bob Floyd who is a professor here at Stanford was awarded the 1978 Turing award both for contributions to algorithms but also to programming languages and compilers so Bob tarjin who uh as we speak is here as a visitor at Stanford and has spent uh his PhD here and has been here as a faculty at other times uh was awarded it for contributions U to graph algorithms and data structures we'll talk some more about some of his other contributions uh in future courses Manuel Blum was awarded the Turing award in 95 largely for contributions in cryptography and many of you probably know Ron rvest as the r in the RSA crypto system so he uh won the uh Turing award along with Shamir and Adelman back in' 02 so in summary if this algorithm seems like one that might have eluded you even on your most creative days uh I wouldn't feel bad about it this is a this is a quite clever algorithm so let's now turn to the analysis and explain why it runs in linear time uh in the worst case