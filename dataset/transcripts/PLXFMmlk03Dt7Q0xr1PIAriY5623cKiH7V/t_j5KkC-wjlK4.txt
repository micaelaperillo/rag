so in this video we'll take a peek under the hood of hash functions and I'll discuss some of the highle principles by which they are implemented so let's briefly review the raison Detra of a hash table so the purpose in life for a hash table uh is to support super fast lookups so maybe you're keeping track of the transactions that happened on your website yesterday maybe you're keeping track of your employees maybe you're keeping track of IP addresses and an internet router maybe you're keeping track of Chess configurations in a in a chess playing program whatever the point is you want to be able to insert stuff into a hash table and later remember whether something's there or whether something's not there so the implementations we'll discuss will generally also support deletions but that's pretty much it it's a very restricted set of operations but the hash table is going to execute them very very well so basically in constant time again subject to some fine print which we'll discuss a little bit in this video uh but then more deeply in a separate optional video so the two caveats are first of all uh the hash table better be properly implemented it's actually pretty easy to screw up a hash table to screw up hash functions we'll talk a bit about that in a few minutes and then also the data should in some sense be non-pathological and that will be discussed more deeply uh in a separate video all right so let me give you an initial glimpse of some of the magic that's happening under the hood in hash functions so first let me say exactly what the setup is the first step is to identify all the things that you might want to be storing so in other words the universe of your application so this would be something like all possible IP addresses of which there's 2 to the 32 all possible names you might encounter perhaps with a maximum of say 30 characters all possible configurations of a chess board and so on and one thing I hope you can appreciate from these examples is that in many cases this universe is really big so the number of IP addresses is quote unquote only 2 to the 32 the number of all names you're probably talking more like 26 raised to the 30 all chessboard configurations I don't even want to think about and what you want to accomplish is you want to maintain an evolving sub set of this universe you so maybe you want to keep track of all the IP addresses you've seen on your website in the last 24 hours you want to keep track of the phone numbers of all of your friends you want to keep track of the chessboard configurations that you've explored in the past 3 seconds whatever and again what I hope is clear from the applications we've been discussing is that this set s is usually of reasonable size it's it's something you could store in main memory you know maybe it's tens of thousands of IP addresses maybe it's you know a few hundred names of your various friends you know maybe it's in the you know Mill millions of chessboard configurations but still way way way smaller than the size of the universe so without data structures you'd have to resort to rather unsatisfactory solutions to maintaining this set so the first thing you could try as we discussed in the previous video would be you just have an array with one position for every imaginable thing you might want to store in your set so this is the solution that's going to work well if all of your friends happen to have names that are integers between 1 and 10,000 but doesn't scale when the universe size uh becomes really big as in most of these applications so the good news is is of course it's an array and it supports fast random access so you can access any position in constant time so if you have an array based Solution indexed by all the elements of your Universe you can do constant time insert delete and look up the bad news is is the space requirement is proportional to the universe and again forget about being unsatisfactory that's just literally impossible infeasible in many applications in which you'd use hash tables now of course to get the memory proportional to the size of the set stuff that you're storing an easy solution would just be to use a list you know say a doubly link list something like that now with the list based solution the good news is is your memory is certainly proportional to the size of the set that you're storing and it's independent of the size of the Universe from which these elements are drawn the bad news is is to figure out whether something is or is not in a list you generally have to Traverse through uh most of that list and so that's going to take time proportional to the length of the list so really the question we're faced in implementing a hash table is can we get the best of both worlds of these two naive Solutions on the one hand we want to have the constant time operations enjoyed by the array Bas solution but on the other hand we want to have the uh linear space in the size of the set that we're storing uh that we get in the list based solution so to get the best of both worlds we are going to use an array based solution but the array will not be big it will not be with size proportional to the universe the array will only have size you know roughly the same as the set that we're storing so somewhere in the ballpark of the the cardinality of s so the first thing we do is we decide on how big we want our array to be so that that length is going to be called n we're going to have an array of length n and n is going to be in the ballpark of the size of s it's going to depend on a few things exactly how n compares to S but for now think of n as like double the size of s we're going to be calling each uh entry of the array a bucket so there's n buckets and then the size of s is about 50% of the number of buckets let's say so one objection you might legitimately raise at this point is you know I thought I said the set was Dynamic the set s right stuff can be added stuff can be deleted so the size isn't always the same it can fluctuate over time so what does it mean to Define an array which is the roughly the same length of this changing set so for Simplicity for the purposes of this video to focus on the key points I'm going to assume that the set size s while s itself can be changing I'm going to assume that the size of s doesn't fluctuate too much so there are additional bells and whistles you can add to a hash table implementation and they're all quite natural I think most of you could probably figure them out on your own to deal with the fact that s might be changing sizes so for example you can just keep track of how many elements are in your hash table and when it exceeds a big a certain threshold so when it's too big relative to the size of your array you just double the array and then you reinsert all the elements into this new doubled array similarly if you want to if the set shrinks uh you can have tricks for shrinking the array dynamically as well so I'm not going to discuss these bells and whistles for resizing your hash table dynamically they are of course important for a real implementation and they are part of the implementations uh in the standard programming libraries but I view those as sort of a second order point in the implementation of a hash table and I want to focus on the first order points uh in this video so summarizing think of the set s there are insertions and deletions we have to accommodate but you know s is going to be roughly the same size and the number of buckets will be you know within a constant factor of the size of the set all right so now we have our array with totally reasonable space space proportional to the size of the set that we're storing and now what we want is we want some some way of translating between the things we care about say our friends names or whatever the elements of the universe are to the positions in this array so the object responsible for that translation from Keys drawn from this universe to positions in this array is called a hash function so formally a hash function takes as input a key so this is going to be an IP address or the name of somebody or a chest board configuration or whatever and it's going to spit out an position in this array so I'm going to label the array entries from 0 to n minus one for this lecture obviously at the moment this is super underspecified there's a zillion functions you could choose which one do you use we'll talk about that but for now there's just going to be some hash function mapping from elements of the universe to buckets two positions in this array now as far as the semantics of this hash function what the hash function is doing is telling us in which position we should store a given key from the universe so if we have some new friend named Alice and we run Alice Through the the key Alice Through the hash function and it gives us a 17 it says we should store Alice's phone number in position 17 of the array if we have some crazy chessboard configuration we feed it into a hash function and it spits out 172 it says we should remember this chessboard configuration in the 17 second bucket of this array so again given X which is some key from this universe we invoke the hash function to get a position in this array to get a bucket and that is where we try to store this X and any Associated data with it so that's the highlevel idea of how you implement a hash table but we're quite far from done and in particular there's a serious issue that we're going to have to deal with that's fundamental to implementing hash tables and that's the notion of a collision so probably many of you have already noticed that this problem might occur which is well what happens if we're storing our friends phone numbers and you know Alice shows up and we ask our H function where to start Alice's phone number and it says oh bucket number 17 and then our friend Bob shows up and we ask our hash function where to store Bob's phone number and what if the hash function also says bucket number 17 for Bob what do we put in bucket 17 do we put Alice there do we put Bob there do we put them both there how do we deal with these so-called collisions so the next Quiz is meant to give get you thinking about collisions and in some sense how unavoidable they truly are all right so the correct answer to this question is the first answer believe it or not all you need is 23 people in a room before you're equally likely to have two people with the same birthday as not so if you're looking to to skim a little money off of your non-mathematical friends this is one way you can do it go to cocktail parties with about 40 people and place bets with people that there are two people in the room with the same birthday so if you have 367 people well there's only 366 distinct birthdays I'm counting February 29th uh here is one of them so by the pigeon hole principle certainly the probability is 100% by the time you get to 367 now by the time you're at 57 you're already at 99% so you already have overwhelming probability to have a duplicate birthday with 57 people so of course with 184 you're going to be almost at 100% 99.99 who knows some large number of nines and at 23 you're at 50% so many people find this quite counterintuitive that you only need 23 people to get a duplicate birthday uh on average and so this is a this is a quite famous example um and it sometimes goes by the birthday Paradox calling it a paradox is sort of a misnomer uh Paradox you know often suggest some kind of logical inconsistency there's no logical inconsistency here it's just that people's brains are not really wired to have this intuition for whatever reason so but it's really just math you can work out the math and and uh and you can just solve it so more generally the principle behind the birth day Paradox is the following so suppose you have a calendar perhaps on some different planet uh which has K days where each everybody's equally likely to have each of the K days as their birthday then it's about the square root of K people that you need in a room before you're equally likely to have a duplicate or not have a duplicate and the reason that you get the square root effect is because if you think about it there's a quadratic number of pairs of people in the room so that's a quadratic in the number of people opportunities to have a duplicate right so each pair of people could be a duplicate there's a quadratic number of pairs and so that's why once the number of pairs starts reaching about the number uh of different days you're you're about you're going to likely see a duplicate around that point so you might be wondering why I'm telling you about the birthday Paradox in the middle of a lecture about hashing but really really it's quite relevant so imagine for example you def find a hash function in the following way now to be clear this is not a practical hash function but just for the purposes of discussion imagine you have a hash function which randomly assigned every single key to a uniform bucket Okay so each each of the one over n buckets equally likely then what the birthday Paradox says is even for a very small data set you're already going to have a pair of things colliding right so if you have n buckets so maybe n is like 10,000 all you need is roughly 100 elements in your data set and despite the fact that the table's only going to be 1% full you're already going to see a collision okay so 99% of them are empty but you're going to have one bucket that has two so that's sort of annoying so the birthday Paradox says you start getting collisions with a hash function even with really tiny data sets so so in this sense if you're going to have hash tables you got to deal with you got to deal with collisions there's going to be a fair number of them and you need some method for resolving them so collisions are a fact of life when you're talking about hashing where Again by Collision what I mean is two different keys so two different elements X and Y from the universe that hash to the same bucket who have the same hash value so in general we can think of a hash function as doing a compression of sorts so we have a huge Universe us and we have this very modest size array a with only n buckets where n we're thinking of as being much much much smaller than you so of course this has function has to map various elements of you to the same bucket so what are we going to do about it how are you going to resolve these collisions well there's two different solutions which are both quite prevalent in practice so solution number one is called chaining or sometimes you'll also see it called separate chaining and this is a very natural solution it's also the one that's relatively easy to analyze mathematically what you do is just for elements that hash to the same bucket you just revert to the list based solution uh that we talked about in a previous slide so each of the end buckets will not necessarily contain just merely zero or one elements it'll contain a list with an in principle unbounded number of elements okay so when we use chaining it's then quite straightforward to figure out how to implement all of the hash table operations namely insert delete and lookup you just hash something to the appropriate bucket and then you you just do insert delete or look up as appropriate in the list that's in that bucket so just to make clear that everything is type checking so here h of X this is the bucket for X that's what's specified by the hash function and then in the H ofx position of this array a in the H ofx bucket is where we find the link list uh that is going to contain X so just to give a cartoon example if you had say four buckets maybe you know the first bucket has exactly one record corresponding to Alice maybe the second bucket just has a null pointer no one's been inserted into the second bucket into the third bucket we have let's say both Bob as well as Daniel and then maybe in the fourth bucket we have Carol okay so because we have a collision between Bob and Daniel both mapped to the third bucket and we resolve that just by having a link list uh with Bob and Daniel in some order so the second solution which is trickier to talk about mathematically but still quite important practically is called open addressing and the principle in open addressing is you're not going to use any space for pointers you're not going to have lists so you're only going to have one object per bucket of the array so now the question is what happens if you know you try and insert Daniel and you go you invoke the hash function on Daniel and it takes you to a bucket that already contains Bob that means there's no room for Daniel ual so what you're going to do is you're going to probe the hash table in some other position so a hash function is now going to be replaced by a hash sequence where you try the hash function tells you the first bucket to try to insert Daniel failing that a second bucket in which to try to insert Daniel failing that a third bucket to try and insert Daniel and so on and you just keep trying until you find an open position somewhere in the array so there's various strategies for trying to figure out the probe sequence uh one strategy is if you fail and say say bucket number 17 which is where the has function tells you to go first you just try bucket number 18 then 19 then 20 then 21 and so on until you find your first open slot so that's called linear probing and another approach is double hashing so this is a solution where you actually have two hash functions hash function number one and hash function number two and the idea is suppose you're trying to insert say Daniel into a hash table with open addressing and you evaluate both of the hash functions and the first one comes up 17 and the F second one comes up 23 so so as usual the first hash function will specify where you look first so if it evaluates on Daniel to 17 you look in the 17th position of the array and if if it's empty that's where you insert Daniel now if it's full what you do is you use the second hash value to be an additive shift so unlike linear probing where after 17 you look at 18 with double hashing if the second hash function gives you 23 that's going to be your offset so after 17 you look at bucket 40 if 40 is already full you look at bucket 63 bucket 63 is already full then you look at bucket 86 so you keep adding increments of 23 until you finally find a bucket uh where that's empty and that's where you insert Daniel now of course if you try to insert some other name if you try and insert Elizabeth you're going to get two totally different numbers in general so maybe you'll get 42 and 27 and so here the probe sequence will be 42 failing that 69 failing that 96 uh failing that 123 and so on so a question you should have at this point is you know I've told you two solutions to resolving collisions in a hash table and you're probably asking well which one should you use if you have to implement your own hash table and you know as usual if I present you with two different solutions for the same problem uh you can probably rest assure that neither one dominates the other right otherwise I wouldn't waste your time by presenting both of them to you so sometimes chaining is going to perform better and sometimes open addressing going perform better and of course it also depends on what kind of metric that you care about so there are a couple rules of thumb that I can tell you so first of all uh if space is at a real premium you might want to consider open addressing instead of chaining and that's cuz with chaining you do have this extra you know it's not huge but you have a little bit of space overhead in dealing with all these pointers and these link lists so if you want to avoid that you might want to think about open addressing the second rule of thumb is deletion is trickier with open addressing than with chaining right deletion is clearly not difficult at all either to code or to understand uh when you use chaining because it just reduces to deletion from a link list which of course you all know how to do open addressing is it's not impossible to implement deletion but it's much trickier so if delet Le's a crucial operation for you that might skew you toward thinking about chaining but ultimately if it's really kind of mission critical code probably the best thing to do is Implement both kinds of solutions and just see which one works better it's a little hard to predict how they're going to interact with memory hierarchies and that kind of thing they're both useful in their own contexts all right so we've covered the two most prevalent ways of handling collisions and we argue that collisions are inevitable no matter how you design your hash function you're stuck with collisions and you can do chaining a link list per bucket or you can do open addressing where you actually have a probe sequence an order in which you look at buckets until you find an empty one and the elephant in the room at this point is you know what is this hash function I told you nothing about hash functions all I told you is that there's some mapping from the set of universe so IP addresses or names or whatever to a bucket number now what kind of function should you use excellent question tons of research on that question and to this day as much art as science but let's start talking about it