so now I get to tell you about the very cool randomized contraction algorithm for computing the minimum cut of a graph let's just recall what the minimum cut problem is we're given as input and undirected graph and parallel edges are allowed in fact they will arise naturally throughout the course of the algorithm that is for given pair of vertices we allow multiple edges to have that pair as end points now I do sort of assume you've watched the other video on how graphs are actually represented although that's not going to play a major role in the description of this particular algorithm and again the goal is to compute the cut so a cut is a partition of the graph vertices into two groups A and B the number of edges crossing the cut is simply those that have one end point on each side and amongst all of the exponentially possible Cuts we want to identify one that has the fewest number of Crossing edges or a Min Cuts so here's the random contraction algorithm so this algorithm was devised by David carer back when he was an early PhD student here at Stanford and this was in the early '90s so like I said quote unquote only about 20 years ago and the basic idea is to use random sampling now we've known forever right ever ever since quick sort that random sampling could be a good idea in certain context in particular when you're doing sorting and searching and one of the things that was such a breakthrough about carer's contraction algorithm is it showed that random sampling could be extremely effective for fundamental graph problems so here's how it works we're just going to have one main Loop each iteration of this while loop is going to decrease the number of vertices in the graph by one and we're going to terminate when we get down to just two vertices remaining now in a given iteration here's the random sampling amongst all of the edges that remain in the graph to this point we're going to choose one of those edges uniformly at random each Edge is equally likely once you've chosen an edge that's when we do the contraction so we take the two end points of the edge call them the vertex U and the vertex V and we fuse them into a single vertex that represents both of them this may become more clear when I go through a couple examples on the next couple of slides this merging May create parallel edges even if you didn't have them before that's okay we're going to leave the parallel edges and it may create a self Loop uh Edge where now both of the end points is the same and self Loops are stupid so we're just going to delete them as they arise each iteration decreases the number of vertices that remain we start with n vertices we end up with two so after n minus 2 iterations that's when we stop and at that point we return the cut represented by those two final vertices you might well be wondering what I mean by the cut represented by the final two vertices but I think that will become clear the examples which I'll proceed to now so suppose the input graph is the following four node 5 Edge graph is a square + one diagonal so how would the contraction algorithm work on this graph well of course it's a randomized algorithm so it could work in different ways and so we're going to look at two different trajectories in the first iteration each of these five edges is equally likely each is chosen for contraction with 20% probability for concreteness let's say that the algorithm happens to choose this Edge to contract to fuse the two end points after the fusion these two vertices on the left have become one whereas the two vertices on the right are still hanging around like they always were so the edge between the two original vertices is unchanged the contracted Edge between the two vertices on the left has gotten sucked up so that's gone and so what remains are these two edges here The Edge on top and the diagonal and those are now parallel edges between the Fus node and the upper right node and then I also shouldn't forget the bottom Edge which is uh Edge from the lower right node to the super node so that's what we mean by taking a pair of vertices and Contracting them the edge that was previously connected them vanishes and then all the other edges just get pulled into the fusion so that's the the first iteration of carer's algorithm or one possible execution so now I proceed to the second iteration of the contraction algorithm and the same thing happens all over again we pick an edge uniformly at random now there's only four edges that remain Each of which is equally likely to be chosen so with 25% probability uh for concreteness let's say that in the second iteration we wind up choosing uh one of the two parallel edges say this one here so what happens well now instead of three vertices we go down to two we have the original bottom right vertex that hasn't participated in any contractions at all so that's as it was uh and then we have the second vertex which actually represents the fusion of all of the other three vertices so two of them were fused the left most vertices were fused in iteration one and now the upper right vertex got fused in with them to create this super node representing three original vertices so what happens to the four edges well the contracted one disappears that just gets sucked into the Super node and we never see it again and then the other three go in where there's go where they're supposed to go so there's the edge that used to be the rightmost edge that has no hash mark there's the edge with two hash marks that goes between uh the same two nodes that it did before just the super node is now an even bigger node representing three nodes and then the edge which was parallel to the one that we contracted the other one with a hash mark becomes a self Loop and remember what the what the algorithm does is whenever self Loops like this appear they get deleted automatically and now that we've done our n minus 2 iterations on just two nodes we return the corresponding cut by corresponding cut what I mean is on one group of the cut is the vertices that got fused into each other and wound up corresponding to the super node in this case uh everything but the bottom right node and then the other group is the original nodes corresponding to the other super node in the contracted graphs which in this case is just the bottom right node by itself so the set a is going to be these three nodes here which all got fused into each other contracted into each other and B is going to be this node over here which never participated in any contractions at all and what's cool is you'll notice this does in fact define A Min cut there are two edges Crossing this cut this one the rightmost one and the bottommost one and I'll leave it for you to check that there is no cut in this graph with fewer than two Crossing edges so this is in fact A Min cut of course this is a random algorithm and randomized algorithms can behave differently on different executions so let's look at a second possible execution of the contraction algorithm on this exact same input let's even suppose the first iteration goes about in exactly the same way so in particular this leftmost Edge is going to get chosen in the first iteration but instead of choosing one of the two parallel edges let's suppose that we choose the rightmost edge to contract in the second iteration totally possible 25% chance that's going to happen now what happens after the contraction well again we're going to be left with two nodes no surprise there the contracted node gets sucked into Oblivion and vanishes but the other three edges the ones with the hash marks all stick around and become parallel edges between these two final nodes this again corresponds to a cut A and B where a is the left two vertices and B is the right two vertices now this you'll notice has three Crossing edges and we've already seen that there is a cut with two Crossing edges therefore this is not a Min cut so what have we learned we've learned that the contraction algorithm sometimes identifies A Min cut and sometimes it does not it depends on the random choices that it makes depends on which edges it chooses to randomly contract so the obvious question is you know is this a useful algorithm so in particular what is the probability that it gets the right answer and we know it's bigger than zero and we know it's less than one is it close to one or is it close to zero so we find ourselves in a familiar position we have what seems like a quite sweet algorithm this random contraction algorithm and uh we don't really know if it's good or not we don't really know how often it works and we're going to need to do a little bit of math to answer that question so in particular we'll need some conditional probability so for those of you who need a refresher uh you go to your favorite Source or you can watch the probability review part two to get a refresher on conditional probability and Independence once you have that in your mathematical toolbox we'll be able to totally nail this question get a very precise answer to exactly how frequently the contraction algorithm successfully computes the minimum cut