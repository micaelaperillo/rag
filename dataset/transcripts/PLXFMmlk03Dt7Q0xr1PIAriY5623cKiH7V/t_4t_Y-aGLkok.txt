this is the second video of three in which we prove that the average running time of randomized quick sort is Big O of n log in so to remind you of the formal statements so again we're thinking about quick sort where we implement the choose pivot sub routine to always choose a pivot uniformly at random from the subarray that it gets passed and we're proving that for a worst case input array for an arbitrary input array of length n the average running time of quick sort where the average is over the random pivot choices is bigo of n login so let me remind you the story so so far this is where uh we left things at the previous video we defined a few random variables the sample space recall is just the uh all of the different things that could happen that is all of the random coin flip outcomes that quick sort could produce which is equivalent to all of the uh pivot choices made by quicksort now the random variables we care about so first of all there's Capital C which is the number of comparisons between Pairs of elements in the input array that quick sort makes for given pivot sequence Sigma and then there are the XI JS and so that's just meant to count the number of comparisons involving the I smallest and the J smallest elements in the input array where you'll recall Z and ZJ denote the I smallest and J's smallest entries in the array now because every comparison involves some zi and sum ZJ we can express capital c as a sum over the x i JS so we did that in the last video video we applied linearity of expectation we used the fact that X IJ are 01 that is indicator random variables to denote to to write the expectation of an XI J just as the probability that it's equal to one and that gave us the following expression so the key insight and really the heart of the quick swort analysis is to derive an exact expression for this probability as a function of I and J so for example if the third smallest element in the array the seventh smallest element in the array wherever may be scattered in the input array we want to know exactly what's the probability that they get compared at some point in the execution uh of quick sort and we're going to get extremely precise understanding of this probability in the form of this key claim so for all pairs of elements and again ordered pairs so we're thinking of I being less than J the probability that zi and ZJ get compared at some point in the execution of quick sort is exactly 2 / J - I + 1 so for example in this example the third smallest element and the seventh smallest element it would be exactly 40% of the time 2 over five is how often those two elements will get compared if you ran quick sort with a random choice of pivots and that's going to be true for every J and I the proof of this key claim is the purpose of this video so how do we prove this key claim how do we prove Pro that the probability that Z ZJ get compared is exactly 2 over Quan J - I + 1 well fix your favorite ordered pair so fix elements zi ZJ with I less than J for example the third smallest and the seventh smallest element in the array now what we want to reason about is the set of all elements in the put array between Z and ZJ inclusive and I don't mean between in terms of positions in the array I mean between in terms of their values so consider the set between zi and ZJ + one inclusive so z z + 1 dot dot dot ZJ minus one ZJ so for example the 3D fourth fifth sixth and seventh smallest elements in the input array wherever they may be okay and of course the initial array is not sorted so there's no reason to believe that these Jus I +1 elements are contiguous okay they're scattered throughout the input array but we're going to think about them okay zi through ZJ inclusive now throughout the execution of quick sort these Jus I + one elements lead parallel lives at least for a while in the following sense begin with the outermost call to quicksort and suppose that none of these Jus I Plus+ one elements is chosen as a pivot where then could the pivot lie well it could only be a pivot that's greater than all of these or it could be less than all of these for example if this is the third fourth fifth sixth and seventh smallest elements in the array well the pivot is either the minimum or the second minimum in which case it's smaller than all five elements or it's the eighth or largest or larger elements in the array in which case it's bigger than all of them there's no way you can have a pivot that somehow is wedged in between the set because this is a contiguous set of order statistics okay now what do I mean by these elements leading parallel lives well in the case where the pivot is chosen to be smaller than all of these elements then all of these elements will wind up to the right of the pivot and they will all be passed to a common recursive call the second recursive call if the pivot is chosen to be bigger than all of these elements then they'll all show up on the left side of the partitioned array and they'll all be passed to the first recursive call iterating this or proceeding inductively we see that as long as the pivot does not is not drawn from the set of Jus I +1 elements this entire set will get passed on to the same recursive call so these J minus I +1 elements are living blissfully together in harmony until the point at which one of them gets chosen as a pivot and that of course has to happen at some point the recursion only stops when the array length is equal to Z or 1 so if for no other reason at some point there will be no other elements in a recursive call other than these Jus I +1 okay so at some point the rivy is interrupted and one of them is chosen as a pivot so let's pause the quick sort algorithm and think about what things look like at the time that one of these Jus I +1 elements is first chosen as a pivot element there are two cases worth distinguishing between in the first case the pivot happens to be either Z or ZJ now remember what it is we're trying to analyze we're trying to analyze the frequency the probability with which zi and ZJ gets compared well if Z and ZJ are in the same recursive call and one of them gets chosen as the pivot then they're definitely going to get compared remember when you partition an array around this pivot element the pivot gets compared to everything else so if Z is chosen as a pivot it certainly gets compared to ZJ if ZJ gets chosen as a pivot it gets compared to Z so either way if one of these two is chosen they're definitely compar if on the other hand the first of these Jus I +1 elements to be chosen as a pivot is not zi or ZJ If instead it comes from the set Z + 1 so on up to ZJ minus one then the opposite is true then zi and ZJ are not compared now nor will they ever be compared in the future so why is that well that requires two observations first recall that when you choose a pivot and you partition an array uh all of the comparisons involve the pivot so two elements which are neither of which is the pivot do not get compared in a partition sub routine so they don't get compared right now moreover since Z is the smallest of these and ZJ is the biggest of these and the pivot comes from somewhere between them this choice of pivot will split zi and ZJ into different recursive calls zi gets passed to the first recursive call ZJ gets passed to the second recursive call and they will never meet again so there's no comparisons in the future either so these two observations right here I would say is the key Insight in the quick swort analysis the fact that for a given pair of elements we can very simply characterize exactly when they get compared and when they do not get compared in the quicks swort algorithm that is they get compared exactly when one of them is chosen as the pivot before any of the other elements with value in between those two has had the opportunity to be a pivot that's exactly when they get compared so this will allow us to prove this key claim this exact expression on the comparison probability that will plug into the formula we had earlier and will give us the desired bound on the average number of comparisons so let's fill in those details so first let me just rewrite the high order bit from the previous slide so now at last we will use the fact that our quick sword implementation always chooses a pivot uniformly at random that each element of a subarray is equally likely to serve as the pivot element in the corresponding partition call so what is this bias this just says all of the elements are symmetric so each of the elements Z zi + 1 all the way up to ZJ is equally likely to be the first one asked to serve as a pivot element now the probability that zi and ZJ get compared is simply the probability that we're in case one as opposed to in case two and since each uh element is equally likely to be the pivot that just means there's sort of two bad cases two cases in which one can occur out of the J minus I +1 possible different uh choices of pivot now we're talking about a set of J minus I + one elements each of whom is equally likely to be asked to be served first as a pivot element and uh the Bad Case the case that leads to a comparison uh there's two different possibilities for that of Z or Z J is first and the other J minus I minus one uh outcomes lead to the good case where Z and ZJ never get compared so overall because everybody's equally likely to be the first pivot we have that the probability that zi and ZJ get compared is exactly the number of pivot choices that lead to comparison divided by the number of pivot choices overall and that is exactly the key claim that is exactly what we asserted was the probability that a given Z and ZJ get compared for no matter what I and J are so wrapping up this video where does that leave us we can now plug in this expression for this probability of comparison probabilities into the double sum that we had before so putting it all together what we have is that what we really care about the average number of comparisons that quicksort makes on this particular input of array n of length n is just this double sum which iterates over all possible ordered pairs i j and what we had here before was the probability of comparing Z and ZJ we now know exactly what that is so we just substitute and this is where we're going to stop for this video so this is going to be our key expression star which we still need to evaluate but that's going to be the third video so essentially we've done all of the conceptual difficulty in understanding where comparisons come from in the quick sort algorithm All That Remains is a little bit of an algebraic manipulation to show that this starred expression really is Big O of n log in and that's coming up next