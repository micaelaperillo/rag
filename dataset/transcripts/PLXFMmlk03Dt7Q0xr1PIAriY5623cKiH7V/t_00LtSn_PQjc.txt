in this video we'll discuss how we actually Implement Dy shortest path algorithm and in particular using the Heap data structure we'll give a blazingly fast implementation almost linear time let me just briefly remind you the problem we're solving it's the single Source shortest path problem so we're given a directed graph in a source vertex s uh we're assuming that there's a path from s to every other vertex V uh if that's not true we can detect it with an easy pre-processing step so our task then is just to find the shortest path amongst all of them from the source for s to each possible destination V moreover every edge of the graph has a non- negative Edge length which we're denoting El subv so recall the dux's algorithm is driven by a single while loop so we're going to add one additional vertex to an evolving set capital x as the algorithm proceeds so X is the vertices that have been processed so far we maintain the invariant that for every process vertex we've computed what we think the shortest path distance uh is to that vertex so initially X is just The Source vertex s of course the shortest path distance from s to itself is zero and then the cleverness in Dyer's algorithm is in how we figure out which vertex to add to the set capital x each iteration so the first thing we do is we focus only on edges that cross the frontier edges that have their tail and capital x and their head outside of capital x now of course there may be many such edges edges that cross this Frontier and we use Dix's greedy Criterion to select one of them so for each Crossing Edge each edge with a tail in X and head outside X we compute the dri greedy score that is defined as the previously computed shortest path distance to the tail of the Ark plus the length of the Ark so we compute that for each Crossing Edge and then the minimum Edge we're calling it V Star W star uh that determines how we proceed so we add the head of that Arc W star to the set capital x and then we compute the shortest path distance to W star to be the previously computed shortest path distance to varar plus the length of this extra hop v w star now back when I explained this algorithm I did it using two arrays an array capital A and array capital B A is what computed the shortest path distances and remember that's what the problem asks us to compute and for clarity I also filled up this array capital B just to keep track of the shortest paths themselves now if you look at the code of this algorithm we don't actually need the array capital B for anything when we fill in the array capital A we don't actually refer to the B array and so now that we're going to talk about real implementations of dyra I'm actually going to cross out all of the instructions that correspond to the bay okay CU you would not as I told you earlier use this in a real implementation of Dy St you would just fill in the shortest path distances themselves so in the next Quiz what I want you to think about is the running time of this algorithm if we implemented it more or less as is according to the pseudo code on this slide without any special data structures and in the answers to the quiz we're going to be using the usual notation where M denotes the number of edges in the graph and N denotes the number of vertices of the graph so the correct answer to this quiz is the fourth one that the straightforward implementation of Dexter's algorithm would give you a running time proportional to the product of the number of edges and the number of vertices and the way to see that is to just look at the main while loop and look at how many times it executes and then how much work we do per iteration of the while loop if we implemented it in a straightforward way so there's going to be n minus1 iterations of the while loop and the reason is is that the algorithm terminates once every single vertex has been added to capital x there are n vertices initially there's one vertex in X so after n minus one iterations we'll have sucked up all of the vertices now what's the work done in each while loop well basically we do naively a linear scan through all of the edges so we go through the edges we check if it's an eligible Edge that is if its tail is an X and its head is outside of X we can keep track of that just by having an auxiliary Boolean variable for each vertex remembering whether it's an X or not and then amongst all of the eligible edges those crossing the frontier we just by exhaustive search remember which Edge has the smallest Dyer store score no we can compute the dyer score in constant time for each of the edges so that's a reasonable algorithm we might be able to get away with graphs that have say hundreds or thousands of vertices using the straightforward implementation but of course we'd like to do better we'd like the algorithm to scale up to much larger graphs even graphs with potentially say a million vertices so the answer is yes we can do better not by changing the algorithm but rather changing how we organize the data as the algorithm proceeds so this will be the first time in the course where we use a data structure to get an algorithmic speed up so we're going to see A really lovely interplay between on the one hand algorithm design and the other hand data structure design in this implementation of Dy algorithm so you might well ask what's the clue that indicates that a data structure might be useful in speeding up Dyer's shortest path algorithm and the way you'd figur this out is you'd say well where is all this work coming from why are we doing a linear amount of work in the edges for a linear number in the vertices iterations well at each iteration of this while loop what we're doing is we're just doing an exhaustive search to compute a minimum we look at every Edge we look at those that cross the frontier and we compute the one with the minimum dyra score so we can ask ourselves oh if we're doing minimum computations over and over and over again is there some data structure which whose raison Detra whose reason for being is in fact to perform fast minimum computations and in fact there is such a data structure it's the Heap data structure so in the following description of a fast implementation of Z's algorithm I'm going to assume you're familiar with this Heap data structure for example that you watch the review video Elsewhere on the course site that explains them so let me just remind you with a lightning quick review of what we learned in that video so heaps are generally logically thought of as a complete binary tree even though they're usually implemented as a laid out inner array and the key property that you get to leverage but that you also have to maintain in a heap is the Heap property that at every node the key at that node has to be at least as small as that of both of the children this property ensures that the smallest key of them all has to be at the root of this tree to implement extract Min you just pluck off the root that's what you return that's the minimum element and then you swap up the bottommost rightmost leaf the last element make that the new roots and then you bubble that down as necessary to restore the heat property when you do insertion you just make the new elements the new last leaf bottommost rightmost leaf and then you swap up as needed to restore the Heap property when we use heaps index's algorithm we're also going to need the ability to delete an element from the middle of the Heap uh but again you can do that just by swapping things and bubbling up or down as needed I'll leave it as an exercise for you to think through carefully how to delete elements from the middle of a heat because you maintain a heap as an essentially perfectly balanced binary tree the height of the tree is roughly the log base two of n where n is the number of elements in the Heap and because for every operation you implement it just by doing a constant amount of work at each level of the tree all of these operations run in O of log n time where n is the number of items that are being stored in the Heap as far as the intuitive connection between the Heap data structure and Dyer's algorithm uh in the main while loop of DX's algorithm were responsible for finding a minimum every single iteration what are heaps good for they're good for finding minimums in logarithmic time that sounds a lot better than the linear time we're spending in the naive implementation of Dyer's algorithm so let's now see how to use heaps to speed up Dyer's shortest path algorithm now because every iteration of the wild Loop is responsible for picking an edge you might expect that we're going to store edges in the Heap so the first subtle but really good idea is to actually use a heap to store vertices rather than edges going back to the pseudo code for DX's algorithm remember that the only reason we focused on an edge was so that we could then deduce which vertex namely the head of that edge to add to our set capital x so we're just going to cut to the chase we're just going to keep vertices not yet in X and then when we extract them in from the Heap it'll tell us which is the next vertex to add into the set capital x so the picture we're going to want to have in mind mind is D shortest path algorithm at some intermediate iteration so there'll be a bunch of vertices in the set capital x The Source vertex plus a bunch of other stuff that we've sucked into the set so far and then there'll be all the vertices we haven't processed yet a big group V minus X then there's going to be edges Crossing this cut in both directions from X to vus X and vice versa now before I explain the second invariant let's just recall what the straightforward implementation of DX's algorithm needs to do what it would do is search through all the edges and I would look for any eligible edges those with tail and x and head in vus X so in this picture there would be three such edges I've drawn the example so that two of the edges the top two edges both share a common head vertex whereas the third Edge has its own uh head vertex the straightforward implementation of Dyer's algorithm would compute Dyer's greedy score for each of these three edges and remember by definition that's the previously computed shortest path dist to the tail of the arc V plus the length of the arc VW so the straightforward implementation just computes this in this case it would comput it for three edges and whichever the three edges W had the smallest score the head of that edge would be the next vertex that gets added to X so let me specify the second invariant and then I'll tell you how to think about it so because we're storing vertices rather than edges in the Heap we're going to have to be fairly clever with the way we Define the key of a Vertex that's in this Heap so we're going to maintain the property that the key of a Vertex V is the smallest greedy dytr score of any ver any Edge which has that vertex as its head so let me show you what I mean in terms of our example where we have three Crossing edges suppose for these three edges in the upper right they happen to have dyri greedy scores of 7 3 and 5 let's look at what the key should be for each of these three vertices I've drawn in vus X now for the topmost vertex this is pretty interesting there are two different edges whose tail is an X and have this vertex as their head so what should the key of this vertex be what should be the smallest dyra greedy score of any of the edges whose tail lies on the left hand side that terminate at this vertex so there's two candidate edges one has D GRE score three one has a text degre score seven so the key value should be three the smaller of those two now the second vertex there's only a single edge that has tail and x and that terminates at this vertex so the key for this vertex should just be the score of that Unique Edge so in this case it's going to be five and then this poor third vertex there's actually no edges at all that uh start an X and terminate at this vertex there's only one Arc going the wrong direction so for any Edge sorry for any vertex outside of X that doesn't have any eligible edges terminating at it we think of the key is being plus infinity so the way I recommend thinking about these Heap Keys is that we've taken what used to be a one round tournament Winner Takes all and we've turned it into a two round knockout tournament so in our straightforward implementation of Dy algorithm we did a single linear search through all of the edges and we just computed the greedy dster score for each and we picked picked the best so in this example we would have discovered these three edges in some order their scores are 3 five and seven we would have remembered the edge with score three as being the best that would have been our winner of this uh winner take all tournament now when we use the Heap we're factoring it into two rounds so first each vertex in vus X runs a local tournament to elect a local winner so each of these vertices in vus X says well let me look at all of the edges for whom I'm the head and also the T of that edge is in X and amongst all of those edges that start in X and terminate at me I'm going to remember the best of those so that's the winners of the local Tournament of the first round and now the Heap is only going to remember this set of first round winners right there's no point in remembering the existence of edges who aren't even the smallest score that terminate at a given vertex because you only care about the smallest score overall now when you extract men from the Heap that's in effect executing the second and final round of this knockout tournament so each of the vertices of vus X has proposed their local winner and then the Heap in an extract Min just chooses the best of all of those local winners so that's the final proposed vertex uh that comes out of the heat so the point is that if we can successfully maintain these two invariants then when we extract them in from this Heap we'll get exactly the correct vertex W star that we're supposed to add to the set capital x next that is the Heap will just hand to us on a silver platter EX exactly the same choice of vertex that our previous exhaustive search through the edges would have computed the exhaustive search was just Computing the minimum in a Brute Force way in a single winner take all tournament uh the Heap implemented in this way chooses exactly the same winner it just does it in this two round process now in Dyer's algorithm we weren't supposed to merely just find the next vertex W star to add to X we also had to compute its shortest path distance but remember we computed the shortest path distance as simply the Dy St greedy score and here the D your grey score is just going to be the key for this Heap that's immediate from invariant number two so we're using the fact here that our keys are by definition just the smallest greedy scores of edges that stick into that vertex W star so that would be again exactly replicating the computation that we would have done in the straightforward implementation just in a much Slicker way okay but we're adding exactly the same vertices in exactly the same order we're Computing exactly the same shortest path distances in this Heap implementation provided of course that we do successfully maintain these two invariants throughout the course of the algorithm so that is now what I owe you we have to pay the piper we've shown that if we can have a data structure with these properties then we can simulate uh the straightforward implementation now I have to show you how we maintain these invariants without doing too much work all right so maintaining in variant number one will really take care of itself really sort of by definition uh the vertices which which remain in the Heap are those that we haven't processed yet and those are the ones that are outside of capital x so really the trick is how do we maintain invariant number two now before I explain this let me point out that this is a tricky problem okay there is something subtle going on so as usual I want you to think about this shortest path algorithm it's some intermediate iteration okay so take a take a snapshot a bunch of vertices have already been added to x a bunch of vertices are still hanging out in the Heap they haven't been added to X there's some Frontier there's EDG just crossing possibly in both directions and suppose at the end of a current iteration we identify the vertex W which we're going to extract from the Heap and conceptually add to the set X now the reason things get complicated is when we move a Vertex from outside X to inside X the frontier between x and vus x changes so in this picture the old black X becomes this new blue X and what's really interesting about the frontier changing is that then the edges which cross the frontier change now there might be there are some edges which used to cross the frontier and now don't those are the ones that are coming into W those were're not so concerned with those don't really play any role what makes things tricky is that there are edges which used to not be crossing the frontier but now they are crossing the frontier and those are precisely the edges sticking out of w so in this picture there are three such edges which I will highlight here in pink to see why it's tricky when new edges all of a sudden are crossing the frontier let's remember what invariant number two says it says that for every vertex which is still in the Heap which is not yet an X the key for that vertex better be the smallest dyri greedy score of any Edge which comes from capital x and sticks into this vertex V now in moving one vertex into X namely this vertex W now there can be new edges sticking in to ver vertices which are still in the Heap as a result the appropriate key value for vertices in the Heap might be smaller now the W has been moved into X and the candidates for the vertices in the Heap whose Keys might have dropped are precisely those vertices on the other end of edges sticking out of w so summarizing the fact that we've added a new vertex to capital X in extracting something from the Heap it's potenti increased the number of Crossing edges across the frontier because the frontier has changed and therefore for vertices that remain in the Heap the smallest greedy score of an edge that sticks into them from the set X might have dropped so we need to update those keys to maintain in variant number two now that's the hard part here's what we have going for us we've damaged the keys perhaps by changing the frontier but the damage is local we can understand exactly whose Keys might might have dropped so as suggested by the picture the vertices whose Keys we need to update are precisely those at the head of edges that stick out of w so for each outgoing Edge from W the vertex we just extracted from the Heap we need to go to the other end of the edge and check if that vertex needs its key to be decreased so here's the pseudo code to do this so when we extract a Vertex W from the Heap that is when we conceptually add a new vertex W to the set X thereby changing the frontier we say well you know we know the only vertices that might have to have their key change they're the ones on the other side of these outgoing arcs from W so we just have a simple iteration over the outgoing edges WV uh from the vertex V now I haven't shown you any edges in the picture like this but there might well be some edges where the head of the arc V is also in the set X has also already been processed but anything in X is not in the Heap remember the Heap is only the stuff outside of X so we could care less about stuff outside of the Heap we not maintaining their keys so we do an extra check if the head of this Edge is in fact still in the heat that is if it's not an X so in the picture for example this would be true for all three of the vertices that are on the other end of arcs pointing out of w and for each of these vertices V we update its key and the way we're going to update its key is we're just going to rip this vertex out of the Heap we're going to recompute its key in constant time and then we're going to reinsert it into the Heap and since all Heap operation take logarithmic time this key update will be logarithmic time as an additional optimization I want to point out that if one of these vertices V's key does change it can only change in one way so remember what is the key the key is the smallest greedy dexra score of all of the edges that start next and stick into this vertex so that's the local tournament or the first round tournament happening at this vertex V now the only thing which has changed before and after we added this vertex W to X is that now one new Edge is sticking into this vertex V all of the old edges sticking into it from X are still sticking into it and now there's one extra candidate in its local tournament namely this Edge WV so either WV is the local winner either it has the smallest Dyer greedy score of them all that terminated this Vertex or it doesn't in which case the previous winner is still the new winner so that is the new key value can only be one of two things either it's the old key value that's the case where this extra entrance The Edge from W Tov is irrelevance or if it's changed it has to have changed to the greedy Dexter score of this Edge WV and the formula for that is the shortest path distance that we just computed for w where W is uh has been processed at this point plus the length of the direct Arc from WV and again conceptually this formula is just the greedy dyous score for the arc WV the new entrance in V's local first round tournament so now having updated V's key appropriately so that invariant number two is restored and once again the key of every vertex does reflect the smallest greedy Dyer greedy score of any Edge sticking into it from the set X we can safely reinsert this node back into the Heap with its new key value and these three lines together are just a key update in logarithmic time uh for one of these vertices that's at the other end of an arc sticking out of the vertex W so let's tally up the running time in this new implementation one thing I want you to check and this will definitely help you understand this refined implementation of Dyer's algorithm is that essentially all the work done is through the Heap API that is all of the running time that we have to account for is in Heap operations we don't really do non-trivial work outside uh of Heap operations and again recall that the uh running time of any Heap operation is logarithmic in the number of elements in the Heap our Heap is storing vertices it's never going to have more than N Things in it so the running time of every Heap operation is Big O of log n so what are the Heap operations that we do well we extract Min and we do it once per iteration of the while loop so there's n minus one iterations of the while loop just like before but now instead of doing an exhaustive search through the edges we just do a simple extract Min from the Heap and it gives us on a silver platter the vertex that we should add to X next so what do we do beside extract mins well we have to do this work paying the piper we have to maintain inv variant number two and and every time we extract them in that then triggers some subsequent key updates remember each of these key updates is a deletion of an element uh from the Heap followed by an insertion so how many deletions and insertions do we do well at first this might seem a little bit scary right because we do a roughly linear number of extract mins and a Vertex might have as many as n minus one outgoing arcs so it seems like a Vertex could trigger as many as n minus1 key updates which is Theta of n Heap operation and if we sum that up over the N iterations of the while loop that would give us n squar Heap operations so and indeed in dense graphs that can be the case it is true that a single vertex might trigger a linear and N number of Heap operations but that's the wrong way to think about it rather then have this vertex Centric perspective on what who's responsible for Heap operations let's have an edge Centric view so for each edge of the graph let's think about when can this be responsible for some Heap operations in particular a decrease and key and the resulting insertion and deletion well if you have an edge and it points from the vertex V to the vertex W there's actually only one situation in which this Edge is going to be responsible for a decrease in key and that's in the case where the tail of the edge V gets sucked into the set X before the head W of this Edge gets sucked into the set X if that happens if V gets sucked into X and W is still outside of X then indeed we're going to have to decrease the key of w W just like we did in the examples but that's all that's going to happen V can only get sucked into X once and never going to leave it so it's only responsible for this single decrease in key of its head W and that's one insertion and one deletion and in fact if the end points of this Edge get sucked into X in the opposite order if the tail of excuse me if the head of this Edge W gets sucked into X first that doesn't even trigger a key decrease for V and V will never have its key decreased uh because of this particular Arc from V to w so the upshot is that each Edge VW of the graph triggers at most one insert delete combo so what does this mean this means that the number of Heap operations is Big O of n that's for the extract mins plus Big O of M that's for the insert delete combos triggered by edges during the decrease Keys now just to I'm going to write this in a in a simplified way this is just o of M the number of edges and this is because of our assumption that there's a path from s to every other vertex if you think about it that means the graph is at least weakly connected if you picked it up it would stay together in one piece so that means it at least contains a tree at least in the undirected sense which means it contains at least nus1 edges so we're in the case of weekly connected graphs where n dominates n m is always at least as big as n at least up to a plus one so what that means is the running time of D algorithm with this Heap implementation is just a log Factor larger remember every Heap operation takes time logarithmic so we do a linear and M number of operations each takes time logarithmic in N so the running time is M log n with I should say quite good constants so this is a really really impressively fast algorithm for computing such a useful problem as shortest paths so we got a little bit spoiled in our discussion of graph search and con ity where it seemed like any problem we cared about we could solve in linear time o of M plus n so here we're picking up this extra logarithmic Factor but I mean come on this is still awesome a running time of M logn is unbelievably faster than a running time of M * n which is what we had in the straightforward implementation so this de use of the Heap data structure has given us a truly blazingly fast algorithm for extremely well motivated problem Computing shortest paths