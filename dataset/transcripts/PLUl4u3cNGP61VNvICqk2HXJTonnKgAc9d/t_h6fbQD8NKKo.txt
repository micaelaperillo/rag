all right let's get started uh today we continue probability the last theme of the class we have three more lectures about probability um today's lecture is about expectation which is a nice summary it's a one number summary of a random variable remember from last time a random variable is neither random nor variable it's really a function from your sample space to something usually real numbers uh so we use this to represent sort of some computation about an experiment we had a similar uh setup with derived variables if you remember back to um State machines uh which were also not variables they were really functions from the state of the machine to numbers so random variable the same idea if I give you if I tell you what sample like what random events happened you can compute a single uh value for this variable that's the meaning and we had a particular type of random variable that's going to be really useful today which is an indicator random variable where the output is always zero or one indicating something happened that's the one or didn't happen so functions are complicated you know if I want to write down a function I got to write down a lot of numbers one for every uh possible sample so uh expectation is a way to take that complicated function and reduce it down to one number obviously it's not going to tell you everything about the function but it tells you what you expect to happen on average what is the it's not the most likely thing but if you take all the things that could happen and you average them that's expectation so let's define that precisely match my notation here so let's call uh random variable X over uh sample space s uh then the expectation of X which we write e x of X although often it's written just e of X so if you look at other probability sources you might see that as well both of these mean the same thing uh it's going to be a weighted average weighted by probabilities so we're gonna sum over all possible samples which we call Omega and S of the probability of that outcome times uh X the function X evaluated at that income outcome Omega for outcome uh so if I right so this is a particular type of average right because the probability sum to one and in particular if the probabilities are all equal this is literally the average value of x okay but of course we would like what we care about is the weighted by the probability if there's something that's more likely to occur that should get a bigger multiplier in front Okay so this is going to be some average of X sometimes the expectation is also called the average uh let's do a very simple example which is we roll a fair uh six-sided die I happen to have such a die right here so we roll it it has values one to six each equally likely here I got a one uh what is the expected value okay so sample space here is one up to six all the probabilities are one six probability of I occurring is 1 over 6 and so the expected value uh I should probably give this a name let's call it D probability that uh D equals I for any particular I between 1 and six is 1 over 6 and so the expected value of D the DI roll is from that formula well it's just uh the probability that uh we get uh a 1 * 1 plus the probability that we get a two * 2 plus and so on uh I'm going to rewrite that a little bit so these these probabilities are all six so we've got 16 * 1 plus6 * 2 plus up to 16 * 6 these numbers it's our favorite summation the Triangular number uh this is uh gal right so if I factor out the six in front then we have that times the sum 1 through six which you should remember is 6 * 7 over 2 it's getting a little crowded this is 1 over 6 * 6 * 7 over two let me get a color chalk it's time for uh the exciting cancellation moment the sixes cancel and so we're left with 7 over2 also known as 3.5 which is as you would expect the average of numbers one through six um but notice notably a point of this example is that the expectation is not actually a valid outcome you never get a 3.5 on a die but you get 1 2 3 four five and six and the average of those is three and a half okay so don't expect don't expect the expectation to be uh an actual point in your an actual value that X could take on all right let's do a more interesting example which we're going to use a lot what if I have an indicator random variable also X oh call it I uh for event a so remember this means uh I is one if event a occurred if what if the sample that happened is in a and zero if a did not occur okay so let's try to compute the expected value of I okay uh so um this is a little tricky with this formula because s even though I only takes on two values s can be you know size a million who knows there's a lot of different random outcomes that could happen and then I kind of projects them all down to this very simple 01 space so I'm just going to write the definition first Omega and S probability of Omega times I of Omega but this thing is either zero or one so this is a summation and we remember one of the techniques for dealing with summations is to rearrange the terms in some useful way and given that every term here is either multiplied by zero which case it disappears or multiply by one let's maybe collect like terms so we can split this summation into two parts there's the sum where W is in a compl uh probability of Omega time0 because I of something in a complement here is zero uh or it could be Omega inside a without the complex and then we get probability of Omega * 1 so these disappear and we're just left with and the one cancels or is doesn't do anything so we get the sum of uh Omega and a Time probability of Omega and this is our definition of probability of a so that's nice and simple another way to write this that's more directly about I is this is the probability that I equals 1 so the expected value of an indicator random variable is always the probability that that indicator random variable equals one this is just a fun fact because I only takes on zero and one the zeros don't show to disappear from the expectation formula and the ones basically add up just the probabilities of of the event occurring okay we're going to use this fact several times today so it's an example and a useful LMA all right uh probability I'm told uh is was originally invented to analyze gambling so let's put that to good use and do some gambling so let me Define a game and then I'm going to need a volunteer couple volunteers to play this game with me it doesn't have a fancy name we're just going to call it the gambling game um so we're going to have three lers and we're going to follow these sequence of steps everybody has some pile of money which we're going to represent by candy but I'll write it as dollars so every round every player puts $2 into a shared pot then um each player uh picks heads or tails you may have played this game in the single player version you just try to guess the outcome of a coin then we're going to flip a Fair coin okay with with multiplayer it's more interesting let's say now mult we could have multiple winners right maybe two people guessed heads and the outcome of the coin was heads then what we're going to do is take the pot of money that everyone uh added to and evenly distribute it among the winners among the people that guess the coin outcome correctly so we split po equally among winners uh there's one special case which is maybe no one guesses the correct value in that case uh we'll also equally split the pot which is equivalent to just giving your money back and trying again so we're going to play this uh game many rounds and our goal your goal is to of course maximize the amount of money you get who would like to play this game oh so many people all right I'm afraid it's only a three- player game uh so I'm gonna pick Jenny my accomplice uh and uh how about you yeah uh no totally fair game don't worry uh what's your name Cleo Cleo all right so everyone welcome Cleo and Jenny to the stage yeah uh I I want you to be in like equally hard and uh good good position so we're going to put you in the middle the Cleo try to keep track here and we've got a coin uh except I don't have a coin I have a Giant die so uh we're going to say was it heads H H is uh huge I gotta write this down or I'm gonna forget H is huge and T is Tiny okay so one two three is a Tails four five6 is an H all right so uh I'm gonna guess first then C why don't you stand in the middle so we're like in order here uh so I'll guess Tails my usual heads Tails okay let's roll this die that doesn't feel very fair but okay well I'll do different types of rolls so we got a four which is H clear winds oh I forgot to distribute the money okay uh these are all equal so pick your pile of cash which are uh poker chips and so it's I think more fun if everyone can see the pile so let me so uh we were supposed to start out by putting two in to the pot and then you are the only winner for the pot so you get all this money it's already looking good all right so I'm going to flip the the we should I should flip after guessing a little too Force otherwise all right I'll try Heads This Time Tails Tails heads Heads okay and we flip okay six is high oh oh I forgot to do our thing two in uh and then we evenly split the pot all right great very consistent coin right play this game properly supposed to put the money supposed to put your money where your mouth is before you play the game all right uh I'll try heads Heads yeah three heads in a row is never useful uh because whatever happens we will just take our money back all right so we flip this is quite fun another heads wow it's very consistent coin here all right so you just a St distribution we put our money back in to each uh I'll do Tails heads Heads Tails Tails very efficient this is great I'm the slow part here rolling oh yeah another heads great I love this there's another problem we'll be working on which is how many times you have to flip a coin until you get tails the answer is two but uh all right so back in and uh I'll do Tails sorry heads heads else all right based on how this D's been going good guess all right have we played enough do you get the idea not yet oh not yet you're you're you're almost depleted there Jenny all right let's see uh one more maybe we should keep going till we get a Tails right that can't take forever famous last words I've done this before all right hey head Tails Tails heads Heads now the gamblers ruin would say we're due for a tails now right it's more likely than 50% oh Gambler was wrong it's 5050 every time all right uh heads tails yes finally aails all right Cleo here has won basically all the candy you can take as many as you like because I'm actually lactose intolerant so I can't eat these uh so both of you are welcome to take as many as you like um so that's the gambling game now is it coincidence that Cleo won and I lost no Wasing Jenny was picking the other one the other from you indeed very observant this is why Jenny was so fast at guessing Jenny's one of our Tas by the way that's uh how I convinced her to cheat uh but she cheated in order to destroy me uh so there's this fun strategy which is uh if you guess the opposite of one of the previous players which if you guess in sequence like this is easy to do Cleo could have done it Cleo actually did it most of the time I think there were only a couple times one time when we matched um and that's a good strategy uh in particular uh well let's analyze shall we how do we analyze a game like this so small we just draw the decision tree or the probability tree all right now it's a little bigger than some of the ones we've done uh luckily um the whole thing is symmetric it doesn't really matter which one you do first uh the whole thing is symmetric so I'm going to do it in the order of let's branch on what player one does player two player three and then what the coin does and then we're going to get some outcome uh which I'll Define in a second uh so uh it turns out whether the first player guesses heads or tails but because the coin is random uh it's going to be symmetric so let's just ignore the whole right half of this space and pretend we're in this left half so suppose I always guessed heads uh or somebody always guesses heads I think it's probably going to be me that I care about yeah uh then uh player two guesses heads or tails now we haven't said what the probabilities are here right uh we didn't I was trying to be roughly 50/50 but I wasn't flipping a coin each time to decide how I should guess the coin uh I was just making some arbitrary Choice C was making some arbitrary Choice Jenny was making some less arbitrary Choice and then the coin this part is random so this one is one half either way so that's helpful and then we get some outcome which I'm going to measure the uh net for uh player one that's this number and I wrote it down here because it's very easy to get these wrong uh so the first case is that we all guest heads and then it doesn't matter what we do just our money is going to go back or the pots going to go back to even distribution whether we win or lose the the money goes uh back to where it started so the net for player one in particular is zero so these are boring uh then we have uh heads Heads tails for the three players and so then if it's heads these two players one and so they evenly distribute so we're always putting six in each time so they'd each get three uh but they started by putting in two and so the net gain is only one this is uh 3 minus two we gained three but we had to pay two to get there okay or we lose whenever we lose and all of these Tales branches uh player one is going to lose because they gu heads and in that case you get minus two because you had to put in the two uh so this case is the same there's two heads and so you each get three and so it's a net of one and then there's this case this is the case you really aiming for this is the best for player one uh because in this case player one is the unique winner so here uh there was heads uh and and the other two guess tals and the coin came up heads and so that's where you're really trying to be uh the unique winner in this game the less common winner that's when you get lots of points okay so uh let's compute the expectation to compute the expectation we need to know what the probabilities are on these branches or something about them uh and I'm going to start by saying let's uh that uh all players are uh uniform and independent so so 50/50 on every Branch okay then the probabilities down here let me use color are going to be 116th in the whole tree or 1/8 in this sub tree so I'm going to just condition on the H in the beginning and so I'll write uh 1/8 down here but if you were drawing the whole tree you'd have to write 11/16th okay each of these things occurs with 1/8 probability get yeah each of these 1/8 and so we get the expected value is uh 1/8 times the sum of these values 0 + 0 + 1 - 2 + 1 - 2 + 4 - 2 uh which I hope is equal to zero because it negative is uh six and the positive is also six so this is what you might call a fair game right the your expected winnings are zero so you're just as likely well it doesn't mean you're just as likely to go above or go to below but on average you will break even okay uh but that's not what we did uh we considered the case where uh let's say player two does not equal player three which is something that player three could enforce and that's what Jenny was doing always choosing opposite of Cleo here in that case uh it's really bad for me right because whatever I guess out here if there's both a heads and a Tails out here if you're if they're always guessing opposite one of them's heads one of them's Tails so that means I always match one of them guaranteed and the other of them is in the unique pile and so they have a 50% chance like in this situation Cleo has a 50% chance of getting that plus4 there's still a 50% chance that we uh that it came up tails of course not with this die but in principle there's a 50% chance that it comes up uh taals but then we each only get one point so if you're focusing on my winnings I will never get four dollars in a round with uh Jenny strategy right I will always get either one or minus two that doesn't sound like a very good game for me if I randomly get 50% chance I get a one 50% chance I get a minus two um so this this was uh I guess expected uh net for player one that's what we've been Computing so in this situation uh the expected net for player one uh if you want to be precise you can say um it's this sub tree here this is when uh the last two guesses are heads Tails or tails heads is the middle part of this sub tree and you can see uh my possible outcomes are limited to these guys and uh it turns out they're equally likely uh in fact independ dependent of what player two does I won't try to prove that here but um because all that matters is this last coin flip 50 if it's heads then I get a plus one if it's Tails I get a minus two every time in this half of the tree and so it's it ends up being half in other words the average of 1 minus two also known as minus a half so given how Jenny played in fact I expect to lose and you saw that happen Jenny also happened to lose the way this is practical if you're a gambler is you if you have two players that collude they decide whatever happens we're going to take our total winnings and split it evenly between us at the end of the game after all the rounds are done then this this is not quite a guarantee but it's a pretty good bet that together uh Cleo and Jenny would get most of the coins most of the money uh because they have a their their expected outcome is plus a half I believe should be the compliment plus yeah anyway it's positive and my expected expect expectation is negative so uh yeah don't play this game if you don't trust players two and three not to collude all right cool you might think this is a silly game who would ever play this game well the Massachusetts lottery uh played this game uh it's a little more complicated there's you I think you had up to four digits and you uh tried to guess a sequence of four digits that would come up randomly I mean pretty similar to lotteries today they just have more numbers uh and there's this great MIT Professor Herman shernoff who we'll talk some of his probability results later in the class um and he wrote this paper how to beat the Massachusetts numbers game which is what the lottery was called originally um and he just looked at some data and it's a similar situation if there are many lottery winners they evenly split the pot also the state takes like 40% or 60% cut I forget which way it goes um but even then uh he made money off of the lottery and there have been more recent versions of this run by MIT students I hear uh to make a lot of money off the massachusett lottery and they've since changed the rules to make those strategies hard to run uh but in particular uh he executed this made a lot of money the whole the idea is if you can guess numbers that are less likely to be guessed by other people and all numbers are equally likely then you expect to win and it turns out people are so predictable uh what's this say zeros and nines were unpopular smaller digits were popular and so we ended up just going with random numbers from like five to eight I think uh and or and zero9 maybe um and uh he won not a lot of money but he wants some money uh you can read the paper for more details it's pretty pretty fun read it goes through all the probability and stuff stuff uh this is like a simplified version so cool practical now you know how to make money uh let's go on to uh some other ways to compute expectation and some more examples and so on all right um we talked about so here we computed if we roll a single six-sided die the expect value of that single die is 3.5 what if I rolled two dice A and B and I want to know the expectation of dice a die a should also be 3.5 right if I roll two dice it doesn't shouldn't change anything but if I computed it explicitly in this way it would be really tedious because the sample space would go from 1 through six to 1 through six squared so now there's 36 different possible outcomes and for each of them I need to like write down a term and add it all up it will come out to 3.5 but that's super annoying to do so here's a nice theorem that makes it easy to do this with six terms instead of 36 terms um if I have a random variable X and I want its expectation this is equal to sum where X is in the range of big X of probability x = x time uh Little X let me erase this my terrible losing game how many coins flips till Tales one two three four five six seven all right keep that in mind seven coin flips to get Tails um all right so here's a formula um it's really exactly what we did here so when we we wrote down here are all the possible outcomes and we multiply them by what the random variable could be and when it was an indicator random variable was either Z or one so there were two groups in general there's whatever the range of X groups okay so if I um yeah so this is exactly this this kind of clustering where we split it into two sums each of them was the probability of being in that group times the outcome of that group this sum is exactly uh probability of not a and this sum is probability of a uh and in general if we if we split into not two groups but all the different possible values of big X could be Little X for every little X in the range of big x uh then this is we get a sum of uh probability of outcomes which is exactly the probability that big x equals small X and we multiply that by small X because that's what we have in the definition of expectation okay so this is an easy theorem I won't write down a proof because uh it's this thing generalized a little bit uh and let's do an example maybe on a different board suppose I want to know the number of hearts in a three card hand okay so what that means is I have 52 cards in a deck I randomly choose three cards without replacement so just like your drawing from the top of a randomly shuffled deck I want to know how many hearts do I get in expectation let's call this uh yeah expected number of Hearts uh is if we just use the definition probability of w times the number of hearts in Omega this would be the definition and S here is uh Size 52 cubed not quite 52 * 51 * 50 it's really big uh so I don't want to have to compute this this explicitly instead I'm going to use this formula and say well look the number of hearts in a three card hand is 0 1 two or three so uh I can write this as the probability that number of Hearts equals 0 times 0 okay that's not very interesting uh we can take the probability uh number of Hearts equals one uh and multiply that by one plus probability the number of Hearts equals 2 plus probability number of Hearts equal 3 * 3 okay and the so now I have three terms relatively easy and these are hopefully things you know how to compute um for example probability I get three hearts I'm going to cheat um this is like 13 choose 3 uh divided 52 choose three right because uh this is there are 13 different heart cards so uh the number of ways to choose three hearts out of those 13 heart cards is 13 choose three the total number of ways to choose three cards is 52 choose three and so that's a probability and you need to multiply it by three uh to get this formula and there's some similar things for these terms I think I maybe won't write them down uh maybe I'll write down the middle one just for KS I went through the effort of of figuring these out so this is at some this point should be something that you could do uh just like on your problem set these are combinatorics problems you know how to solve okay so you get some sum of binomial terms but hey it has some reasonably small size of course these have huge factorials in them uh but you know it's only choose one two or three so they're not too big you plug this into wol from alpha say and you get three quarters very nice number we might come back to this all right uh a lot of the time because this is 61200 we're working with integers natural numbers you know all of the um random variables I've defined so far I believe are integers we happen to get an expectation that was not an integer but all of the values that could take on or or X or Hearts could take on was an integer so let's consider the case where uh I'll say the co-domain of X is the natural numbers 0 1 two 3 um remember co- domain is just what you declare this function could take on for values it doesn't have to take on those values range here the intent is these are just the values that are taken on by this function and so I didn't have to write uh even though the number of Hearts could I don't know be 100 in some other card uh on this sample space we know it's just 0 one two or three and so we just need four terms okay but let's suppose uh potentially all the natural numbers are there but not necessarily all of them then uh expected value of x has a nice form and this is a Formula I encourage you not to memorize you should write it down on your cheat sheet and always look at it up from there because it's easy to get uh wrong especially the next one one to Infinity probability xal I * I okay this is just uh exactly this theorem nothing exciting here I wrote a sum over a range now I'm writing a sum over an explicit range the one clever idea I had is Skip zero because zero is going to get the zero case is going to get multiplied by zero so that never matters so we get to start at one wow I saved this one step forever more uh and then sum up to Infinity if we might have to go that high okay so that is true uh but there's an even cooler form which is sum IAL 1 to Infinity of probability of X greater than or equal to I or there's no I here I equal 0 to Infinity probability X greater than I okay so this this part is just this theorem uh this step is I just change greater than equal to to greater than and changed where I started I so here it started I uh one and here it started i0 and so here I'm effectively adding one to I and so I get to do or subtracting one from I so I do greater than instead of greater than equal to so these two Arrow equalities should be obvious and this one is the interesting one so let's prove that okay proof okay I want to claim I want to compute this sum and claim that it equals this one and I'm going to do it by writing it in kind of an obvious way first I'm just going to write out the infinite series with dot dot dot so we've got x equal to plus uh X greater equal to 2 plus X greater equal to 3 just give me a moment and I'll write all the remaining terms might take a while um and now I want to expand these out into uh separate pieces in terms of x equal I okay so this is what is probability that X greater equal to one given that again that they're all natural numbers uh we know this is probability x = 1 plus probability x = 2 plus plus probability xal 3 plus and so on up to Infinity okay what's this one uh well same thing but starting here probability x = 2 plus probability x = 3 plus and so on this one uh starts over here probability xal 3 okay so if I now sum this way down the columns I get 1 * probability x = 1 plus 2 * probability x = 2 because there are two values here there are two ranges here for X that include xals 2 these two two is not greater equal to 3 four five and so on so I get exactly two of them I get exactly three uh probability xal 3 and so on and if you work out the dot dot dots VI a proof by induction you get some I probability xal I and that's what we wanted one to Infinity so that's why these two sums are the same so the point is to do this work once so that in the future uh if you have a problem you can use any of these formulas you want you could use the definition of expectation which is a sum over outcomes in the sample space or you could use this formula sum over all the things in the range uh with equality here and then you multiply by X or if in the special case where your function only takes on Integer values so this doesn't work if you have other real numbers uh then you can use one of these three formulas probably the last one or the first one are the useful ones if it's easy to compute the probability x equals something then maybe use this formula if it's easy to compute the probability that X is bigger than something this was CDF and this was pmf remember from last time if it's easy if you know have have a nice form for pmf then use that if you have a nice form for CDF use that provided you work with integers do not try to mix these formulas together don't compute like the the sum of I equal 1 to Infinity probability X greater or equal to I time I that would give you something is not expectation okay but surprisingly uh stud students try so don't do that use this one or this one or this one or the definition all right cool let's do some more interesting examples lonely brace those are questions next problem is called meantime to failure it's a little negative uh you can use it to compute successful things as well um it's related to this problem of how many times it is essentially this problem of how many times do I have to flip a coin until I get Tails or until I get heads either way uh I'll write it as heads because that's what my not say uh it's less interest it's more interesting for a biased coin so let's say uh you know the probability of getting heads is p i want to know uh what is is the expected number of flips until I get heads okay so you could use this if you're analyzing coin flipping um but you can also use it for things like uh my laptop every day there's like a one in a million chance that the hard drive dies something so how many days do I expect until uh the hard drive dies hard drives are usually designed engineered to last like I don't know five years or so and then all your hard drives that's for spinning discs ssds are probably different they depend on usage uh so that's uh you know that's something you might care about and that's why this is called metime failure uh it could be something more positive like maybe you have an algorithm you're doing randomized algorithms in the future and you have an algorithm that either solves your problem with some probability uh one minus p no with probability P it solves your problem and with probability 1 minus P it says I don't know there are lots of algorithms like this out there uh how many times do I have to run this algorithm until it actually gives me an answer so I can run it and it gives it might say I don't know but if I run it again it might then solve the problem depending on the random coin flips that it does so that then it's mean time to success how many times do I have to flip this coin do I have to run this algorithm given some probability of it succeeding that's P how many times do I have to keep going until I get a successful answer lots of other uh examples we will get to them in a moment um now our traditional approach to solving tough problems like this is to draw a tree in this case the tree is infinite so that's going to be a little harder to draw we have uh P versus one minus P whenever we get ahe heads uh we stop but this tree keeps going off to the right okay so that's uh maybe let's not look at the infinite tree uh let's use some formulas so I'm going to call this number the number of flips I'm going to call F and then we want to compute remember f is a function so uh there are various outcomes here which correspond to um you know the executions various numbers of flips it's going to be tals taals taals taals tals I times and then heads those are the various outcomes that could happen because we stop whenever we get a heads so it could be zero tails and then heads one Tails then heads and so on uh so that's our sample space and then f is a function that maps that sample space to count how many total flips were there head anails so it's always going to be at least one and then expect so f is a function can take on some integer value between zero and uh one I guess and infinity um and now we're going to reduce this to a single SLE number via expectation what is the average number of flips that we expect to take so uh that's expectation of f now we will use our latest and greatest formula this one let me memorize it for a second it's just sum of X greater than I already forgotten it it's too far from over there to over here uh was it probability f is greater than I I hope yes okay so this is that CDF and I claim uh this is not too hard to figure out using what we know because uh we're assuming each each flip is independent from subsequent flips like the the flips of this coin are mutually independent it's not some magical coin that always comes up heads or always comes up with Tails or something well that would be represented by the P but there's no correlation between the the different flips so um for the for there to be at least are greater than ey flips before I get a heads that means that the first eye flips are Tails these are equivalent events this is this this F greater than I is the same as first I flips are tails right and then after that I don't know might get a heads right away then f is i+ one or it might take longer but F being greater than an i is exactly this situation so what is the probability that the first eye flips our Tails one minus P to the I I saw you Whispering it feel like H yeah cool now the hard part is working out this sum or remember ing what this sum is right this is a geometric sum right so 1us P to the I because this is a chance of getting a taals and then they're each independent so we just take the product by a product rule uh this is a geometric thing sum of x to the I from uh I equal 0 to Infinity is 1 over 1 - x so this is 1 over 1us X here is 1 - P so 1 - 1 minus P that's also known as P so this whole thing is 1 over p key amazingly simple formula for the meantime to failure this is why meantime to failure is such a famous example because it has such a beautiful solution so if I'm flipping a Fair coin 50/50 p is a half I expect to have to flip it twice to get a heads or tails now reality is not equal to the average sadly so I had to flip seven times to get a heads or tails uh but you know if I was gaming for heads it would be very fast it happened the very first step uh so that's um that's the expectation okay it doesn't tell you everything about the distribution this distribution has a name alluded to by this uh geometric Series this was the CDF uh we call this the geometric distribution it comes up somewhat frequently in real life distributions if I were to write down the the pmf it's uh 1 minus P to the I times P this chance that I get ey tails and then a heads that's uh well okay it's either that or probability the way I defined it before it was FAL I + 1 so one of these is true pick one these are both called the geometric distribution if you look at the Wikipedia definition of geometric distribution it says there are two distributions called geometric distribution this one and this one so pick your poison uh both are called that uh so here is an application another application of meantime to failure uh I don't know about you but I like collecting things Everyone likes collecting something right the the to me the epitome of collecting things is gotcha oh that's the video game version of gcha where you're collecting characters in a video game uh please do not play these games they're annoyingly addictive uh I spend most of my nights these days uh but the gacha is named after this notion of uh you can see it in the top right there is H gasa pan which is like uh these these little um you know if you grew up in the US you have uh vend machines that give you candy well these are like the really cool vending machines in Japan this was a gachaan festival and uh you pick your favorite weird thing that you can get in a little ball out of this machine you put in your 200 yen and you get a randomly selected ball from those sets of uh weird toys so this is like a toy delivery or not delivery service it's a toy uh random selection service and if you want to collect all the different things on this list how many times you have to do it this is a problem called coupon collectors or the gotcha problem I would say uh but uh we'll solve it in general in recitation tomorrow uh but I'll solve a very simple version here which is a nice application of this of meantime to failure let's solve the special case where there are only two toys gotcha gacha is a sound that when you crank the things like gacha gacha gacha PA is when the ball drops down uh gotcha with two toys or characters or whatever you're collecting uh and so you get a random Choice say let's say it's 50/50 between the two so in your first pull is what we usually call these at least in the video game context or first crank in the physical context uh you get one of the toys okay so now it's really just how many steps do I need until I get the second toy two this is the coin flipping problem so how many more PS until uh you get a distinct toy and in this case it's going to be 50/50 each each pull and so uh you expect two more uh which is a total of three now when you have K toys you want to collect it's annoying because in the beginning it's really easy to get lots of distinct toys because you're very likely but when you're trying to collect the last toy it's very unlikely that you pull the last toy because there's only like a one ink chance that you get it so you end up with some harmonic series you get a log Factor you'll see that tomorrow okay uh let's do a little more Theory and then some more examples where should I goas gambling I feel like I should have a disclaimer please don't gamble uh it's not good for you please just uh simulate gambling that's better I was writing a simulation uh of of this game this morning to see like what were my chances of actually winning despite the odds being against my favor and with 10 Rounds uh I had like a 20% chance of winning so luckily the demo went in my favor but there was a decent chance that I could have won even though the expectation was against me so it go if there is one thing in this class that you remember about probability I suggest linearity of expectation it is simultaneously the coolest thing in my opinion about probability and the most useful thing for solving problems so what is it uh the expectation function is linear let me formalize um suppose you have two random variables X and Y and you take their sum and then you take their expectation turns out that equals the expectation the sum of the expectations okay uh or uh if you take a random variable and you multiply it by a constant uh you can pull that constant out and so more generally this is the full linearity form if I have a where am I here some I = 1 to n of c i * x i this is uh the sum I = 1 to n of c i * the expected value of XI okay uh it takes almost longer to write it down than to prove it I mean it's actually not hard to prove um you if you stare at this definition enough um it's because this is a linear function right if you look at how it depends on the X's it's a linear function in in X you've got some constant weights I mean they depend on your probability setup but if you mess around with X and don't mess around with with your sample space or its probabilities then uh this is just a sum of constants times uh X applied to things so in particular if I replace X here with X Plus Y and I just Jam that into the sum I can split this into two sums and lo and behold I get expectation of X Plus expectation of Y and these other things follow in the same way so I won't write down a proof there's one in the notes if you want to look uh so it's almost an obvious thing once you once I tell it to you but it's extremely powerful um mainly because it has no conditions you don't need that the XI are independent you don't need that they're disjoint you don't need anything except that they are uh functions over the same sample space I guess that's the one assumption you need uh compare this with remember uh like there's the product rule this only works if a and b are independent or there's the sum rule we use these all the time but you have to be very careful when you use them you have to check are those really independent uh for the sum rule it only works if a and b are disjoint so like when we do law of total probability we're using this all the time but but uh you have to be very careful that you use it correctly whereas linearity of expectation you don't need to be careful other than making sure you define your random variables well okay let's um Let's do an example common one in games gambling games and other games uh dice games let's say we roll two Fair uh two side oh sorry six-sided dice what is the expected value of the sum well uh the expected value of the sum is the expected value of the individual Parts let let me rewrite this as a instead of words let's use some notation let's say D1 is the ren that just gives me what is the value of the first ey and D2 is the random variable that gives me what's the second value the sample space here is a pair an ordered pair of first die comma second die so this extracts the first part and this extracts the second part the expected value of the sum by linearity of expectation is the sum of the expectations and we already did this example right this was 3.5 uh 3.5 so to total is seven easy and what's cool is this didn't even need that the dice were independent you could glue the dice together so that they always roll together as long as that doesn't change the probabilities of the outcomes which maybe a little questionable with gluing but imagine I don't know they're they're quantumly entangled and however I roll this die the other one comes out the same way this will still be true it changes the distribution but it does not change the expectation which is cool all right so we just needed the probabilities of each outcome were equal to get the 3.5 question gluing dice together uh I I'm imagining like if you if I take two dice I glue them together then when I roll them when I roll that unit uh whichever however the first die comes up it forces the other one to come up in a particular orientation right so they're they're literally tied together so that the the D1 determines D2 if they're glued together but this formula applies in that situation provided it's still equally likely that you get one two three four five or six for each die individually okay it's maybe a little clear with coins if I glue two coins together then whichever one comes up heads the other one also comes up heads or comes up tails depending if I glue the head sides together or heads to tails all right uh so I want to do more cool examples and they illustrate how to use linearity of expectation uh with it like the the key to using linearity of expectation is this technique if you want to compute the expectation of some random variable uh decompose that random variable into uh a sum of other random variables possibly indicator random variables okay you see it here already I mean we said what's the expectation of the sum well let's decompose that into the first die and the second and then the sum is the first one plus the second one and then we could split it up using linearity of expectation and then compute each of these individually instead of having to look at the giant sample space which is the pairs of di rolls okay so uh this is a technique we're going to use now several times whatever remains our time so first example so previously we analyzed how many times do I flip a biased coin until I get a heads uh now let's suppose I want two heads natural generalization uh this seems quite a bit harder because you keep flipping and then at some point you get the first heads you keep flipping at some point you get the second heads okay well that sounds kind of like two steps there's how many times do I flip until I get the first head and then how many more times I have to flip until I get the second heads both of those problems sound like meantime to failure so let's write that out carefully with random variables so uh let's call this number of flips F then uh F equal fub1 plus F2 where uh F1 is the number of flips from the beginning until uh we get the first head and F2 is the number of flips starting after the first head until uh the second head okay so to be precise the sample space here is um strings of H's and T's where there's exactly two hes and the last character is an H right because I keep flipping heads Tails heads Tails heads Tails until I get the second H then I stop so that's my sample space and F1 is just counting how many flips are there up to including the first head and F2 is counting how many flips are there starting right after the first head and counting up to and including the second head which is the end of the string so together F1 and F2 count the total number of flips right but crucially uh F1 and F2 if you think about it are exactly the meantime to failure problems uh because they were counting I mean F1 is most obvious it's how many flips do I get do I do until the first head so uh we know here the expected Val value of f is the sum of the expectations F1 is almost literally the definition of meantime to failure so it's uh one over p in expectation F2 if you think about it a little bit you this is the same experiment but starting after the first heads and because all the flips are independent it doesn't matter what happened before now it's still going to be the same situation uh for F2 and so the expectation is 2 p almost as simple and in general if I want K heads then uh the expect expected number flips I need to do is K Over P by linearity of expectation beautiful so simple okay uh let's do another coin flipping example so here I stopped the experiment when I got a desired number of heads what if I just flip a coin n times no matter what I always flip end times how many heads do I expect to get that's kind of the Dual problem what do I want to do uh let's do biased again and biased coins again independent uh let H be the number of heads in those end coin flips we can rewrite this as a sum of n indicator random variables where hi is uh indicator random variable uh for the I coin uh coming up heads okay uh so expected value of H by linearity is the sum of the expected values of the hi okay but the coins are all identical because they're independent and they have the same bias I didn't mention it but we're supposing again probability of heads is p uh so what's the so uh this is just going to be n times the expectation of hi because they all behave the same and what's the expectation of hi we work that out over here if you have an indicator random variable the expectation of hi is the probability that it equals one so the probability of the event which here was the probability of heads so that's just P so this is n * probability h i = 1 which is n * P okay maybe obvious but uh yeah we didn't even need that these were independent that's where it's less obvious right it just it all we need is that for each coin the probability of it coming up heads is p but it could be all the coins always flip the same they're always all heads or all Tails but heads with probability P or it could be they're independent these are different setups but the expected number of heads will in all cases will be n * P by linearity of expectation so that's pretty cool uh you can do a similar trick for did I erase it the hearts problem I think I erased it yeah um I'll just tell you briefly so with the hearts you can say the number of Hearts is a sum of 13 different indicator random variables heart I is um is the E Heart Card chosen again this is a setup where we have 52 cards we choose three without replacement and I want to know how many hearts there are so this is number of hearts and this is just did I choose the I Heart Card in this setup so of course the number of Hearts is exactly the sum of uh one for every heart card that I chose uh so one one this is like Ace and this is King and we got all the ones in between so this is whereas here was the I coin flip or whatever here's the I heart that we potentially choose and the probability of choosing a given heart is is easy it's uh it's not so easy it's some some small expression uh it could be you choose it in the first step or you don't choose it in the first step uh but then you choose it in the Second Step uh or you don't choose it in the Second Step uh and then you'd have to choose it in the third step those are the three ways you can get it and conveniently all the hard numbers here cancel this is exciting and you get uh 2 over 52 3 over 52 I can count uh so you add them up uh 13 of them and then so you get 13 * 3 over 52 and that's 3/4 so kind of nice no binomial coefficients required all right uh one more pair of examples I have in my notes that this is a situation that H happens in all of us are dead which is a great uh zombie High School TV show uh I imagine it just happens in lots of schools but I never went to school so I don't know if you can tell me whether this is the case probably less so in the US maybe l so when you're older maybe when you're young and you still and you have a phone you have to submit your phone when you arrive at school and here's the weird part and this is maybe only in a zombie scenario uh at the end of the day phones are returned uniformly at random I hope this didn't happen to you uh how many people get the right phone natural question you care about whether you get your phone that's also true that's a closely we're going to have to solve that problem in fact okay so assuming here each there's a one toone correspondence between phones and people no ownership um so the number of kids that get their own phone is uh we can write as a sum over all kids we had n kids so k k for kid one up to n of the probability that kid K Kid K gets their phone okay I'm just writing this because I've pre preworked out these examples of course when you're solving them you'll probably know in this part of the class that you should use this technique always if you asked for an expectation probably you might need to decompose the random variable into sums of other random variables you might not have to like this heart problem we solved in two different ways but if you can it's going to be easier so I encourage you to try to do this but how do you decompose into some random variables I mean that's divine inspiration you just got to try a bunch of things until you find something that works you that gives you think about what you know how to compute and then try to build it up or think about how to decompose top down whatever uh but as binmore said what I care about is whether I get my phone and I'm kid seven I don't know uh what's the probability kid seven gets their phone or kid one or whatever it turns out they're all the same because uh oh yeah prob I I I sort of did two steps here right this is how many kids get their phone we can call this uh X and this is going to be um the sum sorry I I skipped way too many steps here the expectation of X is going to be this uh and but the number of kids that get their phone is going to be equal to the sum of XK equal 1 to n where XK is uh an IND or random variable uh for whether uh Kid K got their phone okay this is important because this was a random variable so I if I'm going to write equals I should have some random variables over there when I wrote a probability that means I'm working with a number and so that means the best I'm hoping for is the expectation okay so this first equation I wrote is wrong please do not do that in your homework it's easy to do as you can see but if you you should first set up the random variables which are functions decompose them into sums of other functions and then say okay let's compute the expectation use linearity of expectation this is equal to this uh by linearity the sum of the expectations of the XIs and then by the properties of indicator Rand variables the expected value of an indicator ROM variable is the probability of that event okay so then what's the probability that kid K gets their phone well how many different distributions are there of the end phones help me out n n great answer n different ways there's n different possibilities for the first kid to get their phone back and then factorial yeah there's n factorial different distributions of the phones that's I said oh oh you said n really loud which is n factorial thank you bad pun uh so that's the denominator right those are the all the possible uh all the possible rearrangements of the phones to the kids and very emphatically uh and then how many are there where Kid K gets their phone well this is easy right this is just saying well Kid K gets their phone and then among all the other n minus one phones they're whatever they are how many different ways are there to distribute those phones n minus one hopefully I didn't max out the mic okay n minus one factorial Over N factorial oh my gosh such big factorials but basically everything cancels and this is 1 over n okay 1/ n summed n times that's one one ah one kid expects to get their phone back okay hopefully it's bmore Who's the I mean it doesn't mean that one person will get get their phone back maybe none of them do here's a Rel game suppose uh n diners uh put their phones put their phone singular uh on a turntable sometimes call the Lazy Susan for Distributing food if you're eating family style and uh then you spin the table spin uniformly at random uh and then you take the phone in front of you let's assume that this is a discreet table so when you spin it there's only n different rotations that could come out and so there's always a phone immediately in front of you this is a different way to be terrible with phones in this one you know anything could happen it could be no one gets their phone back that's maybe it's not quite what you expect you expect one person to get their phone back or it could be everyone gets exactly their phone back if you do it randomly anything's possible it's just a one over n factorial chance that any particular outcome happens uh here it's actually guaranteed either everyone gets their phone back or no one does right because if I rotate by zero then everyone gets their phone back if I rotate by any other amount then everyone gets a different phone so it's a different distribution it's a different probability setup but the expectation is the same expected number of uh matching people phones whatever matching phones it's still one here it's really easy to compute because there are only n different outcomes and in one of those scenarios uh you get um so one over n chance everyone gets their phone back and in all other scenarios no one gets their phone back so that disappears you get one over n * n you get one that's sort of the by the definition of expectation how to compute this but you can also set it up in exactly the same way you can say well you could sum over all the diners and check what's the probability that a particular Diner gets their phone back but now you don't have to do this n nus one factorial Over N factorial it's just one over n by the setup was this term here so this is also the uh probability of XI and so you can also do it with linearity of expectation so this is a funny scenario where I have two rather different setups for redistributing phones they have very different behaviors but in expectation they're the same so expectation doesn't tell you everything about the distribution and in the next couple of lectures we'll talk more about understanding the rest of the distribution Beyond just the mean all right