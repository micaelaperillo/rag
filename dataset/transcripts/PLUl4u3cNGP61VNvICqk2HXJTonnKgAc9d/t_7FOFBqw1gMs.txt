hello can people hear me in the back are we good okay so uh welcome to the last lecture of 604 oh no 61200 yeah um I'm I'm totally sayane I can remember which class I'm teaching uh welcome you made it through the semester well done uh okay so for today's material we are going to you know wrap up our discussion of probability and in particular we will be discussing uh tail bounds so you know uh what happens if you have a a random variable like what is the probability that this random variable is like very large or very small like you know very different from from its expectation okay uh so let's start with a a bit a review uh variance okay so I think we uh saw from the last not last lecture two lectures ago possibly uh so the variance of a random variable R uh is defined to be the expectation of uh R minus the expectation of r uh squared okay uh and the standard deviation is just the square root of that you know if you've uh taken you know stats or anything like that that's probably uh you know something that you've seen more more often than variance uh another you know not a definition but another useful formula an equivalent formulation of this is that the variance of r is also equal to the expectation of r s minus the square of the expectation of R okay uh so not the definition but it's equivalent and uh I think in recitation perhaps you uh you proved this um this this formula is is a particularly useful one for what we're going to be doing today okay uh we also saw that uh you know Varian is linear subject to uh you know certain constraints does anybody remember what uh what you need for for variance to be linear yeah Independence okay so if you have R1 R2 RN are independent then uh the variance of the sum is the sum of the variances oops uh is that the right constraint is it correct who who believes this statement who disbelieves who's who's still asleep oh okay maybe we'll we'll give it a few minutes for people to wake up uh okay um well this is a correct statement uh however there's something uh slightly stronger that we can say we can weaken this this condition right we don't need Mutual Independence what do we actually need pair ways Independence yeah okay so if we have a bunch of Parise independent random variables we want to find the variance of their sum we can instead just sum the variances okay so another very useful fact uh hopefully you proved it already in recitations so we don't need to go over the proof uh but these uh well these two formulas are going to be quite useful today okay now time for the first of our tailbones so before I uh give you the bound uh let's let's think about an example so looking at this room uh suppose I pick a random student and uh you know let the random variable R be the the row that the the randomly picked student is is sitting in okay so guesstimate that this is about uh you know the expectation of R is about eight so so pick random student R is the row okay so for uh those of you who aren't in the room those of you who are watching the video uh what does that tell them about uh the probability that R is at least 16 so what's the probability that a randomly selected student is sit sitting in the last five rows I think there 21 rows here yeah does anybody have any idea so maybe I should label this as an example yeah one minus the CDF okay so the people watching the uh watching the video can't I assume they can't see the room so they don't know what the CD is right the only information they know is that the expectation is eight okay yeah oh can we find the variance from that and then see how far away we are uh no that uh requires more information right like we we need to know a little bit more about uh about what's going on right like we we need to you know somehow figure out you know the expectation of R minus 8 squar so like we need to know something more about R than than just its expectation yeah yes there're 21 so 0 through yeah can we assume that it's uniformally distributed uh no and in fact it it is not uh there seem to be you know more students towards the front than than towards the back yeah yeah yeah so your intuition is great though right so um well we're using the observation that uh that you know 16 is is twice 8 right we're we're also using the observation that uh you know the rows are numbered 0 through 20 like they're they're non negative okay so what happens if you know more than half of the students are sitting in the back five rows what does that tell us about the expectation well if if more than half of the students you know give us R is is at least 16 right that tells us that the expectation should be at least eight right or sorry more than eight if if more than half of the students are in the back okay so the converse of that is that there are at most half of the students in the back five rows okay so let's try and formalize this intuition so this is what's known as Markov in equality uh so let R be a non- negative random variable uh then the probability that R is greater than or equal to X is less than or equal to the expectation of r divided by X okay so for the example that we just saw right the probability that uh R is at least 16 it's at most the expectation which is 8 ID 16 so that gives us 1 12 okay does the uh does the statement make sense to people so basically it's saying that you know you can't have too many super large values because that would push the expectation up too high okay so how could we prove this any ideas how do we formalize the intuition that we were just talking about let's try let's try using the law of total expectation so how can we write the expectation of R what might we condition on we don't have too many events that we can work with right which of them might be useful nobody so let's try let's try conditioning on X greater than oh wait was it x uh yeah R greater than or equal x okay so what does the law of total expectation tell us well this is going to be the expectation of our conditioned on R being greater than x multiplied by the probability that R is greater than x okay plus the expectation are conditioned on R less than x times that probability okay do people remember that that coming back hopefully yes no maybe few nods okay so what do we know about each of these values let's start with this one can anybody bound this yeah yeah it's at least X if you conditioned on R being at least X right the expectation of R is is also going to be at least X right every outcome is at least X okay so this is going to be at least x times well this is the probability that that we're looking for so let's just write it out as it is okay now what about the bottom line what do we know about this expectation yeah is it one minus the expectation uh of the other one uh no so the the probability is one minus the uh the other probability uh the expectation does not work like that though yeah it is at most X that is true um we're actually looking for a lower bound though yeah so at least Z yeah okay right we know that that R is always non negative so you know conditioning on anything R is still always going to be non- negative so it's expectation has to be non- negative okay so we we can drop this this is just going to be zero now we've got the expectation of R is at least x times the probability that R is at least X okay now we can just move this x to the other side assuming X is not negative if x is negative then it's a it's a very silly question so you know or sorry assuming X is positive okay are people happy with this proof do anybody have any questions so another form of marov which you uh May often encounter is the following so the probability that R is at least uh C c times its expectation is at most one over C okay for any positive C so essentially equivalent statement just you know you might sometimes see it in this form instead okay so let's take a look at a couple more examples so suppose or is uh the test score of a randomly chosen student instead of the road that they're sitting in okay and uh suppose that these are all in the range uh say 30 to 100% okay uh can we use marov to bound the probability that R is at least say 90% how might we do that h sorry I completely forgot to give you the expectation the answer is no uh okay now can you do it hopefully it's a little bit easier now mhm yeah so find the value of C such that c c * 75 is 90 uh so I guess 75 over or 90 divided 75 that's what's 1.2 is that right uh 75 is 5 by 15 right 90 is 6 by 15 okay nice arithmetic score okay so then uh using uh this formulation here we have the probability that R is at least uh you know 1.2 times uh expectation of r is at most 1 divid 1.2 okay so this is going to be you know something like 83% okay people reasonably happy with that yeah oh the question is um can we explain the difference between these two formulations sorry uh so yeah essentially there is no difference like there're just uh you know different ways of of thinking about uh thinking about the bound you can either think about bounding it in terms of some you know absolute threshold or you can think about it as like in terms of some you know relative threshold like you know multiply the uh the expectation by some by some scaling Factor okay so you know depending on on which of them feels more natural to you uh we could also used the first formulation to say you know probability that R is greater than 90 greater than or equal to is going to be at most uh 75 over 90 which you know same thing 83% okay so either of them Works they both give the same answer they're equivalent formulations it's just you know whichever one you find easier to think about question yes exactly okay so the question was uh we don't just have a non- negative random variable R right we we've actually got an even stronger bound R is at least 30 not just at least zero okay so can we leverage that to get an even stronger bound okay so how could we do that well let's try def finding different random variable so let R Prime be Rus okay so this is another random variable right we're just going to take our original R we're going to subtract 30 um we're not going to do this to people's exam scores in reality don't don't worry uh but that this makes the the minimum exam score zero right so the hope is that you know now we're kind of satisfying the condition to to markov's uh inequality like more tightly so hopefully marov will give us a tighter bound okay so what bound does it give us now what is the probability that R is at least 90 well what is that in terms of R Prime what is that event yeah yeah so this is the same event and so the same probability that R Prime is at least 60 now what happens when we apply Markov to this well this is going to be at most right the expectation of RP Prime ID 60 what is the expectation of R Prime yeah 45 yeah so this is going to be the expectation of R uh minus 30 / 60 which is the expectation so linearity of expectation we can pull this or like we can you know split this into two expectations so this is the expectation of R minus the expectation of 30 there's you know not really any Randomness involved there it's just 30 over 60 right so this is 45 over 60 okay does that make sense to everybody so now instead of this bound of uh you know it's it's at most 83% now we've got the better bound it's at most 75% okay so by shifting our random variable we've managed to get a tighter bound okay what about the probability that R is at most yeah mhm so that that's kind of what we're doing right the the the question was uh in the proof of Markov right we're assuming that the lower bound is zero uh here we've got a lower bound of 30 instead so do we need to do something more complicated the answer is no we don't have to but if we do it gives us a stronger result so that's what we've done here but we don't have to do it right because zero is still a valid lower bound right we could still say we could say that the co- domain of R is 0 to 100 instead of 30 to 100 even even if the range stays unchanged okay so it's still a non- negative random variable so we're still allowed to apply marov to it it's just that you know doing it on r instead of R Prime gives us a weaker result okay does that make sense to everybody another question uh so the question is what do I mean by by a tighter bound when when we shift R uh so tighter in the sense that it is stronger right so uh r at least 30 implies that R is at least zero so r r at least 30 is a stronger condition than than r at least zero okay so that that's what I mean by tighter uh so the the difference right is how we're applying marov right uh we are in the first case we're applying marov to R directly in the second case we are creating a new random variable uh and we're applying marov to that and you know because uh you know we've got a a stronger condition like the the marov markov's um what do you call it precondition is is tight now uh we can get a a stronger result okay yeah uh could it go higher than 83% uh okay so we will get to that in a moment the the question is you know if we're in a different situation uh could shifting it give us something that's higher than 83% and the answer is yes is right in the case where we've applied Markov incorrectly the first time then yes but uh you know if we've applied Markov correctly then uh you know the first is a valid bound right right so you know we we could in principle improve it but uh you know we're not going to do any worse by you know imposing tighter conditions does that like at least kind of intuitively make sense I'll give you a more complete answer in a moment any more questions about this before we move on to the next example yeah yes it is a good thing uh so the the question is is it a good thing that the 75% is smaller than the 83% uh yes we are looking for an upper bound on the probability right so a smaller upper bound is a stronger condition so that's that's better it's um it's a it's a stronger bound you want a smaller upper or AER so that they're the same smaller upper bounds are stronger upper bounds yeah so like less than or equal to 83% implies less than or equal to uh sorry less than or equal to 75% implies less than or equal to to 83% so 75 is is stronger okay okay have people had enough time to think about the probability that R is at most 65 how might we use marov to figure this one out yeah okay so R greater than or equal to 66 so if we assume integer scores okay um and what does marov tell us about this well the probability that R is at least 66 right is going to be at most 75 over which is bigger than one so applying marov does not tell us anything useful it tells us that this is a probability that's that's bounded by one which we already knew so it is a good idea it's not quite what we want here so what if instead of uh you know fiddling with the event we fiddle with r again kind of similar to what we did before yeah yeah exactly so we're going to flip R right so we're going to define a new random variable let's say s equals 100 minus r okay so now the probability that R is at most 65 is the probability that s is at least what 100 minus 65 okay can we apply Markov to that I'm seeing some nods does anybody want to do that and spare me the trouble of doing arithmetic nobody sadness okay uh well what does Markov say well it's at most the expectation of X oh sorry s divided by 35 okay what is the expectation of s well using linearity in the same way that we did a moment ago this is going to be equal to uh what 100 minus the expectation of R which is 75 over 35 so that's 25 over 35 this is 57s okay so does does that make sense to everybody there is at most a 57th chance that you uh did worse than okay now perhaps not terribly realistic in terms of exam scores but uh you know what if say some of the students did so badly that they got scores that are less than zero like maybe you've got uh you know R is in the range you know minus 30 to okay same deal expectation of r is 75 uh question or um sorry um okay so what can we say about the probability that R uh is at least uh say 90 mhm yeah exactly so the observation was right if we try to apply marov to this maybe I should call it a different call it something different let's call it t so if we try to apply Markov to T right it's going to be the same thing as as when we applied Markov to R before it'll give us a bound of of 83% the problem is that that's wrong that does it t does not satisfy the precondition for Markov okay so what we want to do instead is toine T Prime = t + okay and now if we apply Markov to T Prime what do we get so the probability that uh T is greater than 90 is the probability that t Prime is at least okay and by Mark of this is going to be uh expectation of T Prime over 120 okay and you know same deal as before linearity here gives us uh 75 + 30 over 120 105 over 120 that's 78 is that right yeah okay so in this case we do get a you know in some sense a weaker bound than we would have gotten by applying Markov to to t you know directly but you know applying Markov to T directly doesn't actually work this you know looks weaker but it's a correct bound okay so hopefully that answers your question more fully okay does anybody have any questions so even though we couldn't apply Markov directly to T we can create a new random variable T Prime to which marov does apply MH yeah uh so using the lower bound of 30 making the the the statement stronger for for t for S oh for S uh which one was s uh s here um so that does not really help us in this case um because that kind of corresponds to uh an upper bound right rather than rather than the lower bound uh and you know upper bounds don't really appear in in the proof of Markov like we're not really using them in any way so you know imposing a stronger upper bound doesn't really doesn't really help okay does does that kind of answer your question okay cool yeah uh okay is it always the case that the best lower bound appears or sorry the best upper bound I guess appears uh when uh when the the range actually includes zero um essentially yes okay as far as correct bounds go anyway okay [Music] so I guess there's a question of like morally why do we need this this non- negativity um and perhaps a very simple illustrative example is suppose we have the random variable R which is uh plus or minus one depending on you know a Fair coin flip okay so it's it's uniform on positive one and negative 1 okay so if we try to apply Markov to to that corly right what does that tell us about the probability that R is greater than2 well if we try to apply marov directly right the expectation of R is zero so you know no matter what we put here marov would try to tell us that you know the probability is at most zero okay that is clearly rubbish right because you know R can be greater than 1/2 R takes value one with probability 1/2 okay so basically our proof uh where was it here so if we if we get rid of the non- negativity constraint then this no longer works right we can't kind of discard This this term because that zero you know if we don't know that the the random variable is non negative we could in principle have a have a negative value there which you know we we we can't get rid of okay so another question is Markov tight so in other words can we make a stronger statement than what marov tells us you know out of the tin just with you know the information that we we have the mean and we have a non- negative random variable is there anything stronger that we can say who thinks yes couple of tentative hands who thinks no uh couple of less tentative tons who has no idea okay well let's let's think about some some uh simple examples then okay so let's go back to the uh cell phone check problem from uh was it last week don't remember which of the lectures last week Tuesday Thursday both both okay okay so if we consider the Lazy Susan version right and we let R be the number of people who get their phone okay so this is the Lazy Susan uh how could we use Markov to bound the probability that everybody gets their phone back so if everybody gets their phone back right that's R equals n what does marov tell us about this probability yeah yeah it's the most one over n why is that well the expectation of R is one as we saw last week right the bound we're looking at is n okay so there's at most a one and probability that everybody gets their phone back what is the actual probability that everybody gets their phone back yeah yeah the actual probability is 1/ n so this is tight okay we can't say anything stronger than marov without additional information okay does that make sense so if we know something else about our distribution then we might be able to say something more but if all we know is the expectation and the the non- negativity then Markov is the best that we can do okay on the other hand you know suppose suppose we're permuting all of the phones instead of you know putting them on the Lazy Susan Okay so so in this case what does marov tell us about the uh probability that everybody gets their phone back it's still one over n right we've still got uh a non- negative random variable with the same mean we're still looking at the same threshold right so marov gives us the same bound okay what is the actual probability that everybody gets their phone back well that's that's exactly when you have the identity permutation right you've got n factorial possible permutations one of them gives everybody's phone back so what we're looking for is actually one/ n factorial okay so so marov is is very much not tight in this example okay okay so the next question is what can we say if we do have more information about uh about a random variable so suppose we know the variance okay so the variance of those two distributions is very different right uh in the case where we put the the phones on the Lazy Susan we've got a very high variance in the case where we have a random permutation it's much lower okay so maybe the variance can tell us you know more about these probabilities okay so this is a different tail bound uh due to Chubby Chev so probability that R minus the expectation of R uh you know an absolute value is at least X is less than or equal to the variance of x / x^2 okay so note that we no longer require non- negativity here we just require information about the variance okay and well the mean we have to uh we have to compute it relative to the mean okay so but but R can be any random variable we're we're no longer constrained to to looking at non- negative ones it can be anything we just have to compute the variance okay how might we prove chubby shvs inequality any ideas is that a hand or a stretch yeah yeah so we're we're going to prove Chev using marov okay so in order to use marov what do we need well we need an all negative random variable okay so kind of similar to what we were doing earlier with shifting our random variable we're going to define a new random variable that we can then apply Markov to and that should give us this result here okay does that make sense to everybody yeah oh variance of R sorry thank you yes variance of X does not make any sense okay so what might be a useful random variable that we can apply Markov to well maybe here's a way we can kind of cheat uh in markov's inequality what's the bound that we get the bound should be the expectation of our random variable right so can we Define a random variable whose expectation is the variance of of R yeah yeah exactly so R Prime equals R minus expectation squared okay so this is non- negative right it's it's a square of some value uh its expectation you know by definition is the variance of R okay and also if we kind of squint right we can fiddle around with this to you know actually threshold R Prime instead of this absolute value thing that we've got here how do we do that well we just Square the stuff in the absolute value right as the same square as if we didn't have the absolute value okay so the probability that R minus its expectation greater than or equal to x equals the probability that R Prime is greater than or equal to x^2 right because those are exactly the same event okay they're the same event so they have the same probability and now this looks like something we can apply Markov to okay less than or equal to the expectation of R Prime oops divided by x^2 okay does that make sense to everybody so let's take a look at an example so let's look at those test scores again oops sorry my bad so our same deal we've got test scores expectation is what did we have 70 75 75 and say that that the variance is okay so now what can we say about the probability that R is uh most 65 any ideas how how could we how could we apply treby Chef to this that doesn't quite look like the theorem statement right but we can observe that this is at most the probability that R is at most or R is greater than or equal to okay right if we take the union of two events that Union has you know at least the probability ility of one of those two con constituent events so this is only increasing the probability if we add in this this extra you know extra half of the event okay and what do we know about this probability how could we rewrite that in a nicer way yeah exactly so this is just saying R deviates from its mean by at least 10 okay so now we've got it in the form that chubby CHF likes so we can apply chabby Chev this is at most variance of r divided by uh our threshold is 10 yeah 10 squ okay 25 over 100 equals one4 okay now we've got a much stronger bound this time than we did earlier Yeah question ah okay so explain this equality okay uh so R less than or equal to 65 or R greater than or equal to 85 um we could rewrite this as you know R minus uh well r - 75 is uh less than or equal to -10 and this one is r - 75 greater than or equal to positive 10 okay um so you know if you absolute value both of these you know they're both you know greater than greater than or equal to 10 okay does does that kind of make sense okay any other questions about uh about this this example so because we have more information than we had here right we can get a stronger bound okay knowing the variance helps us out so equivalently we could you know rephrase this in terms of uh you know standard deviations uh um where would be a good place to write this how about here so the probability of being at least two standard deviations from the mean is at most 1/4 okay does anybody have any objections to that last statement so if you've uh taken a stats class you probably heard something very different from that oh nobody nobody's taken stats that's good high school stats is terrible um um oh that's on camera um never mind stats are great just uh it's it's good that that you've saved it for University instead of doing it in high school um okay so yeah if if you're looking at a a you know a normal distribution right you actually have a much a much better bound than than 1/4 it's something like you know a few percent okay uh so why is that any ideas well for normal distribution right we know a lot more about the uh about the random variable than just its variance okay so if we know more even more about a random variable than its variance it turns out we can make even stronger statements okay just like adding in the variance was an upgrade from marov let's see how we can upgrade this again yeah what's upal distrib oh what's a normal distribution uh think of a normal distribution as um you know number of heads if you flip a whole bunch of coins it's that's not quite it but you know roughly speaking good cutch oh okay um so okay so yeah as I just said if you flip a whole bunch of coins let your random variable R be the the number of heads right uh you know a lot more about uh about this random variable than just its variance right you're you can decompose the random variable into a sum of a whole bunch of indicators okay and all of those indicators are mutually independent okay um in order to use chubby Chev right you don't need Mutual Independence right if you had something of that form you just need parir wise Independence right like you need to compute the variance okay but if on top of that you have mutual Independence it turns out you can do a lot better okay so suppose uh T1 T2 T3 up to TN are mutually independent random variables and uh well let's say in addition they're bounded um okay and the random variable we actually care about is T which is their sum okay then oh and uh say we've also got some threshold C which is at least one uh the probability that t is at least c times its expectation uh close that as well less than or equal to e to the negative C log of C minus C + times uh the expectation of t okay so a little bit of a mouthful but what exactly is going on here so basically marov was saying right uh that the the probability that you you know deviate from from the mean by a large amount uh it's at most you know it's at most linear in in you know how how far you're you're you're deviating okay Chev said it's uh you know at most quadratic this is saying it's at most exponential or like inverse exponential okay so you have a much stronger condition that gives you a much stronger bound okay uh and how could we prove it not like this any ideas maybe a proof sketch we we won't go through the entire proof so what what tools do we have already what might we be able to do well what happens if we apply Markov how can we apply Markov in order to use Markov right we need a non- negative random variable so in order to prove chubby right we uh you know took a square that made something non- negative what might be a reasonable thing to try in this case yeah add one uh okay so look at t + one instead of uh instead of T so that's actually going to that's not going to help us right T is already the sum of a bunch of non- negative random variables so it's already non- negative right like we're we're not looking to you know turn a non- negative or sorry turn an arbitrary random variable into a non negative one we are trying to find a more useful uh non- negative random variable okay yeah yeah take the log of both sides close what happens if we exponentiate so take T Prime equals c to the T what do we know about t Prime for well we're taking something that's at least one right or you know raising it to some positive power well some non- negative power okay so T Prime is a non negative random variable do we know anything more about it yeah it's at least one yeah so maybe we try applying markup to this okay so now we've got a random variable that takes values in the range from 0 to uh C the n c the N minus one okay now how could we rewrite this condition T greater than or equal to C * expectation of T in terms of T Prime well because C is at least one right exponentiation is monotone so this is the same as you know C to the T greater than or equal to uh C to the C * expectation of T okay and we don't have too much time so I think I will refer you to the book if you are interested but the the main idea right is this step here okay you take the random variable you care about and you exponentiate it okay and then if you apply apply Markov to that right it actually gives you a much stronger bound like you know if you're if you're using the the mutal independence of all of the component random variables right this will give you a much stronger bound than uh than even Shoff okay so I promised you last week that uh you know we would revisit the uh the coin tosses so let's do that briefly okay so suppose R is the number of heads uh if you flip end coins okay so if you recall we were looking at uh the probability that R is uh equal to you know n over4 before okay so or maybe equivalently three over 4 might be a better way to to analogize okay and I promised you that we would revisit this probability R greater than or equal to 3 n / okay now what happens if we apply uh each of our three tail bounds to R well first what happens with Markov so let's call this p p is at most what well the probability that R is at least you know some threshold it's going to be the expectation of r divided by this threshold okay what's the expectation of R and over two okay so this is going to be 2/3 what about chubby shf so similar to what we did with the first chbby Chev example right p is going to be at most the probability that uh R differs from its it expectation in either direction right by n/4 okay so what does that give us uh probability R minus let's say over two uh greater than or equal to n over4 is at most bar of r divided by uh n over 4^ s okay so what is the uh what is the variance of r does anybody remember we've got a sum of a bunch of indicators right they're all mutually independent so the variance is linear what's the variance of a single indicator nobody yeah yeah n over four oh for for R not for a single one okay so n over 4 / n^2 over 16 equal 4 n okay so much better right much better than the 2/3 we just got what happens if we use turnoff okay any ideas yeah plug in three halves for C so c equal 3 Hales okay uh okay um why don't I uh put TR off back up here uh okay and what does that give us probability that uh R is is at least 3es time expectation of R is less than or equal to e to the minus is it C log C minus C + 1 so this is a constant times the expectation of R okay so the expectation of r R is n /2 right this is a constant so we've got something that's exponential or inverse exponential in N oops uh e to the minus order n okay so marov gives us gave us a really bad found chabby Chev you know linear pretty reasonable turn off gives us exponential okay so that's all we have time for today sorry I went a little bit overtime uh it's been a pleasure teaching you all this semester um and uh let's see we have uh the rest of our instructors and at least one ta hello Lily uh yeah if anything went wrong it was probably my fault um anything that went right uh you have your Tas to thank for it um including Lily ly Lily's amazing um so yeah perhaps I will see some of you uh next term in uh in 61 121 um good luck on the final make sure you take the right one uh thanks for being students in this class it's been lots of fun yeah [Applause]