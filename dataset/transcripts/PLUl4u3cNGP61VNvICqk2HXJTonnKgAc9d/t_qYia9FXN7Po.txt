all right welcome back to 61200 today we continue our theme of probability as we will continue to do for the next few lectures um first uh recap from last class and last recitation uh key concept we'll be using today is conditional probability remember this notation is the probability of event a occurring given that you already know that b occurred which is like if you imagine this entire Blackboard as the space as the sample space all the possibilities of what could happen and we have events a is some subset of that space b is some subset of that space what the vertical Bar B means restricting to conditioning on b means focusing on just this red subset of where B is and just think about the probability of a happening relative to those events instead of think the probability of a happening relative to all events and you can compute that as the probability of this intersection uh divided by the probability of B so we're just focusing in assuming B already happened then this is becomes our entire sample space that we can restrict to okay and then we can use that for example to compute probabilities of events so this was law of total probability probability of an event a is uh if you pick your favorite event e sort of like a proof by cases you get to choose any event e you want that's whatever's most convenient then you can compute compute probability of a using by splitting into two cases one where e occurs and one where e does not occur so you take the probability that the E occurs you multiply it by the probability that a occurs given e and you do the same for not e and because uh e and not e are by definition disjoint events exactly one of them happens this uh works out you have the uh the product rule here between these events and the sum rule between these events I think easiest to see in this tree um I tend to draw my trees vertically you can draw them horizontally whatever uh we have uh event e occurring or not occurring and then separately we have event a or not a occurring and any of these could happen in any combination when we write down a tree usually we write on the edges conditional probabilities at the beginning there's no condition so it's just probability of e on one side and probability of not e on the other side uh but then usually on this Branch we write what's the probability of a given that e occurred and on this Branch what's the probability that not a occurred given that e occurred this whole branch is that e occurred and then we care about given that we got here what's the probability of a happening what's the probability of not a happening and similarly on the other side what's the probability of a and not a happening given that e didn't happen that's those are all the cases um and then you can compute the probability of each of these individual situations by taking the product of these probabilities down the path um that's what we have shown in the past and so in particular if you want to compute the probability of a a is these two nodes together these are the two a branches and so that is this product plus this product by construction everything here is disjoint and so you can just add the probabilities up and you get get this law okay we may use it today uh today I want to talk about a related concept which is Independence so today is Independence Day not starring Will Smith or any other modern versions of Independence Day um and the the tagline for Independence Day back in the 90s I was alive back then uh it says the question of whether or not we are alone in the universe has been answered you know are we are we independent from the rest of the universe or are we dependent it turns out the answer is uh we're independent if and only if probability of a given a b is probability of a that's sorry spoilers for the movie but that's that's what you get by the end so that's our mathematical definition of a is independent of B if probability of a given B uh probability of a conditioned on B is is just the probability of a again so in other words conditioning on B does not affect the probability of a with the condition without the condition you get the same thing um we have to also say or the probability of b equals zero uh for this annoying technical reason which I forgot to mention up here probability of a given B is not defined when probability of B is zero because then you get a division by zero error we don't like those so uh I don't even know what this means when B when the probability of B is zero so we need to say whether we're independent in that case and we are so it turns out the empty event where no which never happens is independent of everything also the full event which always happens is independent of everything uh so this is a way to measure uh whether two things are independent uh meaning whether the outcome or like whether a happened whether B happened has any impact on whether a will happen that's intuitively what this means and it's a useful concept here isong page an example uh that gives you some intuition about why the Monty Hall problem comes out the way it does so let's do Monty Hall um I'm G to Define two events one is door one uh has a prize so I forget the door names that uh brinmore used so I'm just going to call them door number one two and three just like in the game show uh and I don't have fancy colored boxes okay I'm I'm not going to repeat the whole analysis of Monty Hall but I just want you to think about these two events so event a is that door one has the price we know without anything else this happens with onethird probability uh event B is that door two is revealed to not have the prize after player after the player chooses door one okay this is a bit of a mouthful but let's just suppose uh that the player starts by choosing door number one uh in the analysis we did we had a uniform random choice of choosing all three doors it doesn't actually matter which door you choose because everything else is random it's fine if you always choose door one but whe whether it's random whether it's deterministic let's just suppose the player the player chooses door one and event B is Will door number two be revealed uh to not have the press okay and now my question is is event a and event B uh are they independent from each other and I claim that they are uh and the way we can determine that is by Computing these two probabilities probability of a and probability of a given B now probability of a we know is uh 1/3 right with that this is just does door one half prize that's uniform random so uh oneir for that and so for this to be independent it better be the case that uh probability of a given B is also 1/3 and if you think about it uh that is one of the things we computed um because what we computed was what's the probability of switching uh the switching rule winning so we're supposing here the player chose door one and so if in the switching strategy they will switch to uh in in conditioned on b means that player the player chose door one and door two was revealed not to have the prize and so we would switch to door three and we worked out that the winning probability if you in the switching strategy was 2/3 so that means the probability that door one has the prize must be 1/3 because the probability that door three three has the priz is 2/3 and 1 - 2/3 is 1/3 so indeed these are equal and the events are independent and while I don't claim this is super intuitive yet um I mean if you stare it's like you stare at it for an hour and then it's intuitive so it's not especially intuitive but I think while before we saw you can just compute everything and find the answer um I think this does give a little intuition the idea is that revealing door two to not have the prize doesn't tell you anything about whether door one has the price and that's intuitively why switching is good because you've reduced down to two uh possibilities instead of just instead of three if you stick to a uh it will be as if you were no doors were revealed right if you suppose you pick door number one at the beginning and you uh decide I'm just going to stay no matter what then whatever information they show you doesn't tell you anything about uh uh whether door one will have the price and that's that's what this is confirming that that vague feeling that might be true uh this shows that indeed this information being revealed tells you nothing about whether a will happen or whether a happened I guess uh the probabilities are the same either way and so this gives you some intuition for why uh the monteal problem came out the way it did still you should compute things but the goal by the end of this class is you'll have at least some intuition about probability and hopefully it will be the correct one here's another situation to think about suppose you have two events A and B which are disjoint so they're two subsets of the sample space and they don't have any elements in common so we normally write this as a intersect B is the empty set then are they independent well uh let's just compute these probabilities probability of a I don't know how to compute but probability of a given B that I know how to compute I zoom into B and I see how many A's are in there and zero there's no a inside B uh in other words the probability here probability of a intersect B is zero because there's no intersection so whatever the denominator is is zero okay and uh so this means they are not independent typically uh unless uh some exceptional cases happen namely uh I guess it could be that a is also the empty set there's nothing in a then probability of a um equals this thing probability of a given B uh and the other situation is uh probability of B is zero because that's another situation where we just have independence by definition okay so disjoint events are not independent uh the intuition here is if I tell you that b happened you know very well a did not happen because we assume these are disjoint events okay another example is uh subsets let's suppose which way is easier B is a subset of a so a is the big thing and B is nestled inside then I want to know uh what is the probability of a given B well if I zoom into B it looks in completely a all of this is included inside a and so this probability is one and so this is another situation where uh A and B are not independent unless some very special cases happen uh namely it could be uh a is everything a always occurs probability of a equals 1 um or again it could be probability of b equals zero so if B is just nothing then uh they're independent just by definition if a is everything then uh yeah restricting to B it's still everything question why don't we say dependent it's a good question uh I believe traditionally not not independent we could just say dependent uh I guess I don't know what dependent means I guess you could try to Define dependence like amount of dependence and maybe statisticians do that but in our worlds we generally just Define independent and then there's the converse and we call it non-independent I agree it's weird you could maybe think of it as dependent but pretty sure it's not standard all right uh let me tell you some more ways of course the in you take two events they're probably dependent in some sense uh Independence is kind of the special thing and it's what we are going to focus on is detecting when when an event is independent so let me tell you some ways to other ways to compute it so we can use this definition and compute it uh but it's It's oddly asymmetric right we talked about the probability of a given B what if it's easier to compute the probability of B given a for example or something else uh there's another nice characterization which I'm going to call the product rule we've already seen a product rule with inclusion exclusion but um here's another one so an event a is independent of another event B if and only if probability of a intersect B is the product of the probabilities okay this is what you this is what makes sense I guess in some sense if uh naively if you try to if you want to think about the probability of of an intersection what's in other words the probability of one event happening and another event happening naively that would be the product and Independence is exactly when you can do this if you're independent this is true if you're not independent this is false so it this is some sense why we care about independence uh and yeah let me get another chalk here and it's effectively what we're using in when I was saying oh uh the probability of this event happening is the probability of this thing happening times the the probability of this thing happening conditioned on this one that that multiplication is is okay partly because I mean in particular because event e is independent of a given e in some sense I guess this is not properly an event but you can think of it that way all right let's prove this theorem uh by cases so case one what I'd like to branch on is is the probability of b equal to zero because it's just annoying to work with this definition there's a special case b equals zero okay so that turns out to be the natural case breakdown case two is going to be probability B is not zero okay so uh when B probability of b equals z we know uh that a is independent of B that's part of the definition so now uh so this part is true so for this if and only if to be true we better make sure the probability of a intersect B is equal to that product okay but then this number is zero so this product is zero so what we really want is that the probability of a intersect B is zero and indeed probability of a intersect B is at most probability of B why because this set is contained in this set and probability is monotone if you take a smaller set it contains all the elements of this set then this probability will be less than equal to that uh and probability B is zero by assumption uh and so it's also equal to probability of a Time probability of B I guess I'm also using that uh probabilities are non- negative and so I've sandwiched this probability between Z and zero which means it equals zero uh it's both less than or greater than or equal to zero so equal zero and so we're done with that case Okay probability be not equal to zero is the more interesting case because that's when we get to work with this formula probability of a given B is equal to probability of a so that's the definition of independence so write Independence if and only if probability of a given b equals probability of a okay so now we have some uh computation to do let's see we also have a formula for probability of a given B up here that's the definition so let's plug that in probability of a intersect B divided by probability of B okay so this is equal to that this is equal to that so these two things are equal and now on this equation I'd just like I see probability of a here I see probability of B on the denominator here I'd like to multiply both sides by probability of B and I get uh this is a equivalent to probability of a Time probability of b equals probability of a intercept B which is exactly what I wanted to prove that's so I'm done uh crucially here though I'm using in order to multiply both sides by probability of B and to get an if and only if it's crucial that this is not zero if you multiply both sides of a formula by zero you don't get a very interesting formula and you don't get an if and only if so but once I assume that probability is not zero then I can actually do the multiplication and uh and I get a useful statement and this is true so I get the cancellation I wanted otherwise I get zero over zero okay so uh this tells us a different way to determine Independence right we could compute this thing and this thing uh or we can compute this thing and this thing uh and if they're equal it's the same thing as that condition being true notably uh this definition or this condition sometimes this is the definition of independence you might see both uh they're they're equivalent so you could use either one this definition is symmetric in A and B if I swap A and B I get exactly the same thing right a intersect B is the same as B intersect a probability of a times probability of B is the same thing as probability of B times probability of a so uh I no longer have to say a is independent of B I can just say A and B are independent without worrying about uh which one's first so corollary uh independent of is a symmetric relation a is independent of B if and only if B is independent of a so I'll just talk about A and B being independent for from now on this definition is not obviously symmetric but now that you know that these are interchangeable if it's easier to compute probability of B given a you can do that as well you can do probability of B given a equals probability of B that's just as good as checking this one not obvious from that definition but through this transformation it becomes obvious all right let's uh let's do some more interesting examples and let's start with flipping to Independent Fair coins okay now that you know what Independence means we're going to be using it a lot uh in particular just as an assumption uh a lot of probability problems are not well defined unless you specify as part of the statement that uh two random events are independent from each other you already saw this in your problem set we wanted all of the errors that the bots made to be independent from each other meaning uh whether one thing happens does not influence the outcome of the other so a simple example of this where you this is a reasonable assumption is you have two coins uh I don't use physical money anymore but imagine you have two coins and you flip them whether this one comes out heads and whether this one comes out heads should be independent of each other unless you I don't know glue the two coins together then they're very dependent I used it dependent um so usually when we're saying we're going to flip a bunch of coins we need to specify are they somehow linked together maybe I don't know they have some quantum entanglement and whether one comes out heads influences the other or they're physically attached or something like that but normally we think of the case where the coins are all dependent okay so we're going to use Independence also as an assumption in the problem statement and that specifies uh in some sense what your sample space should be then there's another assumption here which is fair that means that they come out 50% heads 50% Tails so um sample space is uh heads and tails squared so heads and tails cross heads and tails uh the the set of pairs heads Tails heads Tails um or X Y where X and Y are in H or T I forget whether we've squared sets before but that's the meaning just like the cross product of two of them um and so there's like a there's the first coin and the second coin this is an ordered pair and they're each equally likely the assumption that they're independent tells us they should be uh all all of these outcomes are equally likely or the assumption that they're independent and fair makes them all equally likely I guess all right so let's do this more precisely let's say a is the event uh that the first coin uh comes out heads El is uh and let's let B be the event that the second coin comes out hits okay um I would like to claim that these two events are independent from each other not just by assumption but by Computing according to either of these formulas okay so let's let's do that so we fully understand situation I'm going to draw tree here so this is the first first coin and this is the second coin each one can be heads or tails okay and because we're assuming fair this should be probability half this should be probability half also here the probability of each of these coin flips being header taals given the previous one uh it doesn't matter that the first one happen so uh we just write a half half on all of these edges okay so now I want to say let's say probability of B given a this is going to be a little bit circular because we're using Independence both as an assumption and the thing we're Computing but we should be used to drawing these kinds of diagrams under this implicit Independence assumption by now we are told this the number we write here is the probability of this thing happening given that this one happened okay so probability of B given a uh so this this was um a is this Edge right I guess this node is event a in some sense a is that the first coin flip was a heads so probability of B given a is exactly the probability written on this Edge because this would be uh B given a that event a happened and then B happened or I guess the maybe the edge is more is thought of this way this is more like a intersect B that they both happened okay but however you slice it probability of B given a is a half that's what we defined the probability of the second coin being a heads given that the first one is also a heads shouldn't matter is a half and on the other hand the probability of second coin being heads by itself is a half so yes it's independent I may say okay not a very exciting example let's uh slightly more exciting is that uh let's say first coin uh heads probability is p and second coin uh heads probability is q so I invest in some weighted coins it's probability of P that the first one comes up heads probability of Q the second one comes up heads maybe p and Q are equal to half or maybe there's something else uh then still I get for example uh I don't know the probability that A and B happens is going to be P * Q it's hard to do this without assumption that these are independent events but this is this is how we've been Computing things and that's also probability of a product with probability B okay not very exciting let's make this interesting and Define some events that are not just a function of one coin but in fact depend on the entire sample space so I'm going to go back to this example and define s to be the event that uh I guess I should write a and b are independent here and a and b are independent here okay but now I'm going to write an event that's not so obvious uh the S event is going to be that the coin flips come out the same either both heads or both Tails okay this clearly involves both coin flips so you might think that s and a say are dependent on each other intuitively they are but according to this definition they are independent that's the claim so let's compute it um I claim the easy one is to compute probability of s given a so in this diagram a is that we're here uh that we flipped ahead so far and now I want to know the probability that the coins come out the same well condition on a being a heads that's the same as the probability of uh the second coin being heads right so this is just uh the probability of B which is not quite what I wanted we wanted it to be probability of s I guess but it is equal to the probability of b um which is a half by assumption on the other hand we want to know is the probability of s the same thing well probability of s is uh corresponds to this node and this node right this is the head's heads case this is the Tail's tails case uh we know the probability of this is a quarter because it's 12 * 1/2 and the probability of this is also a quarter 12 * 1/2 we know all of these are equally likely a quarter and so probability of s is the sum of those two uh this is quarter plus a quarter also known as a half and so these two things are equal so you can think of this as a betting game suppose uh I ask you to bet on whether uh two coins are are going to come out the same or different and they're Fair independent coins so I'm going to flip them and you get a dollar if they're the same and you lose a dollar if they're different or something like that um if I flip the first coin and it comes out heads that doesn't tell you anything uh you're still going to have a half half probability of winning when the second flip happens right uh doing the first flip does not tell you anything about whether the second flip is going to be the same as the first one because it's still equally likely to be equal or not equal that's what this is formalizing okay but until you compute it I would say this is not exactly obvious all right let's do the same thing so here uh A and S are independent let's try the same thing with unfair coins suppose we have uh parties p and Q and we have S is the event that the coins come out the same now things are not so easy uh so what's the probability that they come out the same maybe I should draw this tree again for the not same ca for the unfair case so we've got heads tails for the first coin so this is probability P this is probability 1 minus p and then we've got heads and tails for the second coin which we're assuming now is probability q and one minus Q independent of what happened before okay and still s is this plus this and so we just take these products and add them up so probability of s probability of heads Heads maybe I'll write it out uh probability of heads Heads plus the probability of Tails Tails uh the first one is p * Q so the probability of getting the first heads is p the probability of getting second heads is q and by assumption these are independent so I can take their product uh and the other one is 1 P * 1 - q and now I just get some ugly algebra this is like 2 p q minus P minus Q + 1 I think Check Yes okay uh on the other hand let's try uh probability of s given a this one is actually easy because uh this is saying okay we condition here's a we condition on there being a heads in the first step what's the probability that the same well that's the same as the probability that the second coin comes up heads as well and so that's exactly Q so uh these things are going to be independent so I guess uh s and a are independent if and only if uh 2 PQ Min - P - Q + 1 = Q in other words uh 2 p q - P - 2 Q + 1 = 0 and this happens to factor I don't claim this is obvious but it is the same as uh 2 Q minus 1 pus 1 = 0 and so uh there's two there's two ways to for this to be true one is that P equals one in other words the first coin always comes up heads I would call that a one-sided coin or you can make them by manufacturing coin that's heads on both sides that's a two-sided coin but really only one side or uh Q is a half so if Q is a Fair coin sorry if if the second coin is a Fair coin then s and a are independent of each other and so uh this tells us that uh what we found here which was that s and a were independent of each other really needs that the coins are fair fair coins and one-sided coins are the only situation where uh this s event uh here that the coins come out the same is independent of the first or second coin so if we were playing this gambling game with unfair coins and you knew p andq and I told you that the first one came out heads that actually uh tells you something about whether you're more or less likely to uh for the next coin to match it because then matching is no longer uh symmetric all right so lots of examples of coin flipping um maybe it gives you some intuition for some examples that are independent and some that are dependent why do we care about nfir coins uh well one fun uh fact is that normal coins are not fair they're more likely to come up the same orientation that you flip that you started in then they are to flip over and there's a nice physics model by perc diaconus and others uh from back in 2007 that uh computes that for normal coin flips uh you should get uh about 51% chance of staying on the same side so if you play this game with somebody and you make money uh please thank us um there's there's this thing called procession coins when you flip them vigorously as they say uh they tend to also spin in this way which does not cause them to flip over and so they spend more time a little more time uh face original versus face upside down and that gives you a slightly higher chance uh on the right is a is a machine that always flips the coin the same number of flips and so it always produces the same result that's cheating uh this theoretical model was recently verified experimentally for 350,000 real coin flips uh by these 50 authors this was like an online Internet collaboration uh just completed last late last year um and uh they compute maybe not 51% but 50.8% is the thing that they get or somewhere between 50.6 and 50.9 so it confirms this this intuition although it does depend somewhat which currency you use and uh who you are different flippers have a different style in flipping and so your personal probability may be different from this one so keep that in mind uh there are a zillion videos uh online of these like 12-hour marathons just so you know for verifiable science where you can watch people flipping coins and typing in the result and flipping coin type in the result and anyway that is uh you can watch this for the next 12 hours or we could go back to lecture um all right so some more Concepts uh Independence between two events is kind of cool but what if we have more than two events we do this all the time in this class we talk about uh I don't know whether two vertices in a graph are connected and then we want to know well what about what if the we want the whole graph to be connected what if we want all the the vertices in the graph to be connected for that it was enough to do things pairwise we said well if every pair vertic sees there's a path then then that's a connected graph that turned out to be the right answer for graph connectivity with probability it's much more annoying so uh one thing you might Define is what we call pairwise Independence so uh I guess let's suppose I have events um E1 through en n then I'll call them pairwise independent if uh for all I and J uh between one and N uh with I not equal to J um EI and EJ are independent okay of course EI and EI are not independent that's the it's one of the overlapping cases uh so EI is not going to be independent from itself but it should be independent from all the others okay this would be the natural pairwise definition on the other hand we have a stronger notion called Mutual Independence this is more annoying to verify but it's probably what you actually want and it says not only if I take any two events they're independent from each other but if I take any subset of of events it's independent from any one event you could also compare subsets to subsets that doesn't turn out to matter so what matters is uh if you fix any event EI so e uh I is between one and n and I take another set set J it's a subset of the elements from one to n uh except it should not have I because we don't want to compare EI to itself then we want EI to be independent from uh the intersection of the ejs so I forget whether you've seen this notation you've seen big Sigma for sums you've seen big Pi for products this is big uh big intersection for intersection I guess we ran out of clever idea clever Greek letters uh so this is just the intersection of EJ uh for all Little J and Big J so we want each event EI to be independent from the intersection of any subset of the other events this is uh a pain to verify for lots of events let's just think about it for three events for a little bit so there's on the one hand we have pair wise Pence where you just compare E1 versus E2 E2 versus E3 and E1 versus E3 and here uh you do that but then you also compare like E1 versus the intersection of E2 and E3 and you compare uh E2 versus the intersection of E1 and E3 and you compare E3 with the intersection of E1 and E2 okay so twice as much work uh you check this Independence definition and you get your answer uh let us do uh an example maybe first some motivation let's do some forensics okay suppose you are at a murder scene and you find nine pieces of evidence that's a lot of evidence it's probably not realistic but let's uh for sake of example uh say you find nine markers that a uh that are consistent with a particular suspect being at the scene of the crime uh DNA whatever uh and let's say Mi is the event that a randomly chosen human matches marker I oh yeah I should tell you another version of mutual Independence which is useful uh so equivalently this is the product rule form uh for any J that's a subset of one up to n uh the probability of the intersection of EJ for J in Big J is equal to the product of the probabilities of the individual events J and Big J okay this is the natural generalization of uh what we had for the product rule for Independence between two events okay so back to forensics we have uh suppose we have a bunch of these events and for each one we compute we know their probabil because we know taken lots of surveys or whatever let's say the probability of each Mi uh is equal to 10% 10% chance that you match this particular marker for each marker just for Simplicity so say it's the same for all of them in reality it would be different so uh You' now what we care about uh supposing that so this is just assuming like sampling a random human uh maybe in the area I don't know let's say All Humans we're fair or something we have no prior assumption then um what we care about is the probability that all of these come out as matching our particular human that we have in mind so we have a suspect and now we want to take the intersection of all those events we want to and suppose that human matches all of those markers now we want to know what's the probability that that happen for a random human and you would like to say this is 1 10 9 one and billion chance so there's only like six people who could match uh but that's only true if these events are mutually independent it's actually true if and only if the events are mutually independent this is the definition a definition of mutual Independence well okay so mutual Independence is a little stronger it says not only the intersection of all nine events uh is the product probability is the product of the probabilities but also for any subset of those nine events so that's crucial uh we don't need that for this example this example we only care about the intersection of all nine but if you want to prove that something is mutually independent you need to check all of the events intersected together and also different subsets of them intersected together so keep that in mind on problem sets let's do uh a more interesting example uh where this matters okay back to coin flipping the source of all examples today uh let's say we flip three mutually independent coins Fair coins so we're going to State Independence as an assumption this is again this is now saying that the coins are not related any way they're each flipped completely separately from each other no impact uh from one to the other according to that definition say but now I'm going to Define some events that are interesting so a is going to be uh the event that uh the first and second coins come out the same when you flip them uh event B is going to be the event that the second and third coins come out the same and event C is going to be the event that the third and first coins come out the same are these events independent I don't think it's obvious so we compute all right let's start with par wise Independence let's think about uh say the probability of a intersect B versus the product of the probab ities of A and B so we I mean we did this if you were strict to just a for example let's let's start with probability of a probability of a only depends on the first and second coins so this is exactly an example we saw before where we just flipped two independent coins and we had this s was the event that the coins are the same so that's probability of s that's going to be2 okay so probability of a a over here sorry for the relabeling this is just like probability of s before and so it's 12 okay probability of each of these events is individually 1/2 so what we would like is for the intersection of two of them to be probability a quarter right 1 half times2 so let's see if it is all right now we have to actually look at the problem so a is the event that the first and second coins are the same B is the event that the second and third coins are the same so this is like uh this is like coin 1 equals coin 2 and this is like coin 2 equals coin 3 so if they're if both of those things happen if C1 equals C2 and C2 equal C3 uh the the intersection here is um C1 = C2 = C3 right so uh in other words this is the probability of heads heads Heads uh I guess I'll WR as a set oh boy too many too many brackets I'm gonna have all three types of brackets this is exciting probability gets square brackets then set gets curly braces then an ordered pair gets round parentheses I'm happy they're all distinct makes it so much clearer all right so this this braced quantity in the middle here is an event remember events are just sets over the S subsets of the sample space so it's a set of possible samples so uh a intersect B is the same thing as all the coins being the same that means headsets heads or tails Tails Tails okay so that probability we could rewrite this of course as the probability of headsets heads I'm going to Omit some parents here just for Simplicity plus the prob of tals tals tals because these are different samples they are dint from each other and so we can use the sum rule uh and the probability of each of those events is 1/8 right it's 1/ half to the power three it's 1 12 * 1 12 * 1/2 because each of them is uh independent so this is 1/8 plus 1/8 which is one4 and that's what we uh not we wanted that's funny I make a mistake I did I did oh no that's what I wanted right sorry this probability is a what I wanted was this for to equal not probability of a but probability of a times probability of B uh these were each a half and so their product is a quarter and so that matches so these are pairwise independent okay I only computed it for a intersect B but you should also in principle do it for B intersect C and A intersect C all the pairs uh but by symmetry if you think about this the right way those will all come out the same okay I'll just wave my hands at that uh but what about Mutual Independence so these three events are mutually in or pairwise independent but they are not mutually independent let's prove that or let's compute that for that we care about uh we could do probability of intersection I claim it's a little easier to think about this probability the probability of C given a intersect B because we just thought a lot about what a intersect b means it turns out to be equivalent to saying that the three coins are the same so now what is the probability of C given that the three coins are the same prob C says the third coin and the first coin are the same so what's this probability one yeah remember this this notation means compute the probability of this event zooming in the special case where a intersect B is true so that in the S the sample space has eight possible spots it's like a it's like a cube I guess each axis is heads or tails there's also a back back face here uh and what we're saying here is um a intersect B is just the two extremes heads heads Heads Tails Tails Tails maybe you're used to the cube and this is familiar that they're opposite Corners like this maybe not um and so if we zoom into just those two places and we want to evaluate well what's the CH what are the chances that coin 2 equals coin 3 or actually what was it no third first and third coins it doesn't matter right what are the chances that the first coin and the third coin are the same in these two scenarios well 100% it's guaranteed if you already know that all three coins are the same which is what we figured out a intersect b means then of course the first and third coins are the same okay uh whereas the probability of C from the without any condition is 1/4 one half sorry uh just like probability of a here that was the s that we computed before so these are different from each other uh so uh not mutually independent so this is kind of an interesting example where you have pairwise Independence but not full Independence not not triple wise Independence and there's only three events so that's the most you could hope for uh in computer science these things actually matter when you do algorithms and like hashing in particular it matters how much Independence you have some hash functions are pawise independent or maybe three wise independent or five wise independent all these things are important Concepts in hashing for example but we won't we talking about that here that's the next class six 121 all right finally we have well one or two more interesting examples okay um big one is the birthday Paradox or you might call it the birthday principle but I like I like living in a contradiction so we'll keep it as a paradox it's not a paradox it's just a a surprising fun fact something where intuition and uh does not match mathematics uh so the the Paradox is that if you sample a bunch of people and measure their birthdays you're a lot more likely that you might expect to get them to uh to have two people with the same birthday okay let's call them Birthday Twins okay if you're actually Twins then you have the same birthday pretty almost certainly unless you span midnight uh but uh are there any twins in the audience or like both of you are here okay I didn't think so so then I'm going to assume that your birthdays are all independent from each other I think twins are pretty much the only way to get dependence um and I'm going to assume that you're equally likely to be on all days and uh that's less true in reality uh but the the effect of the birthday Paradox will only be stronger if you have a non-uniform distribution like we do in reality uh so um given what you already know in this class in particular uh the pigeon hole principle or the Pidgey hole principle if you're a Pokemon fan um what how how many how many people do I need to take in order to guarantee that I have a duplicate birthday some Birthday Twins you remember all the way back to the pige and H principle yeah 366 for a 365 day year which is which uh so D here let for example could be 365 325 how many days are in a year all right um so in general if Nal D + 1 uh then we get guaranteed duplicate and of course if it's bigger also and the surprising thing is that probabilistically so this is for worst case Behavior I mean if I had n equals D could be each of you has their own birthday each person in their own birthday uh pigeon hole um but that's very unlikely it turns out and we're going to about to compute How likely it is so maybe we can do uh an experiment uh which is I'm going to see whether anyone here has the same any two people have the same birthday if you're willing to raise your hand so please pay attention because I want to go through days really fast so let's start with August the most common month so okay among the August people how many on August 1 August 2nd August 3rd August 4th August 5th August 6th August 7th August 8th August 9 August 10 10 just one August 11 1 August 12th oh two all right August 11th two August 11th yay we did it didn't even have to get through August it's because we have quite a few people here um I don't know maybe a 100 so uh turns out for D equals 365 let's assume no leap years uh if okay so we had like a 100 people I'm going to going to warm you up with 23 people 23 people is where the probability is just barely greater than 50% that there's uh two people so big difference from 365 uh n equal 30 the probability goes up to 70% n equal 60 the probability goes up to 97 % oh 99% 99.4% okay very high uh n equals 100 and he guesses how many nines five six six nines a holy grail of 6 69 97% it's a lot of nines okay so uh the probability grows exponentially uh but in particular this break even point is surprisingly low uh 23 versus 365 it's a little bigger than the square root it's like 1.2 time the square root of 365 is about 23 uh so that's the surprise the Paradox let's compute it it's actually similar to something we computed before in a combinatoric setting which was the uh how many dollar bills where uh there are how many dollar bills are there where none of the digits in the serial number uh were duplicate right so we computed that way back when I'm going to do a similar thing here similar trick uh let me first set up the sample space this is like coin flipping but more like rolling I suppose you have n people each of them rolls a desided die so that means the sample space is just the set of tpls uh do I want to call it D no let's call it B for birthday B1 up to BN uh where each bi is between one and D let's say let's number our days one to D and this is a curly brace uh the event that we care about is getting duplicate birthdays so this is uh so I'm going to call this s so what we are interested in is uh the set of tupal birthdays where um there are some two indices I and J where b i equals BJ right that's the duplicate birthday that's the Birthday Twins this happens with high probability and is very annoying to compute the probability of uh but there's this one trick which you may recall from the uh when we were looking at serial numbers on dollar bills let's think about the complement event so if we look at e bar this is the set of birthday tupal where there are no duplicates that's easier to figure out so we want to say for all I not equal to J bi does not equal BJ okay this is easier to think about as a process if we think of this going back to like generalized product rule uh how we want to know how many different ways are there to do this where the first birthday that I choose it could be anyone I don't care there's D different possibilities for the birth first birthday that I choose then uh the next birthday I choose there's D minus one options if I want to avoid duplication okay then the next birthday there's D minus two options hope play this is old hat by now you're used to generalized product rule and uh hard part is knowing when to stop this is going to be D minus n + one I think should be the right sure yeah this is generalized product rule this is the number of ways and we're assuming that each Tuple of birthdays is equally likely this was our assumption everything is independent and uniform uh so what we need to do is take the number of ways this happens and divide it by the entire size of the sample space divide it by the size of s okay so I'm going to divide this by uh and this is going to give me the probability of e bar here the probability of getting no duplicate birthdays is the number of ways to get no duplicate birthdays divided by the number of different ways to get birthdays period and that is just this is the non-generalized product role how many what is the size of s here yeah D to the N thank you it's either n to the D or D to the N you got to think for a while it's like yeah D to the N there's D ways for this D ways for this D ways so it's just the product of n D's the product of D * D * d n * so I'm going to write that as D * D * D times uh D there's exactly n terms upstairs and there's also n terms downstairs okay so now I have this crazy ratio between into products I just just need to compute it okay this is a bit annoying um but one big Insight so this thing is equal to uh instead of taking this product and this product separately and dividing them I could instead take this ratio and multiply it by this ratio and multiply it by this ratio and so on right that's that's why I wrote out this D to the n as a bunch of D's so I could take them uh element by element so this is going to be equal to the product from IAL 1 to d d uh of n sorry there's n different terms each of them is of the form D minus I over D and I have an index error so I need to start at zero and end at n minus one okay that will give me the right thing on top top I start with D minus 0 I end with d minus nus1 okay so this ugly formula actually gets pretty clean okay now is when uh it's hard to evaluate but there's this great fact uh okay so first I'm going to rewrite this as uh product as one this D over D is one and then we have an i over d in the second half okay this um turns out to be nice because uh one - x is less than e to the minus x e here is Oilers constant two roughly and a little bigger than two and uh if you look at the tailor expansion of e to the minus X which is something you may know from calculus it starts with 1 - x and it's like plus x^2 - x cub whatever maybe some denominators there too but 1 - x is actually um well approximated by eus x uh and it so it's approximately equal for X small and if you think about what x is here uh it's a probability it's less than one so that's pretty small and so this will actually be a pretty good approximation we're going to replace 1 - x with eus X and then this product will be easy to evaluate easier so this going to be e to the minus I over D okay uh sorry not equal this is going to be less than so it's a good approximation when X is small but it's always less than because the next term is positive at least for x non- negative it's going to be less than and so if we get an upper bound remember uh we're evaluating here the probability of ebar ebar is like our error case the bad case we want to show is unlikely so if we can upper bound the probability of the bad thing happening that gives us a lower bound on the good thing happening uh good thing being uh Birthday Twins okay we're almost done with briday Paradox so uh the cool thing here is we have a product of exponentials you may recall that if you have I don't know e to the X time e to the Y this is equal to e to x + y right so if we're this is taking a product of two exponentials is the exponential of the sum and more generally if you take n the product of n exponentials that will be the same as the exponential of the sum of those N Things so this is equal to e to the sum I didn't leave myself in a room e to the sum i = 0 to n minus one ofus I overd I guess maybe I should put the minus out here it's a little cleaner okay uh and I can parenthesize like this over D because this D does not depend on I so the sum of I over D is the of is the same as the sum of I all over D I've still got this minus F front and this is our good friend arithmetic sum the Triangular numbers it's indexed a little funny usually we think one up to n which is n * n plus 1 over two uh this is 0 up to n minus one zero of course doesn't matter uh so it's really one up to n minus one so this is going to be e to Theus uh n * n -1/ 2 and then the whole thing's over D so we end up with a D in the denominator okay so this was the probability that there are no duplicate birthday and you can see uh it goes down exponentially this is remember e to the X is one e to the minus X is 1 over e to the X so so the denominator here is increasing exponentially as we increase n and the big thing is and so that's why you get so many nines very quickly out here but if we're interested in this crossover point where we get 50/50 chance that there's a duplicate birthday versus not which is interesting the big thing that matters is that we have n squ up here there's a minus n but the big part is n s and this if we invert it this is where we're going to get a square root Behavior so uh let's suppose uh that this probability is equal to a half or roughly equal to a half when does that happen uh we did some approximation here with this less than so this isn't going to be exactly right but it's close uh we want this exponential to equal two right so we want e to the N nus1 over 2D sorry move the E down here this is all in the exponent we want this to be equal to two that's when one over it will equal a half okay so we take logs of both sides that's like n * nus1 over 2D equals lwn 2 natural log uh so we maybe move this over we get n * nus1 = 2D L 2 and at this point I'm going to wave my hands a little bit and say this minus one doesn't matter too much and so basically this is a square root so it's going to be n is roughly the square root of 2D lwn 2 and so there's this there's this constant term which is square < TK of 2 L 2 this is about 1.1 77 so this is about 1.2 to the square root of D this is what I claimed before if you take 1.2 * the sare OT of 365 you get approximately 23 if you compute it exactly you get 23 so kind of neat uh in general if you have D days you need about square root of D people to get a duplicate this has all sorts of implications in computer science usually in the context of hash tables if you're trying to if you're randomly placing people into uh locations pigeon holes I suppose uh it's once you have square root of n or square root of D different people you're likely to get two that happen to cohabitate unless uh you know if you choose them uniformly uh so for example if you're if you're a cryptographer and you're signing your emails uh you would you want to guarantee that you don't have uh two emails that have the same signature because if you did uh someone who's receiving them and checking the signatures can't distinguish between the two emails so that tells you You' like the set of possible signatures on your emails to be at least the square of the number of possible emails you could write so this gives you a lower bound on how big cryptographic signatures need to be in order to be safe just in terms of whether they're duplications uh or your Dropbox and you're trying to sync files from one computer to another and you want to compute some hash on the files on both sides to see do I need to retransfer this file did it change on either side it better be that the space of possible hashes is at least the square of the number of possible files otherwise uh you're going to get accidental uh hash matches all right a little more time so let me tell you about one uh independent concept um not particularly related to Independence but related to conditional probability which is gambler's fallacy gambler's fallacy is it can be phrased many ways uh but let's talk about coins because that's that's what we're doing uh let's say you do 10 coin flips and they all come out heads and I want to know what's the probability that the next coin flip is also heads what's the answer uh sorry Fair coin I should say give you a Fair coin each flip is independent from the other flips what are the chances that the 11th flip is heads a half I should hope so uh if you're a probabilist or if you're a student in 61200 uh the answer is one half if you're a gambler probably an addicted Gambler I mean this is a statement about human psychology who knows they say uh less than a half because I'm due for a tals don't you think right you imagine they imagine that uh hyp hypothetical Gambler imagines that the coin has memory it remembers all those heads it got and when you flip it the next time now finally it's going to be tals but no probability is actually a half Gambler the F this this is something that's actually false Gambler believes oh finally I'm due for taals very unlikely that the next coin is Tails you know I haven't seen an earthquake in the last 100 years very unlikely I'll see one this year I mean that may be true but it also may not be true depends on your prior probabilities about earthquake models all right uh and if I tell you it's a fair coin then you know it's not true it has to be exactly a half every single time it's actually pretty likely to get a bunch of heads in a row now it's not that likely to get 10 coin flips in a row that's one in a thousand roughly um so probabilist just just says wow one in a thousand cool well probably the next one is a half okay uh there's a third type of person which I'll call the basian and they would say uh maybe it's bigger than a half maybe you lied to me and the coin is not fair that's the other interpretation and if this if you if you flipped a coin 10 coin 10 flips maybe it's not enough but 11 or 12 then you start thinking hm I think there's something weird about this coin then you want to inspect the coin see if it's heads on both sides or whatever so uh you can formalize this a little bit using the law of total probability combined with Bas rule uh in the following way I'm going to write this a little informally but uh the probability of a head conditioned on getting 10 heads previously you can split it into two parts and say uh I'm just going to think of a simple model either the coin is really fair or you're cheater and the coin is heads on both sides those are the only two possibilities for this model of course you could consider a more General model and there's a whole world about this so uh I'm going to call these two scenarios cheat and fair and hopefully this equation is relatively uh obvious just it's a mouthful okay everything here is conditioned on H to the 10 so you can kind of ignore that part because that's we're assuming throughout that we have 10 coin flips starting as heads okay and now two scenarios it could be your cheating or it could be your fair and these are disjoint scenarios uh so I can split things up according to law of total probability is the probability of cheat times uh the same thing conditioned on cheating in addition or probability of Fair times the probability of the same thing conditioning on Fair in addition to what I conditioned on before so everything's conditioned on H 10 so you can write this out and we actually know what these are they look ugly the probability of heads with a cheating coin that is heads on both sides that's one okay so it's one times the probability of cheating of there being a cheat here uh given H to the 10 plus this probability probability of heads on with a Fair coin that we know is a half times probability of you're using a Fair coin given that I've seen 10 heads now these two coin quantities that's you need more modeling to understand what it what the chances are to that I'm using a cheating coin uh given that I saw H 10 heads but you can compute it and so now you can actually quantify how much bigger than a half in this particular model of cheating uh what's the chances that the next coin flip will be hits but so fun example and that's all for today enjoy your Independence Day