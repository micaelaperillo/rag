all right so today marks the last lecture um on the subject of sorting algorithms or on the subject of uh complexity and specifically we will be talking about sorting algorithms so let's uh remember where we left off at the end of last lecture we sh we we tried to look for elements within a list and this is a really common problem in computer science where the list is basically a large data set that you might have gathered on I don't know biology information or physical experimental data some big file of data and one of the mo most common things you might want to do on such a file is to search for something within that file basically you'll read it in as a list and you'll search for something of interest within this list so we saw two algorithms to search for an element within a list the first was just a straight up linear search that linear search we did on a unsorted list and we also did it on a sorted list and what we saw was that the worst case time complexity for searching for an element within a uh within a list using linear search was Theta of n that's the best that we could do now we saw that the binary search algorithm as an alternate way to search for an element in list but the caveat to using the binary search algorithm was that we had to have a sorted list we can't use this binary search search algorithm on an unsorted list because it will give us an incorrect answer so assuming the list is sorted binary search does a much better job a much faster job at finding the element within a list it does it in Theta of log n time which is faster than Theta of n the timing uh uh timings through a code that we did showed this counting the number of operations showed this and then the theory also showed this all right so clearly it is better to use binary search because it's faster but when does it make sense to use binary search so the idea is given some sort of data set right some list of elements we would have to first sort them in order to do binary search so the question then becomes the time that it takes for us to do a sort plus the time that it takes for us to use binary search to look for an element within that list should be less than the time that it takes for us to do linear search right in that case it makes sense for us to do a sort and binary search this implies that the time it takes for us to sort is less than the subtraction so Theta of n minus Theta of log in so this implies that we can sort a list in less than Theta V time that means we can sort a list without even looking at each element in the list and that's not possible right we have to at least go through each element in the list one at a time to determine that that list is sorted to begin with right so even in the best case scenario to uh to sort a list that's going to be Theta of n time so clearly this will never be true so then the question becomes why do we bother doing binary in the first place well that's because often times if you download a data set or you know you want to do some uh some search on some uh some list or some data set that you get most of the time you're not going to want to do it just once you're going to want to se sort sort that list one time and then do a whole bunch of searches for a whole bunch of different things within that list so if we can somehow amortise the cost of doing one sort over K different searches as K gets really really big it makes sense to do binary search on the sorted list rather than just to look through um using linear search K different times right so then that time to do the sort only once kind of gets absorbed and goes to zero as the number the K number of searches goes to some really big number right so clearly we've shown that if you if you want to do many searches um on a data set it makes sense to do the sort only once all right so now we're going to look at a bunch of different sorting algorithms we're going to start with some really bad ones and then we're going to work our way up to what is considered one of the best sorting algorithms the best that we can do so let's begin by showing a really really bad sorting algorithm and there are actually competitions um where people can come up with really bad sorting algorithms that kind of sort lists in a really weird way while uh being really bad still making forward progress and this is one of them so this one is called BOGO sort uh coming from the bogus sort also called random sort or monkey sort so the idea here and I'm going to use these cards uh as we look at these different sorting algorithms the idea of BOGO sort is that we're going to use Randomness to help us uh sort the list so if we wanted to sort a list or a deck of cards for example the idea of BOGO is that we're going to take all our cards we're going to throw them up in the air we're going to pick them up as they land and we're going to check to see if they're sorted if they are we're done if they're not we're going to repeat the process we're going to throw them up in the air Let Them Fall where they may and then we're going to check if they're sorted okay so the code would look something like this it takes in a list L and it says while the list is not sorted we're going to call this Shuffle function from the random library and the shuffle function just reshuffles or rearranges the elements in the list at random so let me show you how that looks like so here's the assorted function um I'm going to run it so it starts out with this uh list of obviously uh the elements not in order and it took about 02 seconds to to um to just randomly keep reshuffling the elements of that list to give me uh for them to become in sorted order right so it did about 30,000 shuffles and if I run it again it'll take a completely different amount of time each time it's run right so now it was really fast but if I keep running it you know one time I ran it last night it took about two seconds so you can see it's just random so what's the complexity of this function clearly it's not going to be very good at best so in the best case scenario Ario let's say my input list is already sorted so in the best case scenario the Theta would be just Theta of n where n is the length of the list because we have to look at each element once to make sure that it's in its rightful place but in the worst case scenario the Theta complexity of this is unbounded It's So Infinity because at worst case we're going to be super unlucky and we're just never going to get uh the elements in a sorted order okay so clearly not a very good sorting algorithm if you go to the Wikipedia page for this it'll give you a whole bunch of other examples of algorithms similar in this uh in this Spirit of you know being bad but making forward progress towards an answer so next we're going to look at a different sorting algorithm called bubble sort and it's one of the most popular one uh popular sorting algorithms not because it's good but because people really like to make fun of it okay so it's best to understand it so the the idea of bubble sort is that we're going to start with uh an originally unsorted list and like I said I'm going to use this as an example and we're going to try to compare consecutive elements one at a time um and as we do so we're effectively going to Bubble Up the the largest element towards the end of the list okay so we're going to start uh our first pass on this clearly unsorted list and we're going to compare the first two elements if the element at index um I is smaller than the element at index I minus one then I'm going to do a swap so here they were so I did a swap then I'm going to compare the next set of elements so these two are already sorted right these two are not so I'm going to swap them these two are not I'm going to swap them these two are not I'm going to swap them they're not I'm going to swap them and these two are not and I'm going to swap them okay just move it over because that table got in the way all right so at after I finished my first pass this number 11 effectively bubbled up from wherever it was towards the end of the list the place where it belongs basically right it belongs at the end of the list because it's the biggest number since I've done at least one swap on that previous run I'm going to go through again because in the process of doing a swap I might have disarranged something that was already sort of in order so now I'm going to start all over again I'm going to say are these two in sorted order they are are these two no so I swap are these two no so I swap are these two no so I swap I swap and I swap and now after two passes I've effectively bubbled up the next biggest number right you guys can see okay next time through uh next time through I'm going to have to go again because I am um I did one swap last time so again I'm going to compare these two I need to swap them these two I need to swap them these two I need to swap them swap them swap them and these are in order and these are in order okay again five and the four needs to swap five and the one needs to swap five and the zero needs to swap five and the two needs to swap these are in order these are in order these are in order four in the one needs a swap these two need a swap these need a swap ordered ordered ordered ordered next these two need a swap these are okay these are okay and so on and now that I've not I'm going to do one final check these are all in order right so now that I haven't done any more swaps I can say that this list is now in sorted order right so with each pass I'm bubbling up the biggest element towards the end of the list so at the end of n passes the first the the top the last n elements will be in sorted order okay so the code looks something like this I've got a Boolean flag here that keeps track of whether or not I have done a swap if I've done a swap then I know I need to go through and double check that everything is still in order uh by comparing index I and IUS one so to do that we've got a for Loop that goes through from one all the way up to the end of the list because I'm going to compare element at index I with I minus one if I started at zero we'd get an index out of bounds a so that's why I start with one over there and then the inside of the for Loop just checks if the element at I guess J I use j instead of I J and J minus one are in the right order now obviously they are but when I first started this demo they were not right so as long as this J minus one and J are not in order do a swap so here I just change I use this s this this Tuple trick here to do the swap of element J minus one and J and I also reset the Boolean flag that I did the swap to True okay and this goes through uh until I don't do any more swaps and then the code will not go through the Y Loop anymore so let's print how this actually looks like when we run it on our list so here I have my original list each um set here delineated by this line break represents one uh one Loop of my while loop so this thing here right one iteration of my while loop and each line within here represents one iteration of my for Loop okay so what we can see is that as we're comparing the four and the eight the eight bubbles up one one step over then we compare um the uh eight and the six the eight bubbles one itself over and so on and so on until it encounters the 11 and then the 11 starts to Bubble itself up all the way to the end so at the end of the first while loop pass my 11 is in its rightful spot at the top of the list at the end of the list next time through the Y Loop I'm effectively bubbling up the eight to the end so over here next time through the Y Loop the six bubbles to the end next time the five bubbles through the end then the four then the two then the one and then the zero okay all right so what's the Yeah question oh um we don't need the brackets uh just I mean you can put them in you it it won't harm but you if you don't put them it's it's okay python knows that it's it's doing an assignment one by one so this one to that one and that one to that one yeah okay so let's look at the uh worst case complexity analysis so the easy one we can already know is this inner for Loop right this one goes through from one to the length of the list so that's Thea of length list we have another complexity though because in the wor worst case scenario our list is completely backward and so this while loop up here will repeat length L times because we're going to Bubble Up every single one of the elements all the way through to the end of the list so the complexity of that while loop will be Theta of length L as well because thinking about the worst case is when our uh biggest element is here second biggest element is here and so on okay all right so the worst case complexity of this function is Theta of length uh length l s right or Theta of n^ s where n is the length of the list just to be less for both okay clearly not a great sorting algorithm um it's pretty inefficient and some of the things it's doing IE once it's reached um you know sorted some of the stuff up here it keeps comparing them through to the end so it just always goes through to the length of the list we can do uh we can look at another sorting algorithm called it selection sort which is sort of like bubble sort but it does things in a little bit of a smarter way so let me start again with a unsorted list okay and let's see how selection sort will do this okay let's put that there okay so the idea of selection sort is that with each pass we're going to decide which one of these elements belongs at some index so with my first pass I'll decide which element belongs at index zero with my second pass I'll decide which element belongs at index one with my third which element belongs at index two and so on okay so the way we're going to do that is by saying all right I'm going to take this element it's the first one in the list it's the one currently at index zero and I'm going to compare it with every single element from the rest of the list and as I find an element that's smaller than the one currently there I'm going to swap them because I know that that smaller one obviously belongs at index zero so I'm going to compare the five with the eight I'm going to say well the five is smaller than the eight so it currently belongs at index zero I compare the five with the one the one is smaller so I'm going to do a swap and say the one belongs here five with the 11 the one belong oh sorry the one with the 11 the one belongs here one with the six the one belongs one with the two the one's still there one with the zero well zero is smaller than one so let me swap it zero with the four we're done so now at the end of the first P I've decided that the zero is the smallest out of everybody here so it belongs at index zero next time my next my second pass I'm not going to worry about this one I know it's already the smallest so I'm going to determine which element belongs at index one right so the eight is the first one there it's the one currently at index one so I'm going to start with it being the one that belongs there and I'm going to successively compare it with everybody else so the eight with the five the five clearly is smaller than the eight five with the 11 the five is smaller five with the six the five is smaller five with the two needs a swap because the two is smaller two with the one again we swap the one is smaller and then one with the four done so at the end of the second pass I've decided that the one belongs at the next index so now these two elements are in in their correct place they're in sorted order okay third pass we're going to decide which element belongs at the next Index right the index two so eight with the 11 is okay eight with the six we need to swap six with the five we need to swap five with the two we need to swap two with the four everything's okay okay three passes the first three elements are in sorted order now we just need to figure out between these leftovers which one belongs at the next level so eight with the 11 we do a swap eight with the six we do the swap six with the five we bring the five here five with the four we bring it here okay again 11 with the eight we swap these eight with the six we swap these six with the five we swap them right so as you can see as I'm making my way through to figure out which element belongs at the next index I have fewer elements to to decide between which belongs at the next uh uh Index right so here the eight the 11 needs a swap eight with the six needs a swap and then lastly like that okay okay so slightly more efficient in that we're not comparing a bunch of pairs all the time all the way through to the length of the list so the code looks like this I've got one for Loop that goes through the length of the list and one inner for Loop that only starts starts at I and goes through to the end of the list right so unlike bubble sort which started at one and went through to the end of the list all the time here I'm starting at I and going through to the end of the list because in selection sort with each pass I've decided which element belongs at a specific index so I no longer need to worry about comparing that element with everybody else right so when we were you know we were like that we had decided these were in sorted order I only needed to to compare these three amongst themselves to decide which one uh fit at the next spot everybody else was already sorted so what's the complexity analysis of this this is going to be feel very similar to diameter from last lecture because diameter also had this funky thing where we started from I and went through to the length of the list well it's going to be Theta of length l^2 again so there's two ways to think about this okay the first one is to look at each Loop indiv ually clearly the outer loop goes through Theta of length L right no question about that that just goes through range of length L the inter Loop is a little bit trickier right because it doesn't always go from some fixed number to the length of the list but what we can think about is on average right the first time when we were trying to figure out the element that belongs at the first index or index zero we went through to the length of the list we had to compare with everybody else the next time we have to compare with length L minus one then length L minus two and then at the end we only had you know one item to compare so on average that inner loop goes through length L over two times right on average we have to look through about half of the elements in the list um to to uh to to to do the comparison so if the inner loop here on average is Theta of length l is length L over2 right then the Theta of length L over2 is Theta of length L there's just the 0.5 in front of that okay so that's the first way to think about the complexity analysis of this the other way is to ask yourself well what part of this code is doing the repetitions like if we were to think about what we're counting in terms of units which part of this code repeats well well the stuff inside the inner for Loop repeats right so you're going to do a whole bunch of comparisons so how many actual comparisons will you do well the very first time like from the outer first pass through to the end of the list you're going to do approximately length L comparisons the next time you're going to do length L minus one comparisons then length L minus two comparisons and so on and so on down to only one comparison so if we do that sum 1 plus 2 plus 3 plus all the way up to length L the sum uh that formula becomes length L * length L plus 1 over two so that becomes length l^ 2ar over 2 plus length L over2 and that becomes Theta of length L squared right so just a couple ways to think about the analysis of this um and this is a pretty common thing you'll see but just because we start at I doesn't mean that it um decreases the complexity of this function uh dramatically it doesn't decrease it by some order it just decreases it by half right so it's still Theta of length L okay so we can actually do a little variation on this because you might have noticed it was a little inefficient to do the swap every time I noticed another element that's smaller right I didn't have to do the switch all I had to do was kind of just keep track through a variable of the smallest number that I have seen so far and only do the switch at the end when I've determined that that's the smallest number right so the variation basically if this is my list says hey I'm going to look at this element that belongs in this very first slot eight is the first one then I'm going to look through the elements all the way up to the end of the list and keep track of the smallest one the four the one is currently small smallest six is not five is not nine is not two is not the zero is smaller than the one so if I see the zero is smallest then I swap it so I only do one swap at the end next time through I'm going to decide which element belongs at this index the one is the smallest I see so I do the swap only at the end right then I decide which element belongs here the two is smallest out of everybody left the two goes there so I'm doing all these comparisons but I only do the swap at the end right when I've decided hey this is the smallest element let me just swap it with the one that's currently there right so it's just going to go through to the end of that okay so I wrote that variation here so this is selection sort just as we saw it so we can see here that the first pass with the outer loop we have length l um comparisons to make because we're always comparing these two right then the one that's currently at this index and the next uh the one index over the one that's currently at this index and one index over and so on so the first pass I've done length L swaps sorry length L comparisons the next pass I've done length L minus one comparisons because I don't need to look at the zero anymore I already know that's in the right place then after that I do length L minus 2 comparisons then l L minus 3 comparisons so you can see as we're making um progress through our outer loop we have fewer and fewer comparisons to do right so you might think that this is much better but the Theta complexity analysis says it's not so that's the original selection sort and the variation on selection sort looks a little more complicated but it's not doing a swap so it's only doing a swap down here as you can see it's doing it after it finishes this inner for Loop and all this inner for Loop is doing is checking uh is doing the comparisons and keeping track of the smallest number it sees in this variable called smallest and the index associated with that smallest variable in smallest J now if we look at the analysis for this well we still have an outer for Loop that goes through length L we still have an inner for Loop that goes from I to length L all it's doing is eliminating this line here it does it only once at the end but it's still doing all these comparisons it still has to look through all of these elements one uh Pair by pair to do the comparison so actually this slight speed up doesn't have a big impact on my Theta complexity right it's still going to be Theta of uh length L2 any questions so far on these sorting algorithms okay so clearly we're not really doing a very good job about thinking of a unique way to do uh to do the Sorting right because all of these different variations where we're doing slight speedups here and there aren't doing a drastic enough job to bring us a whole complexity class lower right so we have to think about the problem in a completely different way so the iterative approach is not working out for us right where we basically have a loop that does something and then another loop that does some sort of comparison right that's not going to get us a whole uh a whole complexity class speed up so instead what we're going to do is approach the problem from a um uh sort of inspired by binary uh bisection search or binary search right in bisection search we weren't looking at each element one at a time we were taking our list and dividing it in half right so we can try to do a similar approach here and that's what this merge sort algorithm does it's going to take an original list and it's going to divide this list in half with each step and it's going to do this uh recursively it's going to be a divide and conquer algorithm so it's going to recursively divide this list in half each step and then it's going to merge sorted lists in a really smart way such that it'll give us the speed up that we're interested in so let me explain to you how we're going to merge it and then we'll see how we can uh write up this whole algorithm so let's say that that we have let's do this let's say that we've done some sort of uh division of lists right and let's say that we've written this algorithm and it works really nicely in such a way that it gives us two sorted lists right so if somehow my algorithm right where I had one full list of all of these eight elements here divided itself and when it came back together it gave me two sublists that themselves are sorted right so this is a sorted list and this is a sorted list by itself then there's this really smart merge step that we can do so we can recognize that if this list is sorted by itself and this list is sorted by itself to determine the element that is the smallest between both of these lists all we have to do is look at the first element of each list each sublist right this is the smallest out of these guys this is the smallest out of these guys so if I just compare the zero and the four I know the zero will be smallest out of everything okay then I'm left with this list it's still sorted this list it's still sorted I look at the first element of each of these lists which one of these is the smallest well the one is smaller than the four so I'm going to take this one and say this one comes next right so we're using the property that these two lists themselves are sorted so all I need to do is compare the first element of each list then I compare the two and the four I say the two is smaller than the four the six and the four the four goes next the six and the five the five goes here six and the eight six goes here eight and the 11 well they're already in sorted order so we're done so that really smart merge step touched every element only once to bring it into to my master sorted list right I didn't have to do multiple passes I just had to look at the first element of each list so if we can somehow get to this point where we have these two sublists that are sorted I can just do a little merge by looking at the first element in each of these sorted lists and that basically gives me a Theta of n complexity to do the merge from two smaller sorted lists into one big sorted list right so here's the idea of this merge sort algorithm we're going to take an original big unsorted list containing n elements it's unsorted we're going to divide it in half of course these two halves there's no order to them so they are potentially very unsorted we're going to take each one of those halves and divide them as well in half more unsorted sublists now I've got four unsorted sublists of smaller lengths then I'm going to keep dividing them in half I have now maybe just two elements in each of these unsorted lists there's no guarantee that they're sorted and then I divide it in half once more to have a list with one element in each uh yeah a list with one element maybe some of these will be empty but you know so then if I can get to this point where I just have lists containing one element in each list those lists themselves are sorted right an element with just a one in it a list with just a one in it is sorted so then I can begin a merge step which says hey these two here that were originally unsorted let's just merge the pairs back up and we'll do that um that smart merge uh merge way right so these two will merge back in to give me all of these eight sorted lists of element of length to and then we're going to merge these pairs back up again using that smart merge uh merge uh way to give me uh four sorted lists and then we're going to merge these uh pairs of sorted lists to give me bigger sorted lists and finally we're going to merge these two sorted lists to give me my final Master sorted list okay so let's do the process of doing the sort right step out a time so we're going to take our original list like this I'm actually going to try to do this I'm going to need some room to move them down so this is my original unsorted list let's move this here something like that so what's the process going to be step one is to divide them in half step two divide each of these in half step three divide each of them in half so now I've got a bunch of lists with only one element in it now I need to merge them back up so merging these two together to give me a list with two elements says I'm just going to compare them the one that's smaller goes first the one that's bigger goes second again these ones compare them the one that's smaller goes first the one that's bigger goes second again compare them again compare them so now I've done one merge where I have four lists that are sorted by themselves right so now I'm going to merge these two together and these two together so I'm only looking at the first element of each so I compare the zero and the two and I know the zero is smaller than the two then the two and the eight the two is smaller then the eight and the 11 and then the 11 so now this list is now sorted by itself same process here compare only the first element of each list the one comes first then the four comes next then the five comes next and then the six right so now I've reached the exact same spot I was at when I was talking about the merge step right when I showed you that um that we could get to that spot so I've got these two lists that are themselves sorted to merge so all I need to do is look at the first element in each list so there's my zero goes first one compared with the two the one goes next two compared with the four the two goes next four compared with the eight the four goes next five compared with the eight the five goes next six compared with the eight the six goes next and I've removed all the elements in this list so I know I just need to grab whatever is left in here in whatever order it's there because everything's already sorted okay so that's the entire merge sort algorithm right now if I do this demo this is actually going to show you the exact steps that the recursive algorithm is doing and it's not going to be sort of in the same order that that I showed you it's not going to be uh dividing uh this in half and then dividing in half and so on because when we're doing the recurs uh the recursion first we're going to figure out how to sort a left sublist right so if I have my original unsorted list here we're going to figure out how to sort a left subl list first that's a recursive step that we haven't reached the base case for yet we still have to sort this list so we're going to uh try to sort the left sublist of this one and then we're going to try to sort the left sublist of this one so we're going to do something that feels really similar to the Fibonacci sequence uh yes Fibonacci right Fibonacci of n is Fibonacci of n minus one plus Fibonacci of n minus 2 right in that particular case when we were trying to find Fibonacci of six or something like that we were going and exploring the left side until we reached a base case right and only once we reach the base case could we pop up and do the other half and so this algorithm is going to feel very similar to that so here's on my original list I'm splitting the left hand side to try to figure out how to um merge those the all the way to the those left lists so the eight and the four will be compared and the four goes before the eight and then I'm going to merge the then I'm going to merge the one and the six by themselves those are already sorted as we know um then we're going to merge the four and the eight back with the one and the six using that merge step and then we're going to do the same thing to that right hand side right one at a time we'll do another example where we go step by step through this right and now we've got our two four elements together so now we're just doing our final merge step where we decide which one belongs uh next okay so let's look at the merge code and this this is uh this is not yet soorry sorry let's look at the the merge step once more so if I have two lists that I'm trying to merge right the idea was that you look at the first element of each right so first the one and the two compared means the one is smaller so it goes into my result the five and the two gets compared the two is smaller so the two goes into the result the five and the three gets compared the three is smaller so the three goes in the result and so on and so on so we keep doing this process where we just keep looking at the first element until we have one of the lists become empty right so this is my left sublist this is my right sublist when one of these lists becomes empty I no longer need to compare 18 with nothing right all I need to do is grab all these elements and stick them through at the end so let's look at the code for just the merge step we don't need to look at the code for the full algorithm yet but the merge step code code is just the part that takes us from two sorted lists into one bigger sorted list right so it does uh does that step in one this is where the main event happens so this is just going to use indices to compare which element we need to grab next so if I have sort of something like this um like that right then I'm not actually going to make a copy of a list or you know or do any sort of funky stuff with list copying because that'll increase the complexity but we are going to do that trick where we take where we use an integer index to decide where uh where we're going to which element we're going to grab next so that's what this I and J is for we've got I is going to be the in uh index from my left sublist and J will be the index for my right sublist and all it does is it says while I still have elements in in both of these lists just take the pointer and say which one of the elements at these two pointers I and J are is smaller so if the zero is smaller I'm going to create a new list here that's going to have the zero in it I'm not actually taking this element and moving it here all I will do next is say the pointer that tells me which element I should be looking at next moves over one so this list remains unchanged then I'm going to compare the two with the one the one comes next so I'm going to take the one and put it in my list here and this pointer moves here to the next element so now while this list stays as is I'm looking at the element at this pointer and comparing it with the element at this pointer so then the two comes next and this pointer increments by one okay so that's what that code does these two while Loops just deal with the case when we have one list that has finished uh in inserting its elements so like in this particular case here when my right sublist became empty we've already put on all the elements in it into our Master list then all we need to do is take everything that's left over and copy them into my master list and that's what these two while uh what Loops are doing okay so the complexity of this merge store so that's just what it's um what it's doing right so it's just doing one pass it's not doing m multiple passes so we just look at each element once so the complexity of this merge sort of not the sort just the merge step is Theta of length of the list right because we're just looking at all of these elements once now what about the actual algorithm right so here I've got the merge function down here okay it's going to take a left list and a right list and it's going to do that step that we just did where you look at the smallest element in each what about the rest of it well the rest of it is just recursion my base case is when I have a list that's empty or a list with one element in it then I just grab that list that's my uh that's going to be my merge and else what we're going to do is we're going to do the step where we divide the list in half so we're doing integer division from the length of the list because we don't want the middle to be 7.5 for example so we're going to grab some integer index and then we're going to say I'm going to again there's a lot of faith involved in recursion I'm going to say the left sublist so this one here if my algorithm somehow works correctly will now be a sorted list okay and then my right over here right equals this thing here will also somehow be a sorted list so this is me putting faith in my algorithm that I can get a sorted list right from the index zero all the way up to the midpoint and the midpoint all the way up to the end of the list so if somehow I can get a left sublist that's sorted by itself and a right sublist that's sorted by itself all I need to do to get this the final sorted list is to merge them so that's what the merge function is do okay so let's step through so I've got my original list here and this is where we're going to be uh uh thinking about how we kind of Step through Fibonacci here's my original list the first step is to do um is to is to figure out the left part so we're going to divide it in half and it says I need to figure out the sorted version of 8416 but it's not my base case so I need to figure out the sorted version of the left part of that the 84 again it's not my base case so I need to figure out the sorted version of the left just the eight it's single by itself so that's just going to be the eight then we can figure out the right half of it it's four by itself and we merge them then we can figure out the right half of this one here 8416 so we need to figure out what's the sorted version of six well as humans we know it's already sorted but the algorithm goes through looks at the left side looks at the right side merges them up now we merge the 4816 according to the little merge step to give us 14 4 68 and at this point we finished just the left half of 8416 5920 and now we need to do the right half so we do the whole process all over again by taking that 5920 looking only at the left piece then the left piece of that then the right piece of that base case merging them back up the uh right step the left part of that right step the right part of that right step merging them back up so then we do the merge step of 59 and 02 and then the merge step of these two fun two lists 1468 and 0259 right so you can see it has a similar feel to exploring one side of the branch first just like in Fibonacci for the exact same reason because we've got a function called that's recursive we can't complete it until we've explored all the way down to the bottom so the overall complexity of this is going to be the merge step itself is Theta of n like we just talked about but how many levels do we have that is how many times do we take our original list and subdivide it until we get to our base case and the number of times is according to this function very much like when we did bsection search we're going to take an original n elements in my list and I'm going to keep dividing this n Elements by two in a bunch of subl lists I times so I times is how many times we're going to subdivide this list until we get to a base case so what is I in terms of n well I is equal to log log of n right so at each merge step sorry so at each uh Su level I've got a merge step so I've got Theta of uh log of n levels multiplied by Theta of n for my merg step so the overall complexity of this function is Theta of n log n where n is the length of the list okay okay so it turns out that Theta of n log n is actually the fastest we can have a sort be you cannot do a sorting algorithm that's faster than that you can do little tricks here and there based on your data maybe you don't divide the list exactly in half maybe you divide it and you find some sort of Pivot Point that's a little bit smarter about the data but in general the complexity of this function of this of a sorting algorithm is always going to be the fastest it's going to be is Thea of n log okay okay all right um we've seen a bunch of different uh uh algorithms here uh to help us design uh programs so the reason why we do this complexity analysis is to guide the design of a program so if you already have a bunch of nested for Loops in the program that you're trying to consider writing you'll already know it's going to be pretty inefficient and slow so you might want to rethink the design um uh to begin okay all