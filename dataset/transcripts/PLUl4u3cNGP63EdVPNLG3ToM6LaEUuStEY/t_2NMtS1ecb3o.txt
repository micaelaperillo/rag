welcome everybody to the second to last lecture of 6006. uh in this lecture we've mostly covered all of the testable material that we're going to have on uh the final or on quiz 3 right today really what we're talking about is putting into context all the material that we've learned over the course of the term at a high level and talk about where we can go from here in terms of other theory classes and other classes in the department that are related to this material now most things in the department are in some way related to this material and so that's why this is a foundational course but we're going to try to talk about it from a high level and talk about how some future things that you might be interested relate okay so we started out the term in lecture one talking about 6006 and we had four main goals that we had for our course really three main goals uh did anyone remember what those goals were there was uh so uh here was i you got to the last one first the first one was to solve hard computational problems right to be able to solve problems okay so this is kind of like the the let's uh make an algorithm part of of the course right one solve hard computational problems i guess hard here maybe should be in quotes because we saw in the last lecture what hard means in a technical sense right hard could mean that there's no efficient algorithm that we know how to solve a problem on that's getting a little bit of ahead of ourselves computational problems with algorithms is really the key part about this goal it's kind of the same goal that you have in a class like 601 or 609 right you're trying to convince a computer that you solved a problem okay on a finite set of it inputs but really what this class is about is two other things which is more about communication to people rather than computers right your your algorithm might be correct or efficient but you need to be able to communicate that to humans and that's what the other two goals are right so second one is uh argue [Music] correctness basically that the thing that i'm doing to my inputs is always going to lead me to a correct output right no matter what input i give it any valid input there could be a infinite space of possible inputs and in this class that that's the case because we want our input size to grow arbitrarily large we need to be able to argue correctness that it's going to return me the correct thing no matter what my inputs are and in order to do that that's essentially that's that's 6042 right this this whole class has basically been applied 6042 right i've given you some procedures and you have to prove things about these procedures or most of the time we proved it for you and then you've used them as black boxes right but that's that's a lot of what this class is about and the third one is efficiency right argue argue that it's good for lack of a better thing this is efficiency what does good mean well that was hard to know at the beginning of our class and so we set up this model of computation a framework through which we could determine how good or bad our algorithms were by saying by defining a model of computation saying what things we can do in constant time and then just building off of that right so this is basically our model you know plus some you know asymptotics or something like that ran out of space what it's about yeah this is about scalability this is a model of computation tells us how how much time we can spend but it's compared to our input size right this is always about how does our algorithm perform relative to the rate that our problem size grows right and so that's what we mean by good and in this class we don't tend to talk about constant size problems it's about how algorithms can scale as you have arbitrarily large inputs that's why we need recursion and induction to be able to prove things about our algorithms because they're for arbitrary end and that's why we need uh you know this relative to input size the growth factor of of our algorithm's performance relative to the input okay and then the last thing is kind of to me one of the most important things is communicating these things to another human right so communication is key here right if you can always write good code that's always right good for you i can't do that all the time but that might mean that you can be very a competent independent computer programmer right but you're going to be limited in what you can do if you're uh if you're only able to rely on yourself right a lot about computer science is working with others to solve computational problems and when you're working with others to solve computational problems you need to be able to communicate with them and you need to be able to communicate them both what it is you're doing and why it is you're doing it right that it's you're doing the correct thing and that it's efficient right and so that's a big part about what this course is it's at the end of the day on your quiz if you write down um you know python script for a correct algorithm but we don't know what it's doing but it's correct we're not going to give you full points on that because you're not satisfying the conditions of this class right it's really about the communication here okay so just to review since we've not uh discussed uh how the most recent lecture fits into your problem sets we didn't have any problem sets that covered complexity so how does that fit in well argue that this is that the ways that we're solving our problems are good what we proved in the last lecture was that most problems cannot be solved good right they can't be solved in polynomial time with respect to the size of your input however most of the problems that we think about in a sense i can i can prove to you that it's a yes solution i can show you a a simple path in this graph that has a certain length or i can show you a subset that sums to a certain value in a particular problem i can give you a certificate that i can prove to you in a reasonable amount of time that yes i can prove to you that this is the answer to this thing is correct and that's what we talked about in the last lecture what so not always good algorithms to solve problems but many problems we think about can be either checked in polynomial time this is the concept of having a certificate that i could give you of polynomial size that could be checked in polynomial time right in in a sense that's a away check checked in polynomial time this leads to our class of decision problems np or you know can be uh solved by brute force in exponential time right most of the things that we've talked about in this class fall into one of these two categories right we can just brute force over the combinatorial space of possible outputs and check to see if they're correct right or i can give you a certificate basically saying uh look i can solve actually anything that's of this form can be checked in this form because there's only a polynomial number of things to check or sorry an exponential possible number of certificates of polynomial length to check um but basically this is saying that the the problems that we think of mostly fall into these two categories and so there usually are algorithms to solve the problems that we care about even if most random problems in terms of bit strings that we gave in analysis in the last lecture actually proved that most random problems are not solvable right though in a sense the problems we think about are not random they kind of have this structure that they can be checked pretty quickly okay so that's kind of what we mean when we're talking about complexity for the purposes of the final you'll be able to see on your final exam uh practice problems that we're going to give you most of what we uh cover uh in terms of material on the final that will be cove that will be testing the lecture 19 material will be in terms of these definitions do you understand what the the decision problem class np is x biz do you know how these relate to each other x is definitely a superset of np here right np nestles inside here they could be equal probably not right those are the types of things that we would address knowing kind of a directionality of a reduction right if you have a a problem a and a problem b right and i know that this one is difficult by some measure right i already happen to know that it's you know very hard right like np hard or something like that if i can if if this is a problem that i'm interested in knowing the complexity about and i can prove that i can solve it if i had a black box to solve b any black box to solve b and i could make this reduction in polynomial time and if this is hard that means this can't be that means that if this is hard then i better not be able to solve this in polynomial time right because then i would be able to solve this in polynomial time so that's basically the type of argument usually in a true false question we might have on the final exam for you to kind of understand the basic high level definitions involved in what was talked about in lecture 19. hardness right the very most difficult problems of these classes and completeness sorry uh anything harder than things in these classes where completeness is the ones that are in this set but at least as hard as anything in those classes okay so that's just to give you a brief overview of the only material that hasn't been tested but might be tested on the final okay so when we don't have a good algorithm we can actually prove that it uh doesn't might probably doesn't have a good algorithm and that's kind of a problem that you'll be able to solve in future classes if you continue along this track okay so what's the actual content that we talked about and this is a very high level overview of why we're taking this class why you're taking this class right but what is the content we actually covered it kind of i like to break it up into three units and kind of in a sense two subunits okay so quiz one material and quiz two material was about showing you some nice black boxes right basically if i'm going to have inputs of non-constant size it's going to be useful for me to be able to find things among those elements right so that's really what quiz 1 is all about right data structures for finding things in a non-constant size uh uh database sure and when we were storing these things we want to support maybe two different types of queries ones that were intrinsic to the items what the items were and ones based on what an extrinsic order was placed on these items right and that was a way in which we broke down how should i approach looking at this problem i want to be able to support queries and maintain an extrinsic order on these things i might want to sequence right this is a sequence extrinsic order or i want to be able to look up is this thing in my set right by by a key that we identify it with a unique key right so this is some intrinsic queries and often order right not all like a hash table doesn't maintain any order on my keys right but it does support intrinsic queries is this thing in my set or not but we did show you other set data structures that do support a intrinsic order that allows me to see what the next larger and next previous uh the the the next larger the next smaller item is in my set right so here's a summary of those data structures that we had i'm not going to go into how to use these things or how to choose from among them here that's what your uh quiz 1 review lecture was all about right but basically the idea here is if we have a sequence most of the time when you're programming being able to push and pop at the end of a list is pretty good which is why python the most fundamental data structure that you have is a list because it's a super useful thing i just want to store a bunch of things have random access to uh the say 10th element to my thing but i'm not necessarily having to dynamically update the order of these things in dynamically i don't necessarily have to insert something in the middle of the list most of the time what i can do is put it at the end of the list and maybe swap it down into place if i need to right so that's why a list is super useful a sequence adl tree useful but not as ubiquitous as a linked lid i mean as a dynamic array sorry i said linked list i meant python list which is a dynamic array okay so the dynamic array tended to be in in in your coding practice your most common sequence data structure here though uh we can get pretty good for this insert in the middle operation uh with the sequence avl okay then for on the set data structure side i kind of categorize these things into a couple different categories here in terms of the operations we can support on these things these are all intrinsic operations finding things inserting deleting things i think of the first three as being dictionary operations right i want to just look look up whether something's there whereas the last two are order preserving operations where it matters what the order these things are stored in and so as you can see from the uh you know asymptotic complexity of the various operations here the hash table is actually super good if you want a dictionary upper if you just want to support dictionary operations but in the cases where you need to maintain order dynamically a set avl is the way to go right but if you don't need it dynamic but you still need those order operations a sorted array is just good enough if you don't need to change what they are right so that's that's a quick overview of quiz one type data structures material but then we used most of these data structures to get faster sorting algorithms in different contexts right basically everything on this list involved making a data structure and exploiting that data structure to get a better running time except all except for merge sort really right the first two we we presented in terms of a priority queue right whether we used a sorted array or an array we represented it at the end of lecture eight [Music] to get n squared running time we generalized that down to to n log n by using a heap that was a nice optimization but we also got uh interesting data structures using an av i mean interesting sorting algorithms using an avl tree because of the power of maintaining a dynamic order over time but then exploiting a direct access array to be able to sort in linear time for small bounded bounded in terms of the input polynomially bounded in terms of the input ranges of numbers right so we we leverage that count direct access array to get counting sort and then we kind of amplified that effect by sorting on a bunch of digits uh multiple times to get basically polynomial uh blow up in terms of the numbers that we could sort in linear time okay so that's a an overview of the content of quiz one in quiz 2 we were kind of like okay now you know how to find things within a set of of just a flat list of things right you can put it in a data structure but in a sense a graph is a special kind of data structure right that relates the different things in your input right so uh if you've got um a bunch of vertices right there's a relation now between those vertices that are your edges and this is a super useful framework in talking about discrete systems because you can think of a vertex as a state of your system and then connect these transitions as a graph right that's that's the reason why i mean graphs are awesome right but they're awesome because they can be used to model so many different things within our world right it's not just about you know road networks right it can also be about playing your favorite uh turn-based game right like tilt right okay so uh we we talked about a lot of different types of problems that you could solve various algorithms with a focus on a bunch of different ways of solving single source shortest paths and again just like the sorting algorithms and just like the data structures we presented multiple of them because we had this trade-off of generality of the graph that they apply to contrasted with their running time right so i guess in in particular the the the top um uh line there is in some sense the most restrictive we we don't have any cycles in our graph that's a very special type of graph and we're able to get linear time but then even if we do have cycles in our graph we can do better if we have a bound on the weights in our in our thing whether they be uh there's an easy conversion to a linear time algorithm via an unweighted process or whether these things are non-negative so there can't be negative weight cycles and we don't have to deal with that okay so that's quiz two material and then quiz three material was kind of applying this graph material to a recursive framework what was our recursive framework everyone say it with me dynamic programming and the framework was sort bot right missing a letter but sort bot right you can actually think of the quiz 3 material as uh as really an application of the graph material right what what are we doing in sort bot we're defining a set of sub problems this is a set of vertices in a graph what is the relationship doing it's saying what are the relation between the sub-problems right essentially defining the edges of a graph right and then this topological order and the base cases all of these things are just saying what is the problem that i want to solve on this graph and how do i uh compute that for things that don't have any outgoing edges right i need to start writing the board again this is graphs there was a sorting in here too this is basically an application okay graphs was basically a relationship on these non-constant things so this was kind of like useful black boxes right that you can just bundle up and stick in some inputs stick out some outputs and and you're golden right whereas quiz 3 was very different the material in quiz 3 is very different dynamic programming while it was in some sense related to this graph material i'm constructing a graph i have to construct that graph there's a creative process in trying to construct that graph i don't give you a set of vertices usually what i give you are a set of like a sequence or something like that and you have to construct vertices sub problems that will be able to be related in a recursive way so you can solve the problem this is a very much more difficult thing than these other things i think because there's a lot more creativity in this right in the same way that just applying reducing to the graph algorithms we have is fairly easy but actually doing some graph transformations to change the shape of the graph so that you can apply these algorithms that's a harder thing to do right these are these the the difficulty with these two sets of materials is very similar right figuring out what the graph should be figuring out what the sub problem should be and how they relate is really the entire part of the the the entire difficulty with solving problems recursively right and we've only given you a taste of solving problems recursively in future classes like 6046 which is the follow-on to this one in the undergraduate curriculum this is all about introduction to algorithms the next one's about design and analysis of algorithms right it's quite a bit more difficult because we are we've mostly uh left it to you to use the things that we gave you or make your own algorithms based on this very nice cookbook-like framework that you can plug in a recursive algorithm to now actually that cookbook is super nice for any way of looking at a a problem recursively but while uh while in dynamic programming the inductive hypothesis of of combining your sub-problems is almost trivial right uh in other types of recursive algorithms that's not necessarily the case okay especially when instead of looking at all possible choices for example in a greedy algorithm where you're just looking at one of the choices the locally best thing and recursing forward you're not doing all the work right you're not locally brute forcing you're locally picking an optimal thing locally and hoping that it'll lead you to good thing that's a much harder algorithmic paradigm to uh to operate under and so that's more like the material that you'll be talking about in 6046 okay so uh that's double06 a very quick overview of the content of this class and we really like the structure of of how this this class is laid out because it gives you a fundamental idea of the things people use to store information on a computer and a sense of how you solve problems computationally and how to argue that they're correct and efficient right that's really what this problems this this this course is about and if you feel like you enjoy this kind of stuff that's where you go to take 6046 right and 6046 was actually the first algorithms class i ever took here at mit uh as a grad student actually i uh i didn't this is this is hard for me right it was it's actually hard to look at these problems these types and think in a computational way especially having not taken this class 6006. so hopefully you guys are all in a better position uh than i was when i took it there's there's two ways i like to think of the content in 6046 one is kind of just as an extension of double06 right it's the natural follow-on to the things that we do in this class right they still talk about data structures this isn't the core part of 046 but they do touch on data structures for more complicated uh that have more complicated analysis involved in them it's really about you know usually in o46 stating what the algorithm is doing is not so hard right basically giving you the algorithm number one here is not so difficult to state what's happening in the algorithm but the number two and number three here arguing that that thing is correct and arguing that thing is efficient that's where the complexity comes in in o46 the design the the analysis part is quite a bit more complicated in o46 than in 006 right so they they solve a problem called union find and give a much we talked a little bit about amortization this goes into a much better a much more formal way of proving things uh uh run in amortized time okay so this is basically amortization the uh what we call a potential analysis it's basically making that algo that that that that uh that notion that we talked about when we were talking about dynamic arrays of you know we're not doing this expensive thing too often basically what we do is we keep track of the cost of all of uh sequence of operations and prove that the average cost is small right that's that's kind of what this potential analysis is doing it's a little bit more formal process for making that argument uh a little uh more formal right okay so then on on the graph side right this is kind of an extension of quiz one type material this is what what is this union find data structure it's basically it's a set type thing right where i i can make a set of just a single element i can take two sets merge them together make them their union right and then given an object i i say which set am i part of right essentially by electing a leader within a set and saying return me uh you know a pointer to that one right and so this can be useful in dynamically maintaining say the connected components in a dynamically changing graph supporting the query of am i in the same component and as this other guy right that could be a very useful thing to know about a graph as it's changing so that's that's an application of this problem and they get near constant performance for a lot of these these queries it's not quite but you know pretty close okay on the graph side they solve a number of uh very useful problems on graphs uh minimum spanning tree so i'm i'm trying to find a tree connecting all of the vertices in a connected component of my graph and i'm trying to find in a weighted graph i'm trying to find the spanning tree that has minimum total weight right so this is that's a problem a fundamental problem in graph weighted graph algorithms they've solved this via a greedy algorithm okay and network flows uh and i guess cuts right so this is what is this this is i'm given a weighted graph uh basically each of the um the weights correspond to a capacity i could push water through along this edge right and it may be given a source vertex and a sink vertex right and i want to say i want to shove water through the source vertex along the edges with their various capacities and i'll get some amount of water on the other end in the source right so the question is what's the most amount of water that i can push through this well i could build build that pipe network with the different things and just do this experimentally i just stick a bunch of maybe i i'm a mechanical engineer so that that maybe makes sense to me but you want to be able to just look at those numbers and be able to tell me how much water can i push through that's what the kind of max flow in the network is talking about and we give you some polynomial time algorithms in this class basically incremental algorithms that kind of like dijkstra or kind of like bellman ford will incrementally update uh estimates to uh of of a max flow and and improve them over time okay uh then on the basically design paradigms you've got more involved making your own divide and conquer algorithms you know dynamic programming algorithms greedy algorithms basically they go a lot more in depth in terms of how to design these algorithms in these paradigms than we do in this class okay and then the last thing is we only touched on complexity and in a sense 046 is only going to touch on complexity it's a very big field right but it will give you the tools to be able to prove that something is np hard whereas we just kind of say that oh there's this thing called reduction we didn't give you any uh problems in which you actually had to reduce one problem to another and you'll do a lot more of that here so reductions so in a in a big sense oh four six is really just a natural extension to the double o six material plus some additional stuff which i'm gonna get to in a second yeah question randomization uh i'm going to talk about that slightly in a in a separate uh i'll get to your question in just a second i like to think of it as a separate topic which i'll we'll go into right now the separate topic i like to think of it as instead of being the natural extension to the things in in the double 06 units what i'm going to do is kind of relax either what it means to have a correct algorithm or relax what it means to uh what my model of computation is okay so double o six this is kind of as an extension of double o six and this is kind of like 6046 as you know change my definition of what it means to be correct or efficient so we've already kind of done this a little bit in double o six um i'm gonna basically one of the things that we can do which is what the question that uh student asked a question about was about randomized algorithms which is a big part of o46 actually randomized uh analysis of algorithm of algorithms that are not deterministic right it's it's not guaranteed that it'll give you the same output every time or not guaranteed that it will do the same computations over the course of the algorithm every time but it exploits some randomization and in double six this is we've mostly not touched on this except in one area where did we use randomization in hashing right right when we used hashing what were we doing what what what did we change the definition of correct versus efficient we didn't really change the definition what we did was we said that it was okay that sometimes our algorithm was slower than we then then on in expectation right that's what we we meant there right we're relaxing the idea of efficient but we're still saying it's good because most of the time it is good right so this there's two types of randomized algorithms uh they have these weird names uh based on betting uh uh regions of the world shall we say there are uh this is el oh las ladies loss okay vegas algorithms uh these are always correct but probably efficient in a sense that's what hashing is right i'm always going to give you the right thing right whether this thing is in my set or not but some of the time it's inefficient right i have to look through a chain of length of that's linear in the size of the things that i'm storing okay and this is in contrast to a monte carlo algorithm which is always efficient for some definition of efficient but only probably correct and i mean i could define you a hash table that has monte carlo semantics instead right say for example i i say that i'm gonna it's to be exactly the same as a hash table except instead of storing all the things that collide in a place i just store the first two say right well actually that's actually going to be always efficient i'm going to look through the things and see if it's in there and the chan the chains that i'm storing there only have two things it's going to be always efficient it's always going to give me constant time but some of the time it's going to be the wrong thing because i'm not storing everything in that chain right so there's some probability that that's not going to be correct right and so that's that's a different kind of if maybe i want my hash tables to always be fast but i can afford to be wrong some of the time i don't know in practice this is actually sometimes a good trade-off in real systems sometimes it's okay to be wrong some of the times if we get good performance okay so but generally can do better uh if you allow randomization and by better i mean you know usually we can get faster bounds on a lot of problems if we allow randomization and things aren't necessarily always correct or always efficient okay so this is a big area in 0 4 6 that requires a lot more analysis using randomness and probability so if you're uh needs some uh primers on that we didn't have a lot of this in in double o6 but if you go on to o46 that's going to be a really important thing for you to brush up on okay the next part on double06 is kind of changing what our definition of correct or efficient means i mean we've restricted ourselves in this class to a class of problems where we only talk about integers right but there's tons of problems in this world especially in scientific computing where i want to be able to find out what the this real number is and i can't even store a real number on my computer so what the hell jason what are you talking about right i can't do that on a computer but what i can do is basically compute things in a numerical sense numerical algorithms and in o46 a lot of times we put this in the context of continuous optimization continuous uh being the opportune word here not discrete systems you have a continuum of possible solutions real numbers essentially how do we do this on a computer that's a discrete system basically what what what in o46 what you can do and in other numerical methods classes what you can say is well i know that you can't return me a real number i got that or or you can maybe have a model of computation that allows integers to represent other kinds of real numbers like radicals or rationals or something like that and i can do manipulations on those but really what these these algorithms are usually about is computing real numbers not completely but to some bounded precision and i pay for that precision right the more bits of precision i want on my number i have to pay for them right so this is basically i think of these as an approximation a approximation of real number to some precision and i pay for precision with time so let's say you know i want to compute the square root of a number i could have an algorithm just like the algorithms or i guess division right long division you all know the algorithm of long division you you know you put a quotient under here with these you know an a b and you get the c on top or whatever right that's an algorithm that's a procedure using essentially small numbers i'm only talking about the digits 0 to 9 here when i'm doing that algorithm so it's a procedure that only uses small integers to compute arbitrary precision of a division right so that's an algorithm and i have to pay time to get more digits right so that's that's an uh uh an example of this kind of how how we live in the world of real numbers when all we have is a discrete system okay and then the last kind of category i'd like to talk about here is is really approximation algorithms whereas this is kind of an approximation algorithm i'm approximating my outputs this is an approximation algorithm from the standpoint of well there's a lot of problems that i can't solve efficiently they're np hard they're they're in x or you know even harder problems but uh maybe i'm okay with not getting the optimal solution so this is in the domain of optimization problems so most of the dynamic programming problems that we gave you are optimization problems or the shortest paths problems those are optimization problems basically the possible outputs are ranked in some way right the distance of a of a path that you return or something like that they're ranked in some way there's an optimal one right the one with the the smallest metric or something like that right well in an approximation algorithm what i do is okay i get that it's computationally difficult for you to give me the longest pa simple path in this graph or the shortest possible route for my traveling salesman but maybe that's okay i mean my engineering spidey sense tells me that within 10 is fine right so maybe instead of giving me the most optimal thing can i give you an algorithm that's guaranteed to be within a certain distance from the optimal thing right usually we're looking for constant factor approximations which are have low constant or you know maybe even have to do for worse if such things don't exist okay so that's approximation algorithms you know can we get close to an optim optimal solution in polynomial time okay and then the last way we could change things in especially future classes though sometimes they talk about this in o46 as well is we could change the model of computation right we could basically change something about our computer to be put in some other weird paradigm of of of solving problems with more power essentially or or you're in a situation where there's less power okay so change in the model of computation okay so what we've been talking to you in terms of model of computation is our word ramp right word ram that essentially says i can do it arithmetic operations and i can look up stuff in my memory in constant time and but if i allocate a certain amount i have to pay that amount and that kind of thing so that's this word ram model but in actuality all of your computers you know it's a it's a lot easier for me to figure uh to find and read memory that's on my cpu in a register then it is for me to go out to the hard disk ask this well in my day it used to be this this movable mechanical head that had to go and scan over a bit on a on a cd-rom drive and you know actually read what that thing was right so we can add complexity to our model to better account for the costs of operations on my machine one of those models is called the cache model a cache model it's basically a hierarchy of memory right i have you know my registers on board my cpu i have maybe an l1 cache that's close to my uh cpu then i have another set of caches and another set of caches maybe out to ram and reading from a hard disk is a solid state drive of some kind that's the slowest thing to access and i can put a cost associated with each of those things and instead of having to having all of our operations be you know say said to be constant the constants are actually different and i have to pay for that difference okay and so that's you know extending our model to be a little bit more realistic to our machine you know another one is you know we have computers right now that opera operate in classical physics right that exploit things in classical physics but in actuality our world allows for even more complicated types of operations like quantum operations where you're exploiting entanglement and superposition of different atoms to potentially get operations that i can act on my data that are actually provably stronger than the classical models in some sense right so this is the whole huge reason why uh there's a lot of work being done in say you know lots of uh industry research facilities in figuring out these models because maybe if you can make a big enough quantum computer you can break in christian and stuff in polynomial time and that's something that maybe the nsa is interested in and i'm not going to go into that but you know i mean some people like you look at artificial intelligence and things like discussions around artificial intelligence my brain you know might be doing things that a classical computer cannot right it could be using quantum superposition in some way and our computers that are in your phone and your laptop and things like that aren't exploiting those operations so how could we ever get intelligence because you know in some sense our brains are more powerful right and so a lot of what ai should be looking into is what is the actual model of computation of our brains that can give us the power to have sentience right okay so that's that's kind of quantum computing i don't know much about it actually uh and then there's things like maybe i have more than one cpu right i i mean most computer all the computers you have even the ones in your phone probably have multiple cores right in a sense you have lots of cpos running in parallel right so this is like pair uh there's one r in parallel okay parallel computing basically says you know it's cheap for me to make another computer potentially right if i have two computers running on the same problem maybe i can get a two-fold speed up on my on the this the time in which it takes to solve my problem now that's not i mean suppose i had then 100 cpus running on a machine maybe i can get 100 fold speed up and and actually in in real life a hundred fold speed up makes a difference right it's am i waiting for this for 10 minutes or am i waiting for this for a thousand minutes right that's that's like all day i don't want to do that that's maybe it's on weeks i don't even remember right okay but parallel computing right if i can get a 100 fold speed up that might be a huge win but for some problems it's not possible you know if i have k cpus can i get a k factor speed up it's not always possible to do okay and so parallel computing is another paradigm in which uh there's a lot of interesting theory going on uh there's a lot of complications there because you know there are a couple different models you could have a multi-core setup where you have a lot of computers that are accessing the same bank of memory and then you don't want them all to be reading and writing from them at different times because you don't necessarily know what their state is and you get these collisions which are something that you really have to think about in this world or you have situations where maybe i have a bunch of nano flies or something that are going around and they have very small computer brains themselves right but they can talk to each other and pass information to each other but they don't have access to one central network repository of information that's what we call a distributed parallel system where all of the you know cpus that you have can interact with each other maybe locally but don't have access to the same uh memory system so they have to work together to gain to to learn information about the system okay so this is that's a a brief overview of the different directions this class 6006 and theory in general could lead you into a huge array of different uh branches of theory and different problems that you could address with different types of computers okay so uh i know this is a very high level lecture and uh and maybe less applied than some of you might like but i hope this gives you a good understanding of kind of the way the directions you can go after this class uh that i think are really excited in terms of uh how to solve problems computationally okay so with that uh i'd like to end there