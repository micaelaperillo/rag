okay so uh it's a pleasure to see all of you guys i'm justin i am your third instructor for 6006. this is my first time with this course although of course this is material that we all know and love in a computer science department i'll admit i find the prospect of teaching sorting to 400 people all at once my like kind of low-key terrifying but we're going to give it a shot and hopefully that will subside as the lecture goes on today all right uh so we're going to pick up where we left off in our last lecture and continue on with the similar theme that we're going to see throughout our algorithms class here in 6.06 i think jason and colleagues have done a really great job of kind of organizing this class around some interesting themes um so i thought i'd start with just a tiny bit of review of some key uh vocabulary words incidentally you know typically i teach the intro graphics class or geometry course and last year i got feedback that said i have serial killer handwriting i'm not 100 sure what that means but we're gonna use the slides a tiny bit more than normal just to make sure you guys can read and when i'm writing on the board at any point if you can't tell what i wrote it's it's definitely me and not you so just just let me know uh but in any event uh in 6006 uh all the way back in our lecture one i know that was a long time ago we we introduced two uh big keywords uh that are closely related but not precisely the same hopefully i've gotten this right uh but but roughly uh there's a theme here which is that there's an object called an interface right which is just sort of like a program specification right it's just telling us that there's a collection of operations that we want to implement so for example a set as we're going to see today is like a big pile of things and behind the scenes how i choose to implement it can affect the run time and and sort of how efficient my set is but the actual way that i interact with it is the same whether i use you know an unsorted array a sorted array or what have you on the other hand what happens behind the scenes is something called a data structure which is a way to actually in some sense implement an interface right so this is an object that on my computer is actually storing the information and implementing the set of operations that i've laid out in my interface right and so this sort of distinction i think is is sort of a critical theme uh in this course because for instance in the first couple weeks we're going to talk about many different ways to implement a set i'm going to see that there's a bunch of trade-offs right some of them are really fast for certain operations and slow for others uh and and so essentially we have two different decisions to make when we choose an algorithm one is making sure that the interface is correct for the problem that we're concerned with and the other is choosing an appropriate data structure whose efficiency and memory usage and so on kind of aligns with the priorities that we have for the application we have in mind so hopefully this kind of high-level theme makes sense and really kind of spiritually i think that's sort of the main message to get out of this course in the first couple weeks even if you know these o's and thetas and and so on you know are kind of easy to lose the force through the trees in any event today uh in our lecture we're concerned with one particular interface which is called a set set is exactly what it sounds like it's a big pile of things uh and and so a set interface is sort of like an object that just you can keep adding things to it and then querying inside of my set is this object here can i find it and then maybe i associate with my objects in my set different information so for example maybe i have a set which represents all the students in our classroom today yeah and all of you guys are associated uh with your student id which i believe at mit is a number yeah which has a less than sign which is convenient so we can sort all of you guys and that might be the key that's associated to every object in the room and so when i'm searching for students maybe i enter in the student number and then i want to ask my set does this number exist in the set of students that are in 6006 right and if it does then i can pull that student back and then associated with that object is a bunch of other information that i'm not using to search so for instance your name your your i don't know your social security number credit card number all the stuff that i need to uh you know have a more interesting profession so uh in any event um let's let's kind of fill in the details of our our set interface a little bit more uh so our set is a container right it contains all of the students in this classroom in some virtual sense at least uh and so to build up our set of course we need an operation that takes some iterable object a and builds a set out of it right so in other words i have you know all the students in this classroom represented maybe in some other fashion and i have to insert them all into my set i can also ask my set for how much stuff is in it personally i would call that size but length is cool too um and then of course there are a lot of different ways that we can interact with our set right so for instance we could say you know is this student taking 6006 so in set language one way to understand that is to say that the key right the each person in this classroom is associated with the key does that key k exist in my set in which case i'll i'll call this find function which uh will give me back uh the the item with key k or maybe like null or something if it doesn't exist uh maybe i can delete an object uh from my my set or insert it notice that these are dynamic operations meaning that they actually edit what's inside of my set and then finally there are all kinds of different sort of operations that i might want to do to interact with my set beyond is this thing inside of it right so for instance maybe okay so for for the student id example probably finding like the minimum id number in a class isn't a terribly exciting exercise but maybe i'm trying to find the student who's been at mit the longest and so that would be a kind of reasonable heuristic i actually have no idea whether mit student ids are assigned linearly or not but in any event uh i could find the smallest key the largest key and so on uh in my set and these are all kind of reasonable operations to query uh where my object is just a thing that stores a lot of different entities inside of now is this uh description here notice that i've labeled this as the set interface this is not a set data structure right and the way to remember that is that i haven't told you how i've actually implemented this right i haven't told you that you know i'm gonna behind the scenes have an array of information and and look inside of it and that's how i'm gonna implement you know find min or find max with a for loop or whatever all i'm telling you is that a set is a thing that implements these operations and behind the scenes my computer does what it does that might sound abstract but it's more or less what you guys do when you write code in python right you have you know addictive i think in python what we're calling a set is maybe a dictionary i'm a matlab coder i'm sorry i'm a numerical analysis kind of guy but um essentially you know that one of the beautiful things about coding in in these high-level programming languages is that they take care of these ugly details and what you're left with is just the kind of high-level uh interfacing with this object that you need at the end of the day so of course in today's lecture now that we've set out our goal right which is to fill in like if i wanted to write code for a set how could i do it now of course our goal is to give different data structures that implement these and then understand them in terms of their efficiency data storage correctness all that good stuff so before we get into all these ugly details let me pause for a second are there any questions about this basic interface y'all should feel free to stop me anytime because this is going to be hella boring if you're not getting the first slide or two [Music] yes so the question was uh what exactly is this insert operation doing so i think working in the analogy of the students in this classroom is kind of a reasonable one so i'm going to build up an object which is a student right so in this uh lecture notes i think we've been consistent i caught one or two typos we think of x as the object that contains all of the information and then associated with that is one piece which is called the key that's we're going to use the letter k right and that's like your student id that's the thing i'm going to use to search right so what the insert operation does is it takes this whole student object x which includes your id your name your phone number all that good stuff and it starts it into the set with the understanding that when i search my set i'm going to be searching by key right so when i want to find a student i have to put in my id number does that make sense cool any other questions it's great fabulous okay so now uh let's let's talk about how to actually implement this thing and thankfully we're already equipped with uh at least a very simple way that we could implement a set uh based on what you've already seen in your previous programming classes or even in just in the last two lectures which is one way to understand a set or to implement it rather would be to just store a giant array of objects that are in my set i suppose uh continuing with the sort of theme of the last two lectures this is not a space in memory but rather a metaphorical array you know a theoretical but it doesn't really matter and so one way to store my set would be to just store a bunch of x's in no particular order does that make sense so i have a big piece of memory every piece of memory uh is associated with a different object in my set obviously this is quite easy to build right i just make a big ray and dump everything in there and the question is is this particularly efficient or useful way to implement a set right so for instance let's say that i have you know i i have a set of all the students in this classroom there's like some ridiculous number of you guys so actually you know asymptotic efficiency maybe actually matters a little bit and i want to query does this student uh exist in my class you know is eric domain taking 606 the answer is no i think teaching taking i don't know uh but in any event how do i implement it if my set is unordered we'll think about it for a second yeah it's actually an interesting uh suggestion which is going to anticipate what's happening later in this lecture which was to sort the set and then binary search right but let's say that actually i only have to do this once for some reason i build up a whole set of the people in this classroom and i just want to know is eric domain in this class right so then that algorithm would take n log n time right because i've got to sort everybody and then i have to do binary search which is maybe login time but i claim that if the only thing i care about is building up my entire set and searching it once there's actually a faster algorithm this is going to be needlessly confusing because we're going to see that this is really not the right way to implement it in about 38 seconds yes yeah just iterate from beginning to this array and say is this guy eric no is this guy eric no is this guy eric yes and then return him right so in the worst case how long will that algorithm take well in the worst case i have really bad luck and your instructor is all the way at the end of the list right so in this case what is that going to mean that means that i have to walk along the entire array before i find him so that algorithm takes order and time and so your colleague's intuition that somehow this is quite inefficient is absolutely correct right if i know that i'm going to have to search my array many many times for different people then probably it makes sense to do a little bit of work ahead of time like sorting the list and then my my query is much more efficient but this is all just to say that an unordered array is a perfectly reasonable way to implement the set interface and then searching that array will take linear time every single time i search yup and of course if you go down your list of all of the different operations you might want to do on a set you'll see that they all take linear time so for instance how do i build my set well i have to reserve n slots in memory right and and at least according to our kind of model of computation in this class that takes order and time right then i got to copy everything into the set similarly if i want to insert or delete what do i have to do well i have to reserve memory and stick something inside of there in the worst case we saw this amortized argument before if your set is allowed to kind of grow dynamically and finally if i wanted to like find the minimum student id in my classroom sort of the only algorithm i can have if my my list of students isn't sorted is to what just iterate over every single student in the class and if the guy that i'm looking at has a smaller id than the one that i found replace it does that make sense to everybody so basically everything you can do in a set you can implement and i think all of you guys are more than qualified to implement as an unordered array it's just going to be slow yes yeah that's right so i actually i don't know in this class if if you're i guess the set interface the way that we've described it here is dynamic we can just keep adding stuff to it uh in that case remember this amortized argument from eric's lecture says that on average that will take order end time what was that oh that's true that's an even better sorry uh even if it weren't dynamic um if i wanted to replace an existing key like for some reason two students have the same id this is a terrible analogy i'm sorry uh but but in any event if i wanted to replace uh an object with a new one well what i have to do i'd have to search for that object first and then replace it and that search is gonna take order and time from our argument before thank you okay so uh right in some sense we're done right we've now implemented this interface life is good and and of course this is the difference between you know existence and and actually uh caring about the details inside of this thing right we've shown that one can implement a set but it's not a terribly efficient way to do it by just storing a big like hot mess disorganized list of numbers without any order yeah so instead of that uh conveniently our colleague in the front row here has already suggested a different data structure which is to store our set not as just a disorganized array in any arbitrary order but rather to keep the items in our set organized by key right so in other words like if i have this array of all of the students in our classroom and the very first element in my array is going to be the student with the smallest id number the second is the second smallest id number all the way to the end of the array which is a student with the biggest id number now does that mean i want to like do arithmetic on student id numbers absolutely not but it's just a way to sort of impose order on that list so that i can search it very quickly later okay so if i want to fill in the set interface and i have somehow a sorted array of students right so again they're organized by student id number then my runtime starts to get a little more interesting yeah so now uh insertion deletion still takes the same amount of time but let's say that i want to find the student with the minimum id number right this find min function well how could i do it in a sorted array keyword is sorted here where's the main element of an array yes uh yeah in fact i can give a moderately faster algorithm which is just look at the first one right if i want the minimum element of an array it and the array is in sorted order i know that's the first thing right so that's order one time to answer that kind of a question and similarly if i want the the thing with the biggest id number i look all the way at the end now uh in six double o what triple o this mit student class numbers are super confusing to me uh this in 6 001 604 2 you guys already i think learned about binary search and even may have implemented it so what do we know if my array is sorted how long does it take for me to search for any given element yes login time that's absolutely right right because i can cut my array in half you know if my key is bigger or smaller then i look on the left or the right and and so this is a much more efficient uh means of searching a set yeah uh so in particular you know 6006 this year has 400 students maybe next year it has 4 000. you know eventually it's going to have like billions right uh then then what's going to happen well if i use my unordered array you know and i have a billion students in this class it's going to happen well then it's going to take me roughly a billion computations to find any one student in this course whereas log of a billion is a heck of a lot faster right on the other hand i've kind of swept a detail under the rug here which is how do i actually get a sorted array to begin with and what we're going to see in today's lecture is that that takes more time than building it if i just have a disorganized list right building a disorganized list is the easy thing to do you probably all do it at home when you're cleaning house yeah but actually sorting a list of numbers requires a little bit more work and so this is a great example where there's at least a tiny amount of trade-off right where now building my sorted array to represent my set is going to take a little more computation we're going to see it's n log n time but then once i've done that sort of at step zero now a lot of these other operations that i typically care about at a set like searching it for a given key are going to go a lot faster using you know binary search okay so so this is our basic uh uh sort of motivator here and and so now we've seen the set interface and two potential data structures and our goal for the day is going to be to kind of fill in the details of that second one and since you all have already seen binary search you've probably also already seen sorting but in any event uh today we're going to focus mostly on the sort of lower left square here right on just how can i take a disorganized list of objects and put it into sorted order so that i can search for it later right so in other words our big problem for a lecture today is the second thing here right just sorting incidentally in the next couple lectures we're going to see other data sets or data structures rather so data structs that was i used to teach machine learning class uh and we'll see that they have different sort of efficiency operations that we can fill in this table so we're not done yet but this is one step forward okay so hopefully i have sort of ad nauseam justified why one might want to sort things and indeed there are a couple vocabulary words that are worth noting uh so one uh so you remember that your sorting algorithm is is pretty straightforward in terms of how you specify it right so in sorting your input is an array of n numbers i suppose actually really these we should think of them like keys it's not going to matter a whole lot right and our output i'm always very concerned that if i write on the board on the back i can like i have to cover it up um it's going to be uh out it's going to be a sorted um array right and we'll call this guy b and we'll call this one uh hey this classroom is not optimized for short people okay uh so there's a lot of variations on the basic sort of sorting problem and the different algorithms that are out there uh two vocabulary words i'm gonna highlight really quick one is if your sort is destructive what that means is the rather than like reserving some new memory for my sorted array b and then putting a sorted version of a into b a destructive algorithm is one that just overwrites a with a sorted version of a right so a lot of like certainly the c plus interface does this i assume the python one does too i i always forget this uh detail in addition to uh destructive sorts some sorts are in place meaning that not only are they destructive but they also don't use extra memory in the process of sorting right like you could imagine a sorting algorithm that like has to preserve a bunch of like scratch space to do its work and then put it back into a right like for instance the world's dumbest uh destructive sort might be to call your non-destructive sort and then copy it back into the into a right but that would require order n space to do so if my algorithm additionally has the property that it doesn't reserve any extra space at least up to a constant uh then we call that in place okay so those are our basic vocabulary words and they're ways to kind of understand the differences between different sorting algorithms why do they end up using extra oh one space oh yeah sure like any time i just make a temporary variable like a loop counter that that's going to count toward that order one but the important thing is that the number of variables i need doesn't scale in the length of the list yep okay so i present to you the beginning and end of our sorting lecture which is the world's simplest uh sorting algorithm i call it permutation sort i think it's very easy to prove correctness for this particular technique uh so in permutation sort what can i do well i know that if i have an input that's a list of numbers there exists a permutation of that list of numbers that is sorted kind of by definition right because the sword is a permutation of your original list so what is uh what's a very simple sorting algorithm well list every possible permutation and then just double check which one's in the right order yeah so there's sort of two key uh pieces to this particular technique if we want to analyze it i don't see a reason to belabor it too much but there's sort of one is that we have to enumerate the permutations now if i have a list of n numbers how many different permutations of n numbers are there yes n factorial right so just by virtue of calling this permutations function i know that i incur at least n factorial time it might be worse right it might be that like actually listing permutations takes a lot of time for some reason like every permutation itself takes order and time but at the very least you know each one of these things looks like n factorial i want you my my handwriting is terrible all right so that's what this omega thing is doing if i recall properly uh and then secondarily well we've got to check if that particular permutation is sorted um how are we going to do that well there's a very easy way to check if a list is sorted right i'm gonna do maybe four i equals one two and minus one notice not not a python quota it's gonna look a little different right then check you know is b i less than or equal to b i uh plus one right and so if this uh uh relationship is true for every single i that's supposed to be a question mark right this was less than or equal to with a question mark over it it was my special notation right so if i get all the way to the end of this for loop and this is true everywhere then my list is sorted and and life is good right so how long does this algorithm take what's kind of staring you right in the face right because you have an algorithm which is looping from one to n minus one so this step incurs order n time i guess theta event time because we gotta go all the way into the list so when i put these things together permutation sort well remember that this check if sorted happens for every single permutation so at the end of the day our algorithm takes at least n factorial times n time it's a great example of something that's even worse than n factorial which somehow in my head is like the worst possible algorithm yeah so do you think that python implements permutation sword i certainly hope not yes right so the question was why is it omega and not big o which is a fabulous question in this course so here's the basic issue i haven't given you an algorithm for how to compute the set of permutations for a list of numbers i just kind of call some magic function that i made up but i know that that algorithm takes at least n factorial time in some sense or if nothing else the list of permutations is n factorial big because that's all the stuff i have to compute so i haven't told you how to solve this problem but i'm convinced that at least this amount of time so remember that omega means lower bound right so when i put it all together in some sense okay this isn't satisfying in the sense that i didn't give you precisely the runtime of this algorithm but hopefully i've convinced you that it's super useless yeah okay any other questions about that but great so so if we go back to our table for the set interface well in some sense if we implemented it using this goofy algorithm then the lower left entry in our table would be n factorial times n which wouldn't be so hot but notice that actually all the rest of our our operations are not quite efficient right i can use binary search i just obtain the algorithm that i rather obtain the sorted array in kind of a funny fashion okay so let's let's fill in some more interesting algorithms as usual i'm talking too much and i'm nervous about the time but we can we can skip one of them if we need to okay so uh i'm gonna have seen uh selection sort before i see your hand but we're gonna defer for a little bit i'm sorry uh that's fabulous why don't we defer to the end of lecture and we'll we'll do it then okay so so uh the first algorithm that we'll talk about for sorting which is somewhat sensible uh is something called selection sort selection source exactly what it sounds like so uh let's say that we have a list of oops my laptop and the screen are not agreed okay let's say i have a list of numbers this is a message that jason i think is sending me in the course notes but i haven't figured it out uh but in any event and i want to sort uh this list of numbers here's a simple algorithm for how to do it which is i can find the biggest number in this whole list and stick it at the end yeah so in this case what's the biggest number in this list everybody nine good see this is why you go to mit okay so uh i'm gonna take that nine i'll find it and then swap it out with the the three which is at the end and now what's my sort of inductive hypothesis well in some sense it's that everything to the right of this little red line that i've drawn here is in sorted order in this case because there's only one thing yeah so now what am i going to do i'm going to look to the left of the red line find the next biggest thing what's that oh come on there we go yeah yeah wake up okay so uh right so the next biggest one is the eight so we're gonna swap it with the three put it at the end and so on i think you guys could all finish this off i suppose there should be one last line here where everything is green and we're happy but but in some sense we're pretty sure that an array of one item is in sorted order uh and so essentially from a high level what did selection sort do well it just kept choosing the element which was the biggest and swapping it into the back and then iterating now in 6006 we're going to write selection sort in a way that you might not be familiar with uh in some sense this is not so hard to implement with two for loops i think you guys could all do this at home in fact you may have already but in this class because we're concerned with proving correctness proving efficiency all that good stuff we're going to write it in kind of a funny way which is recursive now i can't emphasize strongly enough how little you guys should implement this at home this is mostly a theoretical version of selection sort rather than one that you would actually want to write in code because there's obviously much better way to do it and you'll see that in your recitation this week i believe um but in terms of analysis there's a nice easy way to write it down so we're going to sort of take the selection sort algorithm and we're going to divide it into two kind of chunks right one of them is find me the biggest thing in the first k elements of my array i shouldn't use k because that means key the first i elements of my array and the next one is to swap it into place and then sort everything to the left right that's sort of the two pieces here so let's write that down right so what did i do well in some sense in step one here i found the biggest uh uh with index less than or equal to i right so i started at the end of the list and then kind of moved backward right and then uh step two was to swap that into place notice when i say swap so for instance when i put the eight there well i had to do something with that three so i just put it where the eight used to be and then finally well am i done no i just put the biggest thing at the end of my array so now i have to sort from index one to i minus one right because now i know that the last guy is in sorted order i see i'll return again just a second so yes you can't read the handwriting this is index less than or equal to i great question i warned you it's going to be a problem okay uh so let's uh let's do step one uh first uh so i'm gonna put code on the board uh and then we're gonna fill in the details eric is posting on facebook i'm going to turn that feature off on my watch later uh okay so uh right the uh let's let's let's uh let's implement this this helper function here this is something we're going to call prefix max and this is going to find me the biggest element of array between index 0 and index i inclusive i believe yeah well here's an interesting observation really a deep one which is the the biggest uh element from zero to i that's an i sorry uh there's sort of two cases right either it's uh at index i meaning like i have the first 10 elements of my array either it is element number 10 or what's the other case it ain't yeah in other words it has index less than i this is kind of a tautology right like either the biggest thing is at this index or it's not in which case it has to be to the left does that make sense so this gives us a really simple algorithm for finding the biggest element in the array between index zero and index i which is what i've shown you on the screen here i'd write it on the board but i am a slow writer and already low on time and so essentially what did i implement well i found the biggest element between index 0 and index i minus 1 right so if i have let's say that i have an array i forget the sequence of numbers like 8 3 5 7 9. that'll do it yeah and so like i give a pointer here which is i right then the very first thing that i do is i compute the biggest number all the way to the left of this stuff in this case that is eight there we go now i look at the very last element of my array which is nine are you killing me today guys okay and then what do i return well i want the biggest one between zero and index i so in this case i return the nine that makes sense so you know there's this uh i know jerry kane at stanford likes to talk about the uh what is it the recursive leap of faith that happens uh another term for this is induction right so we want to prove that our uh our algorithm works well what do we have to do we have to show that when i call this function it gives me the max of my array between index 0 and index i for all i right so let's maybe do this inductive proof a little bit carefully and then the rest will be we'll be sloppy about it right so the base uh case is i equals zero right well in this case there's only one element in my array so it's pretty clear that it's the max right okay and now we have to do our inductive step right which means that if i call prefix max with i minus 1 i really do get the max of my array between 0 and index i minus 1 and then really i can just look at my proof my very deep statement which is that either my object is at the end of the array or it's not and this is precisely what we need to justify the inductive step right essentially there are two cases either the biggest element of my array is the last one or it's not we already by our inductive hypothesis have argued that our code can find the biggest element between index 0 and index i minus 1. so as long as we take the max of that and the very last guy we're in good shape okay so this is our our sort of very informal proof of correctness okay so now we have to to justify runtime for this algorithm and that's like actually not 100 obvious from the way i've written it here right there's no for loop but what do i do well in some sense if my runtime is a function s well for one thing if my array has one element in it well my runtime you know it might be seven it might be 23 but at the end of the day it only does one thing it just returns i right so in other words it's theta of one this isn't terribly insightful but what else do we know well when i call my function i call it recursively on one smaller index and then i do a constant amount of work so i know that s of n is equal to s of n minus one plus theta of one right i do a little bit of extra computation on top of that anybody guess what this total run time is going to be yes yeah order n right so let's say that we hypothesize that this takes end time kind of see that right because like at step n we call n minus one we call it minus two and so on all the way down to one right if we want to improve this one of the ways that we uh i think in theory you guys have learned in the past and you're gonna cover in in recitation is a technique called substitution what we do is we're going to look at this relationship and we're going to hypothesize that we think s of n maybe looks something like c n for some constant c that doesn't depend on n then all we have to do is double check that that relationship is consistent with our inductive hypothesis or rather just this recursive function and if it is then we're in good shape yeah so in this case well what do i know i i've guessed that s of n is theta of n so oops in particular uh if i plug into this recursive relationship here on the left hand side i'm going to get cn on the right hand side i'm going to get c n minus 1 plus theta of 1. we just have to make sure that this is like an okay equal sign so what can i do i can subtract c n from both sides maybe put that one on the other side here i'm gonna get the c equals big o of one c is of course a constant so we're in good shape my undergrad algorithms professor told me never to write a victory mark at the end of a proof you have to like do a little square but he's not here okay uh right so now uh i see you but we're a little low on time so we'll save it for the end of lecture um okay so if we want to implement the selection sort algorithm well what do we do well we're going to think of i as the index of like that that red line that i was showing you before right so everything beyond i is already sorted so in selection store the first thing i'm going to do is find the max element between 0 and i and then i'm going to swap it into place right so this is just a code version of the the technique we've already talked about hopefully this makes sense right so you find the biggest element between zero and index i right that's what we're going to call j here i swap that with the one in index i that's step two and then step three is i still have to sort everything to the left of index i and that's that recursive call okay so if i want to justify the uh the runtime of this particular technique well now let's call that t for time yeah well what do i do well for one i call selection sort with index i minus one right so that incurs time that looks like this but i also call that prefix max function and how much time does that take that takes order end time yeah so at the end of the day i have some relationship that looks like this does that make sense so by the way notice that this order n kind of swallowed up the like order one computations that i had to do like to swap and so on okay so remember uh there's this nice uh relationship which you probably learned in your combinatorics class which is that one plus two plus dot dot plus n okay i can never remember exactly the formula but i'm pretty sure that it looks like n squared yeah so based on that and and taking a look at this uh recursive thing right which is essentially doing exactly that right n plus n minus 1 plus n minus 2 and so on i might hypothesize that this thing is really order n squared so if i'm going to do that then again if i want to use the same technique for proof i have to plug this relationship in and then double check that it's consistent right so uh maybe i hypothesize that t of n equals c n squared in which case i plug it in here i have c n squared equals with a question mark over it c n minus 1 squared plus big o or even theta of n here so if i expand the square notice i'm going to get c times n squared plus a bunch of linear stuff right so this is really c n squared uh i should be careful with it uh minus 2 c n plus c plus theta of n yeah notice that there's a c n squared on both sides of this equation they go away and what i'm left with is a nice consistent uh formula right that theta of n equals 2 c n plus oops minus c and indeed this is an order n expression so there's order in the universe life is good yeah this is the substitution method and again i think you'll cover it more in your recitation so what have we done we have derived the selection sort we've checked that it runs an n squared time uh and uh uh by sort of this nice inductive strategy we know that it's correct so life is pretty good unfortunately i promise for you guys on the slides that sorting really takes n log n time and this is an order n squared algorithm so we're not quite done yet i'm way over time so we're going to skip a different algorithm which is called insertion sort also runs an end time uh okay uh where essentially insertion sort kind of runs in the reverse order right i'm going to sort everything to the left and then insert a new object whereas in selection sort i'm going to choose the biggest object and then sort everything to the left but i'll let you guys piece through that at home it's essentially the same argument and instead we should jump to an algorithm that actually uh matters which is uh something called merge story that means i've encountered merge sort before fabulous good so then i'm done uh no okay so so let's say that i have a list now i'm sending a message back to jason i made this one up last night uh so i have seven one five six two four nine three this is not in sorted order but i can make a very deep observation which is that every number by itself is in sorted order if i think of it as an array of length one yeah this is really deep like a deep learning deep okay so now what can i do well i could take every pair of numbers draw a little red box well now they're not in sorted order anymore inside of the red boxes so i'm going to sort inside of every box in this case not too exciting because it's just pairs and now they're in sorted order because i said they were now i'm going to keep doubling the size of my boxes so now let's say i have box of length four what do i know about the left and right hand sides of the dotted lines here on the two sides of the dotted lines the array is in sorted order right there's a one and then a seven right those are in sorted order five and a six that's because in the previous step i sorted every pair so when i merge these two sides together i have an additional useful piece of information right namely that the two sides of the dotted line are already in sorted order that's going to be our basic sort of inductive step here yeah so in this case i merge the two sides i get one five six seven and two three four nine then finally i put these two things together and i have to sort these two uh uh i have to merge these two sorted lists but they're in sorted order yeah and that's going to give me a big advantage right because uh oops i lost my truck i suppose i've got space on this board here oh no uh right so if i want to merge one five six seven and two three four nine there's like a nice clever technique that we can do uh that's going to take just linear time jason tells me it's the two-finger algorithm i think that's kind of a cute analogy here so here are my two fingers they're going to point at the end of the list and i'm going to construct the merged array backwards so how many elements are in my merged array if i'm merging two things of length four i don't ask you guys hard questions it's eight yeah two four plus four eight yeah okay so what do i know i know that my merge array ah five six seven has eight elements and now i'm gonna have two fingers at the end of my array which one should i put at the end of the merged guy the seven or the nine the nine right thank you right so now i can move my lower finger to the left right because i've already added that notice that i never need to look to the left of where my finger is because they're already in sorted order right now what should i add the four the seven the seven and so on dot dot dot yeah so that's going to be the basic idea of the merge sort i'm going to take two sorted lists i'm going to make a new sorted list which is twice as long by using two fingers moving uh from the end backward okay so that's the basic intuition here indeed there's our sorted list stressing me out that there's no eight but i needed a power of two um so i think the merge sort we're gonna present in kind of a backward way from the previous one where i'm gonna give you the high level algorithm and then actually the headache is that merging step which i have four minutes for and i apologize for so what does the merge sort do well it computes an index c which is the middle of my array and it's going to make a recursive call which says sort the left right which is everything between index a and index c and then sort everything on the right which is everything from index c to index b i know this is confusing because usually letters appear in order but c if you think of as standing for center then it kind of makes sense like here's my array i'm going to like choose an index right in the middle i've done myself a disservice by not using a power of two but that's okay i'm gonna say sort everything to the left of the dotted line first sort everything to the right of the dotted line second now i have two sorted lists on the two sides of the dotted line and then i'm gonna use my two fingers to put them together okay so that's what this is implementing here see there's two recursive calls sort from a to c and then sort from c to b oops i didn't actually label this so this is a c b and then i gotta call merge okay now our implementation of merge well we can also do this in a recursive fashion but i personally find this a little complicated i'm going to admit but here's the basic idea here which i'm now rushing so i'm going to think of my upper finger as finger i in my lower finger as finger jack does that make sense okay so i have two sorted lists so maybe like that i don't know one three five seven and then i have a second sorted list here which is maybe two four 72 as one does then i'm going to have one pointer like this which is i and a pointer down here which is j right and my goal is to construct an array a with a bunch of elements in it and the way that i'm going to do it is i'm going to use exactly the same kind of recursive argument right that i can either have the biggest element of my array be the last element of the first guy or be the last element of the second one yeah so here's our going to be our recursive call and in addition to that for convenience we'll have a third index which is b which is pointing to the sort of thing inside of my my assorted array that i'm currently processing yeah just gonna start it a go to b yeah instantly i see a lot of people taking photos of the slides uh these are just copy pasted from the course notes um okay so in this case what should i put in b for my two arrays i have one three five seven two four six seventy two seventy two yeah great so now what am i going to do i'm just going to call the merge function but i'm going to decrement b because now i'm happy with that last element in addition to that i'm going to decrement j because i already used it up and so that's our recursive call here right it's saying if j is launching equal to zero so in other words i have an element to use in in one of the list or the other and uh that maybe the left one is bigger than the right one right that's our first case that does not apply in this example here well then i should make the last element of a from the first list and then recurse um with one fewer element i and similarly the reverse case for j okay so if we do our run time in two minutes or less bear with me guys uh well what is this merge function going to do well in some sense there's two branches right there's an if statement with two pieces but both of those pieces call merge with one fewer uh piece in it right so in some sense we have s of n equals s n minus 1 plus theta of 1 which we already know from our previous proof means that s of n is equal to theta of n so in other words it takes linear time to merge it kind of makes sense intuitively right because essentially you're touching every one of these things once with your two fingers and now our probably the hardest part of the lecture which i left zero time for is deriving the run time for the actual merge sort algorithm and what does that look like well that one's a little bit trickier right because of course i call the merge sort algorithm twice each time on a list that's half the size in this class we're going to assume that our list is always the power of two in its length otherwise this analysis is a itty-bitty bit more of a headache so first of all how long does it take to sort an array of length one i legit i'm not going to ask hard questions everybody yeah just just like one right because like there's nothing to do my array of length one has has one element and it's sorted it's also you know the biggest element and the smallest element okay and now what does our algorithm do well it makes two recursive calls on lists that are half the length yeah and then it calls that merge function and we know that the merge function takes theta of n time that makes sense so uh one thing we might do because we have some intuition from your your 6042 course is that we think that this thing is order n log n right because it makes that two recursive calls and then it puts them together and let's double check that that's true really quick using the substitution method so in particular on the left hand side here maybe i have c and log n now i have two c well i have to put in n over 2 log n over 2 plus theta of n and i want to double check that this expression is consistent i've got about a foot to do it in okay so remember uh let's see if we use our favorite uh identities from from high school class that you probably forgot remember that log of two things divided by each other is the difference of the logs right so this is really two uh okay two divided by two is one so this is uh c times n times log n minus log of two yeah plus theta of n i'm already out of time but notice that there's a c n log n on the right hand side there's a c n log n on the left-hand side so those two things go away and what am i going to be left with i'm going to be left with theta of n equals c n log of 2. notice that c and log 2 are both constants we have a theta of n on the left-hand side so there's order on the universe and and we've derived our runtime so i know i rushed a little bit through merge sort i'm sure that eric and and jason can can review this a little bit next time uh but with that we'll see you uh what thursday and friday and it's been a pleasure to talk to you all