welcome to the fourth lecture of 6006. um today we are going to be talking about hashing last lecture on tuesday um professor solomon was talking about uh set data structures right storing things so that you can query items by their key right by what they intrinsically are versus what professor domain was talking about last week which was sequence data structures where we impose an external order on these items and we want you to maintain those but i'm not i don't really i'm not supporting operations where i'm looking stuff up based on what they are right that's what the set interface is for right so we're going to be talking a little bit more about the set interface today so last on tuesday you saw two ways of implementing the set interface right one using just a unsorted array just i threw these things in an array and i could do a linear scan of my items to support basically any of these operations it's a little exercise you can go through i think they show it to you in the recitation notes but if you'd like to implement it for yourself that's fine uh in and then we saw a slightly better data structure at least for the find operations can i look something up whether this key is in my uh set interface we can do that faster we can do that in log n time with a build overhead that's about n log n right because we showed you three ways to sort two of them were n squared one of them was n log n which is as good as we showed you how to do yesterday so the question then becomes can i build that data structure faster that'll be a subject of next week's thursday lecture but this week we're going to concentrate on this static find right right we got log n which is an exponential improvement over linear right but the question here now becomes can i do faster than log n time and what we're going to do at the first part of this lecture is show you that no you what's up what no okay that you can't do faster than log n time in the caveat that we are in a slightly more restricted model of computation that we were then what we introduced to you a couple weeks ago and then so if we're not in that that more constrained model of computation we can actually do faster right and doing faster is i mean log n is already pretty good right log n is not going to be larger than like 30 for any problem that you're going to be talk talking about uh in the real world on real computers but uh a factor of 30 is still bad right i would prefer to do faster with those constant factors when i can it's not a constant factor it's a logarithmic factor but you get what i'm saying okay so what we're going to do is first prove that you can't do faster for for fine does everyone understand remember what find key meant right i have a key i have a bunch of items that have keys associated with them and i want to see if one of the items that i'm storing contains a key that is the same as the one that i searched for right the item might contain other things but it in particular has a search key that i'm maintaining the set on so that it supports find operation search operations based on that key quickly does that make sense so there's the find one that we want to improve and we also want to improve this insert delete we want to be make this this data structure dynamic right because we we might uh do those operations quite a bit and so this lecture is about optimizing those three things okay so first i'm going to show you that we can't do faster than log n for find which is a little weird okay the model of computation i'm going to be proving this lower bound on right i'm saying that how i'm going to approach this is i'm going to say that any way that i store these the items that i'm storing in this data structure for any way i store these things any algorithm of this certain type is going to require at least logarithmic time that's that's what we're going to try to prove and the model of computation that's that's weaker than what we've been talking about previously is what i'm going to call the comparison model and a comparison model means is that the items the objects i'm storing i can kind of think of them as black boxes i don't get to touch these things except the only way that i can distinguish between them is to say given a key and an item or two items i'm i can do a comparison on those keys right are these keys the same uh is this key bigger than this one is it smaller than this one those are kind of the only operations i get to do with them i don't get to look at what the say if the keys are numbers i don't get to look at what number that is right i just get to take two keys and compare them and actually all of the search algorithms that we saw on tuesday were comparison sort algorithms right what you did was you stepped through the program at some point you came to a branch and you looked at two keys and you branched based on whether one key was bigger than another right that was a comparison and then you moved some stuff around but that was the general paradigm those those three sorting operations uh lived in this comparison model right you've got uh you know comparison operations like are they equal less than greater than maybe greater than or equal less than or equal right generally you have all these operations that you could do maybe not equal right but the key thing here is that there are only two possible outputs to each of these comparators right there's only two things there's there's only one one thing that i can branch on it's going to branch into two different lines right it's either true and i do some other computation or it's false and i'll do a different set of computation right that makes sense so what i'm going to do is i'm going to view a comparison an algorithm in the comparison model as what i like to call a decision tree right so if i specify an algorithm to you the first thing it's going to do if i don't compare items at all i'm kind of screwed because i'll never be able to tell if my keys and they're not so i have to do some comparisons so you know i'll do some computation you know maybe i find out the length of the array and i do some constant time stuff but at some point i'll do a comparison and i'll i'll branch right i'll come to this node and if the comparison like maybe a less than right if it's true i'm going to go this way in my computation and if it's false i'm going to go this way in my computation right and i'm going to keep doing that with various comparisons um sure until i get down here to some [Music] leaf in which i'm i'm not branching right the internal nodes here are representing comparisons but the leaves are representing i stopped my computation i'm outputting something does that make sense what i'm kind of trying to do i'm kind of changing my algorithm to be put in this kind of graphical way where i'm branching what my program could possibly do based on the comparisons that i do right i'm not i'm not actually counting the rest of the work that the program does right i'm really only looking at the comparisons right because i know that i i'll need to compare some things eventually to figure out what my items are and if that's the only way i can distinguish items then i have to do those comparisons to to find out right does that make sense all right so what i have is a binary tree that's representing the comparisons done by my algorithm okay so it starts at one comparison and then it branches how many leaves must i have in my tree what does that question mean right like in in terms of the program what's up the number comparison the number of comparisons no that's the number of internal nodes that i have in the algorithm and actually the number of comparisons that i do in an execution of the algorithm is just along a path from here to the to a leaf right so what do the leaves actually represent those are represent outputs right i'm going to output something here and yeah the number of i okay so i need at least so what is the output to my search algorithm maybe it's the an index of an item that contains this key or maybe i return the item uh is the output right the item so the of the thing i'm storing and i'm storing n things so i need at least n outputs right because i need to be able to return any of the items that i'm storing based on a different search key parameter if it's going to be correct i actually need one more output why do i need one more output if it's not in there right right so any correct comparison searching algorithm i've i'm doing some comparisons to find this thing needs to have at least n plus one leaves right otherwise it can't be correct because i could look up the one that i i'm not returning in that set and it would never be able to return that value does that make sense yeah what's n n is always the num in for a data structure n is the number of things stored in that data structure at that time right so the number of items in the data structure that's what it means in all of these tables any other questions okay so now we get to the fun part how many comparisons does this algorithm have to do yeah up there what's up all right your colleague is jumping ahead for a second but really i have to do as many comparisons in the worst case as the longest route to leaf path in this tree right because as i'm executing this algorithm i'll go you know down this thing always branching down and at some point i'll get to a leaf and in the worst case if i happen to need to return this particular output right then i'll have to walk down the longest thing right it's the longest path so and the longest path is the same as the height of the tree okay so the question then becomes what is the minimum height of any binary tree that has at least n plus one leaves ever understand why we're asking that question okay so unrest yeah why it needs n plus one leads if it's a correct algorithm it needs to return it needs to be able to return any of the n items that i'm storing or say that the key that i'm looking for is not there great question okay so what is the minimum height of any binary tree that has n plus one at least n plus one leaves you'll you can solve that uh you can actually state a recurrence for that and solve that you're going to do that in your recitation but it's log n right like the best you can do is if this is a balanced binary tree right so the min height is going to be at least log n height right right where the min height is logarithmic right so it's actually theta right here but but if i just said height here i would be lower bounding the height right if i could have a linear height right if i just chained comparisons down one by one if i was doing a linear search for example right all right so this is saying that if i'm just restricting to comparisons i have to spend at least logarithmic time to be able to find whether this key is in my set right but i don't want logarithmic time i want faster so how can i do that i have one operation in my model of computation i presented a couple weeks ago that allows me to do faster which allows me to do something stronger than comparisons comparisons have a constant branching factor in particular i can i if i do this operation this constant time operation i can branch to two different locations right it's like an if kind of situation if or else right and in fact if i had constant branching factor for any constant here right if i had three or four if it was bounded by a constant the height of this tree would still be bounded by a log base the constant of that number of leaves okay so i need in some sense to be able to branch a non-constant amount right so how can i branch a non-constant amount this is a little tricky right we had this really neat operation in the random access machine that we could randomly uh go to any place in memory in constant time based on a number right it was a super powerful thing because within a single constant time operation i could go to any space in memory right that's that's potentially much larger than linear branching factor depending on the size of my model and the size of my machine right so that's a very powerful operation can we use that to find quicker anyone have any ideas sure uh we're going to get to hashing in a second but this is a simpler concept a concept in hashing hashing something you probably are familiar with already we've kind of been using it implicitly in some of our sequence data structure things what we're going to do is if i have a an item that has key 10 okay i'm going to keep an array and store that item 10 spaces away from the front of the array right at index nine or the tenth index does that make sense if i store that item at that location in memory i can use this random access to that location and see if there's something there if there's something there i return that item does that make sense this is what i call a direct access array it's really no different than the arrays that we've been talking about earlier in the class we got an array and if i have an item here with key equals 10 i'll stick it here in the 10th place now i can only now store one item with the key 10 in my thing and that's one of the stipulations we had on our set data structures right if we tried to insert something with the same key as something already stored there we're going to replace the item right that's what the semantics of our set interface was but that's okay that's that's that's satisfying uh the conditions of our send interface so if we store it there that's fantastic how how long does it take to find if we have an item with the the key 10 it takes constant time worst case great how about inserting or deleting something what's what's that again constant time we've solved all of our problems this is amazing okay what's not amazing about this why don't we just do this all the time ah i don't know how high the numbers go right so let's say i'm storing i don't know a number associated with the the three or four hundred of you that are in this classroom right but i'm storing your mit ids how big are those numbers those are like nine digit numbers right pretty long numbers so what i would need to do in in if i was storing your keys as uh mit ids i would need an array that has indices that span the entire space of nine digit numbers right that's like 10 to the nine or nine uh 10 to the nine thank you ten to the nine is the the size of a direct access array i would have to build to be able to use this um [Music] this technique to to create a direct access array to search on your mit ids when there's only really 300 of you in here right so 300 or 400 is an n that's much smaller than the size of the numbers that i'm trying to store what i'm going to use as a variable to to talk about the size of the numbers i'm storing i'm going to say u is the maximum size of any number that i'm storing okay it's the size of the universe of space of keys that i'm storing does that make sense okay so to instantiate a direct access array of that size i have to allocate that amount of space and so if that is much bigger than n then i'm kind of screwed right because i'm using much more space and these order operations are bad also right because essentially if i am storing these things uh non-continuously i kind of just have to scan down the thing to find the next element for example right okay what's your question a direct access array is a set data structure that's why it's a set interface up there so uh this is uh your colleague is asking whether you can use a direct access array to implement a set i mean a sequence and actually i think you'll see in your recitation notes you have code that can take a set data structure and implement a sequence data structure and take a sequence data structure and implement a set data structure they just won't necessarily have very good run time so this direct access array semantics is really just good good for these specific set operations that make sense yeah what you u is this the size of the largest key that i'm allowed to store that makes sense right and the the direct access array is supporting you up to you size keys does that make sense okay we're going to move on for a second so what's that that's the problem right we when you largest key we are we're assuming integers here right integer keys right so in the comparison model we could store any arbitrary objects that that supported a comparison here we really need to have integer keys or else we're not going to be able to use those as addresses right so we're making a an assumption on the inputs that i can only store integers now i can't store arbitrary objects items with keys and in particular i also need to this is a subtlety that's in the word ram model how can i be assured that these keys can be looked up in constant time how does my seat my this little cpu right it's got some number of registers it can act upon how big is those registers what well so they're they're right now they're 64 bits but in general they're w they're the size of your word on your machine that's how many uh two to the w is the number of addresses i can access so implicitly i'm kind of if i'm going to be able to use this direct access array i need to make sure that the u is you know less than 2 to the w right if i want these operations to run in constant time right if i have keys that are much larger than this i'm going to need to do something else okay but this is this is kind of the assumption in in this class when we give you like an array of integers or an array of strings or something like that on your problem set or on an exam right the assumption is unless we give you a bounds on the size of those things right like the number of characters in your string or the size of the number and you can assume that those things will fit in in one word of memory okay w is the word size of your machine right the number of bits that your machine can do operations on in constant time any other questions okay so we have this problem we're using way too much space right when we have a large universe of keys so how do we get around that problem any ideas sure okay so what your colleague is saying instead of just storing one value at each place maybe store more than one value if we're using this uh idea right where i am storing my key at the index of the key that's getting around the us having to have unique keys in our data structure it's not getting around this space usage problem does that make sense we will end up storing multiple things at indices but there's an another trick that i'm looking for right now right we have a lot of space that we would need to allocate for this data structure what's an alternative instead of allocating a lot of space we allocate less space right let's allocate less space all right so we have a really like this is our space of keys right you right but instead i want to store those things in a direct access array of maybe size n right something like the order of the things that i'm going to be storing i'm going to relax that and say we're going to make this a length m that's you know around the size of the things i'm storing okay and what i'm going to do is i'm going to try to map this space of keys this large space of keys from like zero to u minus one or something like that right down to a range that's zero to m minus one okay right i'm gonna want a function this is what i'm going to call h which maps this range down to a smaller range does that make sense i'm gonna have some function that takes that large space of keys sticks them down here okay and instead of storing at an index of the key i'm going to put the key through this function the key space into a compressed space and store it at that index location does that make sense sure oh your colleague is comes comes up with the the question i was going to ask right away which was what's the problem here the problem is it's the potential that we might be story have to store more than one thing at the same index location right if i have a function that matches this big space down to this small space i gotta have multiple of these things going to the same places here right it's got a it can't be injective right but just based on pigeonhole principle i have more of these things at least two of them have to go to something over here in fact if i have say u is bigger than n squared for example right there for any function i give you that maps this large space down to the small space n of these things will map to the same place right so if i choose a bad function here then i'll have to store n things at the same index location and if i go there i have to kind of check to see whether any of those are the things that i'm looking for i haven't gained anything right i really want a hash function that will evenly distribute keys over this space right does that make sense but we have a problem here if we need to store multiple things at a given location in memory can't do that i have one thing i can put there so i have two options on how to deal what what i call collisions right if i have two items here like a and b these are different keys right in my universe of space but it's possible that they both map down to some hash that has the same value right so where do i if i if i first hash a and a is i put put a there where do i put b there are kind of two options um is the second data structure a linked list so that um it can store me okay so what your colleague was saying can i store this one as a linked list and then i can just insert a guy right next to where it was what's the problem there is linked lists are linked lists good with direct accessing by an index no they're terrible with get at and set at right they take linear time there right so really the whole point of direct access array is that there is an array underneath and i can do this index from arithmetic and go down to the next thing so i really don't want to replace a linked list as this data structure yeah what's up we can make it really unlikely sure i don't know what likely means because i'm giving you a hash function one hash function and i don't know what the inputs are yeah okay right so there are actually two solutions here one is i i maybe if i choose m to be larger than n right there's going to be extra space in here i'll just stick it somewhere else in the existing array right how i find an open space is a little complicated but this is a technique called open addressing which is much more common than the technique we're going to be talking about today in implementations python uses an open addressing scheme which is essentially find another place in the array to to put this collision but it's open addressing is notoriously difficult to analyze so we're not going to do that in this class there's a much easier technique that we have an implementation for you in the recitation handouts it's what your colleague up here i can't find him over there was saying was instead of storing it somewhere else in the existing direct access array down here which we usually call the hash table right instead of storing it somewhere else in that hash table we'll instead add that key store a pointer to another data structure right some other data structure that can store a bunch of things just like any sequence data structure like a dynamic array or a linked list or anything right all i need to do is be able to stick a bunch of things on there uh when there are collisions and then when i go up to look for that thing i'll just look through all of the things in that data structure and see if my key exists does that make sense now we want to make sure that those additional data structure structures which i'll call chains right we want to make sure that those chains are short right they don't i don't want them to be long right so what i'm going to do is when i have this collision here instead i'll have a pointer to some i don't know maybe make it a dynamic array or a linked list or something like that and i'll put a here and i'll put b here and then later when i look up key k right or look up key a or b let's look up key b i'll go to this hashed value here i'll put it through the hash function i'll go to this index i'll go to the data structure the chain associated with that index and i'll look at all of these items i'm just going to do a linear find i'm going to look i could put any data structure here but i'm going to look at this one see if it's b it's not b look at this one it is b i return yes does that make sense this is an idea called chaining i can put anything i want there commonly we talk about putting a linked list there but you can put you know a dynamic array there you can put a sorted array there to make it easier to check whether the key is there you can put anything you want there the point of this lecture is going to try to show that there's a choice of hash function i can make that make sure that these chains are small that it really doesn't matter how i store them there right because i can just i have i have time if there's a constant number of things stored there i can just look at all of them and do whatever i want and still get constant time yeah so and like let's just say like for some reason the number of things is that most of them get like multiple yeah so what your your colleague is saying is kind of at initialization what is stored here right initially it points to an empty data structure right i'm just going to initialize all of these things to have now you get some overhead here right we're paying something for this some extra space in having pointer and another data structure at all of these things or you could have the semantics where if i only have one thing here i'm going to store that thing at this location but if i have multiple it points to a data structure these are kind of complicated you know implementation details but you get the basic idea right if i just have a zero size data structure at all of these things i'm still going to have a constant factor overhead right it's still going to be a linear size data structure as long as m is linear in n does that make sense okay so how do we pick a good hash function i already told you that any fixed hash function i give you is going to experience collisions and if u is large right then there is the possibility that i for some input all of the things in my set go directly to the same hashed index value so that ain't great let's ignore that for a second what's the easiest way to get down from this large space of keys down to a small one what's the easiest thing you could do yeah modulus great this is called the division method okay and what it's the function is is essentially it's going to take a key and it's going to set it equal to b k mod m okay i'm going to take something of a large space i'm going to mod it so that it kind of just wraps around right perfectly valid thing to do it satisfies what we're doing in a hash table and if my keys are completely uniformly distributed ran like if if when i use my hash function all of the keys here are uniformly distributed over this this larger space then actually this isn't a such a bad thing right but that's imposing some kind of distribution requirements on the type of inputs i'm allowed to use with this hash function for it to be of have good performance right but this plus a little bit of extra you know mixing and bit manipulation is essentially what python does it essentially all it does is kind of jumbles up that key for some fixed amount of jumbling and then mods it m and sticks it there but there are some it's it's hard-coded in the the python library what this hash function is and so there exists some sequences of inserts into a hash table in python which will be really bad in terms of performance because these these chain lengths or the amount number of collisions that i'll get at a single hash is going to be large right but they do that for other reasons they want a deterministic hash function they want something that i do the program again it's going to do the same thing underneath right but sometimes python gets it wrong but if your data that you're storing is sufficiently uncorrelated to the hash function that they've chosen which usually it is this is a pretty good performance okay but this is not a uh practical class well it is a practical class but one of the things that we are uh that's the emphasis of this class is making sure we can prove that this is good in theory as well right i don't want to know that sometimes this will be good i really want to know that if i choose if i if i make this data structure and i put some inputs on it i want a running time that is independent on what inputs i decided to use independent of what keys i decided to store does that make sense right in some sense i want but it's impossible for me to pick a fixed hash function that will achieve this right because i just told you that if u is large right this is if u is large then there exists inputs that map everything to one place so i feel i'm screwed right i can't there's no way to solve this problem that's true if i want a deterministic hash function right i want the thing to be repeatable to do the same thing over and over again for any set of inputs what can i do instead weaken my notion of what constant time is to do better okay use a non-deterministic what does not what does non-deterministic mean right it means don't choose a hash function up front choose one randomly later right so have the user they pick whatever inputs they're gonna do and then i'm gonna pick a hash function randomly they don't know which hash function i'm gonna pick so it's hard for them to give me an input that's bad right okay so how do i'm going to choose a random hash function how do i choose a random can i choose a a hash function from the space of all hash functions what is the space of all hash functions of this form right for every one of these values i give a value in here right that would be a completely like i choose for each one of these independently random number between this range how many such hash functions are there m m to the this number that's a lot of things right so i can't do that what i can do is fix a family of hash functions where if i choose one from randomly i get good performance and so the hash function i'm going to use and we're going to spend the rest of the time on is what i call a universal hash function it has it satisfies what we call a universal hash property so universal hash function and this is a little bit of a weird nomenclature because i'm defining this to you as the universal hash function but actually universal is a uh you know a descriptor right there exists many universal hash functions this just happens to be an example of one of them okay so the hash function uh or really right so we're gonna so here's the hash function it doesn't look actually all that different goodness gracious how many parentheses are there mod p mod m okay so it's kind of doing the same thing as what's happening up here right but before modding by m i'm multiplying it by a number i'm adding a number i'm taking it mod another number and then i'm modding by m okay this is a little weird and not only that this is still a fixed hash function i don't want that i want to generalize this to be a family of hash functions which are this h a b k for some random choice of a b in this larger range all right this is a lot of notation here essentially what this is saying is i have a hash family okay it's parameterized by the length of my hash function and some fixed large random prime that's bigger than u just i'm going to pick some large prime number okay and that's going to be fixed when i make the hash table okay and then when i instantiate the hash table i'm going to choose randomly one of these things by choosing a random a and a random b from this range does that make sense this is a not equal to zero right if i had zero here i kind of lose the key information and that's no good does this make sense so what this is do is multiplying this key by some random number adding some random number modding by this prime and then modding by the size of my thing okay so it's doing a bunch of jumbling and there's some randomness involved here i'm choosing the hash function by choosing an a b randomly from this thing so when i start up my program right i'm going to instantiate this thing with some random a and b not deterministically right the user when they're using this thing doesn't know which a and b i picked right so it's really hard for them to give me a bad example right and this universal hash function this universal hash family shall we say really this is a family of functions and i'm choosing one randomly within that family is universal and universality says that what is it what is the property of universality it means that the probability by choosing a hash function from this hash family that a certain key collides with another key is less than or equal to one over m for all any uh different two keys in my universe does that make sense so if i basically this thing has the property that if i randomly pick or if i for any two keys right that i pick in my universe space if i randomly choose a hash function the probability that these things collide is less than one over m why is that good this is in some sense a measure of how well distributed these things are i want these things to collide with one over m probability so that these things don't collide very likely it's not very likely for these things to collide does that make sense so we won't prove that this hash family satisfies this universality property you'll do that no four six but we can use this result to show that if we use a universal ha this universal hash family that the length of our change chains is expected to be constant length okay so we're going to use this property to prove that okay how do we prove that we're going to do a little probability okay so how are we going to prove that i'm going to define a random variable an indicator random variable does anyone remember what an indicator random variable is yeah it's a it's a variable that with some amount of probability is one and one minus that probability is zero right so i'm going to define this indicator random variable i x i j is a random variable over my choice over choice of a hash function in my hash family and what does this mean it means x i j equals one if hash ki equals hkj these things collide right and zero otherwise okay so i'm choosing randomly over this hash family if for two keys i and j key i and key j if these things collide that's going to be one if they don't then it's zero okay then how can we write a formula for the length of a a chain in this model right so the size of a chain right or let's put it here the size of the chain at i right at i in my hash table is going to equal i'm going to call that the random variable x i that's going to equal the sum over j equals 0 to is it over i think u minus 1 of summation or sorry of x i j right so basically if i fix this uh this location i right if i fix this location i this is where this key goes right so i'm looking at sorry this is the size of chain at h of k i sorry so i look at wherever k i goes is hashed right and i see how many things collide with it right i'm just summing over all of these things right because this is one if there's a collision and zero if there's not does that make sense so this is the size of the chain at the index location mapped to by ki okay so here's where your probability comes in what's the expected value of this chain length over my random choice okay expected value over choosing a hash function from this universal hash family of this chain length well that's just i can put in my definition here that's the expected value of the summation over j of x i j what do i know about expectations and summations if these variables are independent from each other say say what linearity of expectation right basically the expectation of the sum of these independent random variables is the same as the summation of their expectations right so this is equal to the summation over j of the expectations of these individual ones okay one of these j's is the same as i right j j loops over all of the things from zero to u minus one right one of them is i right so when x h i is h j what is what is the expected value that they collide one right so i'm going to refactor this as being this where j does not equal i plus one are people okay with that because if i equals if if if j and i are equal they definitely collide right they're the same key right so i'm expected to have one guy there which was the original key x i right but otherwise we can use this universal property right that says if they're not equal and they collide which is exactly this case right the probability that that happens is 1 over m right and since it's an indicator random variable the expectation is their outcomes times their probabilities right so 1 times that probability plus 0 times 1 minus that probability right which is just 1 over m right so now we get the summation of one over m for j not equal to i plus one oh and this sorry i did this wrong this isn't u this is n we're storing n keys right okay so now i'm looping over j this over all of those things how many things are there and minus one things right so this should equal one plus n minus one over m okay so that's what universality gives us so as long as we choose m to be like larger than n or at least linear in n then we're expected to have our chain lengths be constant right because this thing becomes a constant if m is at least order n does that make sense okay the last thing i'm going to leave you with is how do we make this thing dynamic if we're growing the number of things we're storing in this thing it's possible that as we grow n for a fixed m this thing will stop being m will stop being linear in n right well then all we have to do is if we get too far we rebuild the entire thing the entire hash table with the new m right just like we did with a dynamic array and you can prove we're not going to do that here but you can prove that you won't do that operation too often if you're resizing in the right way and so you just rebuild completely after a certain number of operations okay so that's hashing next week we're going to be talking about doing a faster sort