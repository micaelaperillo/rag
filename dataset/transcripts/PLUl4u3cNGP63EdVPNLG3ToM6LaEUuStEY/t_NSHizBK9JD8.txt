good morning everyone welcome to the 13th lecture of 606 just to recap from uh last time we've been talking about shortest single source shortest paths on weighted graphs for the past two lectures previously we were only talking about unweighted graphs and so far up until today we've talked about three ways to solve single source shortest paths on weighted graphs namely the first one use bfs if you can kind of transform your graph into a linear size graph with that's unweighted that corresponds to your weighted problem essentially replacing each weighted edge with of weights w with w single edges now that's only good for positive weight things and if the sum of your weights are small right but if the sum of your weights is linear in the combinatorial size of your graph v plus e then we can get a linear time algorithm to solve weighted shortest paths using breadth first search then we talked about how we could if we if we the the problem with weighted shortest paths is if our weights were negative and there could exist cycles then we could have negative weight cycles and that would be more difficult to handle because then you have vertices where you have an unbounded number of edges you might have to go through for a shortest path there might not be a finite length shortest path so but in the in the condition where we didn't have cycles in the graph of course we couldn't have negative weight ones so we are also able to do uh that in linear time by exploiting the fact that our vertices could be ordered in a topological order and that we could kind of push shortest path information from the furthest one back to the ones forward right by relaxing edges forward by maintaining this invariant that we had shortest paths as we were processing these things in topological order then last time we were talking about general graphs graphs that could contain cycles and this is our most general algorithm because if there are negative weight cycles bellman ford which we talked about last time can detect them and in particular for any vertex that had a finite weight shortest path path we could compute that a shortest path for it computed systems and for anyone that is reachable from a negative weight cycle not only could we mark it as minus infinity distance but we could also find a negative weight cycle essentially by duplicating our graph to make it a dag and being able to follow pointers back in this expanded dag that had multiple layers okay so that's what we've done up until now we've gotten linear for some types of graphs and we've gotten kind of quadratic v times e for general graphs ones that could contain negative cycles now how bad is this well if the graph is sparse right if if the number of edges in our graph is on the order of v then this is quadratic time and v right v squared but if this is if it's the graph is dense where we have quadratic limit like the complete graph where every edge is present then we have quadratically many edges in our graph in v and so this running time is v cubed v cube's not great in terms of its running time we would like something closer to linear right and so that's what we're going to do today if we have uh this restriction where we have non-negative weights we can't have negative weight cycles right and this is a restriction that comes up a lot for many gra graphs you might encounter right a lot of times you're uh you don't have both positive and negative weights right i don't have a negative distance to my house right in any metric we have non-negative weights right so the these things come up a lot and we can actually do quite a bit better since there are no negative weight cycles we can get almost linear right it's not going to be quite v plus e as you see up here on the slide we're going to get something very close it's v plus e but on the v term we have this logarithmic factor in v which remember for all intents and purposes this log of that thing in real life is not going to be bigger than like a factor of 30 or something like that right maybe 60 but it's a it's a small number and so this is actually pretty good performance it's almost linear that's what i'm saying almost linear here and that's what we're going to try to do today so how do we do this well i'm going to make two observations here first off our idea is going to be to generalize the notion of bfs right when we had bfs we split up our graph to solve unweighted short uh solve weighted shortest paths with bfs we could take our positive edge weights break them up into individual edges but if the the total weight of our edges was large then we'd have a problem because now we've expanded the size of our graph right this is the same issue that we had with something like radix sort where we don't want our algorithm to run in the size of the numbers in our input we want our algorithm to run in the number of numbers in our input right this is the difference between n and u right uh back when we were talking about data structures here if the size of our weights are large compared to v and e then we can't doing this expansion is going to be difficult but if we had say some graph this is my graph g and we had a source vertex s the idea here is going to still be to try to grow you know a frontier of increasing distance from my source and try to maintain all of the things within a certain distance from my source so that's the idea grow a sphere centered at my source repeatedly explore closer vertices before i get to further ones but how can i explore closer vertices if i don't know the distances beforehand right this is kind of seems like a circular logic right i'm going to use the distance to my things to compute the distances to my things that doesn't work so well right so how do we do this well the idea here is to gradually compute the distances compute the distances as we go so that we maintain this property now this property this idea wouldn't work necessarily in the context of negative edge weights right here we have this growing frontier this ball around my source and as i grow my thing these things are at further and further distance right because any edge from something back here as i'm growing my ball of certain distance these things are outside that distance right we're kind of using a key observation here here's my observation one uh if weights uh greater than or equal to zero then distances increase along shortest paths maybe maybe weakly monotonically increase right if there are zero weight edges but in general if i had a path going from s to to some v and it's going through some vertex u right i have some shortest path this is the shortest path from s to v and it goes through some point u some vertex u then this monotonicity more specifically means that the shortest path from s to u and the shortest path from s to v which is this whole thing right how do these relate to each other if this is along that path then this has to be at least as large as the sub-path right because all of these the weight of this path cannot be negative so that's the thing that dijkstra is going to exploit it essentially means that when i'm expanding this frontier of distance away from x it's possible if i had negative weight that this line if i had some very negative weight going from a vertex here to a vertex here this vertex could be within this boundary maybe maybe if this distance is x this guy could be within x right my my the the things that are within distance x of s might not be all contained there could be a path from here to this other vertex with distance x that doesn't have this property because i could decrease in distance along the path okay so that's the first observation second observation well let's see if we can piggyback on dag relaxation right i claim to you that we can solve single source shortest paths faster if we're given order of vertices in increasing distance beforehand distance from s right so here's the idea i'm not going to give you the distances to all these vertices instead i'm going to give you the order of the vertices in some increasing distance from s okay so basically i'm saying if i had some i don't know here's a graph uh let's see if i can remember okay okay and i'm gonna put some edges on here okay and i'm going to call these vertices 0 1 2 3 and 4. okay so here's a graph maybe i put some edge weights on here i'm going to say this one is this one is 2 this one is 3 this is this is 1 this is 0 and this is 0. so from vertex one two two uh that was a two for the labeling of that vertex that edge is zero weight okay so here's a weighted graph okay and i don't necessarily know i could use bellman ford to find shortest paths from this vertex zero right but the idea here is i'm not going to give you shortest paths i'm going to try to compute shortest paths but i'm going to give you some additional information i'm going to give you the order of their shortest path distance from the source and i can just i'm going to eyeball this and say i'm going to change this slightly to make it a little bit more interesting i'm going to say this is distance 4 okay all right so now what we have is the shortest path distance i'm just eyeballing this the shortest path distance to ah bad example all right so these are the weights shortest path distance to 3 is going to be 2 i'm going to say through there shortest path distance here is two also shortest path distance here is also two because i can go through both of these zeros and it's not a problem and then the shortest path distance here is two to here and a third to there okay so these are listed in increasing distance from my source okay i i had to compute those deltas to kind of convince you that this is the right ordering but this is a right ordering of these things now it's not the only right ordering right but it is a right order okay so i'm told i'm i'm arguing to you that i could solve single source shortest paths in linear time if i were to give you the vertices in increasing distance how could i do that well it because of this first observation i know that if these are increasing in distance any edge going backwards with respect to this ordering can't participate in shortest paths with one exception anyone know what that exception is no no edge can go backwards in this ordering based on this observation except under what condition yeah if the weight is zero yeah so if the weight is zero just just like this situation here then i could go backwards in the ordering seems problematic right the idea is i'm going to want to construct a dag so that i can run dag relaxation well if i have a component here that has zero weights i can kind of coalesce this thing down i can i can deal with this this this component separately right let's let's worry about that separately if we do we can kind of collapse this edge down into a single vertex and transform this graph so it does respect the ordering okay so i'm going to transform this graph into a new graph this is a graph contains vertex 2 and vertex 0 vertex 1 and 3 here and vertex 4. okay now we have uh and i'm only going to keep edges going forward in the ah i'm going to need to collapse this entire section right this entire section down into one vertex this doesn't quite work okay let's let's ignore uh zero weight edges for now let's assume these are all right there's something broken here if i have a cycle here yeah right now i don't have a cycle of zero weight right so what i could do is i could take this vertex and put it after both of these vertices and now i would or i could rearrange the order of these three vertices where there's a path of length zero and get a new ordering that still satisfies the property okay and that's always the case because uh paths uh can't increase path can't decrease in in weight i can rearrange the ordering of these things so that three comes first one comes second and two comes third of those three vertices okay yeah so for for every set of uh zero edges i can just flip the relationship if they have the same distance okay in my input i'm given vertices that have the same distance from the source and so if those are the same distance from the source and they're connected by zero eight edge it doesn't hurt me to flip their ordering so i'm gonna do that okay so let's convert that into a graph with a different ordering zero three now one two okay and i have this distance this edge this edge this edge this edge this edge what am i missing two to three and here i think i have all of those edges yeah okay now i have the property that every edge that could participate in the shortest path are going forward in the ordering right because all of these are zero weight so we flip those around so they're going correct with respect to the ordering and any edge going backwards that is positive weight certainly can't be used in any shortest path so i'm just going to get rid of them yeah what do i do if there's a zero weight cycle if there's a zero weight cycle i can just coalesce them all together down to a single vertex because if i reach one of them i can reach all of them okay exactly i'm computing a topological so the idea here is we're trying to construct a dag i can construct this dag in linear time and then i can run dag relaxation on this graph in linear time to get shortest paths so that's that's an approach if i knew the ordering of the vertices in increasing distance then i could use dag relaxation so we're going to use both of these observations that's how we're going to solve this uh single source shortest problem with non-negative weights using dijkstra so that's finally now where we're coming to sorry i missed a case here when i was writing up my notes and i'm trying i tried to fix it live and hopefully you guys followed me okay dijkstra's algorithm did i spell that right kind of okay what dix styx draw okay now dykstra was this dutch computer scientist okay this is him pretty famous he he wrote a monograph on why uh programming languages should uh start with zero indexing as opposed to one indexing so i like him but uh in particular he designed this very nice generalization of bfs for weighted graphs uh but maybe i didn't spell this right because when he writes his name he writes it with a y with a dash over it so in re in reality on a dutch typewriter you might have a a character that looks like this y with a new loud on top of it but on a modern on a on a english keyboard this looks pretty similar to an ij so in a lot of manuscripts we write it as d i j there's no j sound in dijkstra it's coming from this this y here okay so that's a interesting way to remember how to spell dijkstra but the basic idea behind dijkstra is the following idea relax edges from vertices in increasing distance from source okay this is the same kind of difficulty we had before when we were trying to you know generalize bfs so how do we know what the next vertex is with increasing distance to s well the second idea is find next vertex efficiently using a data structure okay and the data structure we're going to use is something i like to call a changeable priority cube okay so this is a little different than a normal priority queue that we had uh at the end of our data structures uh unit this changeable priority queue has three operations we're going to say it's a queue we can build it on an iterable set of items just stick x uh like n items in there we can delete min from the queue okay this is the same now as the priority queue it's this third operation that's going to be different decrease the key of an item that has id id okay so this is a little strange what the heck is this id all right with the changeable priority queue each of our items has two values instead of one value it has a key but it also on which the priority queue is deleting the min item with the minimum key but also each item has an id associated with it a unique integer okay so that when we perform this operation decrease key it can find some item in our data structure with a given id and if it's contained there it's going to change its key to some smaller value okay okay and don't worry about the edge cases here we're always going to make sure this k is going to be smaller than whatever that key was to begin with all right so this is a really a kind of a funky operation if i had a priority queue not a changeable priority queue but i had a priority queue and i wanted to implement a changeable priority queue how could i do it well a regular priority queue is already going to get me these two operations it's just this one i essentially need to find something by a id and then update its key okay so the idea how to implement this is going to be to use a regular priority queue i'm going to call it q prime and i'm going to cross link it with a dictionary d okay so this is just a regular priority queue on my items that has the key as defined above right but i'm going to cross-link it with a dictionary a dictionary that maps ids to their location in the priority queue we've done this many times in the data structures section we're trying to cross-link to data structures to make a query on a different type of key to find its place in another data structure okay so if we had a priority queue in a dictionary we could do this stuff pretty fast okay in particular i'm going to assume that our ids of our vertices are the integers between zero and v minus one and so for my dictionary i could get constant time looking up of that id by using what data structure we could get okay so we could get expected constant time if we used a hash table but if we knew that our vertex ids were just the numbers from 0 to v minus 1 we could get a rid of that expected time by using a direct access array great okay so that's what the assumption and so really the name of the game here is to choose a priority queue here that's going to make these things fast when we start to look at dijkstra okay so we're going to use this data structure to keep track of our distance estimates to all of the vertices away from s okay so this is dijkstra's algorithm okay set so same initialization step we're going to set our this is a estimate d not delta we're going to want the d's to be our deltas at the end of the algorithm that's what we're going to have to prove so we first set all of them to infinity and then set d of ss equal to zero right and here we're never going to update it again right because our shortest distances in a graph with non-negative edge weights certainly can't go below zero okay all right now we build our build our changeable priority queue queue uh with an item i'm gonna say an item is uh x is represented by a tuple of its id and then it's key just for brevity here okay with an item v d of sv so i'm going to be storing in my changeable priority queue the vertex label and its shortest path distance estimate d right and that's going to be the key the minimum that i'm trying to going to be querying on for each [Music] v and v okay so i'm going to build that thing it's going to then have all of my vertices in my graph then while my changeable priority queue still has items not empty i'm going to delete some u d s u so some item such that its distance is minimized right from q that has minimum distance okay so i'm going to remove i'm going to look at all the things in my priority queue at the start it's just going to be s right because everything has shortest path distance estimate infinite except for s and so that's clearly the smallest okay so i'm going to remove that from my queue and then i'm going to process it okay how am i going to process it it's the exact same kind of thing as dag relaxation i'm going to relax all its outgoing edges right so just for completeness for v in the outgoing adjacencies of u i'm going to relax oh sorry we have to check whether whether we can relax it right basically if d the shortest path distance estimate to v right is greater than going to u first and then crossing that edge right if going through that is better this this is violating our triangle inequality and so we relax edge u v and by that we mean sets this thing to be equal to that thing right that's what we meant by relax and then we have one other thing to do we've changed these distance estimates but our q doesn't know that we change these things right we added these items in here right but it doesn't know that my distances has changed right so we have to tell the queue to remember we uh to change its key value associated with the item v right so decrease what is it decrease key vertex v in q to the new s v the one that i just decreased here right and i know that i decreased it because i set it to a smaller value that makes sense all right so that's dijkstra let's run it on an example okay so here's an example i have a directed graph it does contain cycles in particular here are some cycles i think those are the the main ones okay there are definitely cycles in this graph and but as you see all of the weights are non-negative in particular they're positive actually it's going to be just helpful in in writing out this example so let's run dijkstra on this graph okay first we initialize and we set the shortest path distance i'm going to label it in white here to all of the things and i'm going to as i update it i'm just going to cross them out and write a new number okay so that's what it is at the start right that's initialization that's after step one and then i stick things into my queue what's in my queue here's my q right it's everything right it's vertices s a b c d okay i got five items in my queue really it's the item pair with its shortest distance estimate i'm just not going to rewrite that here okay so the idea here is what's the the while loop okay q is not empty great we're gonna delete the one with the smallest distance estimate which is s right yeah so i remove that and then i relax edges out of s right so i relax edge here to a that's better than the distance estimate 10 is better than the distance estimate infinite so i'm going to change this to 10. and then here's another outgoing edge 3 is better than infinite so i'm going to change its delta to 3. okay so now i go back in here and i change the distance estimates associated with my q okay now next step of the algorithm s is done right i've processed everything distance 0 away but i'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now so which one is it a b or c or d yeah it's three c right three is smaller than 10. so q is going to magically delete c for me tell me what that is and now i'm going to process that right i've now changed my boundary to this okay and now i relax edges out of c so here's an edge out of c that's a 4 a 4 plus the 3 is smaller than 10 so i update it 3 plus 8 is 11. that's smaller than infinite so i update it i relax 3 plus 2 is smaller than infinite so i relax that as well okay now of the things still left in my queue i'm actually going to remove it from my queue instead of crossing it out maybe that's better of the vertices still left in my queue which has smallest distance yeah d d has five seven or eleven five is the smallest so i remove d from my q and i relax edges from it and now my boundary looks something like this okay i relax edges out of it five plus five that's ten ten is smaller than eleven so that's a ten and that's the only outgoing edge from d so i'm done okay and then the last seven is smaller than 10. i relax edges out of a right a to b seven plus two is smaller than ten and now i'm done so what i did every time i removed s or i removed a vertex i set its shortest path distance to the small the the last value i assigned to it so this was then three and then a was seven b was nine and then d was five okay so that's dijkstra in action it seems like these are the shortest path distances but how do we prove that did it do the right thing well let's find out so that's what we're going to spend some time on right now is talking about the correctness of dijkstra's algorithm okay correctness follows from kind of two main observations okay so the the claim here that we're trying to prove is that d of s equals the delta s so the estimates equal the shortest path distances at the end of dijkstra for all v and v at ant all right and this is going to follow from two observations so the proof here first if ever relaxation sets d of s of v it sets the estimate equal to the shortest path distance if it ever does that i argue to you that still true at end okay that's not a very strong statement right this is saying if i ever set the the distance estimate to the true distance i'm never going to set it to a different value later on and why is that well relaxation only ever decreases the distance right relaxation only decreases dsv but we proved in lecture 11 so two lectures ago that relaxation is safe and what is safe mean safe means that relaxation that these relaxation will only ever change these distance estimates to be either infinite right it was never there was never a path to my my vertex or it was the length of some path to v length of some path okay so what does that mean it only decreases but it's always the length of some path to v right so if this is the length of the shortest path to v i could never set it to a smaller length right because there are no paths with shorter distance that's the kind of little point okay so with this observation i i'm gonna argue this final claim it suffices to show that my estimate equals the shortest distance when v is removed from the queue okay and since i remove every vertex from the queue in this while loop i will have eventually set all of the distance estimates to the real distance and will be golden happy days all right so we'll be done if we can prove that statement all right so we're gonna prove this by induction obviously production on first k vertices removed from the queue all right so the q we're we're popping vertices from this q in some order so i'm going to just argue that this claim is true for the first k right clearly that's true for k equals 1 base case k equals 1 right what is k equals 1 that means the first vertex that i pop has this property which is definitely true because we set the shortest path distance to s to be zero that's all good okay now we have our inductive step okay assume it's true true for k prime sorry k less than k prime okay and let's let v prime be k prime vertex pot okay v prime okay and now let's look at some shortest path from s to v prime so we got the shortest path from s to v prime it exists v prime is accessible let's say we pruned our graph to be only the things accessible from s so that yeah there exists a shortest path to v prime okay and now let's think about these vertices some of them were removed from the queue and some of them were not right s was definitely removed from the queue right but some of these other vertices might not be right i want to be able to induct on this path in particular the vertex before me so that i can say that when i removed it and i relax the edge to v prime then we're all golden right but that might not be the case there could be a vertex the vertex preceding me in the graph in this shortest path it was not popped from q i need to argue that it was or some other thing okay so let's consider the first vertex in this path from s to v i'm going to call it y i think a vertex y that is not in q right after i pop v prime this is the first or before i pop v prime y is not in the queue now these might be the same vertex right if all of the preceding ones on this path are were in the queue but in particular we're going to look at this guy okay and say its predecessor's x in the path well what do i know i know that x is in the queue right everything here was was popped from the queue not in right which means that by induction the shortest path distance was set here correctly so that the the distance estimate at y can't be bigger than the shortest path to x plus w x y okay but this is on the shortest path to y right because sub paths of shortest paths are shortest paths so this has to equal d s y right the distance to y so actually y is all good here right and so if v prime were y we'd be done right that's the same argument as dag relaxation but we need to prove something about v prime well because we have non-negative weights the distance to v prime has to be at least as big as this distance right because it's a sub-path right so this has to be less than or equal to the true distance to the prime right because of negative uh non-negative weights right because the weights are non-negative but because relaxation is safe we know that our distance estimate for v prime has to be at least the shortest path distance right right this is because it's safe this is weights are uh greater than or equal to zero right the last step here is that because we're popping the minimum from our priority queue right the thing with the smallest shortest path distance this has to be less than or equal to the shortest path distance estimate to y right because this is the smallest among all such vertices in my queue but these are the same value so everything between here is the same value in particular the estimate here is equal to my true shortest path distance which is exactly what we're trying to prove okay so that's why dijkstra is correct and spend the last five minutes on the running time of dykstra well we set this up so that we did everything in terms of this these q operations right so we have these q operations we have three of them i'm going to say if i have a build operation let's say it takes b time delete min i'm going to say it takes m time and this decreased key i'm going to say it takes d time okay so what's the running time of dijkstra if i take a look at that algorithm over there well i guess let's switch these back up again okay so what does this do we build once right then we delete the minimum from the queue how many times v times right we remove every vertex from our q then for every possible edge we may need to relax and decrease the key in our queue once for every outgoing edge okay so the running time is b plus v times m plus e times d right okay so how could we implement this priority queue well if we use the stupidest priority in the world here's here's a list of different implementations we could have for our priority queues and when i say priority queue i mean this priority queue we're already implementing the changeable priority queue by linking it with a dictionary that's efficient okay if i just use an array i can find the min in linear time sure and i don't have to update that array in any way i mean i can just keep the distances in my direct access array i don't have to store a separate data structure i just store the distances in my direct access array d and so i can find it in constant time and i can update the values stored there and then whenever i want the minimum i can just loop through the whole thing right so that gives me a really fast decreased key but slow delete min but if we take a look at the running time bound here we get something if we replace n with v we get a quadratic time algorithm in the number of vertices which for a dense graph this is in linear time that's actually pretty good dense meaning that i have at least a quadratic number of vertices so that's actually really good and it's the stupidest possible data structure we could use for this priority queue now we can do a little better actually for not dense i mean for sparse graphs where the number of edges is at most v then this is pretty bad it's quadratic right we want to do something a little better now if we're sparse a binary heap can delete min in logarithmic time but it can actually if i know where i am in the heap and i decrease the key and i'm in a min heap right i can just swap with my parent upwards in the tree in log n time and free rebalance the refix the binary heap property and so i can do that in logarithmic time okay and if i do that and i put it into this formula i actually get n or v plus v times log v plus e times log v right and so that's going to give me e log v if i'm assuming that i'm first you know pruning out all of the things not connected to me then e asymptotically upper bounds v and i get this e log v running time which is pretty good right that's just an extra log factor on linear now there's a even better well better is is is hard to say really there's a different data structure that achieves kind of both bounds for sparse and dense graphs and everything in between it gives us an e plus v log v running time bound this data structure is called the fibonacci heap we're not going to talk about it in 6.06 they talk about it you can look at chapter 19 in clrs or you can look at i think they talk about it in 6854 if you're interested in learning about fibonacci heaps but these are almost nev i mean they get good theoretical uh bounds so what you want to say is whenever we give you a theory problem where you might want to use dijkstra you want to use this theoretical running time bound for your problem a plus v log v but if you happen to know that your graph is sparse or dense just using an array or a heap is going to get you just as good of a running time very close to linear right and so in practice most people when they're implementing a graph search algorithm they know if their graph is sparse or dense and so they never bother implementing a fibonacci heap which is a little complicated okay so they are usually either in one of these first two cases where v squared is linear because when your graph is dense or you know we're very close to linear e times log v which is v log v if your graph is sparse okay so that's uh the running time of dykstra okay so so far we've gotten all of these nice bounds right some special cases where we're i mean special cases where we're linear dijkstra where we're close to linear and bellman ford you know if we throw our hands up in the air there might be negative cycles in our graph we got to spend that quadratic running time bound now there are faster algorithms but this is the fastest we're going to teach you in this class now in the next lecture we're going to be talking about all pairs shortest paths and we'll pick it up next time