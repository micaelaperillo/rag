hi everyone welcome to the uh 11th lecture of 6006 our first lecture on weighted shortest paths until uh now we've only been talking about graphs that uh where we measure distance in terms of the number of edges in a path right today we're going to generalize that notion but i just want to go over what we've talked about in the last two lectures uh in the last two lectures we've talked about two algorithms breadth first search and depth first search to solve a range of problems here's some of the problems that we've been solving single source shortest paths where distances are measured in number of edges in a path and we use bfs to solve this problem starting from a single source usually a vertex s that we we call uh and and we solved that in linear time right and we solved that in order v plus e that's what we called linear time for a graph for the special case of single source reachability here we had to return a shortest path distance for every vertex and there was at most e things reachable from a vertex so this is uh the bound we got but in the special case for single source reachability when our output only has to list the vertices that are reachable from me the the number of things reachable in a uh basically a spanning tree of the connected component of my source can almost be of order e and so for all the little singleton vertices in my graph i don't really care right so i can get this in order e but that's kind of a little optimization the next thing we did was we talked about connected components and we didn't just reduce to using a search algorithm like a single source reachability algorithm like bfs or dfs we put a for loop around that to explore the entire graph by basically saying if i've explored one connected component then i can look at any other vertex i haven't seen and explore the next one right and so that actually with some a little analysis also got linear time because i'm at most traversing any component of my graph once that's kind of the the idea and then and we can use that using bfs or dfs really because we're just trying to get a thing that searches an entire connected component and then this topological sort we did at the end of the last lecture we used full dfs to give an ordering of the vertices in a dag i maybe i'll specify clearly that this is only for a dag right where we uh have an ordering of the vertices so all the edges go forward in that order for example okay and that we also did in linear time all right in this lecture and in actually the next four lectures what we're going to do is instead of measuring distance in terms of the number of edges in a path so previously distance equaled number of edges we're going to generalize that notion so instead of counting an edge we're going to count an integer associated with that edge it's going to be called a weight all right so here's an example of a weighted graph g and i've labeled in red weights for each of these edges there's a directed graph on eight vertices and i've got a integer associated with each edge you'll notice some of them are positive some of them are negative it's okay to be zero as well it's just any integer edge weight here so generally we're going to be along with our graph g we're going to be given a weight function that maps uh the edges of g to we're gonna say integers okay in this class anyway uh in other contexts in mathematics you might have this be real numbers but in this class we're going to deal with integers so each edge if you have an edge we're going to say this is the edge weight the weight of this edge e from e we we might sometimes if if this edge e is u v right we might sometimes say the weight from u to v since we have a simple graph that's unambiguous right all right so but this is just talking about our notation so in general for example the weight from vertex b to f in this graph is what can someone tell me minus 4 right it's right here and i'll be consistent with my coloring because i've got colored chalk today -4 happiness all right so why do we care about adding weights to our graph well this comes up a lot in many applications for example you know distances in a road network right if i have a road from here uh so so from mass ave uh front of mit to central square we might think of that as one road maybe maybe you've got uh each road is a connection between two intersections in my road network but an edge it takes longer to go from say vassar street to amherst that takes a shorter amount of time than it does to go from memorial drive across the river to beacon street right so we might want to associate a larger distance or a weight associated with that edge right latency in a in a in a network for example maybe strength of relationships in a social network and you could imagine that it's possible maybe you're frenemies with someone right like you you don't like them and so maybe you have a negative weight associated with an edge in a social network i'm not sure maybe not but there are lots of applications where you might want weights on your edges so that that comes to the next question of how do i represent how do i give the user or the algorithm these weights in my graph right we had a represent representation for a graph right our common way to represent a graph was store a set data structure on the vertices mapping to the adjacencies of each vertex which we stored in what we called an adjacency list which really could be any data structure right uh commonly it's just a an array of the adjacencies but you could also have that be a set data structure where you can query in constant time uh what if a particular adjacency exists in that graph so a common way there are two kind of common ways to store these weights one is just with every adjacency i'm going to store its weight maybe just in a tuple some you know with each adjacency also store weight of the edge that it corresponds to right just in any way right uh a second way instead of trying to modify our graph structure that we gave you before let's just have a dictionary of all the edges mapping to their weights right and we already know how to do that just so any set data structure any separate set data structure mapping edges to their i guess weights bad notation but you get the idea okay and it doesn't really matter how we're doing this the the assumption that we're going to rely on here is that we given an edge right given this vertex pair i can query what the weight of that edge is in constant time right and so if i'm going to do that i can either store it with a maybe a hash table of hash tables right a hash table mapping the set of vertices to their adjacencies and then each adjacency list stores its adjacencies in a hash table and that way in constant time i can check what the weight is there or here i'm just i could even have just a single hash table mapping the pair the the edge the tuple constant size uh to its weight right so either way is fine uh we're just going to assume that we can query an edge in constant time the weight of an edge in constant time okay so this is a that graph example it's a little busy here i'm probably going to erase that in just a second but we're going to move on to what giving these edges weights implies for uh kind of these problems that we've defined in terms of unweighted graphs right in particular we're going to be concentrating on single source shortest paths again at least for the next three lectures we'll generalize that even still uh in the in the next lecture i mean in the fourth uh in three lectures from now but what we had here was that the distance before in an unweighted graph was the number of edges in the path here we're going to generalize that notion kind of obviously two weighted paths right and the weight of a path i'm going to call it pi so some weight of path pi right is just going to be the sum of the weights in the edges in the path right so edge in the path i'm going to sum their weights right so that's all this the weight of a path means it's just i'm going to sum all the weights in a path so if i took a look at the maybe there's a particular path here the path from a to b to f to g right is going to be minus 5 minus 4 2 that's going to be minus 9 plus 2 is -7 right okay so just as an example so uh then then what is the shortest path then well kind of obviously among all paths between two vertices it's going to be one with the minimum weight right yeah question can i use the same edge more than once can i use the same edge more than once right now you're asking about the distinction uh in an art class which we have between paths and simple paths right so here a weighted path doesn't really care if we visit an edge more than once right so if an edge appears more than once in pi we have to count that more than once in the edge weight in the weight of the path okay great question um but what we're going to see later on is shortest paths cannot repeat an edge more than once uh in in certain contexts right so so we're going to get to the the problem there a little later in this lecture and we're going to solve that in tomorrow's lecture but if you have we're getting a little ahead of ourselves but when we have negative weights in a graph it's possible that things go wrong we're going to get there in about five lines okay great so uh the the shortest path and in this case i'm going to clarify that this is the weighted shortest path right is a minimum mom sure uh is a minimum weight path you know from s to t right nothing too interesting here but there's actually some subtleties we have to deal with here right uh we're going to call just like we did with uh uh breadth first search when we talked about shortest paths we're going to define the uh uh an expression for what the distance or the shortest path weight is between two vertices and that's going to i'm going to represent that by a delta right a delta from a vertex s to t is going to be let's i'm going to do the wrong thing first the minimum over the weight of all paths for all paths pi from s to t okay so there's a couple things that go wrong here first thing that goes wrong is the same thing that went wrong with breadth first search right anyone remember what could go wrong with breadth first search for this delta definition maybe there's no path right right so if the in except if no path just by convention we're setting uh delta s t to equal infinity but there's one additional problem with weighted shortest paths and it's a little subtle it's possible that a finite shortest uh finite length shortest path doesn't exist and what do i mean by that it means uh i could keep going through edges in my graph and continually getting a shorter path right so if i can if the the shortest the minimum weight of a path from s to t actually goes through an infinite number of edges then this isn't really well defined right so i'm going to change this minimum here to in in mathematics we just to be specific we call it an infiema right so if in the case where there where the uh the weight of a shortest path can approach arbitrarily small right then we'll call this thing minus infinity okay so when does that occur when does that occur when could we have our shortest path go through lots and lots of vertices well let's actually take a look at this example here can someone tell me what the shortest path is from a to actually any vertex in this graph ah okay so well we could look at this this path i have to be let's just take a look at b right i have a path going from a to b that is minus five okay that's pretty good that's pretty small right and it seems that if i go around this graph through another way it might be bigger right so i go seven plus three plus eight that's 15 minus one that's 14 that's that's much bigger than my minus five so it seems like minus five should be good right anyone have a problem with this path or the problem with this being the shortest path and what your colleague just informed me was that there's something interesting happening here in this graph in particular we have a cycle from b to f to g to c that has negative total weight right back back to b right this has minus four plus two plus one minus one right so that total cycle has a cycle weight of minus two right this is negative weight cycle so uh if i wanted to get to b i could go there via this minus five weight edge but every time i circled around this cycle i incur -2 to my pathway right so i just keep going around this cycle over and over and over and over and over and over again and i don't have any finite length minimum weight path right in in such cases we just say that delta is minus infinity right so uh the the problem here is that uh we could have negative weight cycles deserves a capital letter negative weight cycles it's a problem in particular if there exists a path from s to some vertex v that goes through a vertex on a negative weight cycle then i can take that path to that vertex circle around the negative weight cycle and then proceed to v and i can take that cycle as many times as i want then this delta sv we're going to set to minus infinity okay and in such cases in our shortest paths algorithm we don't really care about what the shortest path is right we're not even going to deal with parent pointers here right because there is no finite length shortest path so i'm just going to kind of throw my hands in the air and say you know what i can't return you a shortest path but i might want to return to you a negative weight cycle right if you told me that this thing has bad weight right maybe i want you to tell me what a path is that goes through a negative weight cycle to get back to s right so that's what we're going to talk about next lecture this lecture we are not going to talk about that we are going to talk about weighted shortest paths though that's what uh the remainder of this uh this unit on graphs is really about is weighted shortest paths okay so in weighted shortest paths we actually know an algorithm already to solve a subset of weighted shortest paths namely bfs right now you're like wait jason bfs doesn't solve weighted shortest paths we didn't even know about weighted graphs then right how does that solve weighted shortest paths well there's a couple cases where we might be able to reduce to solving shortest paths using bfs can anyone think of such a scenario uh so let's say i mean kind of what we did before was we counted the number of edges right so if we gave a weight of one to every edge in my graph then just that graph that weighted graph corresponds to an unweighted graph using the other distance metric right so in that case bfs just solves our problem and in fact we can generalize further what if all of our weights were positive but the same value right if it was all positive and the same value then we could just to you know divide by that value right now we have a weighted an unweighted uh graph which we can run bfs and then multiply shortest path distances by that value later on and in fact there's one further generalization we could make which is a little bit of a tricky graph transformation problem but we can also get this linear time algorithm for weighted single source shortest paths in contexts where the weights aren't that large okay so if i have positive edge weights right if i have a positive edge weight let's say using using my weight color here that's like weight of four right that's that's kind of problematic because i don't know how to simulate that using an unweighted graph or do i anyone have an idea of how i could simulate an edge of weight four with an unweighted graph yeah i have four edges of weight one yeah i can just put four edges of weight one in parallel here sorry in series the opposite of parallel okay i can just convert this here into one two three four edges and if i do that for every edge in my graph and we have positive edge weights then that that transformation can hold now that's not necessarily a good transformation to make y yeah the weights might be very big compared to the number of vertices and edges in my graph however if the sum of all weights in my graph is asymptotically less than v plus e right we can get a linear time algorithm again by reducing to bfs okay so that's great today uh but but in general that that gives us a linear time algorithm in this in these very special cases and in general it's an open problem we don't know uh whether we can solve the single source single source shortest paths uh problem in the weighted context for general graphs in linear time we don't know how to do it right but what we do know are some algorithms that do pretty well and that's what we use all the time but in the sp one more special case we're going to go over today is when we have this really nice structure where we have a dag a directed acyclic graph like we were talking about in the last lecture we can actually for any set of edge weights right remember with bfs we kind of we needed to restrict our edge weights to be positive and maybe bounded to get this good running time uh for any set of edge weights if our graph structure is a dag really has nothing to do with the weights if the graph structure is a dag then we can actually solve this single short shortest paths problem in linear time which is pretty awesome right now for general graphs we're going to show you in the next lecture how to for any graph even with cycles even with negative weight cycles we're going to show you how to solve this single source shortest paths problem in something like a quadratic running time bound now this isn't the best known but it's a really practical algorithm and people use it all the time okay and and it we're going to uh show bellman ford in the context of the dag algorithm we're going to solve today okay so that's the very general case in terms of restrictions on our graph but in reality most problems that that come up in applications occur with graphs that have positive edge weights okay you can think of a road network you've got or non-negative ones anyway right that you you're you're traveling along right uh and it's not ever useful to kind of go back to where you came from because you want to make progress to where you're going okay so in the context where you don't have negative weights you don't have this problem where you have negative weight cycles we can actually do a lot better by exploiting that property uh and we get a bound that's a little bit that looks a little bit more like n log n right like it's it's pretty close to linear you're losing a log factor on the number of vertices okay but it's pretty good this is called dijkstra and we'll get to that in two lectures okay so that's kind of the roadmap of what we're going to do for at least the next three lectures uh but before we go on to showing you how to solve single source shortest paths in a dag using this algorithm called that i'm calling dag relaxation here uh i'm going to go back to a thing that we talked about in breadth first search where in breadth first search when we solve single source shortest paths we output two things right we output single source shortest paths these deltas right for the other definition of distance you know the weights i mean not the weights the uh the distances the shortest distances uh but we also return parent pointers right we return parent pointers back along paths to the source along shortest paths right we called this the shortest path tree so i'm going to revisit this topic of shortest paths tree shortest path trees shortest path trees okay and in particular it's kind of going to be annoying to talk about both of these quantities right distances and parent pointers as we go through all three of these algorithms right it's basically going to be bookkeeping to distances are actually sufficient for us to reconstruct parent pointers if we need them later okay so what i'm going to show for you prove to you now is that if i give you the shortest path distances for the subset of the the graph reachable from s that doesn't go through negative weight cycles right if i'm giving you those distances i can reconstruct parent pointers along shortest paths in linear time for any graph i might give you if i give you those shortest path distances okay so that's what i'm going to try to show to you now uh so here's the uh algorithm for weighted uh there's the caveat here i'm going to write down for weighted shortest paths only need parent pointers for v with a finite shortest path distance okay only finite shortest path distance right we don't care about the infinite ones or the minus infinite ones just the finite ones okay so here's the algorithm i'm going to initialize all pv to equal uh sorry oh getting out of myself i'm writing down dag all right uh init all and knit my parent pointer data structure right to be empty okay right first i'm not going to store any parent pointers but at the beginning i'm going to set the parent pointer of the source to be none right so that's what we kind of did in breadth first search as well right now what i've given you is i'm trying to show that given all the shortest path distances i can construct these parent pointers correctly so what i'm going to do is for each vertex u in my graph where my delta s of u is finite what am i going to do i'm going to say well let's take a look at all my outgoing neighbors okay this is kind of what we do in every graph algorithm for each v in the adjacency the outgoing adjacencies of u if there's no parent pointer assigned to this v right there's the potential that i you i you this this u this vertex u is the parent of v it's possible right it's an in it's some incoming edge to v okay when will it be an incoming edge to v if i haven't said if uh v not in p right i haven't assigned it a parent pointer and so this means it could be my parent when is it my parent along the shortest path sure sum the distance along the edge yeah so we have some edge from u to v it has some weight right if i already know the shortest path distance to u and i know the shortest path distance to v right if the shortest path distance from s to u let's let's draw a picture here we've got s we've got some path here to u and we've got an edge from u to v okay if this shortest path distance plus this edge weight is equal to the shortest path distance from s to v then it better i mean there may be more than one shortest path but this is certainly a shortest path so we can assign a parent pointer back to you okay right so let's write that condition down if the shortest path distance from s to v equals the shortest path distance from s to u and then traversing the edge from u to v then then exists shortest path that uses edge uv right in particularly in particular this one right so set the parent of you a v to you okay so this is the algorithm i'm not going to prove to you that this is correct but it kind of intuitively makes sense right if i have these shortest path distances right you can prove by induction that not only does this parent pointer point to the right place along some shortest path here right but it also does so in linear time because i'm looping over all the vertices and looping over its outgoing adjacencies once same analysis as we had for both bfs and dfs essentially right and then since we can do this since we can con compute parent pointers from these distances we're going to kind of ignore computing these parent pointers from now on right we're just going to concentrate on computing the distances because you know we're gonna have to take linear time anyway right at least and all these other things take more time so we can compute the distances in more time and then compute the parents after okay so that's what we're going to do okay so now with all that build up let's show an algorithm right how do we compute shortest single source shortest paths in a dag in linear time okay well a debt i mean this is actually a super useful convenient thing in algorithms in general dags are just nice things right they're kind of ordered in a way right there's this topological sore order that we were talking about before this is going to play a key role right there's a really nice structure to dags not having cycles not having to deal with this negative weight cycle problem right you can only kind of go in one direction along this graph right it's very nice structure to exploit and so we're going to exploit it and here's the idea dag relaxation what it's going to do is it's going to start out with some estimates of what these distances should be right okay so maintain maintain distance estimates and now i'm going to try to be careful here about how i draw my d's okay this is a d this is a delta okay this is shortest paths this is a distance estimate okay so that's what i'm going to be using for the the rest of this time so we're going to initialize maintain these uh estimates of distance d which are gonna start at uh initially infinite right okay i don't know what they are right i don't know what the shortest paths are but they better be less than infinite or else i don't care right so i'm going to that's the kind of worst case scenario right it can't be worse than this for every vertex and we're going to maintain the property that estimates upper bound that should probably be two words upper bound uh delta sv uh we're going to maintain that the upward bound this thing and gradually lower until they are equal okay so this is the idea we start from an overestimate an upper bound on the distance estimate and then we're repeatedly going to lower that value as we gain more information about the graph maintaining that we're always upper bounding the distance and we're going to keep doing it keep doing it keep doing it until as we will try to prove to you these estimates reach actually reach down all the way to our shortest path distances okay so when do we lower these things when do we lower these things we're going to lower these distance estimates whenever the distance at estimates violate what we're going to call the triangle inequality okay what is the triangle inequality triangle inequality is actually a pretty intuitive notion okay it's basically saying if i have three points that's thus triangle right uh maybe bigger so i can write a letter in them okay it's basically saying that if i have a vertex u a vertex v vertex x for example right the shortest path distance right the shortest path distance delta of uv that's the shortest path distance from u to v it can't be bigger than a shortest path from u to v that also goes through x right right i'm i'm of of my paths i'm now restricting the paths that i have to the ones that go through x right the shortest path distance from u to v can't be bigger than restricting paths that go through x and taking that shortest distance right getting the shortest path distance from here and adding it to the shortest path distance here right delta u x delta x v right i mean that that's just a statement of i i'm restricting to a subset of the paths i can't increase my i can't decrease my minimum distance right so this is the statement of the triangle inequality right that the shortest path distance from u to v is can't be uh bigger than the shortest path distance from u to x plus the shortest path distance from x to v for any x in my graph that's not u and v okay so that's the triangle inequality pretty intuitive notion right okay why is this useful okay well if i find if i find an edge in my graph if there's an edge u v in my graph such that this condition is violated for the estimates that i have right it obviously can't be violated on my shortest path distances but if it violates it on the estimates u v is bigger than u x uh sorry u how am i going to do this i want this to be s i'm calculating shortest path distances from s and shortest test distances from s to some incoming vertex u plus the edge weight from u to v okay all right so what is this doing i have some edge u v in my graph okay basically what i've said is that i have some distance estimate to you but going through making a path to v by going through u and then the edge from u to v is better than my current estimate my shortest path estimate to v that's bad right that's violating the triangle inequality these cannot be the right weights right these cannot be the right distances so how we're going to do that is lower this is what we said repeatedly lower these distance estimates i'm going to lower this guy down to equal this thing in a sense this constraint was violated but now we're relaxing that constraint so that this is no longer violated right so that's i'm relaxes a little weird word here we're using it for historical reasons but that's what we mean by when we say relax this thing is a violated constraint it's got some pressure to be resolved right and so what we're doing is to resolve it we're just setting this guy equal to this so it at least resolves locally that constraint now it may violate the triangle inequality otherwise other places now that we've done this change but at least this constraint is now relaxed and satisfied okay so uh relax edge by lowering d of sv to this thing okay that's what we're going to mean by relaxing an edge okay and relaxing an edge is what i'll call safe it's safe to do okay what do i mean by relaxation is safe it means that as i am computing these shortest path distances right i'm going to maintain this property that each one of these estimates sorry these estimates here has the property that it's either infinite or it is the weight of some path to v okay so that's that's the thing that relaxation is safe so each uh distance estimate sv is weight of some path from s to v or infinite okay and this is a pretty easy thing to prove right if i had the invariant that these were all weights of shortest paths let's try to relax an edge right and we need to show that this property is maintained relax edge uv okay now if i relax edge uv what do i do i set this thing or uh sorry i set this thing my shortest path distance to v to be this thing plus this thing right this is an a weight of an edge from u to v now by my assumption that we're maintaining that this is a the weight of some path in my graph right if this thing is bigger i'm setting it to the weight of some path in my graph to u plus an edge from u to v and so this checks out so assign d of s to v to weight of some path okay i i'm not going to write down all the argument that i just said here but basically since this distance estimate was by supposition before the weight of some path to v to to u right then this is again the weight of some path to v okay great so now we're ready to actually go through this algorithm so dag relaxation from over there initializes all of our distance estimates to equal infinity just like we did in bfs then set my distance estimate to myself to be zero right now it's possible that this might be minus infinity or negative at some point but right now i'm just setting it to zero okay and either way zero is going to upper bound the distance to s right so in particular at initialization anything not reachable from s is set correctly and s itself is set as an upper bound to the shortest path distance okay now we're going to process each vertex you in a topological sort order so remember our input to dag relaxation is a deck so this thing has a topological sort order we're going to process these vertices in that order okay you can imagine we're starting at the top and all my vertices are all my edges are pointed away from me and i'm just processing each vertex down this topological sort line okay and then for each of these vertices what am i going to do i'm going to look at all the outgoing neighbors and if the triangle inequality is violated i'm going to relax that edge it's the algorithm is as simple as that for each outgoing neighbor of v sorry of u i always get u and v mixed up here okay if my shortest path estimate to v violates the triangle inequality for an edge for an incoming edge then i'm going to set relax uv ie set d s b equal to d s u plus w u v okay so that's the algorithm so if i were to take a look at this uh example graph over here maybe a is my start vertex i initialize it to uh this is not a dag thank you let's make it a dag i claim to now this is a deck okay in particular a topological sort order is when there's a path through all the vertices then there's a unique topological sort order a b e f g h d c this is a topological order you can check all the vertices the edges so i'm going to start with a uh by setting the uh well actually let's use e let's do shortest paths from e why not okay shortest paths for me vertex a actually comes before e in the topological order right so it has no i mean it's shortest path distance when i initialize i'm going to initialize this to zero and initialize this to infinite infinite infinite infinite all these things to infinite these are my estimates these are not quite the shortest paths yet distances but when i get here clearly i can't be distance to me being infinite can never violate the triangle inequality with something infinite or finite doesn't matter right so i don't do anything to a anything before my source vertex in the topological order can't be visited right because it's b4 in the topological order that's that's the kind of the point there's no path from my source vertex to anything before it in the topological order okay so same with b b is before it in the topological order okay now i'm at e and it's possible we are violating triangle inequality in particular here right i think the shortest path distance to f is infinite but actually if i go to e through this edge with a weight 3 i know that this is violating triangle inequality so actually this thing is wrong and i can set it equal to 3. okay now that might not be the shortest path distance but right now it's a better estimate right so we've said it okay now i'm moving on i'm done with this guy i move to the next vertex in my topological order and again i relax edges out of f okay so here looking at eight three plus eight is better than infinite so we'll say that that's eleven and three plus two is better than infinite so that's five okay now i keep going in the topological order g is the next five plus one is 6. okay so we found a better estimate here right so this 11 is not as good 6 is better so we replace it here we haven't visited before it's still infinite so 5 plus minus two is three okay this is the next in the topological order three plus nine is bigger than six so that's not a shorter path three plus four is certainly smaller than infinite so set that equal to seven then seven plus five is also bigger than six and actually if you can you can confirm that these are all the shortest path distances from e okay so this algorithm seems to work does it actually work let's take a look the claim to you [Applause] is that at the end of relaxation this algorithm we've set claim at end all the estimates equal shortest path distances okay the basic idea here is that if i take uh a the cave vertex in the topological order assuming that these distances are all equal for the ones before me in the topological order i can prove by induction right we can consider a shortest path from s to v right the kth vertex and look at the vertex preceding me along the shortest path right that that vertex better be uh before me in the topological order or we're not a dag right and we've already set it short as path distance to be equal to the correct thing by induction so then when we processed u right s to u to v when we processed u in dag relaxation here processed the vertex and looked at all its outgoing adjacencies we would have relaxed this edge to be no greater than that shortest path distance so this is correct you can also think of it as the dag relaxation algorithm for each vertex looks all at its incoming neighbors assuming that their shortest path distances are computed correctly already right any shortest path distance to me needs to be composed of a shortest path distance to one of my incoming neighbors through an edge to me so i can just check all of them that's what dag relaxation kind of does and again we're looping over every vertex and looking at its adjacencies doing constant work this again takes linear time okay so that's shortest paths in a dag next time we'll look at for general graphs how we can use kind of the same technique in an algorithm we call bellman ford okay that's it for today