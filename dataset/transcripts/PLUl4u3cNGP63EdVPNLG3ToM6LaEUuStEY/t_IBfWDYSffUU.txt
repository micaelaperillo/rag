we just started a new unit on graph theory which is going to be sort of our focus for the next couple lectures uh in 6.06 uh and so i thought we'd give a little bit of review at the beginning of lecture because as usual i muddled together a lot of notions in our previous lecture uh and then start with some new ideas so basically in our previous lecture we talked about an algorithm called breadth first search uh and then almost always you see that paired with the second algorithm called depth first search uh and following tradition and basically logic we'll uh do the same thing uh in 06 today uh but in any event for today we'll we'll stick to the technical material so as a little bit of review i guess actually the one thing i didn't do on this slide was actually draw a graph so we should probably start with that uh so if you recall graph is a collection of nodes or vertices depending i don't know is it like a european american thing or something uh and edges right so here's an example which as usual i'm not managing to draw particularly clearly uh so this uh graph is kind of like a cycle so i have directed edges here here here and here and of course uh there are many kind of variations on the theme right so our basic uh sort of definition of a graph is that we have some set v which is like the set of vertices and then we have a set e which is set of edges and this was a subset of v cross v and this is nothing more than fancy notation for saying that an edge is a pair of vertices right like a from and a two vertex of course there are many variations on this theme you could have a directed versus an undirected uh graph so this one is directed meaning the edges look like arrows if they didn't have arrowheads they'd be undirected uh we defined something called a simple graph where you have essentially no repeated edges so for instance you can't do something like this where you have the same edge twice um and then there are a couple different definitions that were kind of useful right so in particular i'm gonna erase this oops useless edge here maybe make my graph slightly more interesting so i'll add another edge going in the reverse direction so maybe i have um i'm going to give my vertices labels x y z and w then uh we talked about the uh the neighbors of a given vertex which are the vertices that you can reach by following edges in or out of your your vertex right so in particular the outgoing neighbors uh which we sort of implicitly defined in our previous lecture but didn't call it out um we're going to notate with adj plus and these are all of the things that you can reach by going out of a vertex into the next one so for example uh adj plus of w is going to be the set of vertices well notice i can get from w to y and also from w to z yeah so oop nope y comma z okay uh so to continue just our tiny amount of review for the day uh remember that a graph uh there are many different ways to represent a graph uh the sort of brain dead one will be just like a big long list of edges but of course for our algorithms that's not a particularly efficient way to check things like does this edge exist in my graph uh so the the basic representation that i think we're mostly working from in this course is to think of a graph like a set of vertices each of which maps to another set of vertices so roughly every vertex maybe stores its outgoing uh set of edges right and and so this is kind of nice because of course uh very quickly we can answer questions like is this edge inside of our graph or we can iterate over the neighbors of a vertex and so on which are the kind of typical things that we do in a lot of graph algorithms and then finally in our previous lecture we started talking about paths right so a path is like a chain of vertices that can get me from one vertex to the other only following edges of my graph there was a term that i think i forgot to define last time because it didn't really matter a ton which is a simple path which is just a path that doesn't have the same vertex more than once uh and then of course there are many different questions you can ask about a graph that are basically different problems involving computing paths right so for instance the shortest path between two vertices is sort of our canonical one and graph theory or you could ask questions about reachability and so on so there's our uh our basic review from our previous lecture uh do our does our course staff have any questions about uh things so far excellent okay and uh there's one additional piece of terminology that i fudged a little bit last time or other uh my my co-instructors suggested a bit of an attitude adjustment so i thought i'd better uh uh clarify really quick there's this interesting phrase uh linear time which we all know and love in in computer science theory and and the sort of implicit thing especially in this course is that when we say linear time we mean in the size of the input right and so if we have a linear time graph algorithm well how much space does it take to store a graph well we need a list of vertices and a list of edges and nothing else so a reasonable way to interpret this phrase linear time is that it's an algorithm that looks like what we've shown on the screen right the the times proportional to maybe the sum of the number of vertices and the number of edges if that makes you uncomfortable like it does for me because one of these can kind of scale on the other i think it's always fine to add more detail right so if you want to say linear in the sum of the number of vertices and edges that's that's perfectly fine but if you see this phrase that's uh how you should interpret it hopefully that's a fair way to put it excellent okay so um last time we talked about an algorithm called breath first search bfs for those in the know breath first search uh is an algorithm uh and and the reason we use the word breath is because it's kind of remember we we talked about level sets last time uh because we talked about breath first search in the context of computing shortest paths uh and in particular uh we have our our source uh node all the way on the left hand side and then breadth first search constructed all the nodes that were distance one away right that's the first level set and then all the distance two away and then all the distance three away and so on right so in particular like the level set l3 isn't visited until we're completely done with level set l2 today we're going to define another algorithm which is called depth first search which doesn't do that but rather starts with the source vertex and just starts walking all the way out until it can't do that anymore and then kind of backtracks it's one way to think about it uh and so somehow in breath first search we're like drawing concentric circles in depth first search we're doing the opposite we're like shooting outward until we reach the outer boundary and then exploring a graph that way okay and these are sort of the two extremes in terms of graph search kind of techniques uh that are typically used under the basic building blocks for for algorithms and graph theory so in order to motivate and think about death for search we're going to define a second problem which is closely related to shortest path but not exactly the same and that's the reachability problem so here i have the world's simplest uh directed graph so the black things are the edges and the circles are the uh notes or the vertices and i've marked one special note in blue uh and his name is the source node and now the question i want to ask is what are all of the other nodes in my graph that i can reach by following edges directed edges starting with the source right so obviously i can get to the node in the lower right no problem and of course once i get there i can traverse an edge upward to get to that second green vertex notice that i was really sneaky and evil and i drew edges in this graph that might make you think that the red note is reachable the red one being on the upper left i'm realizing now that for colorblind people this isn't a great slide uh but of course uh because all the edges from the red vertex on the left here point out i can't actually reach it from the blue source node so the reachability problem is just asking which nodes can i reach from a given source it's pretty straightforward i think of course there are many ways uh to solve this right in fact one way we could do it uh would be to use our previous lecture right we could compute the shortest path distance from the source to all the other nodes and then what would the length of the shortest path from the source to an unreachable node b any thoughts from our audience here infinity thank you uh professor domain uh right so in addition to this uh of course a totally reasonable question thinking back to our shortest path lecture uh there are sort of two queries we might make right one is just what is the length of the shortest path the other is like what is the actual shortest path from the source to a given vertex we can ask a very similar thing here right which is like okay you tell me that the green guy is reachable but like how like give me a path as as evidence or a certificate if you want to be fancy about it so uh in order to do that just like last time remember we defined a particular data structure that was the shortest path tree uh we can do something very similar here right in particular this is like the extent of my powerpoint skill here if i have a reachability problem i can additionally store i can decorate every node in my graph with one other piece of information which is the previous node along some path from my source to that thing right and just like last time if i want to get an actual path from the source to w what could i do i could start with w and then just keep following those parent relationships until i get back to the source then if i flip the order of that list of vertices i get a path from the source to the target that's valid right so this object is called a path tree just like we talked our parent tree rather uh just like we talked about in our last lecture uh there's no reason why this thing should ever have a cycle in it uh it's certainly a tree um right so uh that's the basic reachability problem and in addition to that we can compute this object p which is going to give me sort of information about how any given node was reachable there's a slight difference between the parent tree that i've defined here and the shortest path tree which i defined last time which is i'm not going to require that the shortest path i get or oh man the path i get when i backtrack along my my tree p is the shortest path it's just a path right because for the reachability problem i actually don't care right like i could have a weird circuitous crazy long path and it still tells me that a node is reachable uh right so that's our basic setup and our data structure and now we can introduce a problem to to solve reachability again we already have an algorithm for doing that right which is to compute shortest paths and and remember that our shortest path algorithm from previous lecture took linear time and the size of the input right it took uh v plus e time now the question is can we do a little better the answer obviously is yes because i just asked it and i gave you this problem okay and here's a here's a technique for doing that which unsurprisingly is a recursive algorithm i'm going to swap my notes for my handwritten notes and this uh algorithm is called death first search and here's the basic strategy i'm going to choose a source node i've labeled that node one here i suppose actually would have made sense for me to actually zero index this maybe in the slides i'll i'll fix it later but in any event i'm going to mark my my source node and now i'm going to look at every node every edge coming out of that node and i'm going to visit it recursively right so that's our sort of for loop inside of this function visit and then for each neighboring node if i haven't visited it before in other words i currently haven't given it a parent right that's our if statement here i'm going to say well now they do have a parent and that parent is me and i'm going to recurse you guys see what this is doing it's kind of crawling outward inside of our graph so let's uh let's let's do the example on the screen and i purposefully designed this experiment or this example to look a little bit different from breath first search at least if you choose to do the ordering that i did so here's our graph one two five three four okay and let's uh think about the traversal order uh that that's first search is gonna do right so here's our source and now what does the source do it record so let's think about a recursion tree so we have uh the source all the way up in here and now he's gonna start calling uh the visit function recursively so um and i'll go ahead and number these the same as on the screen well he has one outgoing neighbor and it hasn't been visited yet so of course the very first recursive call that i'll make is to that neighbor too now the neighbor two also recurses hopefully this kind of schematic picture makes some sense what i'm trying to draw here and well now the two has two neighbors right a three and a five so let's say that we choose three first well the three now recurses he calls four and then the recursion tree is kind of done so now it goes back out and then finally well now the three are oh boy yeah the two looks at its next neighbor which is the five uh and envisions that recursively notice that this is not following the level sets right the death first search algorithm got all the way to the end of my tree in the recursive uh calls and then kind of backed its way out to the two before calling the five these are not the same technique one goes all the way to the end and then kind of backtracks whereas when i say backtrack what i mean is the recursion is kind of unraveling um whereas in breadth first search i visit everything in one level set before i work my way out does that distinction make sense okay so of course we need to prove that this algorithm does something useful uh so let's do that now so in particular we need a correctness proof so our claim is going to be that uh let's see here the depth first search algorithm visits oh uh i guess reachable v um and that it correctly sets uh the parent in in the process um okay so in order to prove this uh of course as with almost everything in this course we're going to use induction uh and in particular what we're going to do is do induction on the distance from the source so we're going to say that like for all vertices in distance k from the source this statement is true and then we're going to prove this inductively on k okay so we want to do induction on k which is the distance to the source vertex so uh as with all of our inductive proofs we have to do our base uh case and then our inductive step so in the base case k equals zero this is a hella easy case because of course uh what is the thing that is distance zero from the source it's the source yeah and take a look at our our strategy all the way at the top of this slide we explicitly set the correct parent for the source and in some sense visit it because the very first thing we do is call visit of s so there's kind of nothing to say here yeah or there's plenty to say if you write it on your homework but your lazy instructor is going to write a check mark here okay so now we have to do our inductive step so what does that mean we're going to assume that our statement is true for all nodes within a distance k and then we're going to prove that our statement is true for all nodes within a distance k plus one okay uh so uh let's do that let's consider a vertex v that's distance k plus one away so in other words the distance from the source to v is equal to k plus one right and what's our goal our goal is to show that the parent of v is is set correctly yeah what's that oh sorry i forgot that the distances in this class are ordered yeah that's absolutely right so it should be the distance from s to v yeah sorry i'm really not used to thinking about directed graphs but that's that's a good fix okay so uh now what can we do well there's this number is distance here so in particular there's some shortest path from s to v so remember our argument last time right that essentially when we look at shortest path and we kind of truncate by one it's still the shortest path uh that property doesn't matter so much here but at least we know that there's another vertex on the path which is one a distance one less away so let's let's take you which is also a vertex to be the previous node on the shortest path from s to v right and so in particular we know that the distance from s to u is equal to k and conveniently of course by our inductive uh hypothesis here we know that our property is true for this guy okay so now our algorithm what do we know well because our property is true the visit function at some point in its life is called on this vertex u right that's sort of what our induction assumes so we have two cases um right so uh when we uh when we visit you um we know that when we call this uh uh visit function well remember that v kind of by definition is in adj plus of view right so in particular dfs is going to consider v when it gets called okay and now there's two cases right so either when this happens p of v does not equal none right well what does that mean well it means that we already kind of found a suitable parent for v uh and we're in good shape otherwise p of v does equal none well in this case a very next line of code correctly sets the parent and and we're all set right so in both of these two cases uh we show that the parent of uh you was set correctly either by that line of code right here or just previously uh and and so in either case our our induction is done all right i guess uh given the feedback i received from our previous lecture we now can and end our latex uh suitably okay so what did we just show we showed that the death first search algorithm can dig around in a graph and tell me all of the things that are are searchable or rather are reachable from a given source just basically by calling visit on that source and then expanding outward recursively okay so i think this is certainly straightforward from an intuitive uh perspective it's easy to get lost when you write these kind of formal uh induction proofs because they always feel a tiny bit like tautology so you should go home and kind of convince yourself that it's that it's not okay so of course what do we do in this class we always follow the same kind of boring pattern the first thing we do define an algorithm second thing we do make sure it's the right algorithm what's the third thing we need to do analyze it that's right in particular make sure that it like finishes before the heat death of the universe uh and indeed uh death first search uh doesn't really take all that long which is a good thing um so let's think about this a bit so what's going to end up happening in depth first search well we're going to visit every vertex at most once right kind of by definition here and in each case we're going to just visit its neighboring edges can we ever traverse an edge more than one time right because the visit function only ever gets called uh one time per vertex and our edges are directed right so kind of you think about the from of every edge uh the from vertex is only ever visited one time and hence every edge is only visited one time do we ever visit ah yes does dfs work an undirected graph uh absolutely so there's sort of uh different ways to think about it uh one is to think of an undirected graph like a directed graph with two edges pointed either way which i think is in this class how we actually kind of notated it in the previous lecture um yeah actually that's that's probably a reasonable way to reduce it so we'll stick with that uh right now does dfs ever visit a vertex that is not reachable from the source well the answer is no right because all i ever do is recursively call on my neighbors and so kind of by definition if i'm not reachable dfs will never see it so if i think about my run time carefully it's not quite the same as breath first search remember that breath for search took v plus e time in depth first search it just takes order e time because i'm expanding outward from the source vertex hitting every edge adjacent to every uh every vertex that i've seen so far uh but i never reach a vertex that i have in the that isn't reachable right and so because this only ever touches every edge one time uh we're in good shape uh and i see a question here yeah does vfs reach vertices that are not reachable uh does bffs reach vertices that are not reachable i guess not now that you mention it but at least in my boring proof of of order v time last time our very first step of bfs reserved space proportional to v um which is enough to already uh make that that run time correct good question yeah so i guess the way that we've talked about it where you construct one level set after a time um if you think of that as reachability then then no it doesn't reach it in the for loop but just by construction when we started uh we already took the time that we're talking about here so notice these runtimes aren't exactly the same so for example if my graph has no edges bfs still is going to take time yeah because it still has to uh take order v time at least the way in the sort of brain dead way that we we've implemented it last time obviously in that case we could probably do something better whereas the way that we we've defined the dfs algorithm it only takes edge time i see confusion on my instructor's face no okay good uh the one thing to notice is that these are algorithms for slightly different tasks in some sense right the way that we wrote down breadth first search last time conveniently it gives us the shortest path um there are breath first algorithms that doesn't i think we're in this class we kind of think of breath first search uh we motivate it in terms of the shortest path problem but it's it's just kind of a strategy of working outwards from from a vertex um whereas here uh the way we've written down death first search there's no reason why the path that we get should be the shortest right so to think of a really extreme example let's say that i have a cycle graph right so i get a big loop like this let's say that i do depth first search starting from this vertex well what will this what will happen well this guy will call its neighbor uh recursively who will then call its neighbor recursively we'll then call his name recursively and so on so of course when i do a death first search when i get to this vertex there's a chain of one two three four vertices behind it is that the shortest path from the source to uh the target here well clearly not right i could have could have traversed that edge i just chose not to okay so that's the death first search algorithm it's just a essentially a recursive strategy where i traverse all my neighbors uh and and each of my neighbors versus their neighbors and and so on okay so why might we want to use this algorithm well we've already solved the uh the reachability problem so let's uh solve a few more things using the same uh basic strategy here so there's some notions that we've sort of actually in some sense already used in the lecture here but we might as well call them out for what they are which is this idea of connectivity so a graph is connected if there's a path getting from every vertex to every other vertex right now connectivity in a directed graph is kind of a weird object right like it could be like for instance think of a directed graph with just two edges and one edge goes from u to v right then i can get from v to u but not vice versa that's kind of a weird uh notion so here uh in in 606 we'll mostly worry about connectivity only for undirected graphs because they're the vertices just basically come in like big connected uh clumps uh or the more technical term for a big connected clump is a connected component yeah so let's see an example so let's say that i have a graph which has an edge and then a triangle this is one graph do you see that there's a collection of vertices and there's a collection of edges but uh it has two connected components right the guy on the right and the guy on the left meaning that each vertex here is reachable from every other vertex here each vertex here is reachable from every vertex here but there's no edge that goes from the triangle to the line segment yep and so in the connected components problem we're given a graph like this guy and initially we don't you know okay when i draw it like this it's pretty clear that uh you know my graph has two connected components maybe my graph embedding algorithm failed and it drew an edge like that well then maybe i don't know it's still pretty obvious that there's two connected components but you can imagine a universe where you don't know that a priori and and the problem you're trying to solve is just to enumerate all these clumps of vertices that are reachable from one another in a an undirected graph and conveniently um we can use depth first search to solve this problem pretty easily right so how could we do it well in some sense how can we find one connected component so let's say that i just choose a vertex in my graph well what do i know about everything in this connected component well it's reachable from that vertex remember we just solved the reachability problem which says if i have a vertex i can now tell you all the other vertices that are reachable from this guy right so i could call dfs on well any vertex of this cycle here called the reachability thing and i know that for every vertex there's one of two things right either that vertex has a parent in that object p or it's the source right so i could very easily find the connected component corresponding to that vertex does that make sense have i found all the connected components no i found one right i found the one corresponding to the arbitrary vertex that i just chose so how could i fix this well it's super simple i could put a for loop on the outside which just loops over all the vertices maybe and if that vertex is not part of a connected component yet then i need to make a new one so then i call dfs on that vertex i collect all the vertices that i got and i iterate so this is a the algorithm that uh in this class we're going to call full dfs by the way you could do the same thing with full breadth first search that's perfectly fine um just kind of by analogy here right so what is full d oh this chalk is easier uh well i'm going to iterate over all my vertices where i stands for for loop right so if v is unvisited then i'm going to do d f s starting at v i guess we use we use visit to refer to this in the previous slide and that's going to kind of flood fill that whole connected component and then i can connect you know collect that connected component and continue be a little bit careful because of course we don't want like checking things something to be visited to somehow take a bunch of time and make my algorithm slower than it needs to be but of course we have a set data structure that we know uh can do that in in order one time at least in expectation okay so this is the full dfs algorithm it's really simple well it's dfs because i called dfs on every vertex it was full because i looped over all the vertices uh right and so if we think about it how much time does this algorithm take it's a little bit sneaky because somehow i have a for loop over all the vertices that i could imagine a universe where i get like vertices times some other number because there's a for loop and there's something inside of it right i think that's how we're used to thinking about run time of for loops but in this case that actually doesn't happen because there's never a case where an edge gets traversed more than one time because if i'm in one connected component then by definition i can't be in another connected component right and so what happens is in some sense this innocent looking call to dfs i suppose if you were like a lisp programmer you somehow wouldn't like this it has a side effect right which is that i marked all the vertices in that connected component as don't touch me again right and so implicitly i kind of removed edges uh in this process so if you think through it carefully the runtime of this full dfs algorithm is v plus e time because every edge is touched no more than one time kind of amortized over all the the different calls to d of s here uh and there's this for loop over vertices so there's clearly an an order v that you you need here does that argument make sense so again we call that linear in the size of the the input i'm going to say it many times to get it in my own head correctly okay uh right so this is the the basic problem this comes up all the time by the way like it seems like somehow a totally brain dead weird algorithm like somehow why would you want an algorithm finds connected components like why would you even have a graph that's disconnected or something um but of course that can happen a lot so if like for instance maybe work at a social media company and people have friends but like you know eric and i are friends and we're not friends with anybody else we have a we have a there's like a blood oath kind of thing uh then you know that might be not so easy to find uh in the graph because of course we're just two among a sea of students in this classroom uh uh all of which have different interconnections that are just enumerated uh based on the list of edges right and and so even though like pictorially it's kind of hard to draw uh connected component algorithm in a way that doesn't make it sound kind of like a useless technique from the start because like it's very clear there are two connected components there uh of course we still have to be able to write code to solve this uh this sort of thing okay so for once i think i'm almost on time uh in lecture today so we have one additional uh application of of death first search uh in our class today uh which is sort of on the opposite end of the spectrum so we just talked about uh graphs that are undirected and thinking about cycles uh now on the opposite end we might think of a dag so a dag is a directed acyclic graph can anybody think of a special case of a dag i suppose i should define it first and then we'll come back to that question uh which means uh exactly what it sounds like so it's a graph that has directed edges now and doesn't have any cycles in it so actually the graph i gave you all the meaning of lecture um i think secretly was an example of one of these so let's say that i have directed edges maybe if i make the header triangle that's a little easier to see i'm not so sure uh in any event so i'm going to have an edge up and an edge to the right and similarly an edge down an edge to the right this graph looks like a cycle but it's not because the only direction that i can move is from the left-hand side to the right-hand side so this is a directed graph and it doesn't contain any cycles meaning there's no path that i can take from a vertex that gets back to itself along the directed edges okay and dags show up all the time now that i've defined what a dag is can somebody give me an example of a dag that we've already seen in 6006 a tree at least if we orient all the edges kind of pointing downward in the tree yep otherwise i guess kind of debatable whether it's a dagger you know if there's if there's no direction to the edges then somehow the definition just doesn't apply um okay so in uh in processing directed acyclic graphs uh there's a really useful thing that you can do that's going to show up in this class apparently quite a bit which is kind of interesting to me i'm curious to see what that looks like which is to compute a topological order on the graph where topology is here so as a geometry professor in my day job i get all excited uh but in this case a topological order is a fairly straightforward thing actually it's defined on the screen and i have bad handwriting anyway so let's just stick with that so topological ordering so if we think of like f as a function that assigns maybe every node an index in array i should i guess i shouldn't use the word right here but it's just like an index in ordering so like this is the first vertex and this is the second vertex and so on then a topological order uh is one that has the property shown here which is that if i have a directed edge from u to v then f of u is less than f of v so in other words if i look at the ordering that i get in my topological order u has to appear before v yeah so let's uh let's look at our example again so let's number let's give our nodes names so here's a b c d well what clearly has to be the first node in my topological order a right because all the way on the left-hand side yeah well after that it's a bit of a toss up what do we know we know that b and c have to appear before d so maybe just to be annoying i do a c b that's b and then d right so it's a topological order notice that things that are on the left appear in my graph before things that are on the right where the word before here uh means that there's an edge that points from one to the other okay by the way are topological orderings uh unique no so if we look at our graph example here a b c d is also a topological order uh and what that means is it's somehow very liberating right it means that when we design an algorithm for finding a topological order uh there's some design decisions that we can make uh and we just have to find one among uh many uh but in any event we're gonna define a slightly different notion of order and then we're gonna show that they're closely linked to each other and that is the finishing order so in the finishing order we're going to call full dfs on our graph remember that means we iterate over all our nodes and if we haven't seen that node yet we call dfs on it and now uh we're going to make an order in which as soon as the call to a node in that visit function is complete meaning i've already iterated over all my neighbors then i add my node to the ordering that makes sense it's like a little bit backward from what we're used to thinking about so the order in which full dfs finishes visiting each vertex yeah and now here's uh here's the claim is that if we have a reverse finishing order meaning that we take the finishing order and then we flip it backward that's exactly uh gonna give us a topological ordering of the vertices in our graph um right so let's uh do that really quickly so in other words our claim here i think yeah let's see is that if i have a directed graph so g is a dag then um uh let's see here then oops my notes are backwards so i should switch to my jason's notes which of course are correct [Laughter] right so if if i have a graph that's a dag then the reverse of the finishing order is a topological order by the way we're not going to prove the converse that if i have a topological order that somehow that thing is the reverse of uh dfs at least the way that maybe i coded it there's a slightly different statement which is does there exist a dfs that has that ordering but that's one that we'll worry about another time around piazza or whatever okay so uh let's see here so we need to prove this thing so what are we gonna do well what do we need to check if is a top large quarter is that if i look at any edge in my graph it obeys the relationship that i have on the screen here uh so in particularly we're going to take the u v inside of my set of edges and then what i need is the u is ordered before v uh using uh the reverse of the finishing order that we've defined here okay so let's think back to our call to the dfs algorithm remember we call this visit function right so we have two cases right either u is visited before v or it ain't yeah uh so let's let's do those uh those two cases so case number one is u is visited before v okay all right so what does that mean well remember that there's an edge like pictorially what's going on well there's like all kinds of graph stuff going on and then there's u and we know that there's a directed edge from u to v right that's our our picture right and maybe there's other stuff going on outside of v so in particular well just by the way that we've defined that visit function what do we know we know that when we call visit on u well v is one of its outgoing neighbors so in particular a visit on you is going to call visit v and we know that because well you visited before v right so currently v's parent is none when i get to u that makes sense now here's where reverse ordering we're gonna have to keep it in our head right because now well you visit a view called visitor v so notice that visit of v has to complete before visited of you right v completes before visit of u well so in reverse uh uh sorting in reverse finishing order here what does that mean well if this completes before uh the other guy then they get flipped backward in the list which is exactly what i want because there's an edge from u to v okay so case one is done now we have case 2 which is that v is visited before you okay so now um i'm gonna make one additional observation okay so uh let's now i'm gonna go back to my other notes because i like my schematic better right so what's our our basic picture uh here i don't know i oh you know what it was i printed out another copy of this that's okay i can do it on my head okay so here's my my source vertex his name is s now there's a bunch of edges and whatever there's a long path and now eventually what happens well i have a node v and somewhere out there in the universe there's another node u and what do i know i know that uh there's by assumption i know that there's an edge from u to v that makes sense so that's our sort of picture so far okay so what do we know we know that our graph is acyclic yeah right that kind of by definition that's our assumption so can we reach u from v in other words does there exist a path from v to u right so that would look like this no because our graph is a cyclic and i just drew a cycle right so this is a big x there's a frowny face here can't do it he has hair unlike your instructor okay so uh right so what does this mean well okay so by this uh picture i suppose we know that uh u cannot be reached from v yeah so what does that mean well it means that the visit to v is going to complete and never see you right because remember though the visit to v only ever calls things that are kind of descendants of v right so in other words visit a v completes without seeing you well that's exactly the same thing that we showed in our first case right so by the same uh reasoning right what does that mean in our reverse finishing order right the ordering from from u to v is is preserved okay so that sort of completes our proof here the reverse finishing order gives me a topological order which is kind of nice and so this is a nice convenient way of taking all of the nodes in a directed acyclic graph and ordering them in a way that respects the topology or the connectivity of that graph so we're going to conclude with one final problem uh which i don't have a slide on but that's okay and that's cycle detection so there's a bit of a an exercise left to the reader here so the problem that we're looking for now is that we're given a directed graph there's a g in graph case you're wondering but now we don't know if it's a dag or not and so the question that we're trying to ask is does there exist a cycle in our directed acyclic graph right so we're just given our graph and we want to know like can we do this let's think through the logic of this a bit so what do we know we know that if our graph were a dag then i could call dfs get the ordering out and then i guess flip it it's ordering backwards so i could compute uh the reverse finishing order and it would give me a topological order of my graph right so if i were a dag i would get a topological order when i called dfs so let's say that i ran dfs i got whatever ordering i got and now i found an edge that points in the wrong direction i i can i can just double check my list of edges and i find one uh that does not respect the relationship that i see in the second bullet point here can my graph be a dag no because if my graph were a dag the algorithm would have worked i just proved it to you right so if if there were if my my graph were a tag then i could do a reverse finishing order and what i would get back is a topological order so if i found a certificate that my order wasn't topological something went wrong and the only thing that could go wrong is that my graph is in a dag or yeah it's in a deck in fact uh sort of an exercise left to the reader and or to your section do we still have section i think we do as of now um is that this is an if and only if meaning that the only time that you even have a topological ordering in your graph is if your graph is a dac this is a really easy fact to sanity check by the way so it's not not like a particularly challenging problem but you should think through it because it's a good exercise to make sure you understand the definitions which is to say that if you have a topological order your graph is a dag if you don't have a topological order your graph isn't a dag so in other words we secretly gave you an algorithm for checking if a graph is a dag at all right what could i do i could compute reverse finishing order check if it obeys the relationship on the second bullet point here for every edge and if it does then we're in good shape my graph is a tag if it doesn't something went wrong and the only thing that could have gone wrong is not being a dag okay so in other words uh secretly we just solved well i guess the way that i've written it here we've solved the cycle detection problem here which is to say that well i have a cycle if and only if i don't i'm not a dag which i can check using this technique of course the word detection here probably means that i actually want to find that cycle and i haven't told you how to do that yet right all we know how to do so far is say like yeah somewhere in this graph there's a cycle and that's not so good um so we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here which is to modify our algorithm ever so slightly to not only say like thumbs up thumbs down is there a cycle in this graph but also to actually return the vertices as a cycle and here's the the property that we're gonna do that which is uh the following which is that if g contains a cycle uh right then a full dfs will traverse an edge from a vertex v to some ancestor v i guess we haven't carefully defined the the term ancestor here essentially uh if you think of the sort of the running of of the dfs algorithm then an ancestor is like something that appears in the recursive call tree before i got to v okay so how could we prove that well let's take a cycle um and we'll give it a name in particular we'll say that it's a cycle from v0 v1 to vk and then it's a cycle so it goes back to v0 okay and i can order this cycle any way i want notice that if i permute the vertices in this list in a cyclical way meaning that i like take the last few of them and stick them at the beginning of the list it's still a cycle it's the nice thing about cycles uh so in particular without loss of generality we're going to assume uh that v zero is the first vertex uh visited by by by dfs what does that mean that means like when i do my dfs algorithm making all these recursive calls the very first vertex to be touched by this technique is v naught okay well now what's going to end up happening well think about the recursive call tree starting at v zero by the time that completes anything that's reachable from v zero is also going to be complete do you see that so like for instance v zero somewhere in his call tree might call v one if it and notice that v one was not already visited so in fact it will for v1 i got to call v2 and so on and in particular we're going to get all the way to vertex k right so in other words we're going to visit vertex v k and notice what's going to happen so remember our algorithm in fact we should probably just put it up on the screen would be easier than talking about it a bunch well v k is now going to iterate over every one of the neighbors of v k and in particular it's going to see vertex v naught right so we're going to see the edge from vk to v0 which is an edge kind of by definition right because we took this to be a cycle here well notice that's exactly the thing we set out to prove right namely that full dfs traverses an edge from a vertex to one of its ancestors here's the vertex k here's his ancestor v naught why do we know that it's an ancestor well because v naught was called in our call tree before any of these other guys right so we wanted an algorithm that not only did cycle detection but also actually gave me this cycle what could i do well it's essentially a small modification of what we already have right so whoops uh right if i want to compute topological order or whatever i can just do dfs and that'll tell me like year nay does their existing cycle if i want to actually find that cycle all i have to do is sort of check that topological order property at the same time that i traverse the graph during dfs and the second that i find an edge that loops back i'm done and so that's our basic algorithm here and this is a technique for actually defining the cycle in a graph using the dfs algorithm