Um maybe maybe we should get started. Um it's been a long time since we've all been in the same place and I hope everybody's doing well. Um today I'd like to talk about Spanner. The reason to talk about this paper is that it's a rare example of a um system that provides distributed transactions over data that's widely separated. That is data that might be scattered all over the internet in different data centers. It's almost never done in um production systems. Of course, it's extremely desirable to be able to have transactions. The programmers really like it. Um and also extremely desirable to have data spread all over the um network for both for fault tolerance and to ensure that data is near um that there's a copy of the data near everybody who wants to use it. Um and um on the way to achieving this, Spanner um used at least two neat ideas. One is that they run two-phase commit, but they actually run it over Paxos replicated participants um in order to avoid the problem with two-phase commit that a crashed coordinator can block everyone. Um and the other interesting idea is that they use synchronized time in order to have very efficient readonly transactions. Um and the system is is actually been very successful. It's used a lot by many many different services inside of Google. It's uh been turned by Google into a a product a service for their cloud-based customers. Um and it's inspired um a bunch of other research and other systems both sort of by the example that um these kind of wide area transactions are possible and also specifically there's um at least one open source system cockroach DB that uses a lot of explicitly uses a lot of the design um the motivating use case the um reason that the paper says they first kind of uh started the design spanninner was that they were already had a um well actually they many big database systems inside Google but their advertising system in particular um the it data was sharted over many many uh distinct MySQL and big table databases and maintaining that sharding uh was a just an awkward and manual and timeconuming process in addition their previous advertising database system um didn't allow transactions that spanned more than a single uh basically more than a single server um But they really wanted to be able to have um to spread their data out more widely for better performance and to have transactions over the um multiple shards of the data um for their advertising database. Apparently the workload was dominated by readonly transactions. Um and you can see this in table six where the um there's billions of readonly transactions and only millions of um of read write transactions. So they're very interested in um the performance of read only of transactions that only do reads and apparently they also required strong consistency um that you know what transactions in particular um so they wanted serializable transactions and they also wanted um external consistency which means that if one transaction commits um and then after it finishes committing another transaction starts the second transaction needs to see any modific ifications done by the first um and this external consistency turns out to be um uh interesting uh with with replicated data. All right. So um I want to draw out just the basic uh arrangement sort of physical arrangement of their servers that that Spanner uses. Um it has the its servers are spread over data centers um presumably all over the world certainly all over the United States. Um, and each piece of data is replicated at multiple data centers. So, um, the diagrams got to have, um, multiple data centers. Let's say there's, um, there's three data centers. Really, there'd be many more. Oops. Um, so we have multiple data centers. Then the data is sharded that it's broken up. You can think of it as been being broken up by key into um, and split over many servers. So maybe there's one server that um serves keys starting with A in in this data center, another starting with B um and so forth. Lots of lots of starting over lots of servers. In fact, every data center has or um any piece of data is any shard is replicated at at more than one data center. So there's going to be another copy another replica of the A keys and the B keys and so on. the second data center and yet another hopefully identical copy um of all this data at the third data center. In addition, each data center has m multiple clients or they're clients of Spanner. Um and what these clients really are is web servers. So if an ordinary human being sitting in front of a web browser uh connects to some Google service that uses Spanner, they'll connect to some web server in one of the data centers and that's going to be one of these um one of these Spanner clients. All right. Um so that is replicated. The replication is managed by Paxos. um in fact really a variant of Paxos that has leaders and is really very much like the raft that we're all familiar with. Um and each Paxos instance manages all the replicas of a given shard of the data. So this shard, all the copies of this shard um form one Paxos uh group and all the replicas of this shard form another Paxos group and within each each of these Paxos instances is um independent has its own leader runs its own version of the own uh of the own instance of the Paxos protocol. Um and the reason for the sharding and for the independent uh Paxos instances per shard is to allow um parallel speed up and sort of a lot of parallel throughput because there's a vast number of clients you know which are representing working on behalf of web browsers. So this huge number typically of concurrent requests um and so it pays more immensely to split them up over multiple shards and multiple sort of Paxos uh groups that are running in parallel. Okay. And you can think of or each of these Paxos groups has a leader um a lot like raft. So maybe the leader for this shard is in data is the replica in data center one and the leader for this shard might be the uh replica in data center 2 and um and so forth. Um and uh you know so that means that if you need to um if a client needs to do a write it has to send that right to the leader of the um of the shard whose data it needs to write. Um just as with raft these Paxos instances are what they're really doing is sending out a log. The leader is sort of replicating a log of operations to all the followers and the followers execute that log which is for data is going to be reads and writes sort of executes those logs. Um all in the same order. Um all right so uh the reason for these for this setup um the sharding as I mentioned is for throughput the multiple copies in different data centers is for two reasons one is um you want copies in different data centers in case one data center fails if you know maybe a power fails to the entire city the data center's in or there's an earthquake or a fire or something you'd like um other copies at other data centers that are maybe not going to fail at the same time. Um, and you know, there's a price to pay for that because now the Paxos protocol now has to talk maybe over long distances to um talk to followers and in different data centers. The other reason to have data in multiple data centers is that it may allow you to have copies of the data near um all the different clients that use it. So, if you have a piece of data that may be read in both California and New York, um maybe it's nice to have a copy of that data, one copy in California, one copy in New York. um so that reads can be very fast and indeed a lot of the focus of the design is to make reads from the local the nearest replica both fast and correct. Um finally another interesting interaction between Paxos and multiple data centers is that Paxos like raft only requires a majority um in order to replicate a log entry and proceed. And that means if there's one slow or distant or flaky data center, the Paxo system can keep chugging along um and accepting new requests even if one data center is um is being slow. All right, so with this arrangement um there's a couple of big challenges that paper has to bite off. One is they really want to do reads from local data centers. Um but because they're using Paxos and because Paxos only requires um each log entry to be replicated on a majority that means a minority of the replicas may be lagging and may not have seen the latest data that's been committed by Paxos. Um, and that means that if we allow clients to read from the local replica for speed, they may be reading outofdate data if their replica happens to be in the minority that didn't see the latest updates. So, they have to since they're requiring correctness, they're requiring this external consistency idea um that every read see the most up-to-date data, they have to have some way of dealing with the possibility that the local replica may be lagging. Um, another issue they have to deal with is that a transaction may involve multiple shards and therefore multiple paxos groups. So you may be reading or writing a single transaction may be reading or writing multiple records in the database that are stored in multiple shards and multiple paxos groups. So those have to be um we need distributed transactions. Um okay so um I'm going to explain how the transactions work. That's going to be the kind of focus of the lecture. Um, Spanner actually treats implements readwrite transactions um quite differently from readonly transactions. So let me start with the read read transactions which are um sort of a lot more conventional in their design. All right. Um Right. So first read write transactions. Uh let me just remind you what a transaction looks like. Um so let's just choose a simple one that's like mimicking u bank transfer. So on one of those client machines, a client of Spanner, you'd run some code. You run this transaction code. The code would say I'm beginning a transaction. Um and then it would say I want to read and write these records. So maybe we have a bank balance in database record X and we want to you know increment we want to increase this bank balance and decrease Y's bank balance and oh that's the end of the transaction and now the client hopes the database will go off and commit that. Um, all right. So, I want to trace through all the steps that uh that have to happen in order to um in order for Spanner to execute this readwrite transaction. So, first of all, there's a client in one of the data centers that's driving this transaction. Um, so I'll draw this client here. Let's imagine that X and Y are on different shards. Um, since that's the that's the interesting case. um and that those shards each of the two shards is is replicated in uh uh three different data centers. So, uh, we got our three data centers here. And at each data center, there's a, um, a server that, uh, I'm just going to write X for the replicas of the shard that's holding X, the bank balance for X, and Y for the these three servers. Spinner runs two-phase commit, just totally standard two-phase commit and two-phase locking almost exactly um as described in the reading from last week from the 6033 textbook. And the huge difference um is that instead of the participants and the transaction manager being individual computers, the participants in the track transaction manager are um Paxos replicated uh groups of servers for increased fault tolerance. So that means just to remind you that um the shard the three replicas of the shard that stores X is really a packless group. Same with these three replicas storing Y. Um and we'll just imagine that for each of these one of the three servers is a leader. So let's say the servant data center 2 is the Paxo's leader for the X's shard and the servant data center one is the Paxos leader for uh Y's shard. Okay. So the first thing that happens is that uh the client picks a unique transaction ID which is going to be carried on all these uh messages so that the system knows that um all the different operations are associated with a single transaction. First thing that is the client has to read. So um despite the way the code looks where it reads and writes X and reads and write Y. In fact um the way the code has transaction code has to be organized. It has to do all its reads first and then at the very end do all the writes at the same time essentially as part of the commit. Um so the uh the client has to do the reads. Um it turns out that it um in order to maintain locks since just as um as in last week's 603 reading um every time you read or write a data item the um server responsible for it has to associate a lock with that data item. Um the locks are maintained the read locks in spanner are maintained only in the paxos leader. So uh when the client transaction wants to readex, it sends a redex request to um the leader of X's shard and uh that leader of X's shard returns the current value of X plus sets a lock on X. Um and of course if the lock's already set, then it won't respond to the client until whatever transaction currently has the data locked releases the lock by committing. Um, and then the leader for that shard uh sends back the value of x to the client. The client needs to read y. Got lucky this time because the um assuming the client's in data center one. The leaders in the local data center. So this read's going to be a lot faster. Um the read sets the lock on y in the paxos leader and then returns. Okay. So now the client's done all the reads. it does internal computations and figures out the writes it wants to do, what values it wants to write to X and Y. Um, and so now the client's going to send out the updated values for the records um that it wants to write and it does this all at once at the end towards the end of the transaction. Um, so the first thing it does is it chooses one of the Paxos groups to act as the transaction coordinator. um and it has to it chooses this in advance and it's going to send out the identity of the which Paxos group is going to act as the transaction coordinator. So let's assume it chooses this Paxos group. I'll just put a double box here to say that not only is this server the leader of its Paxos group, it's also acting as transaction coordinator for this transaction. Then the client sends out the um updated values that it wants to write. So it's going to send a right x a right x request here with a new value and the identity of the transaction coordinator. Um when each um the Paxos leader for each written value receives the right request, it um uh sends out a prepare message to its followers and gets that into the Paxos log. So that um I'll represent that by P into the Paxus log because it's going to commit to being able to or commit the wrong word. it's promising to be able to carry out this transaction that it hasn't crashed for example and lost its locks. Um so it sends out this prepare message. It logs the prepare message through Paxos when it gets a majority of responses from the followers. Um then this Paxos leader sends a yes to the transaction coordinator saying yes um I am promising to be able to carry out my part of the transaction the right to Y. Um the and um notionally the transaction the let's see the client also sends the value to be written to Y to um uh Y's Paxos leader and this server acting as Paxos leader sends out prepare messages um to his followers and logs it and Paxos and waits for the acknowledgements from majority already. Um and then you can think of it as as the Paxos leaders sending the um transaction coordinator which is on the same machine maybe the same program a yes vote saying yes I can I can commit. Okay. So when the transaction coordinator um gets responses from all the different from the leaders of all the different shards whose data um is involved in this transaction. If they all said yes, then the transaction coordinator can commit, otherwise it can't. Um, let's assume it decides to commit. Um, at that point, the transaction coordinator sends out um to the Paxos followers a commit message saying, "Look, um, please remember that permanently in the transaction log that um, we're committing this transaction. Um and it also tells the um leaders of the other Paxos groups involved in the transaction then they can commit as well. And so now um this leader sends out commit messages to his followers as well. as soon as the commits are um actually I think the leader the transaction coordinator probably doesn't send out the commit message to the other shards until its commit is safe in the log so that the transaction coordinator is not guaranteed not to forget its decision. Um once commits these commit messages are committed into the Paxos logs of the different shards, each of those shards can actually execute the rights that is place the written data um and release the locks on um the data items so that other transactions can use them. Um and then the transactions over. So um first of all please feel free to ask questions if uh um by raising your hand if you if you have questions. Okay. So there's some points um to observe about the design so far which is you know only covered the readr aspect of transactions. One is that it's the the locking that is ensuring serializability. that is if two transactions conflict because they use the same data, one has to completely wait for the other to release it locks before it can proceed. So it's using so Spanner is using completely standard two-phase locking um in order to get serializability and completely standard two-phase commit to get distributed transactions. The two-face commits widely hated um because if the transaction coordinator should fail or become unreachable then any transactions it was um managing block indefinitely until the transaction coordinator comes back up and they block with locks held. So people have been in general very reluctant to use two-phase commit in the real world because it's blocking. Spanner solves this by replicating the transaction manager. The transaction manager itself is a Paxos replicated state machine. So everything it does like for example remember whether it's committed or not is replicated into the Paxos log. So if the uh leader here fails um even though it was managing the transaction because it's raft replicated either of these two replicas can spring to life take over leadership and also take over um being the transaction manager and they'll have in their log if the transaction manager decided to commit. any leader that takes over will see a commit in its log and be able to then tell the other right away tell the other um participants in the two-face commit that look oh this transaction was committed. So this effectively eliminates the um problem with two-face commit that it can block with locks held if there's a failure. Um and this is a really big deal because this problem basically makes two-face commit otherwise completely unacceptable for any sort of large scale system that has a lot of parts that might fail. The other another thing to note is that there's a huge amount of messages on um in this diagram here. Um and that means and many of them are across data centers. And so some of these messages that go between the shards or between a client and the shard whose leader is another data center may take many milliseconds. Um and in a world in which you know computations take nanconds this is uh a potentially pretty grim expense. Um and indeed you can see that in from in table six and table six if you look at it it's describing the performance of a um Spanner deployment where the different replicas are on different sides of the United States east and west coast and um it takes about a 100 milliseconds to do a um complete a transaction where the different replicas involved are on different coasts. That's a huge amount of time. That's a tenth of a second. Um it's maybe not quite as bad as it may seem because the throughput of the system since it's sharded and it can run a lot of non-conlicting transactions in parallel the throughput may be very hard high um but the delay for individual transactions very significant I mean 100 milliseconds is maybe somewhat less than a human is going to notice but if you have to do a couple of them um to say generate a web page or carry out a human instruction it's starting to be an amount of time that will be noticeable and start to be bothering bothersome Um on the other hand for I think I suspect for many uses of Spanner all the replicas might be in um in the same city or sort of across town and there the much faster times that you can see in table three um are relevant and there it's table three shows that it can um complete transactions where the data centers are nearby in you know I think it's 14 milliseconds instead of 100 milliseconds so that's not quite so bad. Um, nevertheless, these read write transactions are slow enough that we like to avoid um the expense if we possibly can. Um, and so that's going to take us to read only transactions. It turns out that if you're not writing, that is if you know in advance that all of the operations in a transaction are guaranteed to be reads, then Spanner has a much faster, much more streamlined, much less meth message intensive scheme um for executing readonly transactions. Okay. So, so readonly transactions um start a new topic here. The read only transactions work although they rely on some information from readwrite transactions. The design is quite different from um the read the readwrite transactions. Um and Spanner eliminates two big costs um in its readonly transaction design. Eliminates two of the costs that were present in readwrite transactions. First of all, as I mentioned, it reads from local replicas. Um and so if you have a replica as long as there's a replica the data the client needs the transaction needs in the local data center you can do the read and uh from that local replica which may take a small fraction of a m millisecond to talk to instead of maybe dozens of of milliseconds if you have to go cross country. So it can read from local replicas. Um but note you know again the danger here is that any given replica may not be up to date. Um so there has to be a story for that. And the other big um savings in the readonly design is that it doesn't use locks. It doesn't use two-face commit. Um and it doesn't need a transaction manager. Um and this avoids things like cross data center or inter data center messages uh to Paxos leaders. Um and because no locks are taken out, not only does that make the readonly transactions faster, but it avoids slowing down read only read write transactions because they don't have to rate for locks held by readonly transactions. Um and just to kind of preview why this is important to them, uh tables three and six show a 10 times latency improvement for readonly transactions compared to readwrite transactions. Um so the readonly design gets them a factor of 10 boost in latency. Um and then much less complexity. So almost certainly far more throughput as well. And the big challenge is going to be how to square the uh you know realign transactions don't do a lot of things that were require required on read read transactions to get serializability. Um so we need to f uh they needed to find a way to kind of square this increased efficiency with correctness. Um and so there's really two uh main correctness constraints that they wanted to um have read only transactions imposed. The first is that they like all transactions they still need to be serializable. Um and what that means is that um even though just to review even though uh the system may execute transactions concurrently in parallel um the results that a bunch of concurrent transactions must yield both in terms of sort of values that they return to the client and modifications to the database. the results of a bunch of concurrence transactions must be the same as some one at a time or serial u execution of those transactions. Um, and for readonly transactions, what that essentially means is that the an entire all the reads of a readonly transaction must effectively fit neatly between um all the rights of a bunch of transactions that um can be viewed as going before it and and it must not see any of the rights of the transactions that we're going to view as as going after it. So we need a way to sort of fit the read all the reads of a transaction read only transaction kind of neatly between readrs. Um the other big uh constraint that the paper talks about is that they want external consistency. Um and what this means um it's actually uh equivalent to um linearizability that we've seen before. What this really means is that if one transaction commits, finishes committing and another transaction starts after the first transaction completed in real time um then the second transactions required to see the rights done by the first transaction. Another way of putting that is that transactions even readonly transactions should not see stale data. You know, if there's a committed write from a completed transaction that's prior to the read only transaction, prior to the start of the read only transaction, the readine transaction is required to see that right. Um okay, so um this is actually none of neither of these is particularly surprising. the standard databases some like my SQL or something for example um um can be configured to provide this kind of consistency. So in a way it's sort of the consistency that if you didn't know better this is exactly the consistency that you would expect of a of a straightforward system. Um and the you know you don't have to have it but it makes programmers lives it makes it much easier to uh produce correct answers you know otherwise the if you don't have this kind of consistency then the programmers are responsible for kind of programming around whatever anomalies the database may provide. So this is like a this is sort of the gold standard of of correctness. Okay. So um let's I want to going to talk about how read only transactions work. It's a bit of a complex story. So, um I think what I'd like to talk about first is to just um consider what would happen if we did just absolutely the stupidest thing and had the readonly transactions um not do anything special to achieve consistency, but just read the very latest copy of the data. So every time a readonly transaction does a read um we could just have it look at the local replica and find the current most up-to-date um copy of the data right that would be very straightforward um very low overhead. So we need to understand why that doesn't work um in order. So this is uh so why not read the just the the latest value. And so maybe we'll imagine that the transaction is a transaction that simply reads um X and Y and prints them. It's read only. We're going to print y and we'll just print x comma y. Okay. So um I want to show you an example of a situation in which um read having this transaction just simply read the latest value yields um incorrect not uh not serializable results. So so we have three transactions running t1, t2, t3. Um T3 is going to be our transaction. T1 and T2 are uh transactions that are are rewrite transactions. Um so let's say that uh T1 writes X and writes Y and then commits. And you know maybe it's a bank transfer operation. So it's transferring money from X to Y. And we're printing X and Y because we're doing an audit of the bank to try to make sure it hasn't lost money. Let's imagine that transaction two um also does another transfer between uh balances X and Y and then commits. And now we have our transaction transaction T3. It's it needs to read X and Y. Um so it's going to have a read of X. Let's say the read of X um happens at this point in time. And so I'm uh the way I'm drawing these diagrams is that real time moves to the right. wall clock time, the kind of time you'd see on your watch moves to the right. So the read of X happens here after transaction one completes before transaction two starts. Um and let's say T3 is running on a slow computer. So it only manages to issue the read of Y uh much later. So the way this is going to play out is that transaction 3 will see the y value that t1 wrote but the x value that t2 wrote. Um assuming it uses this uh dubious procedure of simply reading the latest value that's in the database. Um, and so this is not serializable because um, well, we know that any serial order that could exist must have um, T1 uh, followed by T2. There's only two places T3 could go. So T3 could go here. Um but T3 can't fit here because if T3 was second in the equivalent serial order then it shouldn't see rights by T2 which comes after it. It should see um the value of Y produced by T1 but it doesn't right it sees the value produced by T3 by T2. So this is not an equivalent. This serial order wouldn't produce the same results. The only other one available to us is this one. um this serial order would get the same value for y that t3 actually produced but um if this was the serial order then t3 should have seen the value written by t2 but it actually saw the value written by t1. So this execution is not equivalent to any one at a time serial order. So um this is like there's something broken um about read simply reading the latest value. So we know that doesn't work. You know what we're really looking for of course is that either the our our transaction either reads the uh both values at this point in time or it reads both values at this point in time. Um okay. So um the uh approach that um expand our taste of this it's it's a somewhat complex. Um the first big idea is an existing idea. Um it's called snapshot isolation. And um the way I'm going to describe this is that um let's imagine that all the computers involved had synchronized clocks. That is the you know they all have a clock the clock yields uh yields a sort of wall clock time like oh it's um 1:43 in the afternoon on uh April 7th 2020. So that's what we mean by it a wall clock time a time. So let's assume that all the computers assume even though this isn't true that all the computers involved have uh synchronized times. Furthermore, let's imagine that every transaction is assigned a particular time, a time stamp. Um, and um, okay. So, we have these timestamps there. There are wall clocks times taken from these synchronized clocks for read write transaction. its time stamp is um I'm going to say just for this uh for this simplified design is the real time at um at the commit and for read for a um or at the time at uh which the transaction manager starts the commit and for a readonly transaction um that time stamp is equal to the start time. Um all right so every transaction has a time and we're going to design our system our snapshot isolation system gets is designed to execute as if to get the same results as if all the transactions had executed in timestamp order. So we're going to assign the transactions each transaction a time stamp and then we're going to arrange the executions so that um the transactions get the results as if they had executed in that order. So given the time stamps, we sort of need to um have an implementation that will kind of basically honor the timestamps um and basically you know show each transaction the data sort of as it existed at at its um time stamp. Okay. So the way that this works um uh for readonly transactions um is that each replica when it stores data it actually has multiple versions of the data. Um so we have a multiple version um database every database record has um you know maybe if it's been written a couple times it has a separate copy of that record for each of the times it's been written each one of them associated with the um timestamp of the transaction that wrote it. Um and um then the basic strategy is that readonly transactions when they when a readonly transaction does a read it's already allocated itself a time stamp um when it started and so it accompanies its read request with its time stamp and the whatever uh server um you know that stores the replica of the data that the transaction needs. It's going to look into its multi-version database and find the um record that's being asked for that has the highest time that's still less than the time stamp um specified by the readonly transaction. So that means it be only transaction sort of sees data the latest data as of the time as of its time chosen time stamp. Um okay so this is for um this snapshot isolation idea works for readonly transactions or Spanner uses it for readonly transactions. Spanner uses still uses um two-phase locking and two-phase commit for read write transactions. And so the readr transactions allocate timestamps for themselves at commit time but other than that they work in the usual way with locks and two-phase commit. Whereas the readonly transactions um access the multiple versions in the database and get the version that's you know written by the um has the time stamp that's highest but still less than the readonly transactions time stamp. And where this is going to get us is that you know readon transactions will see all the rights of of readwrite transactions with lower time stamps and none of the writes of rewrite transactions with higher time time stamps. Um okay. So, uh how would snapshot isolation um work out for our example? Um um the example that I had here before in which um we had a failure of serial serializability because um the reading transaction um read before read values that were not between any two of the readrite transactions. Okay. So this is now our example but with um snapshot isolation. I'm showing you this to show that the snapshot isolation technique um solves our problem causes the readonly transaction to uh be serializable. So again we have these two read write transactions T1 and T2 and we have our transaction that's a readonly transaction T1 and T2 um uh write as before they write and they commit um but now they're allocating themselves timestamps as of the commit time. So um in addition to using two-phase commit and two-face locking, these rewrite transactions allocate a time stamp. So let's imagine that at uh the time of the commit, T1 looked at the clock and saw that it um the time was 10. And I'm going to use times of 10 and 20 and whatnot. Um but you know, you should imagine times as being real times like 4:00 in the morning on a given day. So um let's say that T1 sees the time as 10 when it committed. Um and T2 um sees that at the commit time the time was 20. So I'm going to write these transactions chosen time stamp after the at sign. Um then the uh database uh storage systems the spanner storage systems are going to store um when transaction one does its writes they're going to store a new sort of not instead of overwriting the current value they're just going to add a new copy of this record u with the time stamp. So it's going to the database is going to store away a new record that says the value of x at time 10 is whatever it happens to be let's say nine. The value of uh record y at time 10 is say 11. Maybe we're doing a transfer from x to y. Similarly t2 chose time stamp of 20 because that was the real time at commit time and the database is going to remember a new set of records in addition um to these old ones. just going to say x at time 20 um if we did a another transfer from x to y and y at time 20 equals 12. So now I have two copies of each record at different times. Now t transaction 3 is going to come along and again it starts um at about this time and does a read of x and again it's going to be slow so you know it's not going to get around to reading y until much later much later in real time however when transaction 3 started it chose a timestamp by looking at the uh looking at the current time and and so let's say so we know in real time that transaction 3 started after transaction one and before transaction two, we know it's got to have chosen a transaction time somewhere between 10 and 20. Um, and let's suppose it started at time 15 and chose time stamp 15 for itself. So that mean when it does the read of X, it's going to send a a request to the local replica that holds X and it's going to accompany it with it time stamp of 15. It's going to say, please give me the latest data as of time 15. Um but of course transaction two hasn't executed yet and but nevertheless the highest time stamp copy of X um is the one from time 10 written by transaction one. So we're going to get um nine for this one. Time passes. Transaction two commits. Now transaction three does it second read. Again it accompanies it the read request with its own time stamp of 15. Sends it to the servers. Now the servers have two records. But again, because the server gets transaction 3's time stamp of 15, it looks at its records and say, "Ha, 15 sits between these two, I'm going to return the highest time stamp record for X for Y." Um, that's less than the requested time stamp, and that's still uh the version of Y from time 10. So, the read of Y will return 11. That is the read of X essentially happens at this time. But because we remembered a time stamp and we have the database keep data as of um different times it was written, it's as if both reads happened um at time 15 instead of one at time 15 and one later. Um and now you'll see that in fact this just essentially emulates a serial one at a time execution in which the order is timestamp order. transaction one, then transaction two, sorry, then transaction three, then transaction two. That is the serial order that is equivalent to the results that were actually produced is the time stamp order of 10, 15, 20. All right. Um, okay. So, that's a kind of simplified version of what Spanner does for readonly transactions. Um there's more complexity which I'll get to in a minute. Um one question you might have is why it was okay for transaction 3 to read an old value of Y. That is it issued this read of Y at this point in time. The freshest data for Y was this value 12. But the value it actually got was intentionally a stale value. Not the freshest value but the value from a while ago. this value 11. So why is that okay? Why is it okay not to be using the freshest um version of the data and um the kind of technical justification for that is that transaction two and transaction 3 are concurrent that is they overlap in time. So the sort of time extent of transaction two is here and the time extent of transaction three is here. they're concurrent and the rules for linearizability and external consistency are that if two transactions are concurrent um then the serial order that the database is allowed to use can be can put the two transactions in either order and here the database spanner has chosen to put transaction three before transaction two in the serial order. Okay, I think we Robert, we Yeah, we have a student question. Does external consistency like with time stamps always imply strong consistency? Um, uh, I'm going to guess. Um, I think so. if strong consistency um strong consistency usually what people mean by that is a linearizability and I believe the definition of linearizability and uh external consistency are the same. So I would say yes and another question how does this not absolutely blow up storage? That is a great question and the answer is it definitely blows up storage and the reason is that um now the storage system has to keep multiple copies um of data records that have been recently modified multiple times. Um and that's definitely expense both um both this cost in storage and space on the disk and in memory and also it's just like an added layer of bookkeeping um you know now lookups have to consider the time stamps as well as keys. Um the storage expense I think is um not as great as it could be because the system discards old records. The paper does not say what the policy is. Um but presumably well it must be discarding old records. Um certainly if the only reason for the multiple records is to implement snapshot isolation of these kinds of transactions then you don't really need to remember values too far in the past. um because um you only need to remember values back to the sort of earliest time that a that a transaction could have started at that's still running now. And if your transactions mostly are always finish or force to finish by killing them or something um within say one minute. If no transaction can take longer than a minute, then you only have to remember the last minute of of versions in the database. Now, in fact, the paper implies that they remember data farther back than that because it um appears they support intentionally support um these snapshot reads which allow them to support the notion of seeing, you know, data from a while ago, you know, yesterday or something. Um but they don't say what the what the garbage collection policy is for old values. So I don't know how expensive it would be for them. Okay. Okay. So the uh the the justification for why it's legal is that in external consistency the the only rule that external consistency imposes is that if one transaction has completed then a transaction that starts after it must see its rights. So T1 maybe T1 completed. Let's say that T1 completed at this time and T3 started just after it. Maybe external consistency would demand that T3 sees T1's rights. But since T2 definitely didn't finish before T3 started, we have no obligation under external consistency for T3 to see T2's rights. And indeed the in this example, it does not. So it's actually legal. Um okay another problem that comes up um is that uh the transaction T3 is needs to read data as of a particular time stamp but um you know the reason why this is desirable is that we're it allows us to read from the local replica in the same data center but maybe that local replica is in a minority of Paxos followers that didn't see the latest log records the leader so maybe our local replica uh maybe it's never even seen, you know, never saw these rights to X and Y at all. It's still back at a version from time, you know, five or six or seven. Um and so if we don't do something clever when we ask for the sort of highest version uh record, you know, less than time stamp 15, we may get some much older version that's not actually the value produced by transaction one, which we're required to see. Um so the way Spanner deals with this is with their notion of safe time. Um and uh the scoop is that each replica remembers you know it's getting log records from its Paxos's leader and the log records um it turns out that the paper arranges so that the leader sends out log records in strictly increasing timestamp order. So a replica can look at the very last log record it's gotten from its leader to know uh how up to date it is. So um if I ask for a value as of time stamp 15, but the um replica has only gotten log entries from a paxos leader up through time stamp 13, the replica is going to make us delay. It's not going to answer um until it's gotten a log record with time stamp 15 from the leader. Um, and this ensures that replicas don't answer um, a request for a given time stamp until they're guaranteed to know everything from the leader um, up through that time stamp. And so this may delay um, this may delay the reads. Okay. Um so the next question I've been assuming I assumed in this discussion that the clocks and all the different servers are perfectly synchronized. So everybody's clock says you know 10:01 and 30 seconds at exactly the same time. Um but it turns out that you can't um synchronize clocks that precisely. um you it's basically impossible to get perfectly synchronized clocks. Um and the reasons are uh reasonably fundamental. Um so the topic is time synchronization. Just sort of making sure clocks say the same real time value. Different clocks read the same value. Um the um um I'll I'll the sort of fundamental problem is that time is defined as basically the time it says on a collection of highly accurate expensive clocks in a set of government laboratories. So we can't directly read them. All that we can know is that um these government laboratories can broadcast the time in various ways. Um and uh the broadcasts take time and so at some time later some possibly unknown time later we hear these announcements of what the time is and we all may all hear these announcements at different times due to varying delays. Um so um actually first I want to consider the problem of what the impact is if on snapshot isolation um if the clocks are not synchronized which they won't be. Okay. So what if clocks aren't synced? Um there's actually no problem at all for the spanner's readwrite transactions because the readwrite transactions use locks and two-phase commit. Um they're not actually using snapshot isolation. So they don't care. So the readwrite transactions will still be serialized by the lock the two-phase locking mechanism. Um so we're only interested in what happens for an for readonly transaction. Um so let's suppose a readonly transaction um uh chooses a time stamp that is too large. So that is far in the future. You know it's now 12:01 p.m. and it chooses a time stamp at say 1:00 p.m. Um so if a transaction's chosen time stamps too big um that's actually not that bad. Um what it'll mean is that it'll do read requests. It'll send a read request to some um replica. The replica will say, "Wait a minute, your you know your clock is far is far greater. Your time stamp is far greater than the last log entry I saw from my Paxos leader. So I'm going to make you wait until the Paxos the time and the log entry from the Paxos leader catches up to the time you've requested. I'm only going to respond then." So this is correct but slow. The reader will be forced to wait. Um but that's not the worst thing in the world. But what happens if we have a readonly transaction um and its time stamp is too small. Um and this would correspond to its clock being well either set wrong so that it's set in the past or maybe it was originally set correctly but the clock its clock ticks too slowly. Um the problem with this this is a obviously causes a correctness problem. This will cause a violation of external consistency because um the multi-verion databases you'll give it a time stamp that's far in the past say an hour ago and the database will read you a value associated with it the time stamp from an hour ago which may ignore more recent writes. So using a assigning a time stamp to a transaction that's too small will cause you to miss recent committed rights. Um, and that's a violation of external consistency. So, not not externally consistent. So, um, so we actually have a problem here. Um, the assumption that the clocks were synchronized is in fact a a very serious assumption. And the fact that you cannot count on it means that unless we do something, um, the system's going to be incorrect. All right. So um so can we synchronize clocks perfectly? Right. That would be the ideal thing. Um and if not why not? So um so what about clock synchronization? the uh as I mentioned um where time comes from is a it's actually collection of the kind of median of a collection of clocks in government labs um the way that we hear about time is that it's broadcast by various protocols sometimes by radio protocols like basically what GPS is doing for Spanner is a GPS acts as a radio broadcast system that broadcasts the current time from some government lab through the GPS satellite ites to GPS receivers sitting in the um uh Google machine rooms. And there's a number of other radio protocols like WWB is another older radio protocol for broadcasting the current time. And there's newer protocols like there's this NTP protocol that operates over the uh um uh internet that also is in charge of um basically broadcasting time. So the sort of system diagram is that um there's some government labs and the government labs uh with their accurate clocks define a universal notion of time that's called UTC. So we have UTC coming from some clocks and some labs. Then we have um some you know radio or internet broadcast or something. For the case of um um spanner, it's the we can think of the government labs broadcasting to GPS satellites. Um the satellites in turn broadcast and they broadcast to you know the millions of GPS receivers that are out there. Um you can uh buy GPS receivers for you know a couple hundred bucks that will decode the timestamps in the um in the uh GPS signals and sort of keep you up to date with exactly what uh the time is corrected for the propagation delay between the government labs and the GPS satellites and also corrected for the delay between the GPS satellites and your current position. Um and then there's um in each data center there's a GPS receiver um that's connected up to what the paper calls a time master which is some server. There's going to be more than one of these for data center in case one fails. Um and then there's all the hundreds of servers in the data center that are running Spanner either as servers or as clients. Um each one of them is going to um periodically send a request saying oh what time is it to the local one or more usually more than one in case one fails to the time masters and the time master will reply with oh you know I think the current time as received from GPS is such and such. Um now um built into this unfortunately is a certain amount of uncertainty. Um and the primary sources of uncertainty I think well there's there's fundamentally uncertainty in that we don't actually know how far we are for the G from the GPS satellites exactly. Um so the you know radio signals take some amount of time even if the GPS satellite knew exactly what time it is. The signals take some time to get to our GPS receiver. If we're not sure what that is, that means that when the G we get a a message from the radio message from the GPS satellite saying exactly 12:00, you know, if the propagation delay might have been, you know, a couple of nanconds, that means that we're uh actually the propagation delay is much more than that. It's really the uncertainty in the propagation delay. Um means that we're not really sure exactly whether it's 12:00 or a little before, a little after. In addition, um all the times that time is communicated, there's added uncertainty um that you have to account for. And in the biggest sources are that when a server sends a request after a while, it gets a response. If the response says it's exactly 12 o'clock, but um the amount but say a second pass, you know, between when the server sent the request and when it got the response, all the server knows is that even if the master had the correct time, all the server knows is that um the time is within a second of 12:00. um because maybe the maybe the request was instant but the reply was delayed or maybe the request was delayed by a second and the response was instant. So all we really know is that it's between you know 12:00 and 0 seconds and 12:00 and 1 second. Um, okay. So, um, there's always this uncertainty. Um, and in order to, which we really can't ignore though, because the uncertainties, we're talking about milliseconds here. Um, and we're going to find out that these that the uncertainty in the time goes directly to the these how long these safe weights have to be and how long some other pauses have to be, the commit weight, as we'll see. Um uh so you know uncertainty on the level of milliseconds is a serious problem. The other big uncertainty is that each of these servers only requests the current time from the master every once in a while say every minute or however often. Um and between that the each server runs its own local clock that sort of keeps the time starting with the last time from the master. those local clocks are actually pretty bad um and can drift by things by milliseconds between times that the server talks to the master um and so the system has to sort of add the the unknown um but estimated drift of the local clock um to the uncertainty of the time. So um in order to capture this uncertainty and account for it, uh um Spanner uses this true time scheme in which when you ask what time it is, what you actually get back is one of these TT interval things which is a pair um of an earliest time and a latest earliest time is the ear early um earliest the time could possibly be and the second is the latest the time can possibly be. Um so when the application you know makes this library call that asks for the time it gets back this pair all it knows is that the current time is somewhere between earliest and latest and so you know earliest might be in this case earliest might be 12:00 and latest might be 12:00 and 1 second just um are guaranteed that the that the correct time isn't less than earliest and isn't greater than latest. Well, we don't know where between that it lies. Okay, so this is what um when a transaction asks the system what time it is, this is this is what the transaction actually gets back from the time system. And now um let's return our original problem was that if the clock was too slow that a uh readonly transaction might read data too far in the past and that it wouldn't read data from a recent committed transaction. So we need to know what we're looking for is how um Spanner uses these TT intervals and its notion of true time in order to ensure that despite uncertainty on what time it is um transaction uh obey external consistency that is a read only transaction is guaranteed to see um rights done by a transaction rate uh transaction that completed before us. And there are um two rules that the paper talks about that conspire to um force this and the two rules which are in section 412. One of them is the start rule and the other is uh commit weight. The sort rule tells us what um time stamps transaction what time stamps transactions choose. Um and basically says that a transactions time stamp has to be equal to the latest half of the um true time current time. So this is tt.now call which returns one of those earliest latest pairs. That's the current time and a transactions time stamp has to be the latest that is it's going to be a time that's guaranteed not to have happened yet because the true time is between earliest and latest. Um and for a uh readon transaction um it's assigned the latest time as of um it's the time it starts and for a read write transaction it's assigned a time stamp um this latest value as of the time it starts to commit. Um okay so the start rule says this is how Spanner chooses time stamps. The commit weight rule um only for readwrite transactions uh says that um when a a transaction coordinator is uh you know collects the votes and sees that it's able to commit and and chooses a time stamp after it chooses this time stamp it's required to delay to wait a certain amount of time before it's allowed to actually commit and write the values and release locks. Um so a readwrite transaction um has to delay until um its time stamps that it chose when it was starting to think about commit is less than the current time um earliest. Sorry. So what's going on here is that it sits in a loop calling ts.now now and it stays in that loop until the time stamp that it had chosen at the beginning of the commit process is less than the current time's earliest half. And what this guarantees is that um since now the earliest possible correct time is greater than the transaction's time stamp. That means that um when this loop is finished, when the commit weight is finished, this time stamp of the transaction is absolutely guaranteed to be in the past. Okay. So, um how does the system actually make use of these two rules um in order to enforce um external consistency for read only transactions? I want to go back to our or I want to um um cook up a uh somewhat simplified uh scenario in order to illustrate this. Um so I'm going to imagine that the writing transactions only do one write each just to reduce the complexity. Let's say that there's two uh readwrite transactions. So we have T0 and T1 are readwrite transactions and um they both write X and we have a T2 which is going to read X and we want to make sure that T2 sees um you know it's going to use snapshot isolation at time stamps. We want to make sure that it sees the latest written value. Um so we're going to imagine that T2 does a write of X and writes one to X um and then commits We're going to imagine that um sorry T1 writes X and commit. T2 also writes X writes a value two to X. Um and we need to distinguish between prepare and commit. So we're going to say it it's really a prepare that the transaction chooses its uh time stamp. So this is the point at which it chooses its time stamp and then it commits sometime later. Um and then we're imagining by assumption that T2 starts after T1 finishes. So it's going to read X um afterwards and we want to make sure it sees two. All right. So um let's suppose that uh T0 chooses a time stamp of one. Um commits writes the database. Let's say t1 starts um at the time it chooses a time stamp it it's going to get some it's not get a single number from the two time system really gets a range of numbers um you know an earliest and a latest value. Let's say at the time it chooses its time stamp, it um the range of values, the earliest uh time it gets is one and the latest field in the current time is 10. Um so the uh the rule says that it must choose 10. The latest value is it time stamp. So T1 is going to commit with time stamp 10. Now, it can't commit yet because the commit wait rule says it has to wait until its time stamp is guaranteed to be in the past. So, uh transaction one is going to sit there keep asking what time is it? What time is it until it gets an interval back um that doesn't include time 10. So, at some point um it's going to ask what time it is and it's going to get a time that where the earliest value is 11 and the latest is I don't know what I'd say 20. And now it's going to say aha now I know that my time stamp is guaranteed to be in the past and I can commit. Uh so T1 will actually this is its commit weight period to sit there and uh wait for a while before it commits. Okay. Now after commits uh transaction 2 comes along and wants to read X. It's going to choose a time stamp. Also um we're assuming that it starts after T1 finishes because that's an interesting scenario for external consistency. So let's say when it asks for the time um it asks at a time after time 11. So it's going to get back an interval that includes time 11. Um so let's suppose it gets back an interval that um goes from time 10 the earliest and time uh 12 uh to latest. And of course the time 12 has to be since we know that uh must be at least time 11 since transaction two started after transaction one finished um that means that the 11 must be less than the latest value. Um transaction two is going to choose its latest half as its time stamp. So it's going to actually choose time stamp 12. Um, and in this example, when it does its read, it's going to ask the storage system, oh, I want to read as of time stamp 12. Um, since transaction one wrote with time stamp 10, that means that, you know, assuming the safe weight, uh, the safe time machinery works, we're actually going to read the correct value. Um, and what's going on here is that um the so so this happened to work out, but indeed it's guaranteed to work out if transaction two as long as transaction two starts after transaction one commits. And the reason is that commit weight causes transaction one not to finish committing until its time stamp is guaranteed to be in the past. Right? So transaction one chooses a time stamp. It's guaranteed to commit um at after that timestamp. Transaction two um starts after the commit. Um it and so we don't know anything about what its earliest value will be, but its latest value is guaranteed to be after the current time. But we know that the current time is after the commit time of T1. um and therefore that T2's latest value uh the time stamp it chooses is guaranteed to be after um when C committed and therefore after the uh time stamp that C used um and because transaction two if transaction 2 starts after T1 finishes transaction 2 is guaranteed to get a higher time stamp um and the snapshot isolation machinery the multiple versions will cause it to read um to it's read to see all lower valued rights from all lower time stamp transactions. That means T2 is going to see T1 and that basically means that we're this this is how Spanner enforces um external consistency for its transactions. So any questions about this machinery? All right. Um I want to step back a little bit. Um there's really um from a my point of view sort of two big things going on here. One is snapshot isolation by itself. Um snapshot isolation by itself is enough to give you that is keeping the multiple versions and giving every transaction a time stamp. Snapshot isolation is guaranteed to give you serializable readonly transactions because basically what snapshot isolation means is that we're going to use these timestamps as the equivalent serial order and things like the safe weight the safe time um ensure that readon transactions really do read as of their time stamps see every readr transaction before that and none after that. Um so there's really two pieces. Snapshot isolation um snapshot isolation by itself though uh is actually often used not just by Spanner but generally doesn't um by itself guarantee external consistency because in a distributed system it's different computers choosing the time stamps. So we're not sure those timestamps will obey external consistency even if though they'll deliver serializability. So in addition to snapshot isolation, uh Spanner also has synchronized timestamps and it's the synchronized timestamps um plus the commit weight rule that um allow Spanner to guarantee external consistency as well as serializability. Um and again the reason why all this is interesting is that programmers really like transactions and they really like external consistency because it makes applications much easier to write. um they traditionally not been provided in distributed settings because they're too slow. And so the fact that Spanner manages to at least make readonly transactions very fast is extremely attractive, right? No locking, no two-phase commit, and not even any distant reads for readonly transactions. They operate very efficiently from the local replicas. And again, this is what's good for a basically a 10 factor of 10 uh latency improvement um as measured in tables uh three and six. But just to remind you, it's it's not all um it's not all fabulous. The the the all all this wonderful machine only applies to read only transactions. Read transactions still uh use two-face commit and locks. Um and there's a number of cases in which even spanner will have to block like due to the safe time and the commit weight. Um but as long as their times are accurate enough uh these uh commit weights are likely to be um relatively small. Okay, just to summarize, the um Spanner at the time was um kind of a breakthrough because it was very rare to see deployed systems that um offer you distributed transactions where the data was um geographically uh in uh very different data centers. Um and surprising, you know, Spanner people were surprised that uh somebody was using a database that actually did a good job of this um and that the performance was tolerable. um and the snapshot isolation and the timestamping part of the um probably the most interesting aspects of the paper. Um and that is all I have to say for today. Um any last questions? Okay. Um I think on Thursday we're gonna we're going to see farm which is a sort of very different um slice through the desire to provide very high performance transactions. Um, so I'll see you all on