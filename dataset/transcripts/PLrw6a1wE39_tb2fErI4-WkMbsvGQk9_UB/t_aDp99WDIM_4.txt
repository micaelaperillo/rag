all right today's topic is distributed transactions and these come in really to implementation pieces and that's how I'll cover them the first big piece of concurrency control the second is atomic commit and the reason why distributive transactions come up is that it's very frequent for people with large amounts of data to end up splitting or sharding the data over many different servers so maybe if you're running a bank for example the bank balances for half your customers are one server and the bank balances for the other half are on a different server let's do it like split the load both the processing load and the space requirements this comes up for other things too maybe you're recording vote counts on articles at a website you know the maybe there's so many millions millions of articles half the vote counts are and are on one server and half the vote cancer or another but some operations require touching modifying or reading data on multiple different servers so if we're doing a bank transfer from one customer into another well their balances may be on different servers and therefore in order to do the balance we have to modify data read and write data on two different servers and we'd really like to or one way building these systems and we'll see others later on in the course one way to build the system just try to hide the complexity of splitting this data across multiple servers try to hide it from the application programmer and this is like traditionally has been a database concern for for many decades and so a lot of today's material originated with databases but the ideas have been used much more widely in distributed systems which you wouldn't necessarily call a traditional database the way people sort of usually package up concurrency control plus atomic commit is in abstraction called a transaction which we've seen before and the idea is that the programmer you know has a bunch of different operations may be on different records in the database they'd like all those operations to be sort of a single unit and not split by failures or by observation from other activities and the transaction processing system will require the programmer to mark the beginning and the end of that sequence of reading and writing and updating operations in order to mark the beginning and of the transaction and the transaction processing system has certainly will provide certain guarantees about what happens between the beginning and the end so for example supposing we're running our bank and we want to do a transfer from account of user X to the account of user wide now these balances from both of them start out as 10 so initially expose 10 y equals 10 and x and y I'm mean to be records in a database and we want to transfer we will actually imagine that there's two transactions that might be running at the same time one to transfer a dollar from account X to account Y and the other transaction to do an audit of of all the accounts at the bank to make sure that the total amount of money in the bank never changes because after all if you do transfers you know the total shouldn't change even if you move money between accounts in order to express this with transactions we might have two transactions the first transaction call it t1 is the transfer well mark the programmer is expected to mark the beginning of it with the begin transaction which all right at the beginning and then the operations on the two balances on the two records in the database so we might add [Music] one might add one the balance X and add -1 to Y and then we need to mark the end by the transaction currently we might have a transaction that's going to check all the balance do an audit of all the balances find the sum or look at all the balances make sure they add up to the number that doesn't change despite transfers so the second transaction I'm thinking about the audit transaction also we need to mark the beginning and end this time we're just reading there's a read-only transaction we need to get the current balances of all the accounts lists they were just these two accounts for now so we have two temporary variables we're gonna read the first one it's going to be the value of balance X just right get to mean we're reading that record we also read Y and we print them both and that's the end of the transaction the question is what are legal results from these two transactions that's the first thing we want to establish is what are you know given the starting state namely the two balances for ten dollars and what could be the final results after you've run both these transactions maybe at the same time so we need a notion of what would be correct and once we know that we need to be able to build machinery that will actually be able to execute these transactions and get only those correct answers despite concurrency and failures so first what's correctness well databases usually have a notion of correctness called acid or bb-8 is acid and it stands for atomic and this means that a transaction that has multiple steps you know maybe writes multiple different records if there's a failure despite failures either all of the right should be done or none of them it shouldn't be the case that a failure at an awkward time in the middle of a transaction should leave half the updates completed invisible and half the updates never done it's all or nothing so this is or not despite failures the C stands for consistent it's actually we're not going to worry about that that's usually meant to refer to the fact that database will enforce certain invariants declared by the application it's not really our concern today the I though it's quite important it usually stands for isolated and this is a really a property of whether or not two transactions that run at the same time can see each other's changes before the transactions have finished whether or not they can see sort of intermediate updates and from the middle of another transaction and your goal is no and the sort of technical specific thing that most people generally mean by isolation is that the transaction execution is serializable and I'll explain what that means in a bit but it boils down to transactions can't see each other's changes can't see intermediate states but only complete transaction results and the final D stands for durable and this means that after a transaction commits after the client or whatever program that submitted the transaction gets a reply back from the database saying yes you know we've executed your transaction the D in acid means that the transactions modifications the database will be durable that they'll still be there they won't be erased by a some sort of failure and in practice that means that stuff has to be written into some non-volatile storage persistent storage like a disk and so today you are in fact for this whole course really our concerns are going to revolve around good behavior with respect to failure good respect good behavior with respect to other from multiple parallel activities and making sure that the data is there still they are after even if something crashes so the most interesting part of this for us is the specific definition of ice of isolated or serializable so I'm going to lay that out before before talking about how it actually applies to these transactions so the ioan isolated is usually and the definition for this if a set of transactions executes you know concurrently more or less at the same time they you are the set of results and here the results refer to both the new database records created by any modifications the transactions might do and in addition any output that the transaction is produced so broader transactions these two adds since they change records their needs change records are part of the results and the output of this print statement is part of the results so the definition of serializable says the results are serializable if there exists some order of execution of the transactions so we're gonna say a specific execution parallel concurrent execution of transactions is serializable if there exists some serial order really emphasizing serial here a serial order of execution of those same transactions that yields the same result as the actual execution and the difference of here is the actual execution may have had a lot of parallelism in it but it's required to produce the same result as some one at a time execution of the same transactions and so the way you check whether an execution is serializable whether some concurrent execution is serializable is you look at the results and see if you can find actually some one at a time execution of the same transactions that does produce the same results so for our transaction up here there's only two orders there's only two one at a time serial orders available transaction 1 then transaction 2 or transaction 2 then transaction 1 and so we can just look at the results that they would produce if executed one at a time in each of these orders so if we execute t1 and then t2 then we get x equals 11 why equals 9 and this print statement since t1 executed first this print statement sees these two updated values and so it will print the string 11 9 the other possible order is that perhaps t2 ran first and then t1 and in that case t2 will see that 2 records before they were modified but the modifications will still take place since t1 runs later so the final results will again be x equals 11 y equal 9 but this time t2 sodded before our values so these are the two legal results for serializability and if we ever see anything else from running these two transactions at the same time we'll know that the database were running against does not provide serializable execution it's doing something else and so while we're thinking through what would happen if or what would happen if will always be against these AHA these are the only two legal results we better be doing something that produces one or the other it's interesting to note that there's more than one possible result depending on the actual order you if you you submit these two transactions at the same time you don't know whether it's gonna be t1 t2 or t2 t1 so you have to be willing to expect more than one possible legal result and as you have more or transactions running concurrently a more complicated there may be many many possible different correct results that are all serializable because of many many orders here that could be used to fulfill this requirement okay so now that we have a definition of correctness and we even know what all the possible results are we can ask a few questions so few what-if questions about how these could execute so for example suppose that the way the system actually executed this was that it started transaction 2 and got as far as just after reading X and then transaction one ran at this point and then after transaction one finished transaction to continue executing now it turns out in with different other transactions than this that might actually be legal but here we want to know if it's legal so we're wondering gosh if we actually executed that way what results will we get and are they the same as either of these two well if we execute transaction one here then t1 is gonna see value 10 t2 is gonna see the value after decrementing Y so t1 will be 10 t2 will be 9 and what this print will be 10 9 and that's neither of these two outputs here so that means executing in this way that I just drew is not serializable it would not be legal another interesting question is what if we started executing transaction 1 and we got as far as just after the first ad and then at that point all the transaction 2 executed right here so that would mean at this point X is value 11 the transaction 2 would read 1110 now print 1110 and 1110 is not one of these two legal values so this execution is also not legal for these two transactions so the reason why serializable serializability is a popular and useful definition of what it means for transactions to be correct for execution of transactions to be correct is that it's a very easy model for programmers you can write complicated transactions without having to worry about what else may be running in the system there may be lots of other transactions may be using the same date as you may be reading trying to read and write it at the same time there might be failures who knows but the guarantee here is that it's safe to write your transactions as if nothing else was happening because the final results have to be as if your transaction was executed by itself in this one-at-a-time order which is a very simple very nice programming model it's also nice that this definition allows truly parallel execution of transactions as long as they don't use the same data so we run into trouble here because these two transactions are both reading x and y but if they were using completely disjoint database records they could it turns out this definition allows you to build a database system that would execute transactions to use disjoint data completely in parallel and if you are a sharded system which is what we're sort of working up to today with the data different data is on different machines you can get true parallel speed-up because maybe one transaction executes Spira in the first shard on the first machine and the other in parallel on the second machine so there are opportunities here for for good performance before I dig into how to implement serializable transactions there's one more small point I want to bring up it turns out that one of the things we need to be able to cope with is that transactions may for one reason or another basically fail or decide to fail in the middle of the transaction and this is usually called an abort and you know for many transaction systems we need to be prepared to handle Oh what should happen if a transaction tries to access a record that doesn't exist or divides by zero or maybe you know since some transaction implementation schemes use locking maybe a transaction causes a locking deadlock and the only way to break the deadlock is to kill one of one or more of the transactions this participating in the deadlock so one of the things that's going to be kind of hanging in the background and will come up is the necessity of coping with transactions that all of a sudden in the middle decide they just cannot proceed and you know maybe really in the middle after they've done some work and started modifying things we need to be able to kind of back out of these transactions and undo any modifications they've made all right the implementation strategy for transactions for these asset transactions I'm gonna split into two big pieces but and talk about both of them the main topics in the lecture the first big implementation topic is concurrency control this is the main tool we use to provide serializability the current or isolation so concurrency control bias by its isolation from other concurrent transactions that might be trying to use the same data and the other big pieces I mentioned is atomic commit and this is what's going to help us deal with the possibility that oh yeah this transactions executing a long and it's may be modified X and then all of a sudden there's a failure and one of the server's involved but other servers that were maybe actually in other parts of the transaction that is if x and y are in different machines we need to be able to recover even if there's a partial failure of only some of the machines the transactions running off and the big tool people use for that is this atomic commit you'll talk about all right so first concurrency control there's really two classes two major approaches to concurrency control I'll talk about both during the course if they're just mean strategies the first strategy is a pessimistic usually called pessimist pessimistic concurrency control and this is usually locking we've all done locking in the labs in the context of go program so it turns out databases transaction processing systems also used locking and the idea here is U is the same as well you're quite familiar with this that before transaction uses any data it needs to acquire a lock on that data and if some other transactions already using the data the lock will be held and we'll have to wait before we can acquire the lock wait for the other transaction to finish and in pessimistic systems if there's locking conflicts somebody else has the lock it'll cause delays so you're sort of treating performance for correctness the other main approach is optimistic approaches the basic idea here is you don't worry about whether maybe some other transactions reading or writing the data at the same time as you you just go ahead and do whatever reads and writes you're gonna do although typically into some sort of temporary area and then only at the end you go and check whether actually maybe some other transaction might have been interfering and if there's no other transaction now you're done and you never had to go through any of the overhead or weighting of taking out locks the locks are reasonably expensive to manipulate but if somebody else was modifying the data in a conflicting way at the same time you were then you have to abort that transaction and we try and the abbreviation for this is often optimistic concurrency control um it turns out that under different circumstances these two strategies one can be faster than the other if conflicts are very frequent you probably actually want to use pessimistic concurrency control not because of conflicts are frequent you're gonna get a lot of aborts due to conflicts for optimistic seems if complex are rare than optimistic concurrency control can be faster because it completely avoids locking overhead today will be all about pessimistic concurrency control and then some later paper in particular farm in a couple weeks we'll deal with an optimistic scheme okay so today talking about pessimistic schemes refers basically to locking and in particular for today the reading was about two-phase locking which is the most common type of locking and the idea in two-phase locking for transactions is that transactions gonna use a bunch of Records like X&Y and our example the first rule is that you acquire a lock before using date any piece of data we're reading or writing any record and the second rule for transactions is that a transaction must hold any locks it acquires until after it commits or aborts you're not allowed to give up locks in the middle of the transaction you have to hold them all you can only accumulate them until you're done until after you're done so until Phoebe done so this is two-phase locking the phases are the phases which we acquire locks and then phase in which we just hold onto them until we're done so for two phase locking to sort of see why locking works your typical locking systems well there's a lot of variation typical locking systems associate a separate lock with each record in the database with each row in each table for example although they can be more more coarse-grained these transactions start out holding no locks let's say transaction one starts out holding no locks when it first uses X before so I'll have to use it it has to acquire the lock on X and it may have to wait and when it first uses Y it acquires another lock the lock on Y when it finishes after it's done becoming these both if we ran both these transactions at the same time they're gonna basically race to get the lock on X and whichever of them gets the managed to get the lock on X first it will proceed and finish and commit meantime the other transaction that didn't manage to get the lock on X first it's going to see if you're waiting before it what you does anything with accent OA can acquire the lock so transaction 2 actually got the lock first you would get the value of X get the value of y cuz transaction one hasn't gotten at this point hasn't locked Y yet it'll print and it will finish and release its locks and only then transaction one will be able to acquire the lock on X and as you can see that basically forces a serial order because it forced in this case it force the order T two and then when T two finishes only then T 1 so with it's explicitly forcing an order which causes the that execution to follow the definition of serializability that you know really is executing T 2 to completion and only then T 1 so we do get correct execution all right so one question is why you need to hold the locks until the transactions completely finished you might think that you could just hold a lock while you are actually using the data and that would be more efficient and indeed it would that is you know maybe only hold the lock for the period of time in which t2 is actually looking at record X or maybe only hold the lock on X here for the duration of the add operation and then immediately release it and in that case that what if we transaction one immediately released a lock on X there there by disobeying this rule of course but if it immediately release the lock on X then transaction two might be able to start a little bit earlier we get more concurrency more higher performance so this rule definitely you know bad for performance so we want to make pretty sure that it's it's good for that's required for correctness so what won't happen if transactions did actually release locks as early as possible so suppose t2 here reads X and then immediately releases this lock on X that would allow t1 since at now at this point in the execution t2 doesn't hold any locks because it's just released it illegally release the lock on X since it holds a no locks that means t1 could completely execute right here and we already knew from from before that this interleaving is not correct as it doesn't produce either these two outputs similarly if if t1 released this lock on X after finished adding one to X that would allow all of t2 to slip in right here and we know also from before that that results in in illegal results there's a an additional kind of problem that can come up with releasing locks after modifying data if t1 were to release the lock on X it might allow t2 to see the modified version of X here to see the X after adding 1 to it and to print that output and then for tteyuu to complete after printing the incremented value of x if transaction one were to abort after that point maybe because bank balance Y doesn't exist or maybe bank bonds Y exists but its balance is zero and you know we're not allowed to decrement 0 for bank balances because that's an overdraft so t1 might modify X then abort and part of the abort has to be undoing its update to X in order to maintain atomicity and what that would mean if it released the locks is that transaction 2 would have seen this sort of phantom value of 11 that went away because t1 aborted you would have seen a value that according to the rules never existed right because then the transaction 1 aborts then it's as if it never existed and so that means the results from t2 had better be as if t2 ran by itself without t1 at all but if it sees the increment that it's gonna print 11 for X 11 10 actually which is just doesn't correspond to any state in the database given that t1 didn't really complete okay so that's why those are two dangers that are averted due to violations serialize ability that are averted because transactions hold the locks until they're done a further thing to note about these rules or that it's very easy for them to produce deadlock so you know for example if we have two transactions one of them reads record ax and reads record y and the other transaction reads Y and then X that's that's just a deadlock if they run at the same time they each of them gets this lock on the record it first read they don't release till the transactions finish so they both sit there waiting for the lock that's held by the other transaction and unless the database does something clever which it will they'll deadlock forever and in fact transactions have various strategies including tracing cycles or timeouts in order to detect that they've gone into the situation the database will abort one of these two transactions and undo all its changes and act as if that transaction that never occurred okay so that's concurrency control with two-phase locking and this is just completely standard database behavior so far and it's the same in a single machine databases as it will be and distributed databases that are a little more interest to us but our next topic is a little is actually specific to building databases or storage systems in general that support transactions on distributed setting that is splitting the data over multiple machines so now the topic is how to build distributed distributed transactions and in particular how to cope with failures and more specifically the kind of partial failures of just one of many servers that you often see in distributed systems so beyond distributed transactions and we're worried about how they behave you make sure they're serializable and also have sort of all-or-nothing ad Amissah T even in the face of failures so you know I you know what the way this looks like is that we may have two servers and we got server one and maybe it stores record X in our bank and we have server two and maybe it's stores record Y so they all start out with value 10 and we need to run these two transactions that transaction 1 of course modifies both x and y so now we need to send messages the database is saying oh please increment X please decrement Y but it would be easy if we weren't careful to get into a situation where we had told server 1 to increase the balance for X but then something failed maybe the client sending the requests or maybe server the server - that's holding Y fails or something and we never managed to do the second update right so that's one problem is failure somewhere may sort of cut the transaction in half and if we're not careful cause only half of the transaction to actually take effect this can happen even without crashes if X does its part in the transaction it could be that over on server-to-server to actually gets the request to decrement bank account y but maybe server 2 discovers this bank account doesn't exist or maybe it does exist and it's balance is already 0 when it can't be decrease and so it can't do its part of the transaction but X look has already done its part of the transaction so that's a problem that needs to be dealt with so the the property we want as I mentioned before is that all the pieces of the system either all the pieces of the system should do their part of the transaction or none right so you know the kind of the thing we violated here is what atomicity against crashes versus failure where atomicity is all or not all parts all parts of the transaction that we're trying to execute or none of them and for you more the kind of solution we're going to be looking at is atomic commitments atomic commit protocols and the general kind of flavor of atomic commit protocols is that you have a bunch of computers they're all doing different parts of some larger task and the atomic commit protocol is gonna help the computers decide that either they're all going to do they're they're all capable of doing their part and they're actually gonna do it or something has gone wrong and they're all going to agree that oh they're actually none of them are gonna do their part of the whatever the overall task is and the big challenges are of course how to cope with various failures machine failures loss of messages and it'll turn out that performance is also a little bit difficult to do a good job with the specific protocol we're gonna look at and is the protocol explained in a reading for today our two-phase commit this is an atomic commitment protocol and this is used both by distributed databases and also by all kinds of other distributed systems that might not have first looked like traditional databases the general setting is we assume that that in one way or another the task we need to perform is split up over multiple servers each of which needs to do some part a different part each one of them so for example because I'm set up I showed here in which the it's really the data that split up and so the tasks being split up our incrementing X and decrementing Y D we're going to assume that there's one computer that's driving the transaction called the transaction coordinator there's lots of ways of arranging how the transaction coordinator steps in but we'll just imagine it as a computer that is actually running the transaction there's one computer the transaction coordinator that's that's executing the sort of code for the transaction like the puts and the gets and the adds and it sends messages to the computers that hold the different pieces of data that need to actually execute the different parts so for our setup we're going to have one computer of the transaction coordinator and it's going to be these server one and server two that hold X&Y transaction coordinator we'll send a message to server one saying oh please increment X send a message to server Y saying oh please decrement Y and then there'll be more messages in order to make sure that either they both do it or neither than do it and that's where two-phase commit steps in something to keep in the back your mind is that in the full system there may be many different transactions running concurrently and many transaction coordinators sort of executing their own transactions and so the various parties here need to keep track of oh you know this is a message for such-and-such a transaction and where they keep state like these turns out these servers are going to maintain table two blocks for example and they keep state like that they need to keep track of oh this is a lock that's being held for transactions 17 so there's a notion of transaction IDs and I'm just gonna assume although you know I'm not actually show it that every message in the system is tagged with the transaction with the unique transaction ID of the transaction it applies to and these IDs are chosen by the transaction coordinator when the transaction starts the transaction coordinator will send out oh this is a message for transaction 1995 and it'll keep all its state here about the transaction will be tagged with 95 and the various tables in the different participants in the transaction will be tagged with the transaction IDs and so that's another piece of terminology we got the transaction coordinator and then the other servers that are doing parts of the transaction are called participants all right so let me draw out the two-phase commit protocol example execution so this is abbreviate this to PC for two-phase commit the parties involved are the transaction coordinator and we'll just say there's two participants that is you know maybe we're executing the transactions I've shown next and why aren't different servers maybe we've got participant a and participant B these are two different servers holding data so the transaction coordinator it's running the whole transaction it's it's gonna send puts and gets to a and B to tell them to you know read the value of x or y or add one to X so we're going to see at the beginning of the tree action that the transaction coordinator is sending for example maybe a get requests to Trent participant a and it gets a reply and then maybe it sends that put for whatever I might see a long sequence of these if there's a complicated transaction then when transaction coordinator gets to the end of the transaction and wants to commit it and be able to you know release all those locks and make the transactions results visible to the outside world and maybe reply to a client or a human user so they were assuming there's a sort of external client or human that said oh please run this transaction and it's waiting for a response before we can do any of that the transaction coordinate coordinator has to make sure that all the different participants can actually do their part of the transaction and in particular if there were any puts in the transaction we need to make sure that the participants who are doing those puts well are actually still capable of doing the puts so in order to find that out the transaction coordinator sends prepare messages to all of the participants so we're going to send pair messages to both a and B and when a or B would receive a preparer message you know they know the transaction is nearing completion but not not over yet they look at their state and decide whether they are actually able to complete the transaction you know maybe they needed to abort it break a deadlock or maybe they've crashed and we started but between you know when they did the last operation are now and they've completely forgotten about the transaction and can't complete it so a and B you know look at their state and say oh I'm going to be able to or I'm not gonna be able to do this transaction and they respond with either yes or no so the transaction coordinator is waiting for these yes or no votes from each of the participants if they all say yes then the transaction can commit nothing goes wrong the transaction can commit and the transaction coordinator sends out a commit message to each of the participants and then the participants usually reply with an acknowledgement saying yes we now know the outcome this is called the echnology all right so they all transaction coordinator since I preparers if all the participants say yes it can commit if anyone in any of them even a single one says no actually I cannot complete this transaction because I had a failure or there was an inconsistency like a missing record and I have to abort even a single participant says no at this point then the transaction coordinator won't commit it'll send out a round of abort messages saying oops please retract this transaction either way the after the commit sort of to two things happen of interest to us one is the transaction coordinator will mint whatever the transactions output is to the client or human that requested it and say look oh yes the transactions finish and so now if it didn't abort a committed it's durable the other interesting thing is that in order to obey these locking rules the participants unlock when they see either commit or an abort and indeed in order to obey the two phase locking rule each participant locked any data that it read as part of doing its part of the transaction so we're imagining that in each participant there's a table of the locks associated with the data stored at that participant and the participant sort of lock things in those tables remember oh this is you know this piece of data this record is locked for transaction twenty nine and one finally the commit or abort comes back versions action twenty-nine the participant unlocks that data and then other transactions can use so we may have to wait here and this unlock may unblock other transactions that's really part of the serializability machinery so you know so far the reason why this is correct basically is that the if everybody's following this protocol there's no failures then the two participants only commit if both of them commit and if I them can't commit if I've them has to abort then they both abort so we get that either they all do it or none of them do it result that we wanted the atomicity result with this protocol so far without without thinking about failures and so now our job is to think through in our head all sort of the different kinds of failures that might occur and figure out whether the protocol still provides atomicity either both do it or neither do it in the face of these failures and how we have to adjust or extend the protocol in order to cause it to do the right thing so the first thing I want consider is what it be crashes and restarts I mean power failure or something be just some suddenly stops executing and then powers restored and it's brought back to life and run some maybe some sort of recovery software as part of the transaction processing system well there's really two scenarios we have to worry about one is B might have crashed before ascending it's yes message back so B crash before sending its yes message back then it never said yes so the transaction coordinator couldn't possibly have committed or be about to commit because it has to wait for a yes from all participants so if B can convince itself that it could not possibly have sent a yes back that is a crash before sending the yes then B is entitled to unilaterally abort the transaction itself and forget about it because it knows the transaction coordinator can't possibly commit it so [Music] there's you know a number of ways of implementing this one possibility is that all of these information about transactions that haven't reached this point is in memory and it simply lost it B crashes and reboots so B just won't know anything about transactions that haven't haven't sent yes back yet and then if the transaction coordinator sends a prepare message to a participant that doesn't know anything about the transaction because it crashed before sending yes the the parties will say no no I cannot possibly agree to that you know please abort okay but of course maybe B crashed after sending a yes back so that's a little more tricky so wasn't in the crash this wasn't a B gets a prepare its it's happy it says yes I'm going to commit and then it crashes before it gets the commit message from the transaction employer coordinator well now we had we're in a totally different situation B is promised to commit if told to do so because the send a yes back and for all knows and indeed the most likely thing that's happening is the transaction coordinator got yeses from a and B and a sent a commit message to a so that a actually will do its part of the transaction and make it permanent and release locks and in that case in order to honor all or nothing we're absolutely required it B should crash at this point that on recovery that it be still prepared to complete its part of the transaction it doesn't actually know at that point whether you know because it hasn't received the committee ette and whether it should commit or not but it must still be prepared to commit and what that means the fact that we can't lose the state for a transaction across crashes and reboots is that before B replies to a prepare it must make the transaction state this sort of intermediate transaction state the memory of all of the changes that's made which may have to be undone if there's an abort plus the record of all the locks the transactions how it held it must make that durable on disk in between it's almost always in a log on disk so before B replies yes before B sends the s4 in reply to a prepare message it first must write to disk in its log all the information required to commit that transaction that is all the new values produced by put plus a full list of locks on the disk or some other persistent memory before applying with yes and then if there should be if it B's your crash after sanity yes that's part of recovery when it restarts that a look at his it's log and say oh gosh I was in the middle of a transaction I had replied yes for transaction 92 I mean you know here's all the modifications it should make if committed and all the locks it held I better restore that state and then when he finally gets a commitment nor an abort it'll know from having read its log how to actually finish its part of the transaction so so this is an important thing I left out of the original laying out of this protocol is that B must write to its disk at this point and this is part of what makes two-phase commit a little bit slow is that there's these necessary persisting of information here okay so we also have to worry about okay and you know the final place I guess where you might crash is you might crash be my crashed after receiving the commit or or after both you might crash after actually processing the commit and but in that case it's made modifications that the transaction means to make permanent in its database presumably also on disk before after it received a commit message and in that case there's maybe not anything to do if it restarts because the transaction is finished so when B receives the commit message it probably writes the copies the modifications from its log on to its permanent storage releases this locks erases the information about the transaction of months log and then replies and of course we have to worry about you know what if it receives a commit message twice probably the right thing to do is either for B to remember about the transaction that takes memory so it turns out that it B simply forgets about committed transactions that it's made durable on disk it can reply to a repeated commit message if it doesn't know anything about that transaction by simply acknowledging it again and that'll be an important a little bit later on ok so that's the story of one of the participants crashes at various awkward points what about the transaction coordinator it's also just a single computer sorry you know if it fails might be a problem okay so again the critical where things start getting critical is if any party might have committed then we cannot forget about that if any either of these participants might have committed or if the transaction coordinator might have replied to the client then we cannot have that transaction go away right if a is committed but maybe its transaction the coordinator sent out a commit message to a but hadn't gotten around to sending a commitment to be the crashes at that point the transaction coordinator must be prepared on restart to resend the commit messages to make sure that both parties know that the transaction is committed so okay so you know whether that matters depends on where the transaction coordinator crashes if the crash is before sending commit messages it doesn't really matter neither party if you know since the transaction coordinator didn't send commit messages before crashing it can just abort the transaction and if either participant asks about that transaction because they you know see it's in their log but they never got a commit message the transaction coordinator can say I don't know anything about that transaction it must have been aborted possibly due to a crash so that's what happens if the transaction coordinator crashes before the commit but if a crashes after sending one or more commits message then it cannot defends action coordinator can't be allowed to forget about the transaction and what that means is that at this point when that after the transaction coordinator it's made its commit versus abort decision on the basis of these yes/no votes before sending out any commit messages it must first write information about the transaction to its login in persistent storage like a disk that will still be there if it crashes and restarts so transaction coordinator after receives a full set of yeses or noes writes the outcome and the transaction ID to its log on disk and only then it starts to send out commit messages and that way if a crash is at any point maybe before its end the first commit message or after its sent one or maybe even after sent all of them if it crashes that point its recovery software will see in the log AHA which is in the middle of a transaction the transaction was either known to have been committed or aborted and as part of recovery it will resend commit messages to all the participants or abort messages whatever the decision was in case it hadn't sent them before it crashed and that's one reason why the participants have to be prepared to receive duplicated commit messages okay so there's some other so those are the main crash stories we also have to worry about what happens if messages are lost in the network you might send a message maybe the message never got there you might send a message and be waiting for a reply maybe the reply was sent but the reply was dropped so any one of these messages may be dropped and need to think through what to actually do in each of these cases so for example supposing the transaction coordinator sent out prepare messages but hasn't gotten some of the yes or no replies from participants what are the transaction coordinators options at that point well one thing I could do is send out a new set of prepare messages saying you know I didn't get your answer please tell me your answer yes or no and you know I could keep on doing that for a while but if one of the partisans is down for a long time we don't want to sit there waiting with locks held right because you know supposing a is unresponsive but but B is up but because that we haven't committed or aborted B is still holding locks and that may cause other transactions to be waiting so we don't want to wait forever if we can possibly avoid it so if the transaction coordinator hasn't gotten yes or no responses after some amount of time from the participants then it can simply unilaterally decide we're gonna abort this transaction because it knows since it didn't get a full set of yes or no messages of course that can't possibly have sent a commit yet so no participant could have committed so it's always valid to abort if the transaction coordinator hasn't yet committed so the transaction coordinator times out waiting for yes or no x' this messages were lost or somebody crashed or something it can just decide alright we're aborting this transaction we'll send out a round of abort messages and if some participant comes back to life and says oh you know I didn't hear back from you about transaction 95 the transaction coordinator will see you oh well I don't know anything about transaction 95 because it aborted it and erased its State for that transaction and it will tell the participant you know you should abort this transaction too similarly if one of the participants times out waiting for the preparer here then you know for participant hasn't received a preparer that means it hasn't send a yes message back and that means the coordinator can't possibly have sent any commit messages so if participant chimes out here waiting for the preparer it's also always allowed to just bail out and decide to abort the transaction and if it's some future time the transaction coordinator comes back to life and sends out preparer messages then B will say no I don't know anything about that transaction so I'm voting no and that's okay because it can't possibly have committed started to commit anywhere so again if something goes wrong with the network or the transaction coordinator is down for a while and the participants are still waiting for prepares it's always valid for participants to abort and thereby release the locks that other transactions may be waiting for and that can be very important in a busy system so that's the good news about if the participants or the transaction coordinators time out waiting for messages from the other parties however suppose participant B has received a preparer and sent its yes and so is in somewhere around here but it hasn't received a commit and it's waiting and waiting and it hasn't gotten to commit back maybe something's wrong with the network maybe the transaction coordinator is its network connection has fallen out or its powers failed or something but for whatever reason B is waited a long time and it still hasn't heard a commit now but it's sitting there holding locks is still holding on to those locks for all the records that were used and it's part of the transaction and that means other transactions may be also blocked waiting for those locks to be released so we're like pretty eager to a border if we possibly can or release the locks and so the question is if B has received prepare and replied with yes isn't entitle to unilaterally abort after it's waited say you know 10 seconds or 10 minutes or something to get the commit message and the answer to that unfortunately is no in this region after receiving the prepare we're out really after sending the yes and before getting the commit it's your time out waiting for the commit you're not allowed to abort you must keep waiting you must usually called block so in this region of the protocol if you don't receive the commit you have to wait indefinitely and the reason is that since be sent back a yes that means the transaction coordinator may have received the yes it may have received yes from all of the participants and it may have started sending out commit messages to some of the participants and that means that a may have actually seen the commit message and committed and made us changes permanent and unlocked and showing the changes to other transactions and since that could be the case for all B knows in this region of the protocol B cannot unilaterally decide to abort at the times out it must wait indefinitely to hear from the transaction coordinator as long as it takes some human may have to come and repair the transaction coordinator and finally get it started again and have it read this log and see oh yes you committed that transaction and finally send long delayed commit messages so and similarly if on a time I you can't you can't unilaterally abort it turns out you can't unilaterally commit either because for all B knows a might have voted no but he just hasn't got the important message yet so you could in this region you can either abort nor commit on a timeout and so this actually this this blocking behavior is sort of critical property of two-phase commit and it's not a happy property it means if things go wrong you can easily be in the situation where you have to wait for a long time with locks held and holding up other transactions and so among other things people try really hard to make this part of two-phase commit acts as fast as humanly possible so that the window of time in which a failure might cause you to block with locks held for a long time is as small as possible so they try to make this part of the protocol very lightweight or even have variants of the protocols that for certain special cases may not have to wait at all okay so that's the basic protocol one thing to notice about this that is a fundamental part of why we're able to get to actually build a protocol that allows a and B to sort of both you know they both commit or they both have or abort one reason for that is that really the decision is made by a single entity it's made by the transaction coordinator alone a and B are neither of them you know except that they vote no neither a nor B is deciding whether to commit or not and they certainly are not engaged in a conversation with each other to try to reach agreement about what is the other thinking or they thinking commit may be all commit to instead we have this much is quite sort of fundamentally simple protocol in which only the transaction coordinator makes the decision a single entity and it just tells the other party here's my decision please go do it the penalty for that for having the transaction coordinator really the single entity make the final decision again is the fact that you have to block there's some points in which you have to block waiting for the transaction recording coordinator to tell you what the decision was one further question is that we know the transaction coordinator must remember information about transactions and its log in case it crashes and so one question is when the transaction coordinator can forget about information in its log about transactions and the answer to that is that if it manages to get a full set of acknowledgments from the participants then it knows that all the participants know that that transaction committed or aborted that all the transactions no participants knew the fate of that transaction and have done their part in it and will never need to know that information right as they both acknowledged it so when the transaction coordinator gets acknowledgements it can erase all information all memory the transaction similarly participants once they received a commit or abort message and done their part of the transaction and made their updates permanent and released their locks at that point the participants also can completely forget about that transaction after they send their acknowledgment back to the transaction coordinator now of course the transaction coordinator may not get their acknowledgement and may send and may therefore decide to resend the commit message on the theory that maybe it was lost and in that case a participant if it receives a commit message for a transaction which it know nothing about because it's forgotten about it then the participant can just send another acknowledgement back because it knows that it gets a commit message for an unknown transaction it must be because it had forgotten about it because it already knew whether it committed or aborted okay so that's two-phase commit for atomic commitment for a little perspective two-phase commit is used in a lot of sharded databases that have split up their data among multiple servers and it's used specifically in databases or storage systems that need to support transactions in which records in which multiple records may be read or written there's a lot of some more specialized storage systems that don't allow you to have transactions on multiple records and for them you don't need it you no need this kind of you don't need two-phase commit if the storage system doesn't allow multi record transactions but if you have multi record transactions and you shard the data across multiple servers then you need to support either toothpaste you need to support two in pace commit if you want to get asset transactions however two-phase commit has an evil reputation one reason is it's slow due to multiple rounds of messages there's a lot of chitchat here in order to get a transaction that involves multiple participants to finish theirs in addition a lot of disk writes both a and B have to not just write data to their disk between the prepare and the sending of the yes they have to wait for that disk rate to finish so certainly if you're using a mechanical Drive that takes 10 milliseconds to append to the log that puts a real serious limit on how fast participants can process transactions you know 10 milliseconds a pop means no without some cleverness you're limited to 100 transactions per second which is pretty slow and in addition the transaction coordinator also has a point in which it must after it receives the last yes they must first write to its log make sure the data is safe on disk and only then is that allowed to send that commit messages and that's another 10 milliseconds and both of these are 10 millisecond periods in which locks are held in the participants and other transactions are slowed up and I keep mentioning that but it's very important because in a busy transaction processing system there's lots and lots of transactions and many of them may be waiting for the same data and we'd really prefer not to hold locks over long periods of time in which there's lots of messages going back and forth then we have to wait for long disgrace but two-phase commit forces us to do those weights and a further problem with it is that if anything goes wrong messages are lost something crashes then if you're not if you're a little bit unlucky then the participants have to wait for long times with locks held so therefore to face commit you really only see it within relatively small domains within a single machine room within a single organization you don't see it for example did you transfers between banks between different banks you might possibly see it within a bank if it's charted its database but you would never see two days can it run between distinct organizations that were maybe physically separate because of this blocking business you don't want to put the fate of you know your database and whether it's operational in the hands of some other organization where they crash at the wrong time you're forced your database was forced to hold locks for a long time and because it's so slow also there's a lot a lot of research has gone into either making it fast or relaxing the rules in various ways to allow to be faster or specializing two-phase commit for very specific situations in which you know you can shave a message or write to the disk or something off it because you know you're only supporting a certain limited kind of transaction so well we'll see fair amount of this and the rest of the course one question that comes up a lot this exchange here where you have a leader essentially and it sends these messages to the followers and you know we can only go forward if the leader can only proceed if it receives you know acknowledgments replies from enough of the followers this looks a lot like raft this construction looks a lot like raft however the properties of the protocol and what you get out of it turn out to be quite different from what we get out of raft they solve very different problems so the way to think about it is that you use raft to get high-availability by replicating data on multiple participants on multiple peers that is the point of raft is to be able to operate even though some of the server's involved have crashed or are not reachable and you can do this in raft raft can do this because all the service are doing the same thing they're doing the same thing so we don't need all of them to participate we only need a majority two-phase commit however the participants are not at all doing the same thing the participants are each doing a different part of the transaction you know a maybe incrementing record X and B maybe decrementing record Y so two-phase commit all the train all the participant they all have to do their part in order for the transaction to finish you really need to wait for every single one of the participants to do their thing so okay so we got you know raft is replicating doesn't need everybody to do their thing two-phase commit everybody's doing something different that has to get done two-phase commit does not help at all with availability you know raft is all about availability you can go on even if some of the participants are not responding two-phase commit is actually not at all available it's not highly available at all if anything goes wrong we risk having to wait until that's repaired if the transaction coordinator crashes at the wrong time we simply have to wait for to come up and read its log and send out the commit messages right if if one of these participants you know crashes at the wrong time you know if we're lucky we simply have to abort then we're not lucky we have to say did you finish that did you finish that so two-phase commit is not at all about high availability in fact it's it's a it's quite low availability as such things go any crash can hold up the whole system and of course raft doesn't ensure that all the participants do whatever the operation is it only requires a majority there may be minority that totally didn't do the operation at all and that's how the fact that raft all the participants do the same thing we don't have to wait for all of them is why raft gets high availability so these are quite different protocols um it is however possible to to usefully combine them like two-phase commit is you know really vulnerable to failures it's correct with failures but it's not available with the others so the question is could you build some sort of combined system that has the high availability of RAF to replication but has two phase commits ability to call as various different parties each to do their part of the transaction and the construction you want actually is to use raft or paxos or some other protocol like that to rep individually replicate each of the different parties so then we would for this set up we would have like three different clusters the transaction coordinator would actually be replicated service with you know three servers and you know we'd run raft on these three servers one will be elected as leader they'd have replicated state they'd have a log that helped them replicate we don't only have to wait for a majority the leader we'd only have to have a minority of these to be up in order for the transaction coordinator to do its work and of course they would all and you know sort of execute through the various stages of the transaction and the two-phase commit protocol by basically by appending relevant records to their logs and then each of the participants would also be a cluster of a rep our raft replicated cluster so we would end up and they would chain exchange messages back and forth you know we'd send a commit message from the replicated transaction coordinator service to the replicated a server and the replicated B server and this is you know this is admittedly somewhat elaborate but it does show you that you can combine these ideas to get the combination of high availability because any one of these servers can crash and the remaining two you keep operating plus we get on this atomic commitment of a and B are doing complete different parts of the same transaction and we can use two-phase commit to have the transaction coordinator ensure that you know that either both commit the whole thing or they both abort their parts of the transaction you'll actually build something very much like this as part of lab form which you will indeed build a shard a database where each shard is replicated in this form and there's a basically a configuration manager which will allow essentially transactional shifting of chunks of shards of data from one raft cluster to another under the control of something that looks a lot like a transaction coordinator so lab 4 is like this and in addition in a little bit we'll be reading a paper called spanner which describes a real-life database used by Google that users also uses this construction in order to do transactional writes to a database all right thank you