the following content is provided under a Creative Commons license your support will help MIT OpenCourseWare continue to offer high quality educational resources for free to make a donation or view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu good morning this is 600 so I hope any of you who thought this was a different course find where you really belong my name is John Guttag and I'll be lecturing the course all semester okay today I want to accomplish several things cover some of the administrative details talk about the goals of the course what what I hope you'll learn and then begin talking about the conceptual material in the course it will seem a little bit slow because it will be a little bit slow I promise starting on Thursday we're going to pick up the pace considerably so let's start with the strategic goals of the course the official introduction to course six is 601 historically students who arrived at MIT with little or no programming experience find 601 an ordeal and the point of this is to prepare freshmen and sophomores for entering course six that's the electrical engineering computer science department in a gentler kinder way so that 601 is not so much of a problem I want to help students feel justifiably and I want to emphasize the word justifiably confident in their ability to write small and medium-sized programs so at the end of the term you should all feel comfortable writing programs the real theme of the course and what I spend most of the time on is how to map problems into a computational framework there's going to be an emphasis on scientific problems rather than say commercial problems but there will be some talk about some non scientific problems as well how to take a problem that may not at first blush appear to be attacked attackable with the program and show you how to formulate the problem in such a way that you can use computation to get insight into the problem it should not take you very long all of the problem sets involve programming in Python a programming language which I'll say a little bit about later today the first problem set basically is getting Python installed on your own computer most of the people will want to just use whatever their own laptop is to do the problem sets on don't get fooled by the first two problem sets into thinking this is a gut course it's not it starts out gently to lure you in and then life gets pretty hard pretty quickly so don't be fooled the quizzes and there will be two evening quizzes in a final hour open-book opennotes when you get to be my age you get very sensitive about how difficult it is to remember things and so we won't be asking you to memorize stuff the course is about solving problems knowing how to solve problems not how much you can remember for many of you who are majoring in biology or course 20 it's going to be kind of a shock that this course isn't about how much you can remember but it's about how well you can solve problems and that's what the quizzes are really going to be focused on probably the most unusual thing about this course is the collaboration policy which is liberal in the extreme you can collaborate with anybody you want on any of the problem sets not on the quizzes but on any of the problem sets you can work with each other which is what I recommend you can work with your parents if one of them happens to be a software engineer you can work with friends in course six whatever you want to do the goal of the problem sets is to help you learn what we've seen in the past is people who are a little shall I say too collaborative ie they just copy the problem set from somebody else live in a fool's paradise which comes crashing down during that the first quiz people who don't spend enough time thinking about the problem sets themselves cannot take the quizzes successfully so it's a fine line but the our goal is not to be policemen I tell my TAS their job is to help you learn not to prevent you from quote cheating so to solve that problem we've eliminated the concept of cheating on problem sets there is no way to cheat on problem sets so just just go and do them there is no textbook we will be posting readings on the web for the most part these will be pointers to websites occasionally we'll post readings that we wrote ourselves doesn't mean you shouldn't buy a textbook in fact there are a number of Python texts it might we'll recommend a few of them it might make sense to buy one and bring it to a quiz because it will have an index that will let you look things up quickly that sort of thing but again a lot of students never buy a text and do just fine we will not be handing out class notes on a regular basis a lot of studies have indicated that students learn more when they take their own notes than when they're handed out and so as a matter of what I think is good pedagogy we don't hand out detailed lecture notes we will be using after today a lot of handouts with code on them which we'll make available but it's not intended to make any sense outside the context of lectures it's not self-contained the main purpose of this course is to help you become skillful in making the computer do what you want it to do once you acquire this skill your first instinct when confronted with many tasks will be to write a program to do that task for you I always tell people I became a computer scientist in part because I'm lazy and there was a lot of stuff that I found it was easier to write a program to make the computer do it rather than do it myself so I do that a lot you know if I need to do something I say can I just write a quick program to do it and I'd like you to be able to acquire that skill and remember that programming is actually a lot of fun so I should say that in addition to learning a lot in this course I hope most of you will find it fun kind of a strange thought MIT course fun is it maybe it's an oxymoron but I don't think so I mean I really do think you can have a lot of fun writing programs for this course there are many people who believe that how shall I say this programming is the most fun you can have with your clothes on it really can be a lot of fun so so so think of it that way alright so the primary knowledge you're going to take away is computational problem solving so to start with we might ask the question what is computation and to think about that this is interesting there's where the chalk is I was afraid I was going to be confronted with a sea of blackboards and erasers in no chalk but there is chalk so if we think about it there are essentially two kinds of knowledge declarative and you're going to see I'm not a great speller and imperative declarative knowledge is composed of statements of fact for example a good health care plan improves the quality of medical care while saving money as we know from doings in Washington it's a lot easier to state that gold and to know how to achieve that goal so the key thing about declarative knowledge is it says something that is true otherwise it wouldn't be knowledge it would be misinformation but doesn't tell you how to do it in a more mathematical sense say why is the square root of x if and only if Y times y equals x all right perfectly clear statement of what it means to be the square root but it doesn't tell you how to find the square root interestingly enough it does tell you how to test whether or not you have the answer to the square root and so if you had some way of generating guesses you can at least check whether they were correct and in fact starting in the next lecture we'll talk about the fact that a lot of computational techniques involve something called guess and check where you have a way to generate guesses and a way to check whether they're right imperative knowledge in contrast tells you how to solve a problem how to accomplish something so you could think of it as like a recipe in a cookbook so it's one thing to say a chocolate cake is something that tastes delicious and is bad for you that's declarative knowledge but you can open a cookbook and get a recipe it tells you how to make a chocolate cake that's imperative knowledge now below we have a recipe for finding not a square root necessarily but an approximation to a square root and one of the themes of this course is that a lot of problems we cannot solve precisely but we can find answers that are good enough for practical purposes and those are called approximation algorithms so here's a way this is a very old method for finding the square root in fact it's believed that Heron was the one who did this Heron of Alexandria in the news much today Alexandria was the capital of ancient Egypt he was the first one to write this method down a long time ago though it's believed that even before hair on the Babylonians know how to do it so you start with a guess G any old guess will do then you say is G times G close enough to X if so you stop so K I've got a good enough approximation of the answer if it's not you create a new guess by averaging G and X divided by G so G new is going to be G old plus X divided by G old over 2 and then using this new guess you go back to step 2 so let's quickly run through an example of this we can start with this pretty easily we'll take a guess let's say G equals 3 so we look at 3 times 3 nine and we say is that good enough well let's say we're looking for the root of 25 guess I should have started with the problem statement sorry about that well 9 is probably not close enough to 25 that we're happy may be good enough for government work but not for most other purposes so we'll reset G and we'll set G to 3 plus 25 over 3 all of that over 2 which equals 5 point 6 6 6 6 etc all right so now we'll multiply that by itself and that gets to be about 30 2.04 close enough to 25 probably not so we'll take another step and we'll set G equal to well when we're done with it all I'm not going to bore you with writing the formula again it'll be 5.0 4 if we square that it's 25.4 we decide that's close enough to 25 and we're done what we say at this point is that the algorithm and that's an important word an algorithm is a description of how to perform a computation we say that the algorithm has converged which is a fancy way to say it's halted what we've got here if you think about it is a set of instructions steps that can be executed and a flow of control the order in which we execute them so if we look at this there's a default order of execution 1 2 3 4 but then there's the go back to step 2 and start over and there's a termination condition tells us when to stop and of course that's important I've always been amused that if you look at a shampoo bottle you'll see an algorithm that says something like lather rinse repeat and if you follow it literally you never get to stop which I suppose makes sense if you're selling shampoo because people use a lot of it but really there ought to be some termination condition there ok so now how do we capture this idea of a recipe in a mechanical process one way would be to design a machine specifically to do square roots so if I knew how to design circuits which I don't I could sit down probably many of you could sit down and design a circuit that would implement this algorithm and in fact that's more or less what you'll find in a cheap for function calculator that does square roots not quite this algorithm but a similar algorithm is just part of the circuitry to go compute that and in fact this used to be the way that all computers worked so the initial computers were to call fixed-program computers they were designed to do very specific things and that's what they did so for example the very one of the very first computers designed in 1941 by absent off and Barry solve systems of linear equations for the purpose of plotting artillery trajectories and that's all it did you know if you wanted to balance your bank account with this computer you couldn't do it but you could figure out how to drop our till she'll somewhere also during World War 2 Alan Turing built a machine specifically designed for breaking the German and English actually a fascinating story of science how that was built but again that was all it could do these computers were useful but only in a very limited way the big breakthrough the thing that made computation really important to society was the invention of the stored-program computer it took people quite a while to figure this out but once they did it seems obvious the basic notion of a stored program computer is that the instructions are the same as data so now there is no distinction between the program that implements the algorithm and the data on which that program operates so there's no difference between the input of 25 part of the data and the steps of the algorithm used to do that once that was possible the machines became infinitely flexible you could change the program any time you wanted and furthermore programs could produce programs because programs can produce data and if program and data are the same thing that means programs can produce programs and we were off and running and that's really what made computers what they are today once this became clear as the paradigm for computers people began to think of the computer itself as a program and in particular as a kind of program called an interpreter and we'll get to more on this later today an interpreter is a program that can execute any legal set of instructions and consequently can be used to describe and accomplish anything you can do with the computer so roughly speaking this is what a stored-program computer looks like this is six double O four and forty seconds it's got memory lots of it today a control unit that basically tells it what to do for example fetch some data from memory put some data into memory send some output to a screen all of those kinds of things what for historical reasons we call the arithmetic logic unit this is in some sense the brains of the computer the thing that actually does computations an accumulator which is part of the ALU that stores results and a bunch of input and output devices the things that we actually see when we use a computer and that's it and again the key thing to notice is there's only one kind of memory there's not a memory for program and a memory for data there's just the memory the nice thing to think about here is given a small set of instructions you can then build any kind of program you want so typically the computers have a very small number of built instruction instructions you know order of dozens and that's it and by combining those instructions in very clever ways you can do arbitrarily complex things in much the same way a good chef can take a very small number of ingredients and from those produce a variety of interesting edibles Alan Turing in the 1930s very famous British mathematician of whom you will hear more showed that in fact there were six primitive instructions each of which operated on one bit of information and with those six primitive instructions you could do anything that could be done with a computer kind of amazing there was six instructions there were things like weird right plus I don't know maybe - I forget what they were and that was it that's all you needed we will not make you write programs using only six instructions will give you a much larger set but still it's really quite remarkable it's what makes programming such an amazing endeavor so what instructions will you be using well that's what a programming language does so a programming language provides a set of primitive instructions a set of primitive control structures so instructions and mechanisms for controlling the order in which they get executed and that's all and then you can do whatever you want with them and what distinguishes one programming language from another is what these things are what are your instructions what of your flow of control and how do you combine them what are the combining mechanisms and in fact it's the combining mechanisms more than anything else that separate one language from another the most amazing thing about programming and this has it's good side in it's bad side and it's something you need to remember as you do the problem sets is that the computer will always do exactly what you tell it to do it's remarkable right you don't have any friends who will do whatever you tell them to do I tell you my children certainly don't do whatever I tell them to do and my wife doesn't either sometimes she probably thinks I do whatever she tells me to do but a computer will do what you tell it to do so that's very empowering it's also very annoying because it means if your program doesn't work it's your own darn fault you got nobody else to blame but yourself because it's not the computers fault you may want to curse the computer but you shouldn't it's just doing what you told it to so be careful what you wish for all right the programming language we're going to use in 600 is Python it's a relatively recent addition to the University of languages I want to emphasize that this course is not about learning Python I will spend relatively little time in the lectures telling you about Python it's about computational methods as with this course is really about and python is merely a teaching tool once you learn to program in Python it it's easy to learn to program in another language it's a very easily transferable skill if we think about what defines any programming language it's got a syntax a static semantics and a semantics or any of you here linguistics majors not a not a one all right when I can make up whatever I want about these terms and maybe you'll believe me all right so the syntax tells us which sequences of characters and symbols constitute a well formed string so it would tell us maybe that we can write something like x equals 3 plus 4 and that's syntactically correct it's well-formed it might also tell us that x equals 3 blank 4 is not syntactically correct it's not a legal string so by analogy with English the syntax describes which strings of words constitute well-formed sentences well-formed not necessarily meaningful so it would tell you that some sentence like Susan is building is syntactically well-formed it may not be very sensible the static semantics tells us which well formed strings have a meaning that our which strings are meaningful so you can think about that as also making sense so in Python it might tell us that some strings which are syntactically fine don't mean anything so for example it might tell us that the string 3 divided by the character string ABC is syntactically well-formed because its value operator value sort of like noun verb noun is syntactically well-formed in English but it would tell us that there's no real meaning to this dividing a number by a string doesn't mean anything and so you would get an error message saying syntax is ok but the static semantics is broken so for example in English the sentence I are big is somehow syntactically well-formed your noun verb noun but we might say it's not it's fails a static semantics test we don't want to assign a meaning to it the semantics of the language looks only at the strings that are both syntax ethically correct and static semantically correct and assigns a real meaning to them in natural language sentences can be ambiguous so one of my favorites when I have to write a recommendation letter for a student that maybe I don't think is so good I might say something like I cannot praise this student too highly well you can interpret that however you want it keeps me from getting sued but I can also claim well I don't like the student at all and English is full of those things programming languages in contrast are designed so that every well-formed program has exactly one meaning there's no ambiguity so you can't typically talk of a program as having a semantic error it is if it is well-formed it means something and that's what it means on the other hand it's easy to talk about a program meaning something other than you wanted it to mean and you will discover in the problem sets most of the time the program's don't mean what you want them to mean that is to say when you run them they don't give you the correct answer and then you will go through this process of debugging them and learning how to do it so what might happen when we write a program that doesn't do what we want it to do it might crash by that we mean stop running and produce some palpable indication that it has done so so I you've all used programs that have crashed right you've sat there using your email program or Word or PowerPoint or something and suddenly it just goes away and you get a message in your screen and an invitation to send Apple or Microsoft somewhat of a file explaining what went wrong so they can fix it in a properly designed computing system when one program crashes it does not damage the overall system so you'd like it to just be local what else might it do it might never stop now if you have no idea how long a program is supposed to run this can be hard to diagnose but again I'm sure you've all run into this I've certainly run into it every once in a while I'll say try and write a PowerPoint file and it'll just sit there or I'll try to read a file and it will just sit there and never finish the job or I don't have enough patience but probably it would never have finished it again you will all write programs that do this it's a good idea to know how long you expect your programs to run so that you can recognize this typically we say that these programs have in them an infinite loop and we'll talk about that when we get to flow of control finally a program right run to completion and produce the wrong answer these problems are kind of in ascending order of badness if it crashes at least you know that something has gone wrong an infinite loop can be very annoying because you just wait for a long time but the worst thing that happens is when you think everything is good and it's not there have been lots of examples of this this is the sort of thing that costs lives there was a radiation therapy machine that produced the wrong dosage of radiation and actually killed quite a few people because they put in the correct input and it would dose the patient with radiation and a fatal dose of radiation that's a really bad mistake there are buildings that collapse because people run programs that do the structural engineering and the program to give the wrong answer lots of bad things can happen so one of the things we're going to spend time on this term is what you can do to avoid writing programs that have this rather unpleasant property how do you test them how do you write them in such a ways that this is the least likely event that's not what you want to happen okay some programming languages give you a lot of help in avoiding these things Python is kind of mediocre in that respect it's not the best it's not the worst it's somewhere in in the middle because what you'd like is a program with very rigorous static semantics such that if you pass those tests it has a high probability of behaving as expected so for example it's a good thing that Python doesn't allow you to do this because who knows what that's going to do something weird you'd rather be told no you can't write that and then you have to write something that's more obviously meaningful rather than it's just making up an interpretation as we will see going forward Python is not for example as good at Java as Java is at weeding out meaningless things or things that have surprising meanings on the other hand it's better than C so kind of in the middle as these programming languages go why do we use Python in this course if it's not the best in that respect it's got several good features one of them is it's easy to learn it's much less complicated than say Java so the learning curve is much steeper that's a good thing you get up to speed faster it's very widely used today in a lot of areas of science particularly the life sciences it has probably become the most popular language in biology in the other life sciences and therefore for those of you who have careers in that area it's the most useful language to know it's also widely used in other areas as well it is easier to debug than most languages and the reason it's easier to debug than most languages or than many is it's an interpreted language so you'll remember I talked about a computer as an interpreter something that you feed in a bunch of instructions that called the source code you do some checking then it executes the instructions including the flow of control instructions produces some output the nice thing that is goes goes on there is if something untoward happens the interpreter can describe in the language of the source code what went wrong the source code is the code that you wrote on the other hand the way a compiler works is you take the source code you check it but then you translate it into another language called the object code this is a language closer to the language that the computer the hardware knows how to interpret then the hardware interpreter interprets the compiled code the object code and produces output and the problem here is if something goes wrong it wants to give you an error message in terms of the object code which you've never seen in your life and that can make it very obscure so the advantage why do we have compilers typically compiled languages are more efficient because they go through this extra step they take less time to run those programs you can compile Python as well if you want to get an efficient version but it's not designed under that assumption and so it works well when it's interpreted which is why we use it