the following content is provided under a Creative Commons license your support will help MIT OpenCourseWare continue to offer high quality educational resources for free to make a donation or view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu good morning this is the second of two lectures that I am retaping in the summer because we had technical difficulties with the lectures that would take during the academic term I feel I need to tell you this for two reasons one as I said before the room is empty and so when I say something hilarious and there's no laughter it's because the room is empty and if I'm not asking the students questions during the lecture it's because there are no students the other important thing I want you to understand is that I do own more than one shirt and more than one pair of pants and the reason I'm dressed exactly the way I was for lecture 13 is I gave lecture 13 five minutes ago even though this is lecture 15 so again here I am and I apologize for the uniformity in my clothing okay on lecture 14 which came between 13 and 15 at the end of it I was talking about flipping coins and ended up with the question how can we know when it's safe to assume that the average result of some finite number of flips is representative of what we would get if we flip the same coin many more times in principle and infinite number of times well we might flip a coin twice get one heads in one tails and conclude that the true probability of getting a head is exactly 0.5 turns out assume I have a fair coin this would have been the right conclusion just because we have the right answer it doesn't mean our thinking is any good and in fact in this case our reasoning would have been completely faulty because if I flipped it twice and gotten two heads you might have said oh it's always heads but we know that wouldn't have been right so the question I want to pose at the start of today's lecture is quite simply how many samples do we need to believe the answer so how many samples do we need to look at before we can have confidence in the result fortunately there's a very solid set of mathematics that lets us answer this question in a good way at the root of all of it is the notion of variance variance is a measure of how much spread there is in the possible outcomes now in order to talk about variants given this definition we need to have different outcomes which is why we always want to run multiple trials rather than say one trial with many flips in fact you may have wondered why am I not if I end up flipping the coin a million times why would I do multiple trials adding up to a million rather than one trial of a million and the reason is by having multiple trials each of which give me a different outcome I can then look at how different the outcomes of the different trials are and get a measure of variance if I do ten trials and I get the same answer each time I can begin to believe that really is the correct answer if I do ten trials and get ten wildly different answers then I probably shouldn't believe any one of those answers and I probably shouldn't even think I can average those answers and believe the mean is a real answer because if I run an eleventh trial maybe I'll get something totally different yet again we can formalize this notion of variance in a way that should be familiar to many of you and that's the concept of a standard deviation something I in fact already showed you when we looked at the spread of grades in the first quiz this semester informally what the standard deviation is measuring is the fraction of values that are close to the mean if many values are close to the mean the standard deviation is small if many values are relatively far from the mean the standard deviation is relatively large if all values are the same then the standard deviation is 0 in the real world that essentially never happens all right we can write a formula for this fortunately it's not all about words and we can say the standard deviation of X where X is a set of trials that Sigma is usually used to talk about that is equal to the square root of 1 over the absolute value of the length of X so that's 1 over the number of trials times the summation of the value of each trial little X and big X of X minus mu squared where mu is the mean and as I said that's the cardinality of X well so that's a formula and those of you who are majoring in math are going to love that but for those of you who are more computationally oriented I recommend you just take a look at the code so here's an implementation of the standard deviation so the standard deviation of X is equal start by getting the mean of X which is by summing X and dividing it by the length of X then I'm just going to sum all the values in X and do the computation so back code and that formula are the same thing alright now we know what standard deviation means what are we going to do with it we're going to use it to look at the relationship between the number of samples we've looked at and how much confidence we should have in the answer so we'll do this again looking at a bunch of code so I've got this function flip plot which doesn't quite fit on the screen but that's okay it's not very interesting in the details what it does is it runs multiple trials of some number of coin flips and plucks a bunch of values about the relative frequency of heads and tails and also the standard deviation of each so again nothing very exciting in the code I'm just going to keep track of for all these trials the minimum and the maximum exponent I'm using that so I can run a lot of trials quickly the mean ratios the mean the differences and standard deviations for exponent in range minimum exponent to maximum exponent plus 1 I'm going to build an x-axis so this is going to be the number of flips and then for the number of flips I'm going to run a bunch of tests and get the ratios of heads to tails and the absolute difference between heads and tails and then I'm going to do a bunch of plotting and again what I want you to notice is when I'm doing the plotting I'm going to label the axes and put some titles on and I'm also going to use semi-log because given that I'm looking at different powers it would compress everything on the left if I were just use linear alright let's run it actually let's comment out the code we need to run it so I'm going to call flip plot with a minimum exponent of 4 a maximum exponent of 20 that's pretty high and I'm going to run 20 trials this could take a little while to run but not too long and will give us some pretty pictures to look at give me a chance to have a drink of water I know the suspense is killing you as to what these plots are going to look like here they are all right so if we look at plot one that's the ratio of heads to tails and as you can see it bounces around in the beginning when we have a small number of flips the ratio moves a bit but as I get to a lot of flips out here you know 10 to the 5th 10 to the 6th what we're seeing is it begins to stabilize we don't get much difference kind of interesting where it's stabilizing maybe not what we'd expected I would have guessed it would stabilize a little closer to 1 than it did as I got out here I maybe I have an unfair coin that's the problem with running these experiments in real time that I can't necessarily get the answer Ike's I want but for the most part actually it looks much better in my screen than it does on your screen in fact on my screen it looks like it's very close to 1 I don't know I guess or some some distortion here think 1 and if we look at the standard deviation of the ratio of heads to tails what we're seeing is that's also dropping from somewhere up here around 10 to the 0 down to 10 to the minus 3 and it's dropping pretty steadily as I increase the number of trials that's really what you would hope to see and expect to see that not the number of trials and I'm reflects re as I flip more coins the variance between trials should get smaller because in some sense randomness is playing a less important role the more random trials you do the more likely you are to get something that's actually representative of the truth and therefore you would expect the standard deviation to drop all right now what we're saying here is because the standard deviation is dropping not only are we getting something closer to the right answer but perhaps more importantly we have better reason to believe we're seeing the right answer that's very important that's where I started this lecture it's not good enough to get lucky and get the correct answer you have to have evidence that can convince somebody that really is the correct answer and the evidence here is the small standard deviation let's look at a couple of the other figures so here's figure three this is the mean of the absolute difference between heads and tails not too surprisingly we saw this in the last lecture as I flip more coins the mean difference is going to get bigger that's right we expect the ratio to get smaller but we expected the mean difference to get bigger on the other hand let's look at figure four what we're looking here is the difference in the standard deviations and interestingly what we're seeing is the more coins I flip the bigger the standard deviation is well this is kind of interesting I look at it and I sort of said that when the descender deviation is small we think that the variance is small and therefore the results are credible when the standard deviation is large we think the variance is large and therefore the results are maybe incredible well I said that a little bit wrong I tried to say it right the first time what I have to ask is not is a standard da vision large or small but is it relatively large a relatively small relative to what relative to the mean if the mean is a million and their standard deviation is 20 it's a relatively small standard deviation if the mean is 10 in the standard deviation is 20 then it's enormous so it doesn't make sense and we saw this we looked at quizzes right if the mean score on quiz 1 were 70 and their standard deviation were 5 we'd say okay it's pretty packed around the mean if the mean score were 10 which maybe is closer to the truth and the standard deviation were 5 then we'd say that's not really packed around the mean so we have to always look at it relative or think about it relative to that now the good news is we have again a mathematical formula that lets us do that get rid of all those figures for the moment and that formula is called the coefficient of variation for reasons I don't fully understand this is typically not used people always talk about the standard deviation but in many cases it's the coefficient of variation that really is a more useful measure and it's simply the standard deviation divided by the mean so that lets us talk about the relative variance if you will the nice thing about doing this is it lets us relate different data sets with different means and talk think about how much they vary relative to each other so if we think about it if the co usually we argue in that if it's less than one we think about that as low variance now there should be some warnings that come with the coefficient of variation and these are some of the reasons people don't use it as often because they don't want to bother giving the warning labels if the mean is near zero small changes in the mean are going to lead to large changes in the coefficient of variation that are not necessarily very meaningful so when the mean is near zero the coefficient of variation is something you need to think about with several grains of salt makes sense you're dividing by something near zero a small change is going to produce something big perhaps more importantly or equally importantly this is something we're going to talk about later is that unlike the standard deviation the coefficient of variation cannot be used to construct confidence intervals I know we haven't talked about confidence intervals yet but we will shortly all right by now you've got to be tremendously bored with flipping coins nevertheless I'm going to ask you to look at one more coin flipping simulation then I promise we'll change the topic and this is to show you some more aspects of the plotting facilities in pylab so I'm going to just flip a bunch of coins run a simulation you've seen this a zillion times and then we'll make some plots and this is really kind of the interesting part what I want you to notice about this let's take a look at here so now we've been plotting curves here we're going to plot a histogram so I'm going to give a set of values set of Y values in this case the fraction of heads and a number of bins in which to do the histogram so let's look at a little example first here independent of this program oops wrong way so I'm going to set L a list equals one two three three three four and then I'm just going to plot a histogram with six bins and then show it I've done something I'm not supposed to do I just know title there's no X label no y label that's because this is totally meaningless I just want to show you a histograms work and what we'll see here is that it's shown that I've got three instances of this value of three and one of everything else and it's just giving me essentially a bar chart if you will again many many plotting capabilities you'll see on the website this is just a simple one what I like to use and use fairly frequently some other things I want to show you here is I'm using X Liam and Y limb so what we can do here is this is setting the limits of the x and y axis rather than using defaults saying the lowest value should be this thing I have the variable called X min which I've computed up here and the highest Y min what you'll see if we go up a little bit so I'm getting the fraction of heads 1 and computing a mean one and the standard deviation 1 then I'm going to plot a histogram of the way we looked at it and then what I'm going to do is say X min and while x max is pylab dot X limb if you call exilim with no arguments what it will return is the minimum x value and the minimum Y value of the current plot the current figure so now I stored the minimum x and x values and the maximum x value for the current one I've done the same thing for y I'm then going to plot the figure here then I'm going to run it again I'm going to run another simulation getting frac heads to mean to standard deviation 2 going to plot the histograms but then I'm going to set for the new one the X limit and the y Y limit for the X limit sorry of this to the previous ones that I save from the previous figure why am i doing that because I want to be able to compare the two figures as we'll see when we have our lecture and how to lie with data a great way to admit to fool people with figures is to subtly change the range of one of the axes and then you look at things that wow that's really different or they're really the same when in fact neither conclusion is true it's just that they've been normalized to either look the same or look different so it's kind of cheating and then we'll we'll do it so now let's run it and see what we get don't need this little silly thing first let's see just going to take a long time maybe one way to fill up a lecture just run simulations that take a long time to run much easier to prepare than actual material but nevertheless it shouldn't take forever I may have said this before I have two computers I have a fast one that sits at my desk that I use to prepare my lectures and a solar one that I use to give the lectures I should probably be testing all these things out in the slow computer before making you wait but really it's going to stop I promise ah all right so we'll look at these so figure one has got a hundred thousand trials of 10 flips each and figure to 100,000 trials of a thousand flips each and let's look at the two figures side-by-side make them a little smaller so we can squeeze them both in alright so what have we got here notice if we look at these two plots the means are about the same 0.5 and 0.499 not much difference the standard deviations are quite different and again you would expect that 100 flips should have a lot higher standard deviation than a thousand flips and indeed it certainly does 0.15 is a lot smaller than 0.05 so that tells us something something good it says as we discussed it these results are more credible than these results not to say that they're more accurate because they're not really but they're more believable and that's what's important notice also the spread of outcomes is much tighter here than it is here now that's why I played with excellent if I use the default values it would not have looked much tighter when I put this up on the screen because it would have said well we don't have any values out here I don't need to display all of this and it would have been about the same visual width as this and therefore potentially very deceptive when you just stared at it if you didn't look carefully at the units on the x-axis so what I did is since I knew I wanted to show you these things side by side and make the point about how tight the distribution is I made both racks ease run the same length and therefore produce comparable figures I also by the way use exilim and while in if you look at the code which you will have in your hand to put this textbox in a place where it would be easy to see you can also use the fault of best which often puts it in the right place but not always the distribution of the results in both cases is close to something called the normal distribution and as we talk about things like standard deviation or coefficient of variation we are talking about not just the average value but the distribution of values of these trials the normal distribution which is very common has some interesting property it always peeks at the mean and falls off symmetrically the shape of the normal distribution so I'm told you know looks something like this and there are people who imagine it looks like a bell and therefore the normal distribution is often also called the bell curve that's a terrible picture I'm going to get rid of it and indeed mathematicians will always call it this this is often what people use in the non technical literature there was for example some very controversial book called the bell curve which I don't recommend reading okay so this is not a perfect normal distribution you know it's not really exactly symmetric we could zoom in on this one and see if it's better back let me make that larger and then we'll zoom in on it now that we're not comparing the two we can just zoom in on the part we care about and you can see again it's not perfectly symmetric but it's it's getting there and in fact the trials are not very big only a thousand flips if I did a hundred thousand trials of a hundred thousand flips each we wouldn't finish the lecture take too long but we get a very pretty looking curve and in fact I have done that in the quiet of my office and it works very nicely and so in fact we would be converging here on the normal distribution normal distributions are frequently used in constructing probabilistic models for two reasons reason one is they have nice mathematical properties they're easy to reason about for reasons we'll see shortly that's not good enough the curve where every value is the same has even nicer mathematical properties but isn't very useful but the nice thing about normal distributions is many naturally occurring instances so let's first look at what makes them nice mathematically and then let's look at how many where they occur so the nice thing about them mathematically is they can be completely characterized by two parameters the mean and the standard deviation knowing these is equivalent to knowing the entire distribution furthermore if we have a normal distribution the mean and the standard deviation can be used to compute confidence intervals so this is a very important concept one that you see all the time in the popular press but maybe don't know what it actually means when you see it so instead of estimating an unknown parameter and that's of course all we've been doing with this whole probability business we have some unknown parameter like the probability of getting a head or a tail and we've been estimating it using a various techniques and typically been estimating it by a single value the mean of a set of trials a confidence interval instead allows us to estimate the unknown parameter by providing a range that is likely to contain the unknown value and a confidence that the unknown value lies within that range it's called a confidence level so for example when you look at political polls you might see something that would say the candidate is likely to get 52% of the vote plus or minus 4% so what does that mean well if somebody doesn't specify the confidence level they usually mean 5% so what this says is that 95% of the time 95th confidence interval if the election were actually conducted the candidate would get somewhere between 48% and 56% of the vote it's the 95% of the time 95% of the elections the candidate would get between 48 and 56% of the votes so we have two things the range and our confidence that the value will lie within that range when we make those assumptions when you see something like that in the press they are assuming that the elections are random trials that have a normal distribution that's an implicit assumption in the calculation that tells us this the nice thing here is that there is something called the empirical rule which are used for normal distributions they give us a handy way to estimate confidence intervals given the mean and the standard deviation so if we have a true normal distribution then roughly speaking 68% of the data or within one standard deviation of the mean and 95% within two standard deviations and almost all 99.7% will fall within three these values are approximations they're not exactly right it's not exactly 68 and 95 but they're good enough for government work so we can see this here and this is what people use when they think about these things now this may raise an interesting question in your mind how do the pollsters go about finding the standard deviation do they go out and conduct a hundred separate polls and then do some math of the sort we've been doing you might hope so but that's not what they do because it's expensive and nobody wants to do that so they use another trick to estimate the standard deviation now you're beginning to understand why these polls aren't always right and the trick they use for that is something called the standard error which is an estimate of the standard deviation and you can only do this under the assumption that the errors are normally distributed and also that the sampled population is small and I mean small not large is small relative to the actual population so this gets us to one of the things we like about the normal distribution that in fact it's often an accurate model of reality and when people have done polls over and over again they do discover that indeed the results are typically normally distributed so this is not a bad assumption actually it's a pretty good assumption so if we have P which is equal to the percentage sample and we have n which is equal to the sample size we can say that the standard aeroshell right se is equal to the formula P times 100 because we're dealing with percentages minus P divided by n to the one-half the square root of all of this so if for example a pollster were to sample a thousand voters and 46 percent of them said that they'll vote for Abraham Lincoln we should be so lucky that Abraham Lincoln were running for office today the standard error would be roughly one point five eight percent we would interpret this to mean that in 95% of the time the true percentage of votes that Lincoln would get is within two standard errors of 46 percent all right I know that's a lot to swallow quickly so as always we'll try and make sense of it by looking at some code by now you've probably all figured out that I'm much more comfortable with code than I am with formulas so we're going to conduct a poll here not really we're going to pretend we're conducting a poll N&P we'll start with no votes and for I in range n if random dot random is less than P over a hundred the number of votes will be increased by one otherwise it will stay where it was and we'll return the number of votes nothing very dramatic and then we'll test the error here so N equals a thousand P equals 46 the percentage of votes that we think Abraham Lincoln is going to get will run a thousand trials results equal that forty and range number of trials results dot append I'll run the poll and we'll look at the standard deviation we'll look at the results and we'll print the fraction of votes and the number of polls all right let's see what we get when we do this well pretty darn close to a normal distribution kind of what we'd expect fraction of votes peaks at 46% again what you expect but every once in a while it gets all the way out here to 50 and looks like a might actually win an election highly unlikely in our modern society and over here he would lose a lot of them and whoops sorry about that if we look here we'll see that the standard deviation is is 11.6 so it turns out that the standard error which you'll remember we computed using that formula to be one point five eight you may not remember it because I set it and didn't write it down is pretty darn close to one point six so remember the standard error is an attempt to just use a formula to estimate what the standard deviation is going to be and in fact we use this formula very simple formula to guess what it would be we then ran a simulation and actually measured the standard deviation no longer a guess and it came out to be one point six and I hope that most of you would agree that that was a pretty good guess and so therefore because if you will the differences are normally distributed the distribution is normal it turns out the standard error is a very good approximation to the actual standard deviation and that's what pollsters rely on and why polls are actually pretty good so now the next time you read a poll you'll understand the math behind it in a subsequent lecture we'll talk about some ways they go wrong that have nothing to do with getting the math wrong now of course finding a nice math tractable mathematical model the normal distribution is of no use if it provides an inaccurate model of the data that you care about fortunately many random variables have an approximately normal distribution so if for example I were doing a real lecture and I had a hundred students in this room and I were to look at the heights of the students we would find that they are roughly normally distributed anytime you take a population of people and you look at it it's quite striking that you do end up getting a normal distribution of the of the heights you get a normal distribution of the weights same thing will be true if you look at plants all sorts of things like that I don't know why this is true it just is but I do know is that and probably this is more important many experimental setups and this is what we're going to be talking about going forward have normally distributed measurement errors this assumption was used first in the early 1800s by the German mathematician and physicist Carl Gauss you've probably heard of Gauss who assumed a normal distribution of measurement errors in his analysis of astronomical data so he was measuring various things in the heavens he knew his measurements of where something was were not 100% accurate and he said well you know I'll bet it's equally likely it's to the left of where I think it is or the right is where I think it is and I'll bet the further I get from its value the less likely I am an to guess that's where it is and he invented at that time what we now call the normal distribution physicists insists today still on calling it a Gaussian distribution and it turned out to be a very accurate model of the measurement errors he would make if you guys are in a chemistry lab or a physics lab or a bio lab mechanical engineering lab any lab where you're measuring things it's pretty likely that the mistakes you will make will be normally distributed and it's not just because you're sloppy in the lab actually if you were sloppy in the lab they may not be normally distributed if you're not sloppy in the lab they'll be normally distributed it's true of almost all measurements and in fact most of science assumes normal distributions of measurement errors in reaching conclusions about the validity of their data and we'll see some examples of that as we go forward thanks a lot see you next time