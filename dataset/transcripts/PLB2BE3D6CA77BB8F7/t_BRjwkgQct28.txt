the following content is provided under a Creative Commons license your support will help MIT open courseware continue to offer highquality educational resources for free to make a donation or view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu good morning everybody all right I ended up the last lecture talking about about how to calculate the absolute goodness of a fit using something called the coefficient of determination uh usually spelled as R SAR or R2 and the formula was was quite simple we measure the goodness of the fit as r^2 = 1 minus the estimated error divided by the measured variance um as I observed R 2 always lies between 0er and 1 if R2 equals one that means that the model that we've constructed the predicted values if if you will explains all of the variability in the data so that any change in the data is explained perfectly by the model we don't usually get one in fact if I ever got one I would think somebody cheated me um if R2 equals zero conversely it means there is no linear relationship at all between the values predicted by the model and the actual data that is to say the model is totally worthless so we have code here the top of the screen uh showing a how easy it is to compute R squ And for those of you who have a little trouble interpreting the formula because maybe you're not quite sure what e and MV mean um this will give you a very straight forward way to to understand it so now we can can run it we can get some answers so if we look at it you remember last time we looked at two different fits we looked at a quadratic fit and a linear fit for the trajectory of an arrow F fired from my bow and we can now compare the two and not surprisingly given what we know about the physics of projectiles what we see is exactly what we'd expect that the linear fit has an R squar of 0.177 showing that in fact it explains almost none of the data whereas the quadratic fit has a really astonishingly good R squar of uh .98 saying that almost all of the changes in the values of the variables that is to say the way the Y value changes with respect to the x value is explained by the model I.E we have a really good model of the physical situation very comforting essentially it's telling us that less than 2% of the variation uh is explained by the linear model 98% by the quadratic model presumably the other 2% is experimental error well now that we know that we have a really good model of the data um we can ask the question why do we care we had the data itself what's the point of building a model of the data and that of course is what we're getting when we run polyfit to to get this curve the whole purpose of creating a model or an important purpose of creating creating a model is to be able to answer questions about the actual physical situation so one of the questions one might ask for example about firing an arrow is how fast is it going right that's kind of a useful thing to know if you're worried about whether it will penetrate a Target and kill somebody in the other side for example um we can't answer that question directly looking at the data points you look at the data well I don't know but we can use the model to answer the question and that's an exercise I want to go through now to show you the interplay between models and theory and computation and how we can use the three to answer relevant questions about data no I do not want to check for new software thank you in fact let's make make sure it won't do that anymore so let's look at the PowerPoint so here we'll see how I'm using a little bit of theory not very much to be able to understand how to use the model to compute the speed of the arrow so what we see is We Know by our model and by the good fit that the trajectory is given by y = ax^2 + bx+ C we know that right we also know from looking at this equation that the highest point which I'll call Y peak of the arrow must occur at X mid the middle of the x axis so if we look at a parabola and it doesn't matter what the parabola is we always know that the vertical Peak is halfway along the x axis the math tells us that from the equation so we can say y Peak is x * X Mid 2 plus b * X mid plus C so now that we have the model we can tell how high the arrow can get the next question I'll ask is if I've fired the arrow from here and it hits the target here and I've exaggerated by it this way it's nowhere's near this steep how long does it take to get from here to here we don't have anything about time in our data yet I claim we have enough information to go from the distance here and the distance here to how long it's going to take the hour to get from here to the Target why do I know that what determines how long it's going to take to get from here to here it's going to be how long it takes it to fall that far it's going to be gravity because we know that gravity at least on this planet is a constant or close enough to itless maybe the arrow were going a million miles and it's going to be gravity that takes tells me how long it takes to get from here to here and when it gets to the bottom it's going to be here so again I can use some very simple math and say that the time will be the square root of 2 * the Y Peak divided by the gravitational constant because I know that however long it takes to get from this height to this height is going to be the same time it takes to get from this point to this point and that will therefore let me compute comp the average speed from here to here and once I know that I'm done now again this is assuming no drag and things like that thing that we always have to understand about a model is no model is actually ever correct on the other hand many models are very useful and that they're close enough to correct so I've left out things like gravitation like wind shear and stuff like that but in fact the answer we get here will turn out to be very close to correct we can now go back and look at some code get rid of this and so now you'll see the on the hand out I'm going to just write a little bit of code that just goes through the math I just showed you to compute the uh average x velocity got a print statement here I use to debug it and I'm going to return it and then we'll just be able to to run it and see what we get well all right that we looked at before let's I forgot to close the previous figure so now I I'm sure this is a problem you've all seen and we'll fix it the way we always fix things is just start over uh oh I bet you guys have all also seen this happen what this is suggesting as we've seen before is that the process the old process still exists not a good thing again I'm I'm sure you've all seen these let's make sure we don't have anything running here that looks like idle we don't just takes it a little time there it is all right all right now we'll go back right all of this happened because I forgot to close the figure and executed pb. showed twice which we know can lead to bad things so let's get rid of this now we'll run it and now we have our figure just using the quadratic spit fit and we see that the speed is 136.28 point2 not really I know it's the ballpark I've sort of confused Precision with accuracy here by giving you it to two decimal places I can compute it as precisely as I want but that doesn't mean it's actually accurate probably I should have just said it's about 135 or something like that but it's pretty good and for those of you who don't know how to do this arithmetic in your head like me this is about 93 mil hour um and for comparison the speed of sound instead of 136 feet per second is 1100 feet per second so it's traveling pretty fast well what's the point of this I don't really care if you know how fast an arrow travels I don't expect you'll ever need to compute that but I wanted to show you this as an example of a pattern that we use a lot so we did is we started with an experiment you didn't see this but I actually stood in my backyard and shot a bunch of arrows and measured them got real data out of that and this gave me some data about the behavior of a physical system I all right that's what I get for wearing a tie maybe it'll be quieter if I put it on my shirt actually it looks silly but excuse me I hope none of you will mind if I take my tie off seems to be making noises to them in the microphone maybe we should write a computation all right so ends my experiment with trying to look dignified not something I'm good at okay had an experiment that gave us some data we then used computation to both find and very importantly evaluate a model it's no good just to find a model you need to do some evaluation to convince yourself that it's a good model of the actual physical system and then finally we use some Theory and Analysis and computation to derive a consequence of the model and then since we believed the mo accuracy of the model we assumed this consequence was also a true fact about the physical system we started with this is the pattern that we see over and over again these days in all branches of science and engineering and it's just the kind of things that you should get used to doing it is what you will do if you you go on to careers in science or engineering okay that's all I want to say now about the topic of data and experiments and Analysis we will return to this topic of interpretation of data later in the semester near the end when we start talking about machine learning and clustering but for now I want to pull back and start down a new track that will I'm sure you'll be pleased to hear dovetail nicely with the next few problem sets that you're going to have to work on what I want to talk about is the topic of optimization not so much optimization in the sense of how do you make a program fast but we will talk a little about that what people refer to is optimization problems how do we write programs to find Optimal Solutions to problems that occur in real life every optimization problem we'll look at is going to have two parts there's going to be one an objective function that will either be maximized or minimized so for example I might want to find the minimal airfare between Boston and Istanbul or more likely between the minimum bus Fair between Boston and New York so there's an objective function sometimes you find the least sometimes you find the most maybe I want to maximize my income and two a set of constraints that have to be satisfied so maybe I want to find the minimum Transportation minimum cost transportation between Boston and New York subject to the constraint that not take more than eight hours or some such thing so the objective function that you're minimizing or maximizing and some set of constraints that must be obeyed a vast number of problems of practical importance can be formulated this way once we formulated them in this systematic way we can then think about how how to attack them with a computation that will help us solve the problem you guys do this all the time I heard a talk Yesterday by Jeremy wer an MIT graduate who founded a company called ITA if youve ever used kayak for example or many other of these systems to find an airline Fair they use some of Jeremy's code and algorithms to solve these various optimization problems like this if you've ever used Google or Bing they solve optimization problems to decide what pages to show you they're all over the place there are a lot of classic optimization problems that people have worked on for decades what we often do when confronted with a new problem and it's something you'll get some experience on in problem sets is take a seemingly new problem and map it on to a classic problem and then use one of the classic Solutions so we'll go through this section of the course and we'll look at a number of classic optimization problems and then you can think about how you would map other problems onto those um this is the process known as problem reduction where we take a problem and map it onto an existing problem that we already know how to solve um I'm not going to go through a list of classic optimization problems right now but we'll see a bunch of them as we go forward now an important thing to think about when we think about optimization problems is how long how hard they are to solve so far we have looked at problems that for the most part have pretty fast Solutions often sublinear binary search sometimes linear and at worst case low order polinomial optimization problems as we'll see are typically much worse than that in fact what we'll see is there is often no computationally efficient way to solve them and so we end up dealing with uh approximate solutions to them or what people might call best effort Solutions and we see that as an increasing Trend in tackling problems all right enough of this abstract stuff uh let's look at an example so one of the classic optimization problems is called the napsack problem um people know what a napsack is sort of an archaic term today people would use the word backpack um but in the old days they called the nap saacks when they started looking at these things and the problem is also discussed in the context of a burglar or of various kinds of thiefs so it's not easy being a burglar by the way way I don't know if any of you have ever tried it uh you've got some of the obvious problems like making sure the house is empty and picking locks circumventing alarms Etc but one of the really hard problems a burglar has to deal with is deciding what to steal because if you break into the typical luxury home and why would you break into a poor person's house if you were a burglar uh there's usually far more to steal than you can carry away and so the problem is formulated in terms of the burglar having a backpack they can put a certain amount of stuff in it and they have to maximize the value of what they steal subject to the constraint of how much weight they can actually carry so it's a classic optimization problem and people have worked for years at how to solve it not so much because they want to be burglars but as you'll see these kinds of optimization problems are actually quite common so let's look at an example you break into the house and among other things you have a choice of what to steal you have a rather strange looking clock uh some artwork A book uh a velvet Elvis in case you you lean in that direction all sorts of things and for some reason the owner was nice enough to leave you information about how much everything cost cost and how much it weighed so you find this piece of paper and now you're trying to decide what to steal based upon this in a way to to maximize your value how do we go about doing it oh I should show you by the way there's a a picture of a typical map sack um all right it's almost Easter after all well the simplest solution is probably a greedy algorithm and we'll talk a lot about greedy algorithms because they're very popular and often the right way to tackle a hard problem so the notion of a greedy algorithm is it's iterative and at each step you you pick the locally optimal solution so you choose the make the best choice put that item in the napsack ask if you have room if you're out of weight if not you make the best choice of the remaining ones ask the same question you do that until you can't fit anything else in now of course to do that that assumes that we know at each stage what we mean by locally optimal and of course we have choices here we're trying to figure out in some sense what greedy algorithm what approach to being greedy will give us the best result so one could for example say all right at each step I'll choose the most valuable item and put that in my napsack and I'll do that till I run out of valuable items or you could at each step say well what I'm really going to ch choose is the one that weighs the least that will give me the most items and maybe that will give me the most total value when I'm done or maybe at each step you could say well let me choose the one that has the best value to weight ratio and put that in and maybe that will give me the best solution as we will see in this case none of those is guaranteed to give you the best solution all the time in fact as we'll see none of them is guaranteed to be better than any of the others all the time and that's one of the issues with greedy algorithms I should point out by the way that this version of the knapsack problem that we're talking about is typically called the 01 napsack problem and that's because we either have to take the entire item or none of the item we can't we're not allowed to cut the velvet Elvis in half and take half of it this is in contrast to The Continuous knapsack problem if you imagine you break into the house and you see a barrel of gold dust and a barrel of silver dust and a barrel of raisins what you would do is you would fill your napsack with as much gold as you could carry or until you ran out of gold and then you would fill it with as much silver as you could carry and then if there was any room left you'd put in the raisins for the continuous knapsack problem a greedy algorithm provides an optimal solution unfortunately most of the problems we actually encounter in life as we'll see are 01 knapsack problems you either take something or you don't and that's more complicated all right let's look at some code so I'm going to formulate it uh I'm first going to start by divining just by putting in a class just so the rest of my code is simpler this is something we've been talking about that increasingly people want to start by putting in some useful data abstractions so I've got a class item where I can put in the item I can get its name I can get its value I can get its weight and I can print it kind of a boring class but useful to have then I'm going to use this class to build items and in this case I'm going to build the item items based upon what we just looked at the table that I think it's in your handout and it's also was on this slide later if we want we can have a randomized program to build a much bigger choice of items but here we'll just try the clock the painting the radio the vase the book and the computer now comes the interesting part I've written a function greedy that takes three arguments uh the set of items that I have to choose from makes sense the maximum weight the burglar can carry and there's something called key function which is defining essentially what I mean by locally optimal then it's quite simple I'm going to sort the items using the key function you remember sort has this optional argument that says what's the ordering so maybe I'll order it by value maybe I'll order it by density maybe I'll order it by weight I'm going to reverse it because I want the most valuable first not the least valuable for example and then I'm going to just take the first thing on my list until I run out of weight and then I'm done and I'll return the result and the total value to make life simple I'm going to Define some functions these are the functions that I can use for the ordering uh value which is just return the value of the item the inverse of the weight because I'm thinking as a greedy algorithm I'll take the lightest not the heaviest and since I'm reversing it I want to do the inverse and the density which is just the value divided by the weight okay make sense to everybody you with me speak now or not and then we'll test it so again kind of a theme of this part of the course as we write these more complex programs we tend to have to worry about our test harnesses so I've got a function that tests the greedy algorithm and then another function that tests all three greedy approaches it's one algorithm with different functions and looks at what our results are so let's run it um see what we get oh you know what I did just the same thing I did last time but this time I'm going to be smarter we're going to get rid of this figure and comment out the code that generated it and then we'll test the greedy algorithms so we see the items we had to choose from which I printed using the string function and items and if I use greedy by value to fill a napsack of size 20 we see that I end up getting uh just the computer if I do greedy by value this is for the the nerd bur burglar um if I use weight I get a different I get more things not surprisingly but lower value and if I use density I also get four things but four different things and I get a higher value so I see that I can run these greedy algorithms I can get an answer but it's not always the same answer as I said earlier greedy by density happens to work best here but you shouldn't consume that that will always be the case I'm sure you can all imagine a different assignments of weights and values that would make greedy by density give you a bad answer all right before we talk about how good these answers are and we will come back to that as in particular suppose I want the best answer I want to stop for a minute and talk about the algorithmic efficiency of the greedy algorithms so let's go back and look at the code and this is why people use greedy algorithms actually there are two reasons one reason is that they're easy to program and that's always a good thing and the other is that they are typically highly efficient so what's the efficiency of this how would we think about the efficiency of this greedy algorithm well what are we looking at here well the first thing we have to ask is what's the first thing it does is it sorts the list right so one thing that CS the efficiency might be the amount of time time it takes to sort the list of items well we know how long that takes or we can speculate at least and let's assume it does some something like merge sort so what's that term going to be order what Len of items times what log n right so maybe that's going to tell us the complexity but maybe not the next thing we have to do is look at the while loop and see how many times are we going through the while loop what's the worst case somebody I know I didn't bring any candy today but you could answer the question anyway be a sport do it for free yeah L of the items the length of the items well well we know this one is bigger so it looks like that's the complexity right so we can say all right pretty good slightly worse than linear in the length of the items but not bad at all and that's a big attration of greedy algorithms they are typically order length of items or order length of items times the log of the length so greedy algorithms are usually very close to linear and that's why we really like them why we don't like them is it maybe that the accumulation of a sequence of locally Optimal Solutions does not yield a globally optimal solution so now let's ask the question suppose that's not good enough I have a very demanding thief or maybe the thief works for a very demanding person and needs to choose the absolute optimal set let's think first about how we'd formulate that carefully and then what the complexity of solving it would be and then algorithms that might be used useful again the important step here I think is not the solution to the problem but the process used to formulate the problem often it is the case that once one has done a careful formulation of a problem it becomes obvious how to solve it at least in a in a Brute Force way so now let's look at a for formalization of the Z 1 napsack problem and it's a kind of formalization we'll use for a lot of problems so step one will represent each item by a pair because in fact in deciding whether or not to take an item we don't care what its name is we don't care if it's a clock or a radio or whatever what matters is what's its value and what's its weight we'll write w as the maximum weight that the thief can carry or that can fit in the knapsack so far so good nothing complicated there now comes the interesting step we're going to repr represent the set of available items as a vector we'll call it I and then we'll have another vector v which indicates whether or not each item in I has been taken so V is a vector and if V sub I is equal to one that implies that I subbi big I sub little I has been taken is in the napsack conversely if the subi is zero it means I subi is not in the knapsack so having having formulated the situation thusly we can now go back to our notion of an optimization problem as an objective function fun and a set of constraints to carefully State the problem so the for the objective function we want to maximize the sum of V subi times is subi value where I ranges over the length of the vectors so that's the trick of the zero and one if I don't take it it's zero so it's zero times the value if I take it it's one times the value so this is going to give me the sum of the values of the items I've taken and then I have to subject to the constraint and again we'll do a summation and it will look very similar V subi times I sub I but this time weight is less than or equal to W straightforward but a useful kind of skill and people do spend a lot of time on doing that if you've ever used mat lab you know it wants everything to be a vector and that's often because a lot of these problems can be nicely formulated uh in this kind of way all right now let's return to the question of complexity what happens if we implement this in the most straightforward way what would the most straightforward implementation look like well we could enumerate all possibilities and then choose the best that meets the constraint so this would be the obvious root Force solution to the optimization problem look at all possible solutions choose the best one I think you can see immediately that this is guaranteed to give you the optimal solution actually an optimal solution maybe there's more than one best but in that case you can just choose whichever one you like for whichever comes first for example the question is how long will this take to run well we can think about that by asking the question how big will this set will be how many possibilities are there well we can think about that in a pretty straightforward way because if we look at our formulation we can ask ourselves how many possible vectors are there how many Vector V's could there be which shows which items were taken and which weren't and what's the answer to that well if we have n items how long will VB length n right 0 one for each if we have a vector of zeros and ones of length n how many different values can that Vector take on we've we've asked this question before what's the answer somebody shouted out I've got a vector of length n every value in the vector is either a zero or a one so maybe it looks something like this how many possible combinations of 0 ones are there 2 to the N because essentially this is a binary number exactly and so if I have an N bit binary number I can represent two to the N different values and so we see that we have 2 to the N possible combinations to look at if we use a Brute Force solution how bad is this well if the number of items is small it's not so bad and you will see that in fact I can run this on the example we've looked at two to the five is not a huge number suppose I have a different number um suppose I have 50 items to choose from not a big big problem uh I heard yesterday that the number of different airf fars between two cities in the US is order of 500 500 different air fairs between say Boston and Chicago so looking at the best there might be two to the 500 kind of a bigger number let's look at 2 to the 50 let's say there were 50 items to choose from in this question and let's say for these sake of arguments um it takes a microsc one millionth of a second to generate a solution how long will it take to solve this problem in a Brute Force way for 50 items who thinks you can do it in under four seconds how about under four minutes wow Skeptics four hours it's a lot of computation four hours for starting to get some people four days all right well all right how about four years you know still longer just under four decades solving looking at one choice every microsecond it takes you roughly 36 years to evalue all these possibilities um certainly for people of my age that's it's not a practical solution to have to wait 36 years for an answer um so we have to find something better and we'll be talking about that later