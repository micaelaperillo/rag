the following content is provided under a Creative Commons license your support will help MIT open courseware continue to offer highquality educational resources for free to make a donation or view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu we ended up the last lecture talking about dynamic programming and we'll spend all of today on that topic we showed how it could be used to provide a practical solution to the shortest path problem a solution that would allow us to solve what was in principle a complex problem quickly and we talked about the properties that make it possible to solve that problem and in general the properties we need to make dynamic programming applicable so let's return to that topic right now what we looked at is we looked at two properties the first was optimal substructure and you recall what this meant is that we can construct a globally optimal solution by combining solutions to local sub problems so we've looked at a lot of problems already this term that have optimal substructure merge sort for example which exploits the fact that a list can be sorted by first sorting components of it and then combining those so merge sort exhibited optimal substructure the second property we looked at was overlapping sub problems and what this meant was that in the course of running our algorithm we would end up solving the same sub problem more than once and that is what gave us the power of using memorization to use table lookup instead of recomputing the solution notice that merge sort does not have overlapping sub problems there's no reason that we would expect if we're sorting a list that the two that we would ever encounter the same sublist twice and so in fact we cannot use dynamic programming to solve sorting because because it has one of these two properties but not both so how about shortest path does it have these Pro properties well let's first think about optimal substructure you might Begin by asking the question if I knew the shortest path from A to B and I knew the shortest path from B to C can I ne necessarily combine those to get the shortest path from a to c no exactly right because for example maybe there's a direct link from a to c so can't combine them that way so that gives us the question oh pardon almost got it there so that gives us the question what are the what is the optimal substructure here well there is something we do know about shortest path that if I have the shortest path from one node to another and I take any subpath of that I will have so let's say I have a path that goes from let's say I know that the shortest path from a to c is a A to B to D to e to C if this is the shortest path from a to c I know that this is the shortest path from B to e right because otherwise I wouldn't have bothered going through D if there were for example link directly from B to e then the shortest path from a to c would not have in included this so that's the optimal substructure I have and that's the substructure that I exploited last time in showing you the dynamic programming solution to the shortest path problem you will also recall that when we looked at the shortest path we' found overlapping sub problems because I would end up solving the same intermediate problem multiple times figuring out how to get from one node to another so indeed we saw that the shortest path problem exhibited both of these properties and therefore was a meable to Solution by dynamic programming and in fact we ran it and we saw that it ran quite quickly it's not immediately obvious but the 01 knapsack problem also exhibits both of these properties you'll recall a few lectures ago and also in a problem set not so long ago we looked at a recursive solution to the 01 napsack problem called solve in this code it uses backtracking to implement a decision tree so if we look at the decision tree we had there so I gave you a small example here of the 01 napsack of problem I've got a b c and d I've got some values and I've got some weights we started by saying at the beginning we looked at this node here where we had decided not to take anything we still had the list a b c and d to consider the total value of our items was zero and for our example I think we had five pounds of material left or five units of weight we then considered a decision what happens if we take a well if we take a we have b c and d left to consider we now look at this node and say all right our value is six the value of a but we only have two pounds left we then considered going depth first left first in this case this was a depth for search we've looked at that before all right let's consider the next Branch well the next Branch we cons consider C well we discover no we consider B rather we can't take B Because B weighs three so this is a branch that we can't get to we can elect the other decision not to take B in which case we still have a we have C and D left to consider and still six and two we then proceed and consider right well can we take C yes we can and that leaves us with a value of 14 and no weight left so since we have no available weight we might as well stop considering things so this is a terminal node we then back up and say all right let's consider the decision where we don't take C uh can we take D and the answer is no because it weighs too much and then we're done and so we see on this brand on this side of the tree we've explored various possibilities and this is our best option so far and we can walk through and now we consider well what if we don't take a well then we have these decision to make and eventually we can look at the whole thing and make it decision by the way I noticed this morning that there was an error on your handout uh I chose not to correct it in the slide so that you would notice it was in your handout as well what should node 18 be what's the error here pardon right that should be the empty one right because we've considered everything in fact typically all of your bottom nodes should either have zero weights or no items left to consider not very deep just a typo but has the advantage that by looking for it you can see whether you understand how we're constructing these decision trees so this is a very common way to deal with with an optimization problem you consider all combinations of decisions in a systematic way and when you're done you choose the best one so this is using depth first search and backtracking um and this is essentially what you did in your problem set now what you saw in your problem set is that if the set of items is even moderately large this algorithm can take a a very long time to run how long well at each level of the tree we're deciding whether to keep or not keep one item so what's the maximum depth of the tree how many levels can this tree go if we have n items pardon and levels exactly so if we have n items it can go in levels good grab all right how many nodes do we have at each level well at level zero we have only one node but what's the down at the bottom let's say we have an enormous amount of weight so that in fact we never run out of weight in our napsack um we'll have quite quite a broad tree right how many nodes at level two at each level right down here we have up to four nodes up to eight nodes up to 16 nodes so we had say 39 40 items at level 39 we'd have two to the 39th nodes pretty darn big tree right not very deep but very very bushy so we know that for any reasonable number of items and a reasonable amount of weight this is just not going to work and that's why when you wrote your problem set and you were trying to solve the optimal set of courses to take you could only run it on a small subset of the courses at MIT because if we gave you everything and we gave you a lot for a test you noticed it effectively just wouldn't finish it so now we have to ask the question well can we use dynamic programming to solve this problem and in particular that boils down to the question of does this solution exhibit optimal substructure and overlapping sub problems well optimal substructure is easily visible in both of the decision tree and the code right each parent node combines the solution we can look at the code since you have the sub Tree in your handout or the decision Tree in your handout and the key place in the code is where we combine decisions from lower down in the tree as we go up up so at each parent node we select the better of the two children right if the left child is better than the right child we select the left otherwise we select the right and we just percolate up the tree so there's clearly optimal substructure here that we can solve the higher nodes with solutions to the lower nodes and we see that again in the code where it says choose better Branch it's less obvious to answer the question whether or not there are overlapping sub problems if we go back and look at the tree at first glance it may appear here that there are no overlapping sub problems you'll notice that at each node we're solving a different problem right the problem is described in some sense by this for tupal that if I've already taken a and c and I have D left to consider what should I do or up here I've taken a and I have b c and d left to consider what should I do and by design of the decision tree each node is different right we're not considering the same thing over and over again so you might look at it and say well we're out of luck there are no overlapping sub problems not true so let's think hard for a second and ask in what sense are there overlapping sub problems when are we potentially at least solving the same problem well what is the problem we're actually solving we're solving the problem that can in some sense be stated as follows at each node we're saying what should we do about the nodes left to consider so we're solving the problem given a set of items what items we have at a node given an available weight which items should we take what's missing from this it says nothing about the items we've already taken in order to decide what to take next we need to know how much weight we have available but we don't need to know why we have that much weight available which items we have previously decided to take that part of the for Tuple turns out not to be relevant to the problem I still have to solve why is that important because there may be many different sets of items I could take that would add up to the same total weight therefore leaving me the same problem to solve and that's the key observation that tells us we can use dynamic programming to solve the 01 napsack problem does that I should ask the positive does that make sense to anybody raise your hand if it makes sense a small number of hands raise your hands if it doesn't make sense okay can any of you to whom it doesn't make sense formulate a question well it's hard toal weight the same total value the same total weight because the question is are there many sets of items with the same total value or the same total weight there might be many with the same total value but that doesn't really matter because in choosing what to do next as I go down the tree I don't care what the value is above the tree because I'll still try and find the best solution I can to the remaining sub problem if I value above is a million or the Val above is three it doesn't matter what I should do next which makes sense but if you use different things to get that weight wouldn't you have a different set of items to choose from right so the question is it makes sense that there are many different sets of items that would have the same total weight but what I'm going to but wouldn't I have different items to choose from well you'll notice that I do have to look at what items I have left but as I go through let's assume here that I have a list of items to take as I go through from the front say I'll label at each note of the tree each item will have either a zero or a one depending upon whether I decided to take it or not and then what I have to consider is the remaining items and let's say the values of the first two items the first four items were uh well well let's say they were all one just to make life well that'll be confusing since I'm using that for taken or not taken let's say their values were all two when I get here and I'm deciding what to do with these items I might so this tells me that I've used up four pounds of my allotment right but if I had done this one I would also used up four pounds of my allotment and so which of these I take or don't take is independent of how I got here I do have to keep track of which items are still available to me but I don't care how I've used up those four pounds and obviously there are a lot of ways to choose two that will that we use up four pounds here right but the solution to this part of the problem will be independent of which two I took that make sense now therefore as long as there's a prefix of my list of items such that multiple things add up to the same weight I will have overlapping sub problems now you can imagine a situation in which no combination added to the same weight in which case dynamic programming wouldn't buy me anything it would still find the right answer but it wouldn't speed anything up but in practice for most 01 knapsack problems they may not be this simple but you could expect and we'll see this complexity later that as long as your possible weights are being chosen from a relatively small Set uh you'll have many things add up to the same thing particularly as you get further down this list and have a lot longer prefix to consider so indeed I do have overlapping sub problems does that answer the question all right now uh people feel better about what's going on okay maybe looking at some code will make it uh even clearer and maybe not anyway I do appreciate the question since it's sometimes hard for me to appreciate what's coming across and what's not coming across get rewarded for good questions as well as good answers all right so now let's look at a dynamic programming solution um I've just taken the previously the example we looked at before of solve made it fast solve and I've added a parameter of memo this is the same kind of trick we used last time for our shortest path problem uh I should point out that I'm using this calls to mind a a dirty little secret of python when I have uh previously been hiding because it's it's so ugly I just hate to talk about it but I figured at some point honesty is the right policy um what I'd like is the first time I call fast solve I shouldn't have to know that there's even a memo fast solve should have the same interface as solve the items to consider and the available weight and that's all you should need to know because the memo is part of the implementation not part of the specification of solving the 01 napsack problem we've made that argument several times earlier in the semester and so you might think that what I should therefore do is initialize the memo to say the empty dictionary I'm going to use dictionaries for memos as before and then just check and if it's the empty one that means it's the first you know no I can know whether it's the it'll work fine for the first call well it doesn't work fine and here's a dirty little secret in Python when you have a parameter with a default value that default value is evaluated once so the way the python system works is it will process all of the death statements and evaluate the right hand side here once and then every time the function is called without this optional argument it will use the value it found when it evaluated the death statement now if this value is immutable it doesn't matter you know none will be none forever 28 will be 28 forever 3.7 will be 3.7 forever but if this is a mutable value for example a dict then what will happen is it will create an object which will be initially an empty dictionary but then every time fast solve is called without this argument it will access the same object so if I call fast solve to solve one problem and in the course of that builds up a big dictionary and then I call it again to solve another problem instead of starting with the empty dictionary it will start with the same object it started with the first time which is by now a dictionary filled with values and so I will get the wrong answer this is a subtlety and it's a common kind of bug in Python and I confess to having been bitten by it very recently as in yesterday myself U so it's worth remembering and there's a simple workaround which is the default value is the immutable value I chose none and what I say when I enter it is if the memo is none it means it's been invoked and now I'll initialize it to the empty dictionary and now now every time it will get a new one because we know what this statement says is allocate a new object of type dict and initialize it to empty this will happen dynamically when the thing is invoked rather than statically at the time python processes the diffs it's a silly little problem I hate to bring it up I don't think it should work that way but it does work that way so we're stuck yeah I'm sorry I have to speak more loudly well why doesn't my first call so the question is when I go to test it say why don't I start by calling it with fast solve in an empty dictionary and it's because as we'll see when I get there I want solve and fast solve in this case to have the same interface and in fact we could say I want them to have the same specification because in fact imagine that you wrote a program that called something called solve many times and it was slow and then you took 600 said I know why it's slow because I've used a stupid solve let me use dynamic programming I want to then be able to not name the new one fast solve but replace the old solve by the new solve and have all the programs that use solve still work that will not happen if I insist that the new solve has an extra argument now I could put what's called a wrapper in and call solve and then have it call fast solve with the extra argument and that would work too that would be an equally good solution to this this problem but does that make sense so I I either one would work I chose this one but what wouldn't work in a practical engineering sense is to change the specification to solve all right so it's a silly little thing but since people do get bitten by it um I figure I should tell you about it and I guess while I'm on the subject of silly little things I'll tell you one more thing before we go back to this algorithm down here in the place where I'm uh testing it you'll note that I've imported something called CIS and then said cy. set recursion limit to 2000 in Python there's a maximum depth of recursion when this is exceeded it raises an exception depth exceeded as it happens the default value for that is some tiny number I forget what it is uh such that when I run this on an interest in size example it crashes with that exception so all I'm doing here is saying no I know what I'm doing it's okay to recurse to a greater depth and uh I've set it to 2,000 here which is plenty for what I need I could set it to 20,000 I could set it to 50,000 um again if you're writing a serious program you'll probably find that the default value for the depth of recursion is not enough and you might want to reset it I don't expect you to remember how to do this I expect you to remember that it's possible and if you need to do it you can Google recursion limit Python and it will tell you how to change it but again I found in testing this the default was too small okay um let's go look at the code now for fast solve it's got the items to consider what's available the available weight and a memo I'm going to keep track of the number of calls just for pedagogical reasons we'll want to review that later okay so I'll initialize the memo if if it's the first time through and then the first thing I'll do is what I'm going to code what I have available essentially the way I coded it here sorry what items are remaining by using an index so my items are going to be a set of lists and I'm going to just sort of keep track of where I am in the list just March through exactly the way I marched through here and so if the list of things to consider the length length of it because every time the length is the same it will be the same list since I'm systematically examining a prefix I'm not shuffling the list each time so the length can be used to tell me what I've already looked at so if I've looked at that subl Lisk before with this available weight it will be in the memo and I'll just look up the solution result equals memo of Len of to consider in Veil aail so those will be my keys for my dictionary the key will be a pair of essentially which items I have left to consider which is coded by number and the amount of weight another number or if there's nothing left to consider or there's no weight available then I'll return zero and the empty tupal no value didn't take anything otherwise I'm now in the interesting case um if two consider Subzero first one here if the weight of that is greater than what I have available then I know I can't take it right so I'll just Lop it off and call fast solve recursively with the remaining list same old value of a veil in the same old memo otherwise well now I have an option of taking the first element in the list I'll set the item to that element and I'll consider taking it so I'll cost call fast solve with to consider without the first item but the amount of weight will be of Avail available now is what was available before minus the weight of that item this is my left Branch if you will where I decide to take the item and so now I'm solving a smaller problem the list is smaller and I have less weight the next thing I'll do is consider not taking the item so I'll call fast solve again with the remainder of the list but AAL and memo are not changed that's the right branch and you'll remember our decision tree the right Branch a veil and weight were never changed because I elected not to take that item then I'll just choose the better of the two Alternatives as before and when I'm done I'll update the memo with the solution to the the problem I just solved all right so it's exactly the same as the recursive solution you looked at few weeks ago except I've added this notion of a memo to keep track of what we've already done well let's see how well it works so I've got this test program um just so things are repeatable I've set the seed to zero doesn't matter what I set it to this just says instead of getting a random value each time I'll get the same seed so I'll get the same sequence of pseudo random numbers makes it easier to debug uh all of this Global variable numb calls I'm arbitrarily setting the capacity to eight times the max maximum weight so I'm saying the maximum value of an item is 10 the maximum weight is 10 this just says run slowly is false as in don't run the slow version run only the fast version we'll come back to that I set the capacity of an appsc to eight times the max weight and then for the number of items and I'm just going to go through a different number of items 4 8 16 up to I'm going to call build many items again we've seen this program before that just takes a number of items a maximum value and a maximum weight and build some set of items choosing the values and weights at random from the ones we've offered it this saves me I wasn't going to type a set of 1024 items I guarantee you that if run slowly then that I'm going to test it on both fast solve and solve notice that these are the names of the functions not invocations of the functions because remember functions like everything else in Python are just objects otherwise my tests will be only the Tuple fast solve and then for each function in tests I'm going to set the number of calls to zero I'm going to load up a timer just because I'm ches how long it takes and then I'll call the funk notice again getting back to what we talked about before both fast solve and solve get called with the same arguments I could not have done this trick if fast solve had required an extra parameter and then I'll just see how well it did so let's start with this equal to true so in that case we'll test both of them and let's see how we do so it's chugging along and we see that if I have four items uh fast solve made 29 calls took this much time the Good News by the way you'll notice that fast solve and solve gave me the same value each time we would hope so right uh because you're both supposed to find an optimal solution they could find different sets of items that would be okay but they better add up to the same value um but we seem to be stuck here so you'll notice at 16 solve made 131,000 calls fast solve 3500 only took a third of a second but we seem to be kind of stuck at actually fast Sol only made 1,200 at 32 fast solve made 3500 calls but solve seems to be stuck should this be a shocker that going from 16 to 32 made a big difference well remember here we're talking about two to the 16 possibilities to investigate which is not a huge number but now we're 2 to the 32 which is quite a large number and so we could wait quite a long time for uh solves to actually finish and in fact we're not going to wait that long we'll interrupt it so let's see how well fast solve Works whoops we just call that so we'll set this to false says don't run slowly I.E don't call Sol so not only did we not get stuck at 32 items way up here we didn't get stuck at items huge difference right instead of only being able to process a set of 16 we can process a set of over a thousand and in fact I don't know how much higher we can go I didn't try anything bigger but even this big difference between getting stuck here and not getting stuck here um and in fact not only did we not get stuck it was only 2 seconds so let's ask ourselves a question how fast is this growing not very fast more or less what we see here and this is not something we can guarantee but in this case what we see is as we double the number of items the number of calls kind of doubles as well so we're actually growing pretty slowly um well okay that's good but suppose we want to look at it a little bit more carefully and consider the question of what does govern the running time of fast solve well we know that looking things up in the dict is constant time so that's okay so what's going to govern it is every time we have to add an element to the memo it's going to slow us down because we're gonna have to solve a problem every time we can just look something up in the memo we'll get our answer back in instantaneously so if we think about the running time it's going to be related to how many different key value pairs might we have to compute for the memo well what governs that so we know that the keys in the memo are pairs of to consider and a Val and so we know that the number of possible different keys will be the number of possible values of two consider multiplied by the number of possible values of a veil right well how many possible values of two consider are there what governs that that's the easy question number of items right because I'm just marching across this list chopping off one item at a time at most I can chop off n items if the list is of L l in a veil is more complicated what does a veil depend upon it depends upon well the initial available weight if the initial available weight is zero well then then it's going to end really quickly if it's really big I might have to churn longer but it also depends and this is the key thing on the number of different weights that sets of items can add up to because you'll recall the whole secret here was that we said that different sets of items could actually have the same total weight and that's why we had this business of overlapping sub problems now here since I only had 10 possible weights that tells me that I can't have very many different combinations right that any set of say one item has to be zero through 10 or 0 through N I forget which it was right but either way that means that all I only have 10 different possible sums for sets of length one whereas if my weights ranged over a 100 I would have a hundred different possibilities for sets of length one so that's an important factor in in governing it all right so it's a complicated situation but just to see what happens try to remember how long this took for uh 1024 took 2.2 seconds I'm going to allow 20 different weights and let's see what happens all right it took roughly twice as long all right so that's sort of what we would have expected so again we're going to see the running time is related to that so we can see that it's actually a fairly complicated thing suppose I did something really nasty and went up here where I built my items so here you'll see when I built my items I chose the weight between one in max weight and these were all integers ins suppose instead of that I do this so here after I choose my value between 1 and 10 I'm going to multiply it by some random number between zero and one we've all seen random. random so now how many possible different weights am I going to have a huge number right the number of random numbers between real floats between zero and one is close to infinite right and so in fact now I'm going to see that with a reasonable probability every single item will have a different weight and so things adding up to the same could still happen even if they're all different but it's not very probable so let's see what happens when I run it now it's slowing down pretty quickly pretty much where the other one stopped right remember we got through 16 with slow solve but not through 32 because effectively I've now reduced fast solve to the same as solve it will never find anything in the memo so it's doing exactly the same amount of work as solve did and it will run very slowly okay life is hard but this is what you'd expect because deep down we know the 01 napsack problem is exponential inherently exponential and while I think dynamic programming is kind of a miraculous how well it usually works it's not miraculous in the lurgical sense right it's not actually performing a miracle and solving an exponential problem in linear time it can and all things go bad be exponential and that's what it is here here this kind of algorithm is called pseudo polinomial that it kind of runs in polinomial time but not when things are really bad and uh I won't go into the details of pseudo polinomial but if any of you are in course six you'll hear about it in 66 and 6046 okay uh we can adjourn I'll see you all on Thursday and we're not going to wait for this to finish because it won't