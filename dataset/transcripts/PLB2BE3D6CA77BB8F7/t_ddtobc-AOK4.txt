the following content is provided under a Creative Commons license your support will help MIT open courseware continue to offer highquality educational resources for free to make a donation or view additional materials from hundreds of MIT courses visit MIT opencourseware at ocw.mit.edu all right today I want to spend a few more minutes on plotting and then return to a subject that will occupy us for couple of weeks which is the use of Randomness in in solving problems uh don't save all right so let's first look at one more example of plotting uh it's it's it's simple it's so simple you'll find it's not in your handout um so here it is to start with all I'm doing here is uh wrote a little program to to show the effect of uh compound interest nothing very sophisticated we start with some principle and an interest rate and then we just apply it over and over again and then we're going to plot to show uh what the principle has become if we just keep compounding the interest so it is kind of what you'd expect compound interest is a nice formula you can actually get rich applying it and we see this nice little graph um on the other hand we can't really tell what it is and this is the sort of thing that I see all too often uh including my graduate students produce it they come to my office they show me a graph and they start explaining it and I usually refuse to look at it if it looks like this there is no point in ever and I mean ever producing a graph that does not have a title and labeled axes and in particular you have to label the axes to say what they mean uh fortunately it's easy enough to do um and here I've just done that so I'm going to run the same code to com to compute the interest but I'm going to put a title on the graph you've seen this before I just want to remind you how it works py. tile and then I'm going to label the x- axis and the Y AIS and that gives me a much more useful graph um nothing magic here it's just a reminder that you really need to do these things you'll notice here I've not only told you that this is the years of compounding and that this is the principle but that I've measured it in dollars maybe I should have been even more explicit and said well US Dollars whatever one of the things I did want to point out is uh you saw that you have these various icons that will let you do things like zoom in on a graph and save a graph uh here's this icon that I think uh Professor Grimson mentioned in fact I know he did it's a floppy disc just in case you've never seen one uh I brought a floppy disc to show you this is one of the older floppy discs um these were invented in 1971 by IBM they were originally 8 in in diameter and held all of 80 kilobytes of data um and as you can see unlike later floppy disc they actually flopped eventually uh apple and others pioneered a non-f floppy floppy disc um that was in the 80s um the interesting thing today is is I typically carry around a USB stick with me about that big that holds a roughly 400,000 times more data than this floppy and so uh it's just quite incredible how things have have gone along all right I now want to return to what will be the main theme for uh as I said a couple of weeks which is Randomness and in order to talk about Randomness we have to talk about probability and I know that Professor Grimson started down that path uh just before spring break but if you're anything like me your mind kind of deteriorated a little bit over spring break and your head isn't quite into things and so I'm just going to back up a tiny bit and and start over to get our heads into it and then fairly quickly move on to new things so let's start by asking a simple question you can tell my head isn't quite yet back to things because I forgot that I needed to begin by gathering chalk I've now got it and we'll come over here and take a look at some examples all right so the first question I want to ask is suppose I take a six-sided die a fair one and I roll it 10 times what's the probability of not getting a single one out of that that die well how do we go about answering this well there is a wrong way to do it which is sort of the obvious way and many people will start down this path they'll say well the probability of rolling a one on the not rolling a one on the first try is one over six right right that's that true that's not true right what's the probability of not rolling one the first time 5 over six all right what's the probability of not rolling a one in the second tribe 5 over six well the wrong thing to do of course would be to start adding them up and say well okay we'll just add these up well one way we can tell that's wrong is if we add up 10 of these we get more than one probabilities can never be more than one as we'll see so let's now try and think of the right way to look at this problem so you can think about it if we roll these a DI 10 times each time I'll get a number so I might get a three and then a four and then a two how many possible 10 digigit numbers are there on a six-sided die if I roll it 10 times how many six 10 6 to the 10th exactly just when we looked at binary numbers if I take a 10-digit binary number and ask how many different numbers can I represent in 10 binary digits it's going to be 2 to the 10th here we're base six so it's going to be 6 to the 10th pretty big number now I can say how many of those numbers don't contain a one all right so that's really the question I'm now asking how many of these don't contain a one so as we said if I look at the first R the odds of not getting a one the first time is 5 over six now what's the odds of not getting a one the first or the second time it's 5 over 6 times 5 over six that Mak sense because these are independent events and that's a key notion here I'm assuming that whether I get a one on the second role is independent of whether I got a run in the first role it should be true assuming my dieser die is fair similarly I can do this for the third roll Etc so the probability of not getting a one in 10 rolls is going to be 5 over 6 to the 10th that Mak sense if not speak up because things are going to get more complicated quickly all right so that's pretty simple you all you all with me on that now suppose I ask you the inverse question what is the probability of getting at least one one if I roll the die 10 times so here I've given you how to compute the probability of not getting any ones suppose I ask the probability of at least one one yeah exactly thank you so that would be one minus because we know that the probability the sum of all the possible things that we can do when we do a probability always has to be one it was a good effort um you know that's it if you take if you want to get something where everything is covered the probabilities always have to sum to one and so now there are only two possibilities here one possibility is I don't get any ones one possibility is I get at least one one so if I take all of the possibilities and I subtract the possibilities of not getting any ones the result must be the probability of getting at least one one this is a very common trick in Computing probabilities very often often when I ask or somebody says what's the probability of X the simplest way to compute it is to compute the probability of not X and subtract it from one okay again heading down a wrong track for this one might have said well all right the probability of getting one on the first roll is 1 over six the probability of getting a one in the second roll is one over six probability of getting a third R roll is one over six I'll just add them up and that will give me the probability of getting at least one one how do I how can I be sure that's wrong well when I'm done I would claim the probability is something like that and we know that can't be true because a probability always has to be less than or equal to one so this is a good trick to keep in mind whenever you're given a probability problem try and figure out whether you have a good way to compute it directly or whether it's simpler to compute the not of the probability and then subtract it from one probability is really a fun field um it's interesting its history is intimately connected Ed with the history of gambling and in fact almost all of early probability Theory owes its existence to Gamblers uh people like cardano Pascal fmat bruli Deo llas all famous names you've heard were motivated by a desire to understand games of chance um mostly it started with dice that's why I've been talking about Di Dice and in fact dice are probably the human Race's oldest gambling Implement um they date at least archaeologically to about 600 BC where a pair of dice was found in in Egyptian tombs actually longer than that two Millennia before the birth of Christ people found dice in Egyptian tombs um typically they were made from animal bones but that doesn't matter Pascal's interest in it and Pascal is really considered the founder of probability Theory came when a friend asked him to solve the following problem which I want to work out with you is it profitable to bet that given 24 rolls of a pair of fair dice you would roll a double six he actually had a friend who was in the business of gambling making these bets so they said you've got a pair of dice you roll it 24 times and ask the question what is the probability of getting what we call today box cars and in those days they just called two sixes this was considered a really hard problem in the mid 17th century and in fact Pascal and fmat uh two pretty smart guys as it happens debated this they exchanged letters with each other trying to figure out how to solve this problem shows how math is Advanced because in fact today it's quite an easy problem so let's work it through and think how would we answer this question so what's the probability of rolling of not rolling a double six on the first try well the probability of not rolling a six on one die is six one over six the probability of not rolling a one with the next die is also one over six so the probability of not getting a die in the first rle first double sixes is sorry the probability of getting a double six is 136 so the probability of not getting a double six is 35 right so now we know that the probability of not getting it is that what's the probability of not getting it 24 times in a row it's that which is approximately equal to 0.51 so you can see why the answer was not obvious just by experience but there is a slight Edge in betting that you will not get a double six and 24 times again as assuming you have Fair dice as old as dice is people have built cheaters dice the excavation of Pompei for example they discovered a pair of loaded dice dice with a little weight in it so one number would come up more often than it should uh and in fact if you look at the internet today you will find many sites where you can let's see one I found this morning says quote are you unusually unlucky when it comes to Rolling dice investing in a pair of dice that's more reliable might be just what you need and then it says of course for amusement only um yeah we believe that all right um as much as I trust probability Theory I don't trust my ability to use it and so what I did is uh wrote a little simulation to uh see if see if Pascal was right when he did this so I've got the first just this little test roll which uh rolls a dice number of times and gets a result um now then I decided to check Pascal so I was going to run 100,000 trials and keep track of the number of times it worked so what you'll see I'm doing here is for I in the range number of Trials this is the way we'll do a lot of these simulations and in fact as we deal with probability we'll be dealing a lot with the notion of simulation as you are doing in your current problem set so for I in range number of trials for J in range 24 because that was Pascal's friend's game I'll roll the first ey I'll roll the second ey if they're both sixes I'll say yes equals one and I'll break and then I'll compute the probability of winning or losing okay so let's let it rip so now let's Let It Rip 100 there it is and we can see that it actually comes out pretty close to what Pascal predicted should we be surprised that it didn't come out to exactly well let's see it is is it exactly what is uh 30 5 36 to the 24th so that's the well to 17 digits of precision the exact answer um and you can see we came up with something close to that not exactly that and we wouldn't expect to um now I only did a 100,000 trials if I did a million trials I'd probably come up with something even closer but if I did two trials who knows what I'd get come up with right could be could get one I could get lucky both times or unlucky later on we'll talk more about the question of how do we know how many trials to run now the interesting thing is I'm sure it took me less time to write this program than it took Pascal to solve the problem now the truth is I had several hundred years of other people's work to build on but in general I think one of the questions you'll find is is it easier sometimes to write a simulation than it is to do the probabilities what I often do in practice is both I'll scratch my head and figure out how to figure out the answer analytically and then if it's easy I'll write some code to simulate the problem and expect to get roughly the same answer giving me confidence I've done it correctly on the other hand if I done this simulation and it had come up with something totally bogus or totally different then I would have had to work hard to figure out which was right the code or the math same sort of thing you saw saw when you looked at the random walk and the first time it was done an answer showed up that was just wrong but you need to have some intuition about a problem so that you can look at it and say yeah that's in the ballpark and if it's not it's time to worry this kind of simulation that I've just done for the dice game is what's called a Monte Carlo simulation it is the most popular kind of simulation named after a casino on the Riviera uh in in the small principality of uh Monaco um this was back in the time when it was hard to find a place you could Gamble and this happened to be one of the places you could um the term was coined in 1949 by Stannis ulam and Nicholas U metropoli two very well-known mathematicians ulam who later became famous for Designing the hydrogen bomb with with teller invented the method in 1946 and I'm going to quote from his description of how he invented it the first first thoughts and attempts I made to practice the Monte Carlo method were suggested by a question which occurred to me in 1946 as I was convalescing from an illness and playing solitar the question was what are the chances that a Canfield Solitaire laid out with 52 cards will come out successfully after spending a lot of time trying to estimate them by pure combinatorial calculations I wondered whether a more practical method than quote abst ract thinking end quote might not be to lay it out say 100 times and simply observe and count the number of successful plays this was already possible to Envision with the beginning of a new era of fast computers and I immediately thought of problems as you would I'm sure immediately thought of problems of neutron diffusion and other questions of mathematical physics and more generally how to change processes to described by certain differential equations into an equivalent form interpretable as a succession of random operations later I described the idea to John Vine noyman and we began to plan actual calculations so as early as 1946 people were thinking about the question of moving away from solving systems of equations to using randomized techniques to simulate things and trying to find find out what the actual answer was that way now of course fast is a relative term ulam was probably referring to the eniac computer which could perform about 10 to the three editions a second not very many a thousand operations a second and weighed approximately 25 tons uh today's computers by comparison perform 10 to the 9th editions and weigh about 10 the minus 3 tons all right this technique was used during the Manhattan Project to predict what would happen doing during nuclear fision and worked Monte caros simulations are an example of what's called inferential statistics in brief and I am going to be brief because this is not a statistics C course inferential statistics is based upon one guiding principle and that principle is that a random sample tends to exhibit the same properties as the population from which it is drawn so if I try and Sample people say for predicting an election the notion is if I go and I ask a thousand people at random in Massachusetts who they're going to vote for the average will be about the same as if I looked at the whole population so whenever we use a statistical method like this so for example we assumed here is those 100,000 times I threw the pair of dice that that would be representative of all possible throws of the dice the infinite number of possible throws um one always has to ask the question whether this is true or whether one has a sampling technique that is for example giving you a bias sample a little later in the term we'll talk about many ways in which you can get fooled here and think you're doing a fair statistical analysis and get all the math right and still come up with the wrong answer because this assumption doesn't actually hold all right let's think about it now in terms of coins a little simpler than dice where you can flip a coin and you get either a head or a tail um suppose Harvey Dent for example flipped a coin and it came up heads uh would you feel good inferring from that that the next time he flipped the coin it would also come up heads um I wouldn't suppose he flipped at heads and it came up heads twice in a row would you feel comfortable that the third flip would be ahead probably not but suppose he flipped it a hundred times in a row and it was ahead each time what would you infer I would infer that the coin was two-headed and that in fact every time it was going to come up heads because it is so improbable that if it was a Fair coin what's the probability of getting a 100 heads in a row with a Fair coin one over what one over 100 one over two to 100 right a half the first time times a half times a half a huge number a very small number rather right so the probability and a Fair coin of getting a 100 heads in a row is so low with a just 100 flips that I would begin to think that the coin was not Fair all right suppose however I flipped it a 100 times and I got 52 heads and 48 Tails well I wouldn't assume anything from that would I assume that the next time I flipped it 100 times I'd get the same 40 52 to 48 ratio probably not right you're Common Sense tells you you wouldn't right uh probably it tells you you wouldn't even feel comfortable guessing that there'd be more heads than tails the next time um so when we think about these things we have to think about the number of tests and how close the answer is to what you would get if you did things at random this is sort of comparing this is technically called comparing something to the null hypothesis the null hypothesis is what you would get with a random event and when you do a simulation if you get something that is far from that or when you sample a population you get something that's distant from the null hypothesis you can assume that maybe you're seeing something real all right let's let's look look at this in a little less abstract way so let's go look at some coin flips so I wrote a a simple program flip just flips the coin some number of times and uh tells me what fraction came up heads so we can run it and let's look at uh suppose I flip 100 I get 0.55 if I flip 10 I get 04 if I flip 10 again I get 0. five now look at that same thing twice in a row but now I get 0.2 so obviously I shouldn't infer too much from from 10 flips and even from 100 where I got 0.55 let's see if what happens if I flip 100 again 41 big difference so this is suggesting that we can't feel very good about what happens here now if I do the following well I'm feeling a little bit better about this uh well for one bad reason and one good reason the bad reason is I know the answer is 0. five and that these are both close to 0. five so I feel warm and fuzzy that's cheating I wouldn't even to write the simulation if I knew the answer um but mostly I feel good about it because I'm getting kind of the same answer every time okay and that's important the more I do uh the more stable it gets the the larger the number of Trials this is an example of what's called The Law of large numbers uh also known as bui's law after one of the bruli family of mathematicians and I can't for the life me remember witch bruli there were a whole bunch of them um anyway the law states and it's important to understand this because again it underlies the inferential statistics that in repeated independent tests and it's important to not note the word independent each test has to be independent of the earlier test in this case the tests are Flips of the coin with the same actual probability we'll call it P often used to represent probability of an outcome for each test the chance that the fraction of times that outcome occurs the outcome with probability P converges to p as number of Trials goes to Infinity all right so if I did an infinite number of Trials the fraction of heads I would get in this case would be exactly 0.5 of course I can't do an infinite number of Trials but that's the law of large numbers that says the now it's worth noting that this law does not imply that if I start out with deviations from the expected Behavior Uh those deviations are likely to be quote evened out by opposite deviations in the future so if I happen to start by getting a whole bunch of heads in a row it does not mean that I'm more likely to get tals in a subsequent trial all right because if I were if that were true then they wouldn't be independent independent means memoryless so if I have an independent process what happens in the future cannot be affected by the past and therefore I don't get this business of they even out now people refuse to believe this if you go to any gambling place you'll discover that if the people at the roulette wheel if black comes up 20 times in a row there'll be a rush to bed on red because everyone will say red is due red is due red is due and every psychologist who's ever done this experiment finds that people don't believe it that it's not true people just don't get probability and it happen so often it's got a name called the gambler's fallacy and uh there's been great examples of of of of people going broke doing this now notice that the law of large numbers here is about the fraction of times I get an outcome it does not imply for example that the absolute difference between the number of heads and the number of Tails will will get smaller as I run more trials right it doesn't say anything at all about that it says the ratio of head to tails will approach one but not that the difference between them all right let's look at an example showing that off so what I've got here is this program called flipp plot this is on your handout this is just going to run this business of flipping coins um I should point out just I did it this way just to show you what I'm doing is each flip is random. random is less than five I'll call it a head 0 five I'll call it a heads otherwise a Tails you'll notice that it appears that maybe I'm biasing a little bit because I'm giving point .5 a value but there are so many floating Point numbers between zero and one that the probability of getting exactly 0.5 is so small that I can ignore it it isn't going to really make a difference um random. random is the key issue the key function that's used to implement all the other random functions that we have in in that package all right so I'm going to do it and I'm going to do it over a range of values the minimum exponent to the maximum exponent and for exponent in range Min X to Max x + one I'm going to choose an x value that is two to that so this lets me go over a big range so I'll see what happens if I get one flip and two flips and four and eight and 16 and 32 Etc and then I'm going to just do some plots I'm going to plot the absolute difference between heads and tails and the ratio of heads to tails let's see what happens when we run that actually probably nothing because I didn't uncomment the Run part of it let's do that so I'm going to call Flip plot with four and 20 running from four Trials 2 to the 4 to 2 to the 20 see what we get now you may get different things when you run at different times in fact you will um so here we see something kind of uninteresting um let's cheat and see what we got the first time I ran it uh which is on your handout and I have a PowerPoint with it I was I knew this might happen doesn't usually but sometimes when you run it you get surprising results so here's what happened when I first ran it uh here was the difference between heads and tails and it seems that okay the difference was low it went up it went down it went up it went down uh it seemed to go down dramatically um if you remember remember what we just saw when I ran it we also saw something where it went up a little bit and it went down and then it shot up dramatically at the end which was why that scale was so funny and if we look at the ratio what we see is it seems to start above one drop below one and then seems to converge towards one now I show this because I want to make a couple of points of plotting um let's look at this out here looks like we have a pretty dramatic trend of this linear drop do we do we actually have a trend here well let's think about it the default behavior of the plot command in PAB is to connect points by line how many points do I actually have out here well you saw the code you have the code in a handout how many points do you think there are out here a th000 100 three two two to three right depending what I mean by out here so what we see here is something that happens a lot people plot a small number of points connect them by a line and mislead the audience into thinking there's a trend when in fact maybe all you have is an outlier so it's problematical here to do it that way so let's see what happens if we change the code and what I'm going to do is change it in two ways well maybe I'll change it in one way first oops ah uncomment uncomment so what I'm doing here is I'm plotting it a different way this uh quote Bo says don't connect it by lines but just put a dot as an O and B says make it blue I use blue because it's my favorite color so now if we look at these things we'll see something pretty different so that's the difference between head and Tails that's the ratio but now if we look at the difference between heads and entails here what we see is it's pretty sparse so yeah maybe there's a trend but maybe not right because way out here I'm only connecting two points giving an illusion that there is a trend but in fact no reason to believe it so I always think if you're plotting a small number of points you're much better off just plotting the points than you are uh trying to connect them now if we look at this this one again maybe we'd feel kind of comfortable there is a trend here that there are several points on this line we can't see much of what's going on over here which gets me to the next thing I want to do is I'm going to use logarithmic axes here so pb. semilog X says make the x-axis logarithmic PAB semi log y the Y AIS and so in the case of the absolute difference I'm going to make both logarithmic why am I doing that because both have a large range and by making it logarithmic I can see what's happening at the left side in this case where things are changing when I look at the ratios the Y AIS does not have a very large range and so there's no need to make it logarithmic we'll run it so here we can see the difference between heads and tails and now we can see what's going on at the left as we can in figure four and we can see things much more clearly so log scales can be enormously useful and in fact I use them a lot everyone uses them a lot but again it's very important to observe the fact that it's logarithmic and not get fooled all right um so we talked about linear scaling logarithmic scaling um and we now have charts where I can perhaps actually reach some conclusion about what's going on the next question is how certain can I be can I really be certain that indeed this should be converging to one um here if I sort of look at it it does look like there's kind of a linear trend of the absolute difference growing as the number of Trials goes how certain can I be of that you can never get absolute certainty from sampling because you can never be sure that you haven't been vastly lucky or unlucky that's not to say you can't get the absolute correct answer maybe it'll I could get 0 five which is the correct answer but I can't know that that's the correct answer so now the question I want to pursue and it's what we'll cover on Thursday is what techniques can I use to make a statement of the form I'm certain within the following range that I have the right answer that I know the right answer is highly likely to be this close to the answer my simulation is giving me and we'll look at how we can make those statements and actually believe them okay see you on Thursday