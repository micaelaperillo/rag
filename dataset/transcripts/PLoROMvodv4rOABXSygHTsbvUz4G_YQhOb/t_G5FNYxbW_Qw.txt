all right hey everyone welcome back um is this people hear me okay all right so if as usual you can take a second to enter your uh Su ID so we know who's here um so today's lecture will be a Choose Your Own Adventure lecture um so I think you know by now you've learned a lot about the um Tech iCal aspects of building learning algorithms and then in the third course uh in the third set of modules you saw some of the principles for debuging learning algorithms and how to actually use these tools um in order to be efficient in how you build a machine learning application what I want to do today is uh step through with you a moderately complicated machine learning application and um throughout all of today's lecture I'm going to you know step you through a scenario and then ask you to kind of Choose Your Own Adventure because if you're working on this project what are you going to do right um and to give you more of that practice in the next um what hour and a bit that we have uh on thinking through machine learning strategy um and you know I've seen in so many projects uh there there sometimes things that a less strategically sophisticated team will take a year to do but if you're actually very strategic and very sophisticated in deciding what you will do next right how the drive a project forward I've seen many times that what a different team will take to do maybe you could do it in a month or two right and you know if you're trying to um I don't know write a research paper or build a business or build a product the the the ability to drive a machine learning project quickly gives you a huge advantage and just you know you're Mak it much more efficient use of your life as well right um so in for today I'd like to uh uh I'm going to posee a scenario pose a machine learning application and say all right I mean you are the CEO of this project what are you going to do next so but I'd like to have today's meeting be quite interactive as well so can I get people to sit in groups of two in ideally three or so maybe plus minus one and um try to sit next to someone that you don't work with all the time uh so so if you're sitting sitting next to your best friend I'm glad your best friend is in the class with you but go sit with someone else because I think um I've done this multiple times and the discussion is actually richer if you talk to someone that you don't know super well so actually take a second introduce yourself and and and and just reach your neighbor I guess so the example I want to go through today is actually a continuation of the example I described briefly uh uh in in the last lecture I taught building a speech recognition system right so remember I briefly um multiv this uh trigger word wake word or trigger word detection system last time where you know uh right I I I I actually have both an Amazon Echo and a Google home uh but you know it's it's a lot of work to configure these things to turn on and off your light bulbs um and so if you can build a chip uh to sell to say a lamp maker to recognize uh phrases like you know let's say we call the lamp robit right um then you can recognize phrases like robit turn on right robit turn off and you have a little switch to give this thing different names you call robits or uh ler or Alice or something you can also have lener turn on Lena turn off and give give your lamp a name and just say hey Robert turn on right so rather than detecting different names and turn on and turn off I'm just going to focus on just with a technical discussion I'm just going to focus on the phrase Robert turn on uh but it's kind of the same problem you need to solve like four times to give it two names or to turn on and turn off so I'm going to abbreviate Robert turn on as RTO right if you want to call your name Rob it and um uh tell your lamp to turn on um I think I was inspired by well Isaac azimov wrote these um robotic novel series and and all his robots Nam started with r so maybe R's robot turn on um and so uh let's see so let's say that um you are the new CEO of a small startup with you know three persons uh and your goal is to build an is is to build a circuit oh actually your goal is to build a learning algorithm um that can recognize this phrase robit turn on uh so that when someone you know buys this lamp and they say robit turn on that the lamp can turn on right and just focusing on the task of building a and then you know to to to be SE of this St you need to do a lot of things right you need to figure out how to do the embeded cry figure out who the land makers the sales so there's all that stuff but for today let's just focus on the machine learning aspect of it um and so my first question to you is very open-ended is but and and this is the life of a CEO right you wake up one day and you just got to decide what to do um but so my first question to you is open-ended question is uh you're the co uh you're going to show up at work uh you know tomorrow in your startup office and you want to build a learning algorithm to detect the phrase Robert turn on for this application right so um so my question is what are you going to do right so take a take a minute answer that by yourself first uh no don't don't discuss your neighbor yet but you know you're going to show up in your office and and then you're going to start working on this enging problem to build a new network to do this so uh and and do this as yourself right don't don't don't pretend that you're this hypothetical whatever startup SE with 10 10 billion dollar to spend whatever just do it as let's say yeah I but I I don't think this is a terrible startup idea I I this is not the best idea but I think this could work so you actually welcome to do this but let's say you decide to do this and you go into your office tomorrow like what do you do right why don't you take um why don't you take let's say two minutes to enter an answer then we can then we can discuss in fact I I think um yeah yes one thing I really like about answer is actually the uh V is existing literature part right um in fact when you're sting a new project um uh uh and I think um uh when you're sting a new project like that assuming you've not worked on trigger word detection before you know reading research papers or reading cod in GitHub or reading blog post on this problem actually very good way to quickly level up your knowledge um and I think that you know it it turns that um uh in terms of your uh exploration strategy right um I want to describe to you how I read research papers um uh which is so this is um not a good way to review the literature which is if the x-axis is time and the vertical axis is research papers what some people will do is find the first research paper and read that until it's done and then go and find the second research paper and read that until it's done and then go and find the third research paper and just has this very sequential way of um reading research papers and I find that the more strategic way to to go through these resources everything ranging from block po um lots of good medium articles that explain things right uh research papers um right good Hub is if you use a parallel exploration process where this this is actually what it feels like when I'm doing research on when I'm trying to learn about a new field that I'm not that experted in right so I've actually done a lot of work on trigger word detection but if I hadn't worked on this before then I would probably find you know three papers so again x- axis is time and vertical AIS is different papers and um you know read a few papers kind of in parallel at a surface level and skim them and based on that you might decide to read that one in Greater detail and then to add other papers that you start skimming and maybe find another one that you want to read in great detail and then to gradually add new papers to your reading list uh and read some to confusion and some not to confusion um yeah I was actually chatting with um uh uh one of my friends petb a former student uh at Berkeley who mentioned that he was wanting to learn about a new topic and he he was uh he told me he was compiling a reading list of 200 research papers they want to read that sounds like a lot you you rarely read 200 papers but so I think if you read 10 papers you have a basic understanding if you read 50 you have a pretty decent understanding and if you read like a 100 I think you have a very good understanding uh of a few but often this is time well spent I guess um and uh some other tips again this is I'm really thinking if you really are CEO of this startup and this is what you want to do what advice would I give you um uh uh when you're reading papers uh other things to realize uh one is that uh some papers don't make sense right and that's fine uh uh you know even I read some papers I just go no I don't think that makes sense uh and and it's not that uncommon for us to uh find papers from a decade ago that and we learned that half of it was great and the other half of it you know was really talk about things that were not that important right so it's okay uh authors you know usually papers are technically accurate but often what they thought was important like maybe an author thought that using Bashon was really important for this problem but it just turns out not to be the case that that happens a lot that happens sometimes um and I think the other tactic that I see Stanford students sometimes not use enough is uh talking to experts including contacting the authors so when I read the paper um uh I don't I I don't bother the authors unless I've actually like tried to figure it out myself right but if you actually spend some time trying to understand the paper and if it really doesn't make sense to you uh uh uh is is is okay to email the authors and see if they respond and and people are busy maybe there's a 50% chance of respond and that's okay because it takes you five minutes to write an email and there's a 50% chance to get back to you that could be time pretty well spent uh uh but but don't don't don't bother people unless you try to do your own work I actually get a lot of emails from you know high school students that that do not feel like they've done their own work and and I just right and then right so so just don't don't don't bother people unless you've actually tried to um cool so after um looking at the literature uh and having a base maybe downloading a open source implementation or getting a sense of an Al you want to try oh and it turns out the trigger word detection literature is actually one literature where there isn't consensus on this is a good Al this is a bad Al room right despite all the trigger word or wake word detection systems that you know some of you may use already uh there there there isn't actually consensus in the in in the research for me today on like this is the best Aver to try um but so let's say that um you read some papers downloaded some open source implementations and now you want to start training your first system right last time we talked about this we talked a little bit about how much time you would spend to collect data and and you know we said spend a small amount of time spend like a day or maybe two days at most to collect your first data set to start training up a model though um but my next question to you is what data would you collect right um in particular what train depth test data would you collect so you've decided on an initial neuron Network architecture and you want to train something to recognize this space robit turn on uh I think there's uh probably I don't think it's possible to download the data set I don't think anyone has collected the data set with the words robit turn on and posted down on the internet so you have to collect your own data for this particular trigger phrase that you want to use but um you know as CEO of this startup trying to build a neonet to detect the phrase robit turn on um what data do you collect right so once you take once you're again take I don't know let's say three minutes to write an answer to this yeah I think this is an interesting one um Robert turn on over and over and then data augmentation um data augmentation is one of those techniques that um uh is a way to reduce uh variance in your learning ALG because you're generating more data and uh having worked on this problem I happen to know data augmentation works you know is very useful for this problem but if you didn't already know that fact this is is one of the things I would probably not do right away because I would train a quick and dirty system validate that you really have a high variance problem before investing in the effort in data augmentation so data augment is one of those techniques that some you know like it never hurts it rarely hurts usually helps but I don't bother to make that investment unless you have collected the evidence that you actually have a high variance problem and that this is actually a good use of your time right yeah I think this this one actually this is actually nice so um uh record everyone started say Robert turn 100 times the really nice thing about that you can get it done really quickly um uh when I'm working with teams um I actually think in terms of hours in terms of how long it take us to do do something so this one you could probably do in like 30 minutes right so you get your data set collected in 30 minutes and get going or or or or if you run around Stanford and just ask you know friends or strangers to speak into your uh laptop microphone you spend a few hours to get a much bigger data set than possible with startup so I probably do that I probably actually go and collect data in several hours rather than only spend 30 minutes but this is actually pretty interesting as well because let you get it done really quickly that make sense right so um yeah so let me actually uh uh share some more concrete advice right and and I think actually some sometime back um to to prepare a homework problem that you see later in this course Ken and Unis and I we're actually you know building the system posy to to to create a homework right that that that you see later in this so this is like a uh this trigger word I think is a nice running example that we're using in a few points throughout this course um so here's one thing you can do uh and this this is actually what um uh what we did right which is uh collect um well simplify a little bit [Music] um collect 100 examples of uh uh 10-second audio clips right and so uh it turns out once you grab a hold of someone uh and ask them to speak into your microphone you know you can keep them for um 3 seconds which is how long it takes to say Rober turn on or you can keep them for 10 seconds which they're actually very willing to spend an extra seven seconds with you right um but so if this is 10 seconds of audio data you know so this is 10 seconds of audio right and and audio is just patterns of little changes in air pressure right so if you plot audio the reason it looks like this waveform is just uh the the way you're hearing my voice is you know my voice or the speakers are creating very rapid changes in air pressure and your ear measures those very rapid changes in air pressure interprets the sound and so a microphone uh is a is a sensitive device for recording these very very high frequency changes in air pressure and this plots that you see in audio is just what is the air pressure at different moments in time right but so given a um a 10-second clip like this if this is the 3C section where they said Robert turn on then what you would like to do is to build a desk slamp say they can sit here and the lamp is turned off turned off turn off turn off turn off turn off and at the moment they finish saying Robert turn on you know you turn it on so this is the output label y really right and then and then it's not detecting the phas right so so so what you want to do for the trig word system is at you know pretty much the moment they finish saying Robert turn on uh you want your learning algorithm to Output a one that's your target label y saying yep I just heard this trigger word uh and for all other times you want it to Output zero right because because uh and then the one is when you decide to turn on the lamp at that moment in time right so to collect a data set um here's something you can do which is collect 100 audio clips of 10 seconds each and you know when I'm prioritizing my work or or my team's work I would really you know look at these numbers and think okay let's say let's say actually if you're doing it let's say you're running around Stanford and you want to collect 100 audio clips uh uh maybe 10 people 10 Clips per person or maybe a 100 different people um I would actually estimate you know if you go to Stanford cafeteria uh how long does it take to get one person right you could probably get one person every minute or two if you go to busy place on on like a Stanford cafeteria so you could probably get this done in like 100 to 200 minutes like two or three hours right it's not that bad so you get this done quite quickly um and so and and let's see collect 100 audio clips and actually for the for for the purposes of uh today let's say you collect 100 audio clips to use for training 25 for your Dev set um and zero for the test set right it's actually not that uncommon if you're building a new product to just not have a test set because your goal is to build something that yach convinces you know just early prototyping phases of a project sometimes I don't bother with a test set if if you if it goes to publisher paper then of course you need a rigorously collected test set but if you're just building a product and you don't need a rigorous evaluation sometimes you can just get started without dealing with a test set right so it's pretty e to get started um and [Applause] then all right so taking that audio clip from above um one thing you can do to turn this into supervised learning problem um is to take so you the the the phrase Robert turn on can be said in less than 3 seconds so let's say you take 3 seconds as the duration of audio right so what you can do is uh clip out so let's say here was when Robert turn on was it so what you can do is um right the taret 1 z z um what you can do is then clip out different audio clips of 3 seconds so here's one audio clip and you can take that audio clip this is X and the target label is zero because because Robert turn on was not said um and you can take I know this audio clip a different randomly clipped 3 second clip and that clip also has the target label zero um and you know for this one right which is a 3 second clip that come that that that ends at the real on the last part of the on sound you would have a Target label of one right so and and uh when when when you learn about sequence models or RNN you learn a better method than than this explicit clipping but for now let's say you take these um audio clips and turn it into so take a 10-second clip and by clipping out Rand different Windows you can take your um let's say 100 uh uh clips and because for each 10-second clip you can take different Windows you could turn this into let's say uh 3,000 training examples right so here I took a 10-second clip and and and show you know took three three different 3se second windows but if you take 30 3second windows then each 10-second audio could becomes 30 examples and now you've turned the problem into a binary consecration problem where you need to train a neuron Network that inputs a 3 second clip and labels it as either zero or one right does make sense and so this is an example of uh uh the the the more complex uh pipelines you might have if you're building a learning algorithm to take a continuous You Know audio detection problem turn into the bind classification problem which you've learned how to build various neuron networks for right and again when you learn about RNs you learn about other ways to process sequence data or temporal data okay so um go ahead theed right now is that manually La the data oh uh is this manly lab yes I I would yeah actually if you have 100 examples um it's not that hard to just listen to it you know on your laptop with some audio playing software to figure out when when they finish saying Robert turn on and then at that moment to put a one in the Target label right because this is really when you want the lamp to turn on right make sense cool so um any other questions actually feel you to ask clarifying questions yeah go ahead um I wonder if this is going to cost the problem that um ones are two spars oh sure let me get back to that sure anything else all right for a specific reason we only train them with 3 seconds the voice instead five like some people's voice oh I see yeah oh why do we do 3 seconds and four five seconds there a yeah is there another hyper PR you can test so I think uh I don't know uh you you have to say it really slowly to take I know right 3 seconds is this right a robit turn on right so again it's it's a design Choice yeah yeah um all right so so um let's say you do this feed it to supervis learning algorithm training new network um and let's say that when you classify this uh when you run this algorithm you end up with uh 99.5% accuracy right um uh but you find that the algorithm has zero detections right um and and and and what I mean is that whatever audio you give it it just outputs zero all the time so the hour of them just says Nope I never heard the phrase Robert turn on you know so so so um so uh and so my question to you is you know and by the way the reason I'm going through these scenarios is um I found that uh a good way to gain good intuitions and and to become good at making these decisions is these are the decisions that project leader right a tech leader or Co needs to make these are actually like pretty much exactly the decisions you need to make and I find that um one of the ways to gain this type of experience if you you know find a job with a good AI team and work with them for five years right and then you actually live through this and you see what they do but instead of needing you to go and spend five years to see 10 examples of this I'm trying to step you through maybe one example in in in one hour so so instead of uh you know gaining this experience through work experience which is great but takes many many years many many months uh hoping to you know let's just put you in the position of making these decisions you can learn from that much faster right um but so uh and and all the examples I'm giving are actually completely realistic right there either exactly or very similar to things I have seen in in actual you know very real projects so question is uh your learning album gives this result 95% of aity zero detections what do you do let me mention some of some of the answers I really liked um I think that uh um you know I when I think of building learning algorithms uh the process is often specify a depth set and or test set that measure what you care about and then um you don't always have to do it but it's good hygiene it just is it is um uh sharpens Clarity of your thinking right if you have a very clear specification of problem and I think one Insight out of this is that if your death set is really out of whack right because it's so unbalanced that accuracy in your death set doesn't transl relate to what you actually care about uh because you know presumably it is 99.5% accurate on the dep set as well but this performance is terrible so it's doing great on the depth set on your accuracy mat but giving terrible performance so I think of it as good hygiene you know it's kind of good sound practice uh to to just specify make sure you at least have a death set and evaluation metric that corresponds more closely to what you care about so making the dep set more balanc uh equal numbers of positive and negative would would be good step to of that um uh and then I think um uh you could also uh there are a few people that talked about um give higher weights to the positive examples right so you know uh uh one way to do this is to resample your training and your dep sets to make them more proportionate in terms of maybe closer to balance ratio positive negative examples that' be okay the other way to not do resampling would just give the positive examples a greater weight right um I would probably resample um another thing you could do uh uh uh you know in the in the interest of um uh speed even if it's not the mathematically most most sound thing to do is to change the target labels to be a bunch of ones after that um uh and this is a hack this is not formally rigorous but if you've implemented the rest of this code already this might be a reasonable you know a little bit hacky thing to do but this is this this this might work well enough right I I would I might not I don't know if I would want to try to you write an academic research paper with this method maybe you get away with it but this is all thing that I think if you try to publish a paper with this academic reviewers might raise their eyebrows and say maybe you know maybe this is okay but I think if you want something quick and dirty that just works I think uh uh labeling the ones changing a bunch of labels to be on so that say a clip here right uh that ends just a little bit after Robert turn on the still label one that would be pretty reasonable but this would be saying that um uh for anywhere within maybe a 0.5 second period after Robert turn on finish it's okay to turn on the light anytime within that period that you kind of want to be turning on the light turning on the lamp you know say within half a second right after Robert turn on has has been said right like and this would be a not this would be a way to just get more labels of ones in there right that make sense um um with like rebalancing your data sets like the class imbalance um how does that translate to like when you deploy this you're not going to see Robert turn on as much right like one out of 1,000 might be reflective of what you expect to see yeah this is going yeah right so um I think that uh how to put it um so if you actually yes so well I uh this is sort of a depth set and evaluation measure kind of question right so uh one of the couple of the metrics that people often use uh when actually working on this is um when someone says Robert turn on what is the chance that actually she wakes up or the lamp turns on and then the second is if no one is saying anything to the lamp you know how often does it randomly turn on by itself without you having said anything so those are the two metrics people actually use and and uh sometimes you could also try to combine them a single number evaluation metric or something uh uh but I think that um uh you could then Define a data set to measure both of these things and and then and then hopefully find a way to combine them into single real number which I think yeah I think one of the ways we talked about in the in the videos as well right does that make sense uh yeah but I think I think the question is really um uh what is it that satisfies a user need right yeah and oh and just one one thing about um the straightforward way of rebalancing is that if you don't do this then your whole data set just has very few positive examples right um and so if you throw away all the negative examples so that you cut down the number of negative examples until you have exactly equal numbers of positive and negatives you've actually thrown away a lot of negative examples does this make sense and so one one one problem with the straightforward way of rebalancing is that you know in your audio clip in your test 10 second second clip that we collected by running around Stanford um you have one example of robit turn on and so if you want exactly perfectly balanced positive and negative it means that you're allowed to only clip out one negative example all of this you can say that's a negative and that's a positive and you can't clip out more negative examples from this right so so so if you use a if you insist on the perfect rebalance you're actually throwing away a lot of negative examples that that could be helpful for the learning of them right um so all right so um you know a lot of the workflow of uh building learning algorithms is um uh building learning algorithms feels more like debugging right because what happens in a typical machine learning workflow is you implement something and it doesn't work so you figure out what is the problem so you fix that uh uh like rebalancing or reweighting or adding more once and so that fixes the current problem and then after fixing the current problem which which is the one we just solved say you then come across a new problem and you have to solve that you fix that problem you come across another new problem so I find that uh the workflow of um when I'm work on a machine learning project it often feels more like software debugging than software development right because you're often trying to figure out what doesn't work and then trying to fix that and after you fix that problem then another Buck surfaces and you squash that and you do that and another and you kind of keep doing that until the AL works so if I keep talking about you know your Al doesn't work what do you do next right that that's kind of the theme of today's presentation uh but that that is what the workflow that is what your day-to-day work of developing a learning Alum is usually like because it's like it doesn't work you fix it it still doesn't work you fix that it still doesn't work you fix it and you do that enough times until it works right that that that is actually what often working on the learning out Works looks like um all right so let's say you fix that problem um and you conclude uh through doing error analysis that your algorithm is overfitting right so you know you you've added a lot more ones so the data set is a little bit more balanced so let's just add a bunch of ones like I did on that previous board right let's just add a lot of ones here so the data set isn't as unbalanced and um let's see um right okay good um let's say that sorry too many pages of notes here okay good so let's say that um you find that it achieves now 98% accuracy on training and 50% accuracy on the dep set right so very large gap between your trading and your um death set performance and so a clear sign of overfitting and so I think one of the earlier questions someone talked about data augmentation uh and so when you have this clear sign of overfitting um this is a good time to consider data augmentation right and and so let's say you go ahead and do data augmentation so for audio this is how you could do data augmentation which is um collect a bunch of background audio you know so I guess if you're trying to build a lamp that might go into people's homes then you could go into your friends's homes and uh you know with their permission record right what the background sound in their home looks like you know maybe people talk in the background maybe with the TV on in the background what whatever goes on people's homes um and then it turns out that if you take a um say a 1C clip of Robert turn on of RTO and you add that to a background clip then you can synthesize an audio clip of what it sounds like in your friend's house if someone were to suddenly pop up and say rob it turn on against the background sound of your friend's house right um and and it turns out that um uh uh if you want to make this system robust so actually for example I have a I don't know I actually know someone that lives unfortunately closely to a train station and so their Halls actually has a lot of train station noise from the cow train uh and so so what you can do to make your system more robust is also uh take you know a clip of say train noise right like cow train noise and if you take that noise and take a in this case let's say 1 second 1 second or 3 second clip of someone saying rob a turn on and you synthesize that on top of the train in the background then what you end up with is a 10-second clip of someone saying rob it turn on against a noisy you know train in the background type of type of noise right and so in order to do data augmentation or data synthesis you can take some one second clips of people saying Robert turn on in the quiet background and then take some one second clip of people saying random words right let's say you know Cardinal right say a stford and synthesize this against the train noise background and then you would have in this case you would have what sounds like tray noise tray noise TR noise TR noise Robert turn on TR noise TR condos right and then uh you could generate the labels now as Zero's there ones there and then Zer there right because if this is what it actually sounded like in a in a user's home then um you want the lamp to turn on after rob a turn on but not after these random words you can pick different random words right um so let's see right so um what I'd like you to do is uh evaluate um uh three different possible ways um to collect noisy data right uh to to to collect this type of background data right um and so um what I like you to do for the next question is let's say you and your team you know have uh uh uh brainstormed um uh uh brainstormed a few different ways uh to collect this type of background noise data um and let's say you've decided that uh you would like to collect uh 10 hours of background noise data right so okay so I'm going to going to present to you three options one is um you know run around Stanford and place microphones around Stanford or in your friends homes do this with consent and don't don't you know California actually you're not supposed to don't record people about their knowledge and consent right uh second is uh downloads Clips online right uh it it turns out if you go to YouTube there are these like 10hour long Clips uh of you know rain noise or cars driving around right so you actually uh and again if you do that find something that's Creative Commons and of appropriately license right um another thing you could do is uh use a Mechanical Turk and mechanical tur we can have people all all around the world um be paid you know modest amounts of money to submit audio clips right so for the next exercise what I want you to do because um and I want you to have this exercise of of of this discipline which is what I want you to do is um I want you to estimate let's see what time is it now okay it's 12:30 p.m. right now what I want you to do is uh write down three numbers in the next exercise to estimate if you were to do this you know let's say you were to go do this right now right by what time will you have finished if you were to do option one what time would you finish you were to do option two what time would you finish you were to do option three if your goal is to collect 10 hours of data through one of these mechanisms does that make sense so it's 12:30 p.m. now so what I like you to do is just write down three numbers um first number is what time is it what time will it be by the time you collected 10 hours of data you know from around stand what time will it be right and and if you could do this in so so if if you think you do it by tonight then write 900 p.m. if you think it'll do if you think it'll take you one week then write the date one week from now right whatever it is uh but just write down three numbers of these three activities okay let's want do this one relatively quickly can people do this in like a maybe a minute and a half all right cool this is interesting um yeah what do people think actually this surprisingly large variability I'll mention one thing that um surprised me um I'll give you my own assessment I think that uh you know when I'm leading startup teams we tend to be very Scrappy right and so I think that um if it goes to collect 10 hours of data if you have three friends with laptop you can collect three hours of data per hour because you got three recordings going in parallel so if I were doing this with say two other friends you know I bet I bet we could get this done by tonight right uh uh because if you need nine hours of data that's each person needs to collect three hours of data and you run around Stanford and C the microphone's running I bet I bet I could get this done by 6 p.m. right maybe maybe even earlier I don't know um download Clips online uh is actually I don't know it's actually an interesting one maybe about the same time um it turns out one tricky thing about downloading Clips online is that um uh I think a lot of the you there are people that um have trouble sleeping at night so they listen to Highway noise or whatever right and so there are these you know 20 hours of Highway Clips Highway noise on YouTube that you can find but I I don't know how those were generated and I suspect a lot of them Loop right meaning it's the same one hour play over and over so I actually think it's harder than than than one might guess to get 10 hours of um non-repetitive data and it's one of those things you know if I take an R of high highway sound and loop it you can't tell the difference because all highway sound sounds the same I just can't tell one minute of Highway sound from another one but um if you have one hour of Highway sound looped 10 times the learning Alm wasy perform much less well than if you have 10 hours of fresh Highway sound so this I would actually have a harder time doing I think I probably I I I would Pro if I were doing this I because of these problems I would probably budget until sometime tomorrow right may maybe maybe 9:00 p.m. or something maybe that's doable I'm not sure um the one surprise to me was some people thought they could do this by tonight uh I again I've used Amazon Mechanical it's actually a huge process to set up Amazon Mechanical get people on board um and especially to get them microphone uh uh I don't know if you implement something on flash they can speak in their web browser or and and Flash isn't be supportive it's actually so it's actually not that easy to get a lot of turkers to do this and the global supply of turkers is also unlimited so I would if I were doing this I would probably I don't know maybe a week or something right hard to say I'm not sure um but so the specific opinion isn't that important but I want you to go through this excise because this is how um efficient startup team should you know brainstorm a list of things and then you all figure out how long you think it'll take to do these things and I think uh we can have a debate about how high quality the data is I think you can get very high quality data from this and from this uh I I I just don't trust a lot of those online audio sources uh but if this is really fast and you can get pretty high quality data I would probably do this to collect the background sound to get going right but I think that part of the workflow I see of you know fast moving teams is um pretty much exactly what you did which is why have that exercise of brainstorming the list of options and then really estimating oh what time can we get this done and then use that to pick an option right um and then I want to just mention one last thing um which is that these differences matter right um you know I've actually I've built a lot of speech system bu a lot of machine learning systems but um oh and and I think by the way if you do everything we just described and you see this later in a problem Set uh you can actually with this set of ideas pretty much this set of ideas that we just went through today you can actually put a build build a pretty decent trigger Weare detection system or wake word trigger detection system in fact we ask to do pretty much this in the later homework exercise but now you know when you get to that homework exercise when you do RNN of you know how you could come up with this sort of process yourself if if you didn't already know how to make these types of choices yeah just one question at what time of my research do I have like to think about like which SK of how my micro will affect my results for at the beginning I could think like it's not important like my micro phone on the light is the same as the one that is used when I run around St or when I download C but it might mess a lot my data so that's what point do I have to think about it yeah so my advice so what does your microphone affect your results right my my advice would be to uh get something going quick and dirty and then uh develop a depth set right with the actual types of data you think you get on your real microphone and then see if it is a problem and it may be different microphones do have different characteristics and if it is a problem then go back and think about how you collect data that's more representative of how you test okay I want to mention one more quick thing do I handle clost surveys I want to do something real quick which is um I want to tell you why these things really matter which is um if this is a performance right let's say actually let's say error and um this is time right and if this is today and you're the CE of this s remember that's that's what we're doing in this lesson and this is six months from now and this is 12 months from now great um you know maybe of a competitor actually maybe maybe I don't know maybe because we talked about this so much in this class maybe two of you in this going to build this thought up but but a competitor um but over time most machine learning [Music] teams you know the error actually goes down over time as you work on problems right I mean this is what I see in tons of practical projects you know we work on the project improve the system and the error actually goes down over time as you work on this over the next 12 months say right if you're really see of a startup doing this and it turns out that is the startups have the discipline to constantly be the most efficient um don't do something that takes you two days if you can get a similar result in one day the difference is not that you're one day slower the difference is that you're 2x faster right and then and having that mindset if we can take this whole chart and compress it on the horizontal axis um then you want to be the startup that you know makes the same amount of PRS in 6 months inste of 12 months right because uh if you're able to do this then your startup will actually perform much better in the marketplace assuming you know accuracy is important which it seems to be for Wake word and so don't think of this as saving you a day here and there think of this as making your team twice as fast and that's the difference between this level of performance and that level of performance so that's why when I'm you know building teams and executing these projects I tend to be pretty obsessive about about uh making sure we're very efficient in exploring the options and don't wait till tomorrow to collect data of dubious quality when you have a better idea of collecting data by today because the difference is not that you wasted 12 hours the difference is you are twice as slow as a company right so I think uh so hopefully through this example and your ongoing experiences throughout this qualter can help you continue to get better at this right um last thing we want to do was uh we're about halfway through the course go ahead um we want to hand out a survey uh an anonymous survey uh to get some feedback from you about this class and whenever we get these surveys uh we end up uh uh thanks to previous generations of students feedback we've already been gradually making class better so I think uh Ken and I actually read all of these questions ourselves and try to find ways to take your feedback to improve the class so uh if you can take you know five minutes uh um f the survey and you can hand it in just drop it off anonymously up here in front uh be very grateful for your suggestions okay so um I think if you haven't entered your ID yet uh you could still do so but uh that's it for today so please follow the survey and the anonymously just drop off back and front then we'll wrap up okay thank you