all right Harry one okay I guess we're live so as Aarthi was saying please enter your son at ID we can bring this up again at the end of class today we're just taking another like what 20 seconds and then we'll we'll go onto the main discussion all right so um what I want to discuss with you today is maybe what I'm gonna call full cycle deep learning applications and so I think this Sunday you'll be submitting your proposals for the class projects you do this quarter and in most of the in a lot of what you learn about the machine learning projects you learn how to build machine learning models what I want to do today is share view the bigger context of how a machine learning model you know have a neural network my train fits in the context of a bigger project so what are all the steps right just as if you're writing a software product you know you take other classes and don't you know that that teach you how to build a website for example what is that but Sybilla product requires more than just building a website right so what are the what are the other things you need to do to actually do a successful software project in this case to do a successful machine learning application and so let's see so - oh yeah oh test test is the only alarm test could you turn up the audio No how's this nope can't hear me at all my oh I think I'm broadcasting I hear myself great okay you can hear me now great thank you all right thank you all right so one over this is share view a full cycle machine learning not just how to you learn a lot about how to build deep learning models but how does that fit in a bigger project right just as if you're taking the claws on building a website you know then great you know how the code of a website that's really valuable but what are all the things you need to do to make a successful website to build a build a project that involves launching a website up mobile back or whatever so as you plan for your class project proposals do to Sunday if you're doing an application project that fits in the context of a bigger application also take some of these steps in mind right so you know these are what I think of as a steps of an ml project oh really maybe maybe not class project but maybe you're serious machine learning application right and I think oh no I've built a lot of machine learning products over several years so some of these are also things that I wish I had known like you know many years ago um one this was kind of maybe kind of obvious but you know select a problem and let's say for the sake of simplicity that if you use supervised learning right it turns out for the CSU 30 class projects I think more than 50% of the projects tend to use supervisor and then there are also other projects that use end up using gans which talked about later this quarter or all the things but I think you know let's say you supervised learning to build a machine application and oh and I think for today I'm gonna use as a running example building a building a voice-activated device right so you know I don't know actually how many of you have like a smart speaker in your home like a voice-activated device in your home you know there were in the u.s. well not that many of you it just okay cool yeah so I think you know the the Amazon echoes google homes the apple series or the the in China might one of my form of tea is built by two 200s but let's say for the sake of argument that you want to build a voice-activated device and I'm going to use as a running example and so in order to build a voice-activated advice and again I'm not gonna use any of the commercial brands like Alexa okay Google or hey Suri or I guess in China was a hello sale dude won't sell do anyhow which means kind of roughly how long I don't do um but let's use a more neutral word which is less you wanted to build a device that your response to that will activate and you're actually gonna implement this as a problem set later this quarter but so you want to build a yeah okay no volume publish let's see how they okay is this better no yes yeah this is better okay cool thank you no but ironic don't have speech recognition and the volume is higher okay um so let's say you want a WoW is it let me know if I can suffocate it thank you um so let's you want to build a voice-activated device so the key components the key machine learning deep learning component is going to be a learning algorithm that takes us input and audio clip and outputs to the detect what's sometimes called the trigger word yeah did I go soft again okay this'll be great alright and and O+ why you know zero one did you to check their trigger word such as a lexer or okay google or history or a hollow little do or or activate on whatever wake where they'll trigger word right um and so step one is select a problem and then in order to train a learning algorithm you need to get labeled data if you apply supervised learning and then you design a model use backdrop or some of the other albums you learn about momentum atom various optimization algorithms gradient descent to train the model and then maybe you test it on your test set and then you deploy it meaning you start selling these smart speakers and you know putting them into hopefully until you uses homes and then you have to maintain the system I'll talk about this later as well and and this is not chronological but one thing that's often done but I want to talk about it at the end instead it's not really step 8 is IQA which is a quality assurance which is an ongoing process right and so one let's see so as you so if you want to build a product if you want to sell a machine there any product these are maybe some of the key steps you need to work on some observations when you train them although training them all is often a very iterative process so every time you train the machine there in your model you find that you know I can almost guarantee whatever you do it will not work at least not the first time right and so you find that even though I've written is a sequence of steps when you train them although you're on the go note that neural network architecture didn't work I need to increase the number of hidden units or change the regularization or switch there are n N or switch to a totally different architecture and sometimes you train them all and go nope that didn't work I need to get more data right and so this is often a very iterative process where you're cycling through oh there's several different steps here and then I think one distinction that you have not yet learned about in the Coursera in the d-plan Dalia kosair videos is how to split up the data into train dev and test so I'm going to simplify those details for now but just as a foreshadowing you guys know what oh you learn later in the in the deep end ie i conserve videos is how to take a dataset you have training to use my entire training set into a set that you actually test cross validate using during development called a deficit or development set or hold our cross-validation set that's what's a separate test set so you learn about this later but I'm just simplifying a little bit for today okay so um so I think the first thing I want to do is ask you a question right so we're gonna talk through many of these steps so and it turns out that what a lot of machine learning classes do and do a good job teaching is focusing on maybe these three steps or maybe these four steps right and what I want to do today is spend more time so this is the heart of machine there I mean how do you build a green model and what I want to do today is spend more time talking about step one and six and seven and then just a little bit of time talking about that call this because you kind of need to do the other steps was well if you wanna throw the deep learning product or build a machine learning application okay um so let's sort of a discussion question um I'm actually curious if you are selecting a project to work on what other actually so I don't don't answer this yet I'll tell you what the question I'm going to ask is which is alright uh what properties make for a good candidate deep learning project but don't answer yet right now I want to say a few more things before before I invite you to answer which is that all of you for the last few days I hope I've been thinking about what price you want to do for this cause and what I want to do is just discuss some properties of what a good project to work on and what are maybe not good practice and where okay and and think of this as your chance to give your classmates advice right one of the things your cosplay should think about the challenge decides is a good price to work on okay um and so what I want to do for today is use this voice-activated thing as as long as it most an example and you know there's actually one project I was working on actually a father where actually there's one project I thought of working on but decided not to work on and that there's a voice-activated device so it turns out that um these voice-activated devices and echo Google homes and so on they are taking off quite rapidly in the US and around the world um it turns out that one of the you know significant pain points of these devices is the need to configure it right to set it up for Wi-Fi so I've done a lot of work on speech recognition you know a hotel de la working on speech system I let the by to speech system so I've been published papers on speech recognition and I have a I have one of these devices in my home right actually I have an Amazon echo in my innovative but even to this day I have configured exactly one light bulb to be hooked up to be controlled by my echo because the the set up process not blaming any country is just difficult to hook up you know a Wi-Fi enabled light bomb and then to set it up so that your small speaker or whatever as in say you know smart device turn off the lamp so I have one light bulb in my living room right that I can turn on and off and that's it right even as a speech researcher so um we must have valleys um so one one one application that I think that actually sir sequencing working on is to build a embedded device that you can sell to lamp makers so that I don't know where you buy an ounce from and you know have a few Lancer Mike here if you lands or wherever but you can buy a desk lamp so that when you buy the desk lamp there's already a built-in microphone so that without needing to connect this thing to Wi-Fi you know as I hey here's a twenty dollar desk lamp put them on your desk and you can go home and say desk lamp turn on or just lamp turn off then I think that will help a lot more users get voice activated devices into their home and it's actually not clear to me if you want to turn on a desk lamp is actually not clear to me that you want to turn to small speaker and say hey smart speaker please turn on that lamp over there it may be a fuse one actor they just talk directly to a desk lamp and tow it to turn on the turn and so so far well is where if someone friends and I we evaluated this we actually thought that this could be a reasonable business to build embedded devices to sell to lamp makers or other device makers so that they can sell their own voice-activated devices without needing just complicated Wi-Fi setup process and so to do this you would need to build a learning algorithm and have it Raman invent a device that just inputs an audio clip and outputs you know whenever it detects the wave word and instead of a wake where being activated the week where it would be a lamp turned on or lamp turn off you need to wake where so trigger words want to turn it on when to turn it off right oh and and and I think just the other thing that I think would make this work is to to give these devices names so if you have five lamps or two lambs you you need an way to index into these different desk lamps so let's say you decide for your project you know to have a little switch here so this lamp could be called John or Mary or Bob or Alice like a four-way switch so that depending on where you set this four-way switch you can say you know John turn oh right always if you decide to call this lamb John I girls would give us some of the names so you don't have every lamp by the same name okay um so what I'm gonna do is use as a motivating example this as a possible project oh and I'm not working on this if any of you want to be able to start up doing this go for it this is not know I felt my team's night way better ideas so we want to do other things in this by I should don't see anything wrong with this I think there's actually could be a reasonable thing to pursue yourself and I'm not doing it so yeah very welcome to if you want okay so now the question that one opposed to you is when you're brainstorming project ideas you know like this idea some other idea um what are the things you would want to watch out for well what are the properties that you have want to be true in order for you to few good proposing this as a as a CSU 30 project right so why should take a minute and write this down I think uh yeah what if you're asking your friend if a friend is asking you what are the things I should look at to see if something is a big project what would you why you recommend to them so feel free just write down a few key words and then we'll see what people say and then and then I'll tell you what I tend to look out for when I'm selecting projects and I have a list of five points my stick like I don't know like two minutes - oh sorry this is not activated you're not able to answer is up enter SS okay just checking on yeah BAM connect to the internet RT any ideas oh I see okay all right let me try that it's what's working now okay thank you yes thank you so you take like two minutes to enter and I think I think I can figure this and let you enter multiple answers mistake 2 News all right another one minute 30 seconds okay three two one well maybe in hindsight that wasn't the best visualization can people see this well than one trying to see if all right so detail in novels he lost his data some of these re small human doable number of examples during two months no office you industrial fields clear objective practical useful oh ok finish in time he'll stroll life problem useful hasn't been done computationally tractable yeah generalization see cool great oh let me make some comments on fees I think I this is this is pretty good um I had a list of five bullet points that maybe I just share view my list of five which is I mean just some things I encourage you to pay attention to well you know just this may or may not be the best criteria but interests I think interest just it doesn't hopefully you'd work on something that you actually interested in um and then I think right data availability which many of you cited is a good criteria or one of the ways that Stanford class projects sometimes do not go well is if students spend a month to try to collect data and after month I've not yet found it in your car again and then you know and then it's and there's a lot of waste of time um one thing that I would encourage you to consider as well is domain knowledge um and I think that if you are a biologist and have unique knowledge into some aspect of biology to which you want to apply machine learning that will actually let you do is very interesting project right that is actually difficult for others to do um and I think more generally as advice for navigating your careers right so yeah this is a gene because AI machine learning deep learning there's so much there's so many people wanting to jump into machine learning and deep learning actually giving example so I sometimes talk to doctors near radiology students including Stanford and other universities recognizes students that want to learn about machine learning right because they hear about you know deep learning maybe someday affecting radiolysis jobs and so they want to be part of deep learning and so my career advice to them is usually to not forget everything they learned as a doctor and try to you know do machine learning 101 from scratch and just forget everything they learn as a doctor and just become a CS major I think that that path can work but I think where radiologists could do the most unique work that that allows them to make the most unique contribution is that they use their domain knowledge of healthcare radiology and do something in machine learning applied to radiology right and so all right how many Millennials are there in this class what does that mean me me anything all right this is really wrong yeah I I think it's because a word cloud so everybody counts where frequency right the money thing I don't know have very mixed feelings about that all right um but I think actually fir I actually know that some of you are taking you know deep learning because you work on a different discipline and you want to do something and this hot new exciting thing of machine learning and I think whatever discipline you're in if you had told me knowledge about some other area you know Education civil engineering biology and law taking deep learning allows you to do very unique work apply machine learning to your domain right let's see um I think that I think well I call the utility but several of you mentioned as well something that has a positive impact that she helps other people and I don't know money could be an aspect of utility but maybe not the most inspiring one and then I think um I think one of the biggest challenges we face in the industry today is still frankly is actually good judgment on feasibility um so today I still see too many leaders sometimes CEOs of large companies that stand onstage and announce to the whole world you know we're gonna do this machine learning project to do this by this deadline and then 20 minutes later I talked to their engineers and the NSA no there's no way not happening what the CEO just final stage how engine motivation is not doing it and knows it's impossible so I think one of the biggest challenges is actually feasibility um in fact I actually know that a chapter of RT about the TA office hours and I know that there been a lot of you know long if you have been thinking about applying end-to-end deep learning right you know can you input any X and output any Y and do that accurately and sometimes it's possible and sometimes it's not and it still takes relatively deep judgement about what neural networks can and cannot do with a certain amount of data that you may or may not be able to acquire in order to do some of these things right so so I think throughout this quarter you gain much deeper judgment as well on what is feasible and I guess no Swedish thing I once no III knew a CEO of a very of a large company that once told his team he actually gave his team these instructions he said I watched assume that a I can do anything and and and I think that had an interesting effect I guess yeah cool all right so I think step one um was select a project I hope there's this thing project I keep some of those things in mind um step two is get data and so uh what I want you to do I'm going to pose a second question and then have some of you discuss this let's say that you're actually working on this you know smart voice-activated embedded device thing right so let's say that you and your friends wonderful startup so train the deep learning algorithm to detect you know phrases like John turn on Mary turn off or Bob turn off or whatever to sell to device makers so that they can have low voice embedded voice detection tripped it doesn't require a complicated Wi-Fi setup process right so let's see one that let's say that you want to do this so you need to collect some data in order to start training a learning algorithm okay so the second question I posed to you is to a question in two parts but but have you answer it all at the same time which is um in how many how many days let's say you actually proposed this for your C su-30 project this Sunday and then you start work on it you know like on Monday or even it's not work on it today before the proposal but how many days would you spend collecting data and how would you collect the data okay and I think um actually how many of you have participated in engineering scrum if you know what that means oh okay a few you they'll see the industry okay alright so engineering estimation when you estimate how long a project takes one of the common practices is use a Fibonacci sequence to estimate how long a project will take right and so Fibonacci sequence 1 1 2 3 5 8 13 and so on and there's roughly powers of 2 but doesn't grow as fast as powers 2 and Fibonacci numbers are cool right but so so so what I want you to do a universal special have a configuration right when I with speech bubbles okay yeah that's good all right so what I'd like you to do is in the text answer I really write two things one is write a number how many days do you think you spend on collecting data you and your teammates if you're actually doing this project and then how how would you go about collecting the data okay so much take like another two minutes to write in an answer oh I'm sorry they're still not activated sir all that I'm trying to hit oh you just think that it's not helpful all right damn it's definitely not helpful all right let's do this write down your answer on a piece of paper first and take two in this design so the two questions are how many days pick a number from a Fibonacci sequence and are you oh okay yeah let's swap out my computer varieties Oh actually yeah oh if hotties computers working I should go ahead oh yeah I can just present yeah yeah let's plug in your laptop so you just use your laptop yeah doesn't say when there was a network problem or web browser problem I started using a Firefox recently in addition to Chrome and Safari and Dallas Firefox I tried with other web browsers later I cook bacon thank you thanks Artie all right can maybe we have made people that take another minute from now just extend the time bit turned alright another 10 seconds let's see my sugar pills answers okay alright well 365 so there's a there's a there's a lot of variance in the answers right I don't know download from online depends on what data you want it turns out well so if you're trying to find data or phrases like John turn on then that data doesn't exist online it turns out we're trying to find audio clips of the web activate there are some websites with single words pronounced but those but not a lot of audio clips actually so they trade the world of the wake word is the word activate there are some websites we can download like maybe 10 audio clips of a few people are saying activate but it's quite hard to find hundreds of examples of different people saying they were activate five days it falls in the sky all right so let me suggest let me suggest that you guys discuss with each other in small groups what you think would be the best strategy how many days we find collecting the data and how would you start going and try to convince people next to you on that and and before I ask you to start discussing I want to leave you one thought which is how long do you think I'll take you to train your first model right and so if I take you a day to train your first model or two days do you want to spend X time collecting the eternal and then spend let's say you know I don't know just out of a deep learning thing train them although it might take a couple of days very especially if you download open source packages so so if the amount of time needed to collect data is X followed by two days to train your first model what do you think X should be the amount of time once you guys spend like two minutes to discuss with each other and see if you can compare their answers are there's very large variance right once you guys discuss if you actually if the people sitting next to you are your project partners why should discuss with them how many days you think you should spend collecting danger and how you collect your data okay let's take two minutes to discuss them [Applause] [Applause] all right all right guys so Wow all right guy hey guys so all right lot of exciting discussion so actually how many of you how many of the groups wound up on the on the low end how many of you you know convince each other that maybe it should be like three days or less oh just a few of you how come so someone someone say why why said wife oh yeah got them open the data to test how the other works before you were going to make a massive you said and then anyone has had a high end like a 13 days or more very few how come anyone actually anyone anyone with insights you want a share of the whole classes you what were you are discussing so excited knowledge that I actually can take a long time especially for this colony like based on the one I gave you this doesn't be a statue if they can make pretty you say movieclip something like subtitles to make generate sound like audience it means as far as we were just wanted to get our system live and that would take like a time to like mine yeah yeah yeah right yeah and then company systems to look at subtitle videos right like YouTube videos with captions or something and if there's appropriately Creative Commons data there that you could use yeah so let me let me tell you my bias I just tell you what I would do if I was working on this project well one caveat if I haven't done so much work and speech recognition previously fragments was my first project um I would probably spend one to two days collecting today's Hera kind of on the short end right and I think that Dallman you know one of the and and and one of the reasons is that machine learning kind of that circle I grew up there is actually a very iterative process where um until you try it you you almost never know what's actually going to be hard about the problem right and so so if I was seeing this project I just so you wanna see what I would do okay now that you thought about this project a bunch right including you know trying to validate market acceptance and so on but um which is that I would get a cheap microphone user or use the built-in laptop microphone or buy a microphone off you know buy a microphone off Amazon or something and go around say go around Stanford campus or go to your friends and have them just say hey do you mind saying into this microphone the word activate or don't turn on or whatever and collect a bunch of data that way and then and with one or two days you should be able to collect at least hundreds of examples and that might be enough of a data set to start training a rudimentary learning algorithm to get going because if you have not yet worked on this problem before it turns out to be very difficult to know what's going to be hard about the problem so it's what's going to be hard highly accented speakers right oh it smells gonna be hard background noise what's gonna be hard you know confusing turn on with turn off you hear John turn and then but when you build a new machine learning system it's very difficult to know what's hard it was easy about the problem what's going to be difficult that Fafi which is the technical term for if the microphone is very far away all right so turns out that you know if we turn on the microphone on my laptop now for example the laptop which is like three meters away from me will be hearing voice directly from my null as well as voice bouncing off the wall so there's a lot of reverberation in this room and so that makes speech recognition harder humor here are so good at processing out reverberant sounds reverberations that you almost don't notice it but it makes it actually but but learning every room will have sometimes has problems with reverberations ray or echoes bouncing off the hard walls in this room and so depending on what you're learning album has trouble with you will then want to go back to collect very different types of data or explore very different types of algorithms well that's the problem that sometimes it's because just the volume is just too soft in which case you know maybe you need to do something else and normalize all the volumes or buy more since it might for something so it turns out that when building most machine learning applications unless you've experienced working on it so I've actually worked on this problem before so have a sense it was hard it was easy but they work on the new project for the first time it's very difficult to know what's on it was easy and so my advice to most teams is rather than spending say 20 days to collect data and then two days to collect model to train a model and it's often by training a model and then seeing what are the examples it gets wrong whether the averin fail that that lets you feedback to either collect more data or redesign the model right or try something else and if you can string the data collection peering down to be more comparable to how long you end up taking to train your model then you can start iterating much more rapidly on actually improving your model right oh and um so maybe one roof that I should tend to recommend for most cost projects is I don't know if it may be if you need to spend a week up to a week to collect data you know maybe that's okay but you can get going even more quickly I would even maybe more strongly recommend that and there been so few examples in my life where the first time I trained the learning algorithm it works right it like pretty much never happens yeah it happened once about a year ago and I was so surprised I still remember that one time and so what so so machine learning development is often a very iterative process and by quickly find a set and and often datasets are collected through sweat and hard work right and so I would literally you know and actually what my version along well speech indicate going quickly I would probably just have myself well my team members run around and find people and ask them to speak into microphone and record all your clips that way and then only when you validate that you need a bigger data set which you go to more complicated things I said of an Amazon Mechanical Turk thing right to crowdsource which I've also done actually I've also had very largely a self collected of Amazon Mechanical Turk but only in a later stage the project and you understand what you really need um so as you as you start work on your class projects maybe maybe keep that keep that in mind now so one other tip that machine learning researchers on average we tend to be terrible at this but I'll give this advice anyway is when you're going through this process yes someday there are design a model a literature search would be very helpful you know so see what other see what algorithms others are using for this problem it turns out the literature actually quite immature there isn't a convergence of like a well standard set of standard algorithms for trigger word detection in literature right now much people are still making up algorithms so if you if you do the survey you find that to be case but you need trained initial model and in most machine learning applications you go through this process multiple time so one tip that I would recommend you do is uh keep clear notes on the experiments you've run because so often be as we train them although you see oh this model works great on American accent two speakers but not on British accent two speakers right I was born in the UK so I'm just use Pradesh accents run example if you're a different part of the world you think of different global axes it sends down from the UK I'm just a pick on British accents I guess keep clear notes on the experiments run because what happens in every machine learning project is after a while you have trained 30 models and then you and your team is occurring oh yeah we tried that idea two weeks ago didn't work and if you have clear notes from when you actually did that work two years ago then you can refer back rather than have to rerun an experiment oh the other thing that some groups do is have a spreadsheet that keeps track of what's the learning rate you use what's the number of hidden units what's this was this was this or cheaper than a in a text document so that which will make it easier to refer to it to know some ways you try earlier this is one piece of comedy giving advice and there's one of those things that every machine learning person knows we should do this but on average we're very bad at doing but but that you could I don't know but at the times I manage to keep good knows is that she save them all the time right to try to remember what exactly you tried two weeks ago okay so um Baba this class will be on this process how to get data develop the chain dev test the design and model we train the model eventually test them all then innovate so a lot of us causes on this so when they jump ahead to when you have a good enough model and you want to deploy it okay so step six my guess is deployment now um this is uh one of the reasons I want to step through this example going through a concrete example is I find it when you're learning about machine learning for the first time it's often seeing you know what my team's tend to call wall stories kind of stories of projects that others have built before that often provides the best learning experience so I think like I have built speech recognition systems it took me like a year or two years ago me to do it so I'm trying to so rather than you know having you spend two years here alight building speech systems if can summarize a war story right to tell you what the process is like I'm hoping that these concrete examples of what building these systems are like in you know large corporations that that can help you accelerate your learnings without needing to get two years of on-the-job experience you can just hear the salient points okay now if you're deploying a system like this one of the things intersection true there's actually real phenomenon for deploying speech systems is uh yet the audio clip you have a new network and then you know this will output zero one and the neural networks that work well will tend to be relatively large relatively large mall the Marshall or his engine is relatively high complexity and if you have so the smart speakers in your home you recognize that a lot of them are age devices as opposed to purely crawl computation right so we all know what the cloud is and what an edge devices an edge device is a small speaker that's in your home or the cell phone in your so edge devices are you know the things that are close to the data is supposed to cloud which is a giant service we have in our data centers right so um because of network latency and and and and because of privacy a lot of these computations are done on edge devices like the small speaker in your home or like I guess hey Suri or okay Google can wake up your cell phone right and so edge devices have much lower computational budgets and much lower power budgets limited battery life much less powerful processors than we have in our cloud data centers and so it turns out that salt salt serving up a very large neural network is quite difficult right it's very difficult for you know a low-power inexpensive microprocessor sitting in the spots between your living room to run a very large neural network with a lot of hidden units with all the parameters and so what is often done is to actually do this which is to input an audio clip and then have a much simpler algorithm figure out if you know anyone is even talking right because so the smart speaker you know in my living room here silence most of the day right because usually just no one at home writes no no no voice and then only if it hears you know someone talking then feeding to the big neural network that you've trained and ramped up use a larger power budget in order to classify 0 1 ok this component goes by many different names in in reasonably standard terminology but not totally standard terminology in the literature I'm gonna call this VAD for a voice activity detection it turns out that voice activity detection is the standard component is in many different speech recognition system if you are using a cell phone for example VAD is a component that tries to figure there is even talking because if it thinks no one is talking then there's no need to encode the audio and try to transmit the audio right yeah LT could you know yeah um and so so the next question I want to ask you and then I I thought this is timely because well is a couple options right option one is to build an on machine learning based EAD system voice activity detection system which is just you know see if the volume of the audio your spawn speakers recording is greater than epsilon so the silence just together and option two is train a small neural network to recognize on on on human speech right and so my next question to you is if you work on this project which you pick option one or would you pick option to write as you as you as you work to what oh sorry and I think on a small neural network so to a small neural network or in some cases I've seen people use a small support vector machine as well for those you know what that is a small model can be run with a low computational budget it's a much simpler problem to Detective someone is talking than to recognize the word this is so you can actually do this you know what reasonable accuracy was small new network but if you actually work on this project for CS 230 which would you try for us so could we come to the next question yeah yeah you can let them start on screen I guess and I mean why are you afraid other projection cool I'll just keep unlocking it periodically are people able to vote no they're no pants yeah well I see I guess you write so much code you have a shortcut to go through your coding environment oh you're that all right cool oh well great right people have seen quickly another like 20 seconds if that's enough time to get your answers all right cool that's fascinating there's a lot of disagreement in this house people will not say why why would you choose option 1 why would you choose option 2 and then IIIi have a very strong point of view on what I would do right but but I'm curious why why option 1 and why option to go ahead either [Music] option 2 you can probably kind of already like this simplify the problem when a consultant know exists not if it knows I mean activates the machine but if it's out parking option to be much better yes option 2 300 when someone's whistling oh yeah right if you're in the noisy place like you know I have a friend who saw the statue this next a train station and so right so option one we picked up a lot the train which ever it has to be running constantly so you want something in Spanish so it seems like option one is better because yeah whether it has to become running constantly you still want to be like no power no country so let me show you for the pros and cons um so um I think you know there are pros and cons option when the option to versus while you're sewing so so many votes for both options I perceive would choose option 1 but but let me just let's just discuss the pros and cons right I think that um option 1 um first is just a few lines of code this is yes maybe option 2 isn't that complicated but option 1 is even simpler and I think that um actually maybe I would say if I hadn't worked on this problem before I which is option 1 but since I have experience as feature a commission eventually I know you need option 2 but that's because I because I've worked on this problem before but if your first time work on the speech application problem I would encourage you on average to try to really simple quick and dirty solutions and go ahead and so let's see how long would it take you to implement this right I would say like 10 minutes five minutes I don't know right Harlan would think of them with that oh four hours one day I I don't really know actually right now let me just write one day and I'm not quite sure all right but if um option one commence in 10 minutes then I would encourage you to do that and go ahead and put the smart speaker in your home or in your potential users homes and only when you find out that the dog barking is a problem or the train on the railway sings you know whatever it's a problem then go back and invest more in fixing it right and in fact um it's true that maybe it's annoying that the dog barking keeps on waking up the system but maybe that's okay because if the large new network then screens out all the dog barking then the overall performance system is actually just fine and and and then you now have a much simpler system rights but but but it turns out that um the reason you might need to go to option to eventually is because there are some homes in noisy environments you know this constant background noise and so that will keep the large new network running longer too frequently so so if you have a large engineering budget you know so it's not the small speaker teams are hundreds of engineers working on it they have hundreds of engines work on that totally options who will perform better but if you're strapped a start-up team is scrappy startup team with three of you work on a cross project you know the evidence that you need that love of complexity is not that high and I would really do that first and and use that to gather evidence that you really should make the investment to build more complex system before actually making the investments of days or and eventually I think this is one day to put your first prototype right and then eventually will be will be more complicated um it turns out that the other reason the other huge advantage of the simple method is the following oh and this is one of the frankly this is one of the this is actually one of the big problems and big weaknesses of machine learning algorithms and deep learning of rooms which is what happens is uh when you build a system and you should ship a product the data will change right and so I'm gonna sin Phi the example of it but you know I know Stanford is very cosmopolitan this powell's is very hot so on see the collect data in this region you get access from people all over the world right because because that's Stanford all that's although but but just to simplify these app a little bit let's say that you train on u.s. accents right but you know for some reason when you ship a product maybe it sells really well in the UK and you start getting data with UK or with British accents so one of the biggest problems you face in practical deployment of machine learning systems is that the data you train on is not going to be the data you need to perform well on and and I'm going to share with you some practical ideas for how to solve this but this is one of those practical realities and practical reasons is machine learning that is actually not talked about much in academia because it turns out that the data says we have in academia are not selling well for researchers to study and publish papers on this I think we can sell new machine learning benchmarks in the future but there's one of those problems that is actually kind of underappreciated in academic literature but that is a problem facing many many practical deployments machine learning algorithms and and so more generally eat the problem is one of data changing right and you might have new classes of users with new accents or you might train a lot on the maybe you get data from even Stanford users and maybe Stanford is not too noisy or Stanford at certain you know types of characters things when you ship it to another city another country there's much more noisy you know different background noise right or you start manufacturing the small speaker and to lower the cost of the speaker they swap it out they swap out the high-end microphone that you use from your laptop to collect the data from low-end microphone this very common thing done in you know well done the manufacturing right if you can use a cheaper microphone wine and often to human ears the sound sounds just fine on a cheaper microphone but if you change your learning algorithm using your you know I guess yeah well I use a map but the Mac has a pretty decent microphone so if you train the data using all your craft or a Mac and then eventually is a different microphone it may not generalize well so one of the challenges of machine learning is that you often develop a system on one dataset and then when you ship a product something about the world changes and your system needs to perform on a very different type of data than what you had trained up and so and so what would happen is after you deploy the model the world may change and you often end up going back to get more data redesign the model right and I guess sorry and this is this is a the maintenance of the machine learning model only give some of the examples web search right this happens all the time at multiple search engines which is you train a neural network or you train a system to give relevant web search results but then something about the world changes your for example there's a major public web and some new person is elected president of some foreign country or there's a major scandal or just the internet changes right or there's a actually what happens in China is a new words getting invented all the time in China China says that by of were that Google and Baidu but the Chinese language is more fluid than the English language and so new words get invented all the time and so the language changes and so whatever your train just isn't working as long as it used to right or maybe a different company suddenly shuts off you know their entire website to your search index because they don't want you indexing their website and so the internet changes and what have you had done doesn't work anymore or self-driving it turns out if you build a self-driving car in California and then you try to deploy these vehicles in Texas you know it turns out traffic lights in Texas look very different than traffic lights in California so um although it rained on California Texas so a new network trained to recognize California traffic lights actually doesn't work very well on Texas traffic lights right I'm trying to remember which way round leanest I think California Texas has a different distribution of horizontal versus vertical traffic lights for example right it's actually humans don't else's you go oh yeah red yellow green but the learning algorithm doesn't actually generalize that well if you go to different locations go to a foreign country again traffic light signage the lane markers all change or I guess what one example is working on earlier this week right manufacturing right landing a guy working on inspection of parts and factories and so if you are doing visual inspection in the factory and the factory starts making a new component you know they're making this model cell phone but cell phones turn over quickly and so but in a few months later they're making a different type of cell phone or something weird happens in a vacuum process so the lighting changes with a new type of defect so the world changes and um so what I'd like to do is actually revisit the previous question in light of this the world changes phenomenon right which is let's say you've collected all data with American accent two speakers and then you know we ship the product in the UK and then and then for some reason you find that you've all these British accent speakers right trying to use your spot speaker so between these two algorithms the non machine learning approaches I said the threshold versus train a neural network which system do you think would be more robust for dat voice activity detection all right take like another 40 seconds all right yeah interesting if you want to comment well more people voted for non ml just want to explain why for the VAD boys activity section if you just measure the volume then it doesn't really depend on on the accent like so non ml might be more robust anyone else all right so okay let me show you I thought so it turns out that um if you train a small neural network to you know American accent is speech there's a bigger chance that your neural network because it's so clever right that'll learn to recognize American speech and have a harder time generalizing to British accent in speech he says and so one of the things that have seen a lot of teams where is so one way the non-mo thing could fail to generalize would be a British speakers are systematically you know allowed there or softer than American speakers right sir you know I don't know I don't have Americans saris Oakley allowed their own less loud and British but but you know but if but if American British because one one country just as louder voices and softer voices then maybe the threshold you set won't generalize well but that seems unlikely right I don't see that being realistically but but they were training on your network a lot parameters then it's more likely that the neural network will pick up on some idiosyncrasy of American accents to decide the cities even speaking and thus maybe less robust to generalizing into a British accent speech right and another way to think about this is if you imagine to take it even further example imagine that you're using VAD for a totally different language than intent in English right where take a different language you know Chinese or Hindi you all Spanish or something where the sounds are really different if you create a VAD system to detect you know English it may not at all work for detecting Spanish or Chinese or French or or some other language and so if you think of British accents as somewhere on the spectrum not the foreign language binding means but just more different then I think the nominal system is more likely to be robust and so one lesson is that too many that a lot of machine learning teams during the hard way is uh if you don't need to use a learning algorithm or something if you can hand code a simple room like if volume greater than 0.01 do this all that those rules are can be more robust and the one of the reasons we use learning algorithms is when we can't hang called something right I don't know how the hand comes something to detect a cat or to take a car in the real goal detect the person so use learning our ones for those but there's actually hand coded rule that actually does pretty well you find that it is more robust to ships in the data and will often generalize better oh and if any of you take a we talked about this about this little bit in CS 239 I think this is your ninety talks about this as well but this particular observation is backed up by very rigorous learning theory and the learning theory is basically that the fewer parameters you have if you still do well on your training set if you can have model with very few parameters that does well on your training set you generalize better right so there's this very rigorous machine learning theory that basically says that and in the case of the non machine learning approach there's maybe one parameter which is what's the threshold for epsilon and that's welcome well now for your training set then you're also fit generalizing even when the data changes is um much higher right um now the last question um I want to post the discussion today is when when discussing deployments oh and so one of the lessons deployment is that's just a way the world works you know build a machine learning system deploy it the world will usually change and you often end up collecting data and have it integrated and maybe improve the model right and they're fixing waffle for British speakers or nothing um so we talked about edged appointments as well called appointments and so um ignoring issues of user privacy and latency which is super important but for purposes question let's let's let's put aside issues of user privacy and network latency if you need to maintain the model sorry maintenance means updating the model right even as the world changes sorry I missed mr. history does a column or H deployment make maintenance easier if not of right why don't you watch you just enter a one-word answer and why right and so maintenance is going the world changes something changes so you need to update the learning model to take it back take care of this British accent so which type of deployment makes it easier let me just take like yeah another two minutes and your answers all right another 50 seconds all right cool see what people wrote Wow cool great all right almost everyone the same college most people are saying cloud alright cool great and then just to summarize I think there are two reasons why most people say this is easier push updates that's part of it I think the other part of it is that if all the data lives at the edge if all the data's process you know they use this home and then if it comes to crawl then even if you have all these unhappy British accents and users you may not even find out right you say the company headquarters you have all these users that mysteriously you know seem to be not using your device maybe because they're in satisfied with it but if the data isn't coming into your service in the cloud then you may not even find out about it now there's serious issues about user privacy as well security right so so so please if you ever bought the product please be respectful of that and then take take take care of that in a very thoughtful and respectful way of users but if first if so this is the cloud if you have a lot of edge devices and all the data is processed there um you won't even know what your users are doing and they're happy unhappy you just don't know but if some of the data are in the stream to your service at the cloud and if the user privacy would really please use good music consent tell people what you doing on the data but if you take care of that you know in a reasonable and sound way if you're able to examine some of the data then you can at least figure out that gee looks like analyzing the data there are these people this acts on this background noise that is giving it back rather than experience and you can also maybe have the data so you can gather the data from the edge to feedback to your model right so so lets you detect that something's gone wrong it lets you have the data to retrain the model to solve the British accent problems you can retrain the model for a lot British accent to speak and then finally lets you push them all back home okay so the first unless you detect what's going on - it gives you data for training then three unless you more easily push the model back up push push the new model to a production it's a deployment okay oh and this is also why even if your computation needs to run on the edge if you could in a way respectful of user privacy in this transparent about how you use data if you can get even a small sample of data or have a few volunteer users send you some data back to the cloud that will greatly increase your ability to detect there's something gone wrong as well maybe give you some data to retrain the model so even if you can only do so that push updates right this this will just will help greatly okay um all right so finally one last comment I think one one one last challenge is a lot of machine learning systems you're not done at deployment there's a constant ongoing maintenance process and I think one of the processes you know AI teams are getting better on this wall I set up QA to make sure that we update the model you don't break something so I think QA and large companies Quality Assurance process it's called testing us and I think the way you test machine algorithms is different in the way you test try there's no software because the performance of machine learning algorithms is often measured in a statistical way right so it doesn't work and it doesn't work it neither works no doesn't work instead it works you know 95 percent of the time or something and so lot of companies are evolving the QA processes that this type of statistical testing to make sure that even you change the modern you to push update its the works you know 95 or 99 percent of the time or something rather than so-so so putting in place new QA test processes as well ok all right I hope that was helpful stepping through what the full arc of a machine learning project will look like well well later this for certain course vias was no later lectures are present we keep talking about machine learning strategy and how to make business so let's break for today