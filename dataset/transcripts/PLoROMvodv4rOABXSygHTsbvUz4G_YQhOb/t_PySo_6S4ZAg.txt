okay hey everyone morning welcome to CST 30 deep learning so many of you know that deep learning these days is the latest hottest area of computer science or AI arguably deep learning is the latest hottest area of you know all the human activity maybe but this is a cost CST 30 deep learning where we hope that we can help you understand the state of the art and become experts at building and applying deep learning systems unlike many Stanford courses this class will be more interactive than than others because this class we often in the flipped classroom format where we'll ask you to watch a lot of the videos at home a lot of the deep learning AI content hosted on Coursera does preserving the classroom and discussion section time but much deeper discussions so to get started let me let me first introduce our teaching team so the co-instructors Archaean cotton guru who had actually one of the co-creators of the deep learning specialization the atlanta AI content that were using in this class and the rest of the teaching team swathi Dube is the cost coordinator and she has been working with me and others on coordinating I guess CSU 30 also cs2 29 CSU generate to make all of these classes run well and let you have a relatively smooth you know experience Eunice Mori is the cause adviser and he'd also worked closely with IANA me in creating blobby online contents that you use and Eunice is also head ta 462 98 which some of you may also be taking and then we have two co-head TAS or RT by guru who's worked on machine learning research for a long time and opposition oi who is still traveling back I think and also a large team of TAS that I think about half about TAS and CS 230 had previously ta schools and their expertise spans everything from applying machine learning problems in the health care or climate learning or applying deep learning to problems it in robotics to problems in computational biology to problems in so I hope that as you work on your projects this quarter as policy as 2:30 you'll be able to get a lot of great advice and help and mentorship from all of the tiers as well so the plan for today is I was going to spend maybe the little bit of time sharing with you what's happening in deep learning why you know why deep learning is taking off and how this might affect your careers and then in the second half I have Ken will take over and talk a bit more about the projects you work on in this class and not just a final term project but you know the little machine translation system you build the face recognition system you build their our generation system you build their all of the many pretty cool machine learning deep learning applications I mean you get to build throughout the course of this quarter and also share view the the detailed logistics for the plan for the class ok so I think that let's see all right I'm going to just use the whiteboard for this part so um you know deep learning right you know seems like the media still can't stop talking about it and it turns out that a lot of the ideas of deep learning happen around for several decades right the basic ideas of deep learning happen around for decades so why is deep learning suddenly taking off now that why is it quote coming out of nowhere on whatever whatever people say I think that the main reason that deep learning has been taking off and why you know suddenly all of you hopefully will be that do really powerful things with it much more effectively than two or three years ago is the following um for a lot of over the last couple decades with the digitization of society we've just collected more and more data so for example all of us spend a lot more time on our computers and smart phones now and whenever you do things on the phone you know that creates data right and and and what used to be represented through pieces of paper is now much more likely a digital record as well so you're if you go take an x-ray as at least in the United States less than some other kind in developing colonies beliefs in the United States there's much higher chance now than your x-ray in the hospital is a digital image rather than a physical piece of film or if you order a new marker right there's a much higher chance that the fact that you order the marker you know off a website it's now represented as a digital record compared to ten years ago when the state of the global supply chain actually if you order if you order ten thousand markers there's a much higher chance you know ten years ago that the fact that you place that order was stored on a piece of paper that someone scribbled saying a ship ten thousand markers to Stanford but now that's much more likely to be a digital record and so the fact that so many pieces of paper and our digital has created data and for a lot of application areas the amount of data has sort of you know exploded over the loss twenty years but what we found was that if you look at more traditional learning algorithms traditional machine learning algorithms the performance and most of them would Plateau even as you feed it more and more days so by traditional learning algorithms I mean logistic regression support vector machines you know maybe decision trees develop initial details and it was as if out all the learning algorithms didn't know what to do of all the data you can now feed it but what we start to define several years ago was they between a small neural network right it's performance may look like that if we train a medium neural net the ones may look like that and if you train a very large neural net you know the performance kind of keeps on getting better and better up to some usually up to some theoretical limit called Bayes error rate which is learned about later this coarser a bit but performance can never exceed 100% but sometimes sometimes there's some seething in the performance but also we've been able to measure on many many problems with not yet I think that across machine learning and deep learning broadly I think we've not yet hit the limits of scale and by scale I mean the amount of data you can throw the problem that's still useful for the problem as well as the size of the neural networks and I think you know GPU computing was a large part of how we were able to go from training small two mediums and now training very large neural networks and once upon a time I think you know the first actually I think a lot of the early work on training neural networks on GPUs done here at Stanford right who they're using crew that the training neural networks but what used to be you know one thing one lessons we learn over and over in computing is that what yesterday's supercomputer is today's you know processor on your on your SmartWatch right and so what used to be an amount of computation that was accessible only to you know large research labs in Stanford they could spend a hundred thousand dollars on GPUs today you could that honor on a cloud relatively inexpensively and so the availability of relatively large neural network training capabilities as allow really students really know almost everyone many people not not many many people to have enough access computational power to train what are large enough nearing that where else to drive very high levels of accuracy for a lot of applications right and it turns out that if you look broadly across AI you know I think the mass media right newspapers reporters use the term AI I think within within academia or within the industry you tend to say machine learning and deep learning but if you look broadly across AI it turns out that AI has many many tools that's beyond machine learning does even beyond deep learning and if any of you take you know CS 221 write stamp is a high class great class you learn about a lot of these other tools of AI but the reason that deep learning is so valuable today is that if you look across many of the tools of AI and that's saying you know there's a deep learning slash machine learning oh and and and and again some you know new networks and deep learning mean almost exactly the same thing right it's just that as you know as we start to see deep learning rise of the last several years we found that deep learning was just a much more attractive brand and so you know and so so that's the brand that took off but if you look at if you even take an AI class it was a broadly across the portfolio of tools you have an AI I think that you know I'll often use deep learning machine learning how sometimes also use a probabilistic graphical model right we should learn the button cs2 Tony also great cause sometimes I use the planning algorithm you know when I'm working on a self-driving car right you need a motion planning algorithm you need various planning our rhythms sometimes I use a search algorithm sometimes I use knowledge representation it's very sick this is one of the technologies especially knowledge drafts is one of the technologies that is widely used in industry but I think often underappreciated in academia if you do a web search and a web search engine pulls up a hotel and the list of room prices and what this Wi-Fi was a swimming pool that's actually a knowledge graph or knowledge representation knowledge graph but so it's actually used by many companies this large databases but this is that he may be under appreciated in academia or sometimes even game theory so if you learn about AI there is a very large portfolio of many different tools you will see but what has happened over the last several years is if you go to a conference on probabilistic graphical models right if this is time and this is a performance e you see that you know every year probably see graphical models work a little bit better than the year before if you go to the u AI conference uncertainty an AI conference maybe the one of the leading conferences maybe the leading one not shown on P GM's you see there every year you know researchers published papers that better than the year before in the state it's the the field is steadily marching always I'm saying for planning if you go to Tripoli on something you see you know a feud is advancing social rooms are getting better another obsession Alvarez game better getting Theory albums again better and so the the field of AI marches forward across all of these different disciplines but the one that has taken off you know incredibly quickly is deep learning machine learning and I think a lot of this progress was initially driven by scale scale of data and scale of computation and the fact that we can now get tons of data during the surge on your network and get good performance but more recently has been also driven by the positive feedback loop of seeing early traction and deep learning thus causing a lot more people to do research and deep learning algorithms and so there's been tons of algorithmic innovation in deep learning in the last several years and you hear a lot about algorithms that were you know relatively recently invented to sauce as well right and so really I think that initially the twin forces of a scale of data scale computation but now the triple forces have also a lot of algorithmic innovation and massive investment is continuing to make deep learning make tremendous progress and so in CST 30 we kind of have you know I I think two main goals the first is to have you become expert in the deep learning algorithms have you have you learned the city arts have you have you have you have deep technical knowledge on the save outs and deep learning and second is to give you the know how to apply these algorithms to whatever problems you want to work on so one of the things I've learned so I think you know actually some some of you guys know my history right so you know birthed at Stanford for a long time then um started as leading the Google brain team which did law projects at Google and I think the Google brain teams you know built from scratch was arguably the leading force for helping Google go from what was already a great internet company into today a great AI company and then there's something some that I do in China oh it's Chinese hey cause in China which kind of helped I do go from also what was already a great company into today you know many people say China's greatest AI company and I think through work on many projects at Google many friends if I do and now leading landing AI are helping many companies on many projects and running around to different companies and see many different machine learning projects they have I think I've been fortunate to learn a lot of lessons not just about the technical aspects of machine learning but about the practical know-how has fangs the Machine your name and if you and and I think that what you can learn from you know the internet or from purely academic sources or from reading research papers is a lot of the technical aspects of machine learning and deep learning but there are a lot of other practical aspects of how to get these algorithms to work that I actually do not know of any other academic course that that kind of goes into great deaf teaching rates there might be one but I'm I'm not sure but one of the things that we hope to do in this class is to not just give you the tools but also giving know-how on how to make it work right and I think you know I should spend a lot of time thinking about so actually late last night I actually stayed that very late last night meeting this new book by um Jon osterhaus on a software architecture right and I think that there's a huge difference between you know a junior software engineer and a senior software engineer maybe everyone understands the c-plus paused in the Python in the Java syntax yeah you can get that from promote from you just figure out hey this is how c-plus this works inside job where else is how Python numpy works but it's often the high level judgment decisions of how the architecture system what abstractions do you use how do you define interfaces that defines the difference between a really good software engineer versus you know a less experienced software engineer it's not understanding c-plus or syntax and I think in the same way today there are lots of ways for you to learn the technical tools of machine learning and deep learning and you will learn that in this class you know you learn how to train a neural network you learn the latest optimization algorithms you understand deeply what the content is whether recurrent neural network whereas when lsdm is you you understand what intention mod allows you you learn all of these things in great detail your work impression could be vision nationally entrusting speech and so on but I think one other thing that is relatively unique to this class and to that I guess the the things you see on the defender AI course are websites as what's the things with doing cause is trying to give you the practical know-how so that when you're building a machine learning system you can be very efficient in deciding things like should you collect more data or not right and the answer is not always yes I think I think um with I think that many of us try to convey the message that having more data is good right and that's actually more data pretty much never hurts but I think the message of big data has also been overhyped and sometimes it's actually not worth your while to couldn't collect more data right but so when you're working a machine learning project and if you are either doing it by yourself or leading a team your ability to make a good judgment decision about should just spend another week collecting more data or should you spend another week searching for Hyper parameters or tuning parameters your own network that's the type of decision that if you make it correctly can easily make your team 2x or 3x or maybe 10x more efficient and so one thing we hope to do in this class is more systematically imparts to you this this type of knowledge right and so I think even today I you know actually I actually visited lots of machine learning teams around Silicon Valley around we're on the cusp you what they're doing and you know recently I visited a company that had a team of 30 people trying to build a learning algorithm and the team about 30 people was working on learning out run for about three months right and and they had not yet managed to get it to work so they're basically you know like you know not succeeded after three months one of my colleagues took the data set oh yeah can your broadcasting don't say anything bad alright so one of my colleagues took the data set home and spend one weekend working on what's he doing now and and and one of my colleagues working on this problem in one long weekend here at Sun over long weekend for three days was able to build a machine learning system that outperform what this group of 30 people have been able to do after about three months so was that desica oh no that's more than a tengas difference and right and and a lot of the differences between the great machine learning teams versus less experienced ones is actually not just do you know how to you know implement it's not just you know how to implement and LST em right in intensive though or carrots or whatever you have to know that but there's actually other things as well and I think Ken and I and the teaching team are looking forward trying to systematically impart to you a lot of this know-how so that when hopefully someday what you're leading a team of machine learning engineers or deep learning engineers that you could help direct the team's efforts more efficiently and oh actually if any we're interested one of the things happen actually how many of you have heard of machine learning yearning machine learning yearning Wow almost none of you okay interesting um so this is a if this is your first machine learning class this may be too advanced for you but if you've had a little bit of other machine learning background machine learning yearning is a booklet being right did I've been I've been working on its slowing draw form but if any of you want to but machine learning yearning is my attempt to try to turn gather best principles the turning machine learning from a black art into systematic engineer discipline and so if you go to this website you know this website will send you actually I just finished the last just finished the whole draft last weekend and so email allowing students if you want a copy go to the website and enter your email address now make sure that you know when we send out the book actually might be later today not sure that well then you get a copy of the book drop this wall I tend to write books and then just post them on the internet for free so you could but this here was just email them them out to people so you can you can you can get it if you go to the web site and I think this will and I think this calls to talking all about lot of principles of machine learning urine II but give you much more practice as well then they're just reading a book might um so let's see okay so um Jen will give a greater overview of what we'll cover in this class but one of the principles have learned as well is that you know it so I think I'm actually some of you know my background right is a co-founder Coursera was initially for a long time so spent a long time really thinking a lot about education and I think cs2 30 represents you know Keon and mine are teaching teens really best attempt to deliver a great on-campus deep learning course and so and so the format of this class is what's called a flipped classroom class and what that means is that so you know and I think I've taught on SCPD for a long time right for many many years I guess and I found it even for classes like CST to nine or other Stanford courses often students end up you know watching videos at home and and I think with the flipped classroom what we realized was if many students are watching videos of these lectures at home anyway why don't we spend a lot of effort to produce higher quality videos that you can watch then a more time efficient for you to watch at home and so our team created videos DVR I created you know kind of the best videos we knew how to create on deep learning there are now hosted on Coursera and so with I actually think that will be quite time efficient for you to watch those videos do the online program exercises do the online quizzes and what that does is it preserves the class time both the weekly sessions that we meet right here on Wednesdays as well as the TA discussion sections on Fridays for much deeper interactions and for much deeper discussions and so the format of the class is that we ask you to you know do the online content created by the Avaya host on Coursera then in class both the meetings with enemy Anakin and I will split these sessions roughly 50/50 as was for the deeper small group discussion sections you have for the TAS that lets you spend much more time interacting with the TAS interacting with knme and going deeper into the material then just then the then the then the then the online content by yourself and that will also give us more opportunities to give you advanced material that goes beyond was hosted online as well as give you additional practice with these concepts right and so let's see yeah and so um I was a finish up with two more files and now I hand it over to Karen I think you know machine learning deep learning AI whatever is changing a lot of industries right IIIi think you know I think AI is the new electricity much as the rise of electricity about 100 years ago starting in the United States transform every industry really you know the rise of HST transform agriculture because finally we have refrigeration right that transform agriculture a transform healthcare imagine going to a hospital today there's no electricity or how do you how do you even do that right computers medical devices have even run a healthcare system with transform communications through telecom through the Telegraph initiative and now so much the communications really needs electricity but electricity transform every major industry and I think machine learning and deep learning has reached a level of maturity where we see a surprisingly clear path for it to also transform pretty much every industry and I hope that through this class after these next ten weeks that all of you will be well qualified to go into these different industries and help transform them as well and I think you know after this class I hope that you'll be well qualified to like get a job and some of the big shiny tech companies that have large AIT I think a lot of the most exciting work to be done today still is to go into the less shiny industries that do not yet have AI machine learning yet and to take it to those areas actually underway in us chatting with a student that works in cosmology who was commenting was that you know who was it so oh at the back I was commenting the cosmology needs more machine learning right and and then maybe he will be the one to take a lot of the ideas or deep learning into cosmology because I think even outside the shiny tech areas like and then maybe since I helped play around there AI transmission of two large research companies I'm like done transforming internet search companies and I think that but I think and I think it's great that we have those great AI teams like Google grain I do AI grew other large tech companies are great a I teams I think that's wonderful I think a lot of the important work to be done now how many of you will do is to take AI to health care taking out the competition ology taking out to civil energy intake Anatomy country I think all of this is worth doing just like electricity didn't have one color app it's useful for a lot of things and I think many of you will go out after this cause and execute many exciting projects both in tech companies and in you know other areas that that like cosmology right or other areas they were not traditionally considered CAS areas um so just wrap up with a to lost thoughts I think that one of the things that excites me these days is on hoping you know I always share view one of the lessons I learned right watching the rise of AI in multiple companies and smell a long time thinking about you know what is it that makes a great AI company and one of the lessons I learned was really a hearing Jeff Bezos speak about what is it that makes for an Internet company right and I think a lot of lessons that we learn with the rise of the Internet will be useful you know an internet was maybe one of the last major technology ways of disruption and just as there's a great time to start working on the Internet maybe 20 years ago I think today is a great time start working on a iot of learning and so sir wait to turn on the lights on this side as well do I do I control that okay thank you okay so so I want to show you one of the lessons either and really spend a lot of time trying to understand the rise of the internet because I think we useful to many of you as you navigate the rise of machine learning AI in your upcoming careers as well which is um one of the lessons I learned was it can take your favorite shopping mall and build a website for the shopping mall that does not turn your shopping mall into an Internet company right so you know like my wife like Stanford Shopping Center and I and Stanford Shopping has a website but even if you know a great shopping mall sell stuff on the website there's a huge difference between a shopping mall with a website compared to true internet comfy like an Amazon so what's the difference about five six six six seven years ago I was chatting with the CEO of a very large American retailer and at that time he and the CIO were saying to me they're saying look Andrew we have a website we sell things on the website amazon has a website Amazon sells things on the website is the same thing but of course it's not and today this peculiar large American retailers you know future existence is actually a little bit in question Poggi partly because of Amazon so one of the lessons I learned really very influenced by Jeff Bezos is that what defines the Internet company is not just whether you have a website instead it is have you organized your team or your company to do the things that the internet lets you do really well for example internet teams engage in pervasive maybe testing right we know that we could launch two versions of a website and just see which one works better and so we learn much faster where's a traditional shopping law you can't launch two shopping malls in two parallel universes and see which one works better so you just so much harder to do that we tend to have short shipping times right you can ship a new product every day or every week and so you learn much faster whereas the traditional shopping mall may redesign the shopping mall once per once every three months right and we actually organize our teams differently we tend to push decision-making down to the engineers or engineers and product managers because in the traditional shopping mall you know things kind of move slower and maybe the CEO says something and then everyone just does what the CEO says and that's fine but in the Internet era we learned that the technology and the users are so complicated that only the engineers and the product managers for those who don't know what that is are close enough to the technology to the algorithms and the users to make good decisions and so we tend to push decision-making power in Internet companies down to the engineers so engineers and product managers and you have to do that in the Internet era because that's how you organize a company or organize a team to do the things the internet lets you do really well so I think that was the rise of the internet um I think we've divided the AI era or AI machine learning or deep learning whether you really call it we're learning that if you have you know a traditional company plus a few neural networks that does not by itself turn the company into AI company and I think what will define the great AI teams of the future will be do you know how to organize your own work and organize your team's work to do the things that modern you know machine learning and deep learning and other AI things let's you do really well and I think having many items at Google and Baidu other buyers I think you know Google and Baidu like great and many other countries and thinking the through but I think even the best companies in the world haven't completely figured out what are the principles by which to organize AI teams but I think some of them will be that we tend to I think that AI teams tend to be very good at a strategic data acquisition and so you see AI companies or AI teams even even you know do things that may not seem like it makes sense and why do these companies of all these three products that don't make any money well some of it is the required data that you can monetize through other ways right through advertising or through learning about users and so there are a lot of data acquisition strategies that at the surface level may not make sense but actually do make sense if you understand how this can be married with deep learning algorithms to create value elsewhere and I think that uh AI companies tend to organize data differently right ai teams tend to be very good at putting our data together I think before the rise of deep learning many companies have fragmented data warehouses where I have a big company if you have 50 different databases you know in 50 different divisions it's actually very difficult for an engineer to look at all those dates and put it together to train the learning algorithm to do something valuable so the leading AI companies tend to have unified data warehouses and I guess and I know we have a large home audience or SCPD or other home audience here so if any of you work a large tech companies you know this is something that that many companies are investing in today to lay the foundation for learning algorithms we tend to be very good at smarting a pervasive automation opportunities and which is very good at spotting opportunities where you could instead of having people do a task of a deep learning algorithm to at all so I have a different thing I offer into a toss and we also have me descriptions which I don't have time to talk about but just as book the rise of the internet we started creating a lot of new roles for engineers I think actually once upon the time the world was simple and there was just a software engineering title but as technology gotten got more complicated we started to specialize so that's why you know with the Internet where front end back and mobile right and then we have you know and then with increasingly other roles right cue a DevOps IT move into increased specialization of knowledge and so what the rise of machine learning we're starting the creation of new roles like machine learning engineer research machine learning research scientists and our product managers and AI teams also behave differently than proper managers and internet companies and so one of the things we'll revisit a few times throughout this quarter is and I don't mean to to corporate I know that many of you are you know some of the SUV the audience or online orders already working company many of you when you graduate from Stanford we end up maybe starting your own company or joining an existing company but I think that solving a lot of these questions of how to organize your team's effectively in the AI error will help you do more valuable work and I think to make one more analogy you know I think that one of the things I hope Ken and I will share of you throughout this quarter is just as in the software engineering world it took us a long time to figure out what is agile development right or whether the pros and cons of you know waterfall model versus agile or how do you what does a strum process right oh this is code review a good idea it seems a good idea to me right it's but this these practices after after program languages were created or invented or whatever we still had to figure all these ways to help individuals and teams write software effectively and so if you worked in you know high-performing corporate industrial AI teams using these software engineering practices there is an Co review to agile to whatever you know you know that having a team work effectively to write software is more than everyone knowing C++ syntax are wondering Python syntax and I think in the machine learning world we're still in the process of inventing these types of processes what is the strum what does the agile development what's the equivalent of code review for developing machine learning algorithms and I think probably this class more than more than this class and machine learning earning more than any other easels I'm aware of right now I think we'll try to systematically teach you these tools so that you don't just are able to derive a learning algorithm and implement a learning algorithm but that you're actually you know very effective in terms of how you go about building these systems so last thing before I pass it can is on the other question that I've been asked I guess several times this week now that just pre-emptive the answer is a so there are multiple machine learning classes going on at Stanford this quarter so the other frequently asked question is which of these classes should you take so let me just address that preemptively before someone else maybe because I've been asked twice already and the other two classes is quarter so I think actually what what's happened over the last several years the standard is the demand for machine learning education has you know been rising dramatically because I mean years the majority of CS PhD applicants in Stanford you know are applying to do work and machine learning or applying to do work in AI and I think all of you can kind of see that there's such a shortage of machine learning engineers right and then there's a little bit of and and and I think that shortage should continue for a long time so I think many people see that if you can explain the machine learning there'll be great opportunities for you to do meaningful work on campus to take machine learning to compile or cosmology on the can train or do great research on campus as well as Brad from Stanford and do very unique work when I wonder around Silicon Valley I feel like there are so many ideas for great machine learning projects that exactly zero people see it through working on because just aren't enough machine learning people in the world right now so by learning these skills you could you have many opportunities to be the first one to do something very exciting and meaningful right alright and and um you probably read in the newspapers about how much money machine there any people make I'm actually much less more I actually find that I hope a lot you make a lot of money but I actually personally don't find out that you know as exciting I think that every time there's a major technological disruption it gives us an opportunity to remove large parts of the world and I hope that as some of you go improve a health care system improving educational system maybe you know see if we can help preserve the smooth functioning of democracy around the world I think that it really your unique skills and deep learning will give you opportunities to do that I think hopefully very meaningful work um but because of this massive massive rising demand for machine learning education there are some for long time CS 239 machine learning was the core machine learning class at Stanford's and then CS 230 is actually the newest new creation I think and the other costs that were involved in that units and I are involved in this quarter is CS 229 a so so if China decide which of these classes to take I think I think that these classes a little bit like Pokemon right you really should collect them all but better but I think we've been trying to design these classes to actually teach different things and not have too much overlap and so there is so I have seen students take two classes at the same time and that's actually fine there's not that we have old lab is fine that you actually learn different things if you take any two of these classes at the same time 69 is machine learning is the most mathematical of these classes and we go much more since through now it goes much more into the mathematical derivations of the algorithms CS 229 a is applying machine learning is much less mathematical but spends a bit more time on the practical aspects is actually easier on Brown to machine learning as well as the least mathematical of classes CS 230 is somewhere in between this is Monmouth Alden 69 a less Matt Matthews SCS 230 but where CSU 30 focuses on is a deep learning which is just one small subset of machine learning but it is the hottest subset of machine learning whereas there are a lot of other machine learning algorithms from your PCA k-means recommender systems support vector machines that are also very useful that I use you know in my work quite frequently that we don't teach in CS 230 but then stored in C it's two three nine six four two two nine eight oh we're so the unique things about C's 230 is it focuses on deep learning so I'll know if you wanted list deep learning on your resume I guess maybe this is the the easiest way to do it I don't know again it's not what I tend to optimize for but but and I think CS 230 goes to D pers in their practical know-how and how to apply these algorithms oh and so just and I want to set expectations accurately as well right so what I don't want is that you guys did complain in the other quarter that you know there wasn't enough math because that's actually not the point what has happened in the last decade is the amount of math you need to be a great machine learning person has actually decreased I think and I wanted to do less math and CS 2:30 but spend more time teaching you the practical know-how of how to actually apply these algorithms right so yeah and I think to 2000 a is very the easier this cause that's the most technical this is the most most hands-on apply you do a lot of projects on different different topics right and I think these courses are often the foundation or some subset that these are often the foundational courses as students say because if you say learn deep learning some common sequence first student sister you know learn the foundations of machine learning or [Music] machine learning of deep learning and so you have the foundation first before you go which then often sets you up to later go deeper into computer vision or national Enders processing or robotics or deep reinforcement learning and so common sequencing that common tactic that Stanford says take is to use these in the foundation you see a bit of every thing from divisions national processing in speech recognition you know touch low bill on self-driving cars but that gives you the foundation to then decide you want to go deeper into the National image processing or robotics or enforcement learning or computer vision or something else this is common sequencing of classes that students take ok so um look forward to spending this quarter with you let me just check out any quick questions and you're not hand it over takes you into a decision making by engineers and product managers you may be pushing decision making I wrote this room aching by engineers there but really engineers and probably managers Oh a pervasive old sorry a pervasive automation so to say that like like so far you like what what are the most like the most meaningful successes of machine learning that you think have happened already so all of you are using learning algorithms probably dozens of times a day maybe even hundreds of times a day without knowing it right every time you use a web search engine there's a learning algorithm that's improving the quality of search results there's also learning however trying to show you the most relevant as and this helps those companies actually make it all the money every time it turns out that actually both Google and Baidu have publicly said that over ten percent of searches on mobile are through voice search and so I think it's great that you can now talk to your cell phone rather than typed on the tiny little keyboard if you wanna do a do a web search and mobile if you go to you know website like Amazon or Netflix or there are learning algorithms recommending more rubber movies on the more relevant products to you every time you use your credit cards there's a learning algorithm kind of probably from almost all companies I'm aware of does the learning algorithm kind of figure out if it's you using a credit card or if it's been stolen so they should so they should you know there's a lava see if it's a fraudulent transaction or not every time you open up your email the only reason email is even usable it's because of your spam filter which is because of learning algorithm they're worse much better now than then before I don't know I and so there's a III think you know one of the amazing things about AI machine learning is I love it when it disappears in the background right you you you use your you know you use these algorithms you boot up your map application and it finds the shortest route for you to drive from here to there and there's a learning algorithm predicting what traffic will be like on highway 101 one hour from now but you don't even need to think that there was a learning algorithm trying to figure out what traffic will be like one are in the future seems pretty magical right that you know but but that you could just use it this you can but all these wonderful products and systems that help people but abstract away a lot of details so that's the present and I think in the future near future most of my PhD students most my research group here is work on machine learning for healthcare I think that will have significant inroads you know and my team at landing a I spent a long time with a lot of industries for manufacturing the agriculture so other things I'm excited about machine learning for education keep people precise to tell how people recommended crew size contents this fascinating research done here at Stanford by Chris peach and a few others on using running errands to give people feedback on coding homework assignments I so so sorry there's so many examples of machine learning I could talk for quite some time yeah alright one last question hand over cancer yeah the C so the so the format of the class is that you watch videos created by people and AI Oh Sarah so you see me a lot there but in addition Kiran and I will be having lectures here in this classroom every Wednesday and that will be you know completely new material that is not online anywhere at leas right now yeah yeah and then also that I think the the point the point that the flipped classroom saying really is some of the things is really more time efficient for you to just learn online so there's the online content but what it does is it leaves this classroom time for us and not you know deliver the same lecture year after year but to get other get spend time to get to know you on they have more time answer your questions and also give you more in cost practice on these things right so there's the Coursera the vendor course our content but what what we do in CS 230 is to augment that to give you much deeper practice more advanced examples some more deeper mathematical derivations and more practice so you know you deepen your knowledge of that and with that let me hand it over to the Ken yeah I'm gonna get back at him by making noise while he's talking okay okay thanks Andrew hi everyone I'm John we're excited to have you here today those of you who are in class but also those of you who are CPD students we wanted to take a little more time to explain a little bit about the course logistics what this course is about and also what it is to be a CS 230 students in fall two thousand eighteen so the course online is structured into five chapters or sub courses let's say what we will teach you first is what is the neural you need to know that's after understanding what a neuron is you're going to build layers with these neurons you're then going to stack these layers on top of each other to build a network that can be small or deep this is the first course unfortunately it's not enough to deploy a network just just building a neural network is not enough to get it to work so in the second course we're going to teach you the methods that are used to tune this network in order to improve their performances this is the second part as Andrew mentioned one thing we're really putting a huge emphasis on in CS 230 is the industrial applications and how the industry works in AI so the third course is going to help you understand how to strategize your project that you'll do to file the quarter but also in general how do a AI teams work you can have an algorithm you have to identify why does the algorithm work why does it not work and if it doesn't work what are the parts that you should improve inside the algorithm the two last courses course fourth of course four and five are focusing on two fields that are defined by two types of algorithms first convolutional neural networks that have been proven to work very well on imaging or videos and on the other hand sequence models that include also recurrent neural networks that applied the lots in natural language processing or speech recognition so you're going to see all that from the online perspective we use a specific notation in CS 2:30 so when I will say C 2 M 3 it refers to course to module 3 so the third module of improving deep neural networks okay and I'd like everyone to go on the website see a 230 syllabus after the class to look at all the syllabus throughout the quarter check when the midterm is and when the final poster presentation is the schedule is posted there so check it out and we're going to use the Coursera platform as you know so on Coursera you will receive an invite on your Stanford email and you should have received it already for course one in order to access the platform from the platform you will be able to watch videos do quizzes and do programming assignments and every time we finish one of these courses so c1 has four modules when you're at c1 m4 you will receive a new invite to access c2 and so on okay inside CS 2:30 we're going to use Casa as a class forum for you to interact with the TAS and with the instructors you can post privately or publicly depending on the matter okay so let's see what it is to be one week in the life of a CSC 230 students so we're going to do ten times that over this the Fall Quarter so what is one module in a module you will watch about ten videos on Coursera which will be about one hour and a half you will do quizzes after watching the videos this is going to take you about 20 minutes per module and finally you will complete programming assignments which are on Jupiter notebooks you will get cells to test your code and also submit your code directly on the Coursera platform in one week of class in Stanford here we will have two modules usually on top of these two modules you will come to lecture for a 1 hour and a half in class lecture on an advanced top that is not taught online and after that you will have ta sections on Fridays that are around one hour and it's a good chance for you to meet other students for your projects and also to interact with the TAS directly finally we have also personalised monitor ship this quarter where every one of you will meet 15 minutes per week with the TA in order to check in on your projects and give you the next steps so we put your huge emphasis on the project in this class and we want you you will see it later to build to the side of your teams by this Friday in order to get started as soon as possible next week you will have your first mentorship meeting with the TAS okay it's gonna be fun assignment and quizzes that are part of modules are due every Wednesday at 11 a.m. so 30 minutes before class so you can come to class with everything done and understand it and do not follow the deadlines displayed on the Coursera platform follow the deadlines posted on the CS 230 website the reason the deadlines are different is because we want to allow you to have late days and Coursera was not built for late days so we we put the deadlines later on on Coursera to allow you to submit even if you want to use a late day does that make sense okay so we're also using a kind of interactive this this is gonna start course to we we will use an interactive tool that is called multimeter to check in attendance in class and also for you to answer some interactive questions so it's gonna start next next week sorry not course tone regarding the grading formula here it is so you have a small part on attendance that is two percent of the final grade eight percent on quizzes 25 percent on programming assignments and big part on the midterm and on the final projects so this is posted on the website if you want to check it attendance is taken for in-class lectures for 15 minutes CIA meetings and for the TA sections on Friday you can have a bonus and we've had students very active on on Casa that answered questions to other students which was great and they got a bonus so I encourage you to do the same maybe we don't need TAS and instructors there okay so I wanted to take a little more time to go over some of the programming assignments that you're going to do this quarter so that you you know where you're going in about three weeks from how you're going to be able to translate these pictures here in the numbers that they corresponds to in in sign languages so it's sign language trust translation from images to the output signification you're going to build a convolutional neural network and the first villages segregation and then a convolutional neural network in order to solve this problem a little later you're going to be a deep learning engineer in a house that is not too far from here called the happy house so there's only one rule in this house and the rule is that no sad person should enter the house should avoid that and because you're the only deep learning engine that has the knowledge you're given this task which is don't let these sad people in just let happy people in and you're going to build a network that will run on a camera that is in front of the house and that is going to let people in or not and unfortunately some people will not get in and other people will will get in because they're they're happy and you will save the happy house at the end of the assignment hopefully this is one of the applications of the permeate I that I personally prefer its called object detection you might have heard of it so this is running real time and that's what is very pressing you're going to work on a deep learning architecture called Yolo v2 and Yolo v2 is an object detection algorithm that runs real time and is able to detect 9000 objects as fast as that so it's it's really really impressive you have a few links here if you want to check the paper already but maybe you will need some weights to understand okay actually we have a we can even run it directly on my computer I think she's going to be fine oh yeah we can run it so here you see it's running live on this computer and so you see that if I move it will find out that I move so I cannot escape yeah here it is okay okay a few other projects one two weeks from now you will build an optimal goalkeeper shoot prediction so in soccer you're a goalkeeper and you want to decide where you should shoot the ball in order to make it land on one of your teammates you're going to find what's the exact line on the field which tells the goalkeeper were to shoot two weeks from now about in the in the fourth course a convolutional neural network you're going to work on card detection so this is a bigger image this is exactly the programming assignment so you're going to work on the autonomous driving application that is finding cars finding stop signs finding lights finding pedestrians and all the objects that are related to Road features okay this is pretty cool and you will generate these images yourself so this is a picture taken from a camera put in the front of a car and was was generated by dr dot ai you will have a face recognition system that is going to first do face verification is this person is this person the right person but also face recognition who is this person which is a little more complex we're going to go over that together both online and in lecture our generation some of you have heard of this it's an algorithm called neural side transfer and again we usually put the papers at the bottom of the slides in case you want to check in yourself for your project but this is a problem where you give a content image which is the Golden Gate Bridge and a style image which is an image that was painted usually by someone or an image from which you want to extract the style this algorithm is going to generate a new image is going to mix the contents of the first image with the style of the second image music generation which is super fun you're going to generate jazz music in the fifth course sequence models you're going in the same course also generate text by giving a huge corpus written by Shakespeare a long time ago of poems you're going to teach the algorithm to to generate poems as if it was written by Shakespeare so you can even write the first sentence is going to continue and modify you all have smartphones and I guess you notice that when you write the sentence on your smartphone it usually tells you what you should put next and sometimes it's an emoji you're going to do this part you're going to implement the algorithm that takes an input sentence and tells you what's the emoji that that should come after it machine translation is a is one of the application that has been tremendously performing well with deep learning you're going to implement not a full machine translation from one language to another but a similar task that is as exciting which is changing human readable dates to machine readable days so you know let's say you're you're you're filling in a form and you're typing a date the the entity that that gathers this data will have a hard time convert all these dates into a specific format you're going to implement the algorithm that is going to take all these different dates in different formats and generate the right format translate it to human from human readable to machine readable days and finally trigger word detection that I also love and and some of you have have seen us buildeth algorithm a year ago I believe which was which unison and Andrew and I have have worked on trigger word detection is the problem of detecting a single word so you know you you probably have objects from big companies that detect the voice and activate themselves under a trigger word you're going to build this algorithm for the trigger word activate yeah and many more projects that you will see now these are the things that you will all build in this course every one of you will be lit through programming assignments but you also have to choose your own projects to work throughout the course and these are example of projects that CS 230 students have have built in the past and which have worked very well one is coloring black-and-white pictures using a neural network into the color representation of these features so it's pretty cool because we can now watch movies that were that were filmed in the 1930s or 1950s or I don't know when in color which is super cool predicting a price of an object from a picture so this was a great project in the first iteration of 6 to 30 where you give it a bike and then around that 4 it guesses how much is the bike so if you want to sell stuff you don't know how much you just give it then you sell it at under the price the student had actually implemented an algorithm to see which features of the bike are related to the price so it was super fun to see if it's the steering wheel or if it's the wheels or if it's the body of the bike that makes this bike expensive according to the algorithm and many more so last quarter specifically we've had a lot of projects in physics and an astrophysics and chemical engineering and mechanics which was great some examples are detecting earthquake precursor signals with a sequence model predicting the atom energy based on the atomic structure of an atom so you have you have for instance software's that run that are really computationally expensive that look at the atomic structure of an atom and will output the energy of this atom this takes a long time these students have tried to make it a three second problem by running a neural network to find the energy of yeah - so you have a bunch of problem across industries so healthcare cancer parking sonar dimer detection we've had a lot of these we've had brain tumor segmentation segmentation is the problem of on an image classify every pixel tell me which pixel correspond to the tumor for example so we were really excited to see what you guys are going to build at the end of this quarter and that's why we want you to build your team very quickly get started because the project is what you be proud of at the end of the quarter we hope that you guys will come at the poster session proud of your poster proud of the final project that you sent us and you can talk about it in the 10 next years or 20 next year hopefully and I guess Andrew can-can can confirm that cs2 to 9 students from the few past years have done projects that are amazing today and have been featured around the world in as a researcher or industrial project so to sum up in this course you will build a wide range of applications it's very applied there is some math but less than she has two to nine more than cs2 to 9a and you have access to personalized mentorship thanks to the amazing ta team and the instructors and finally we will have to build a 10 week long project so now we we get to the serious thing what is what we are up to this week so at the end of every lecture you'll have one slide that's gonna remind you what you have to do for next week next Wednesday 11:00 a.m. so create your courser account based on the invite that you receive if you didn't receive an invite send it as a private post on Piazza we will send it again finish the two first modules of course 1 C 1 M 1 and C 1 M 2 it corresponds to two quizzes and two programming assignments and around 20 videos ok which are listed here and for Friday it means two days from now by the end of the day fine project team mates and fill in the form to tell us who are your teammates it's going to help us find your mentor finally there is a TA section also this Friday no project mentorship it would start next week but we we will see you on Friday I'm gonna take a few questions to shout about yes yeah these times we're going to put be posted at the end of this time [Music] so the tail sections we're going to have a large range of TA section on Friday so there's going to be basically every time you're going to be assigned to one of them and if you want to move you can send an email as a plat suppose privately to us to be moved to another section how big is the same usually it's from one to three students exceptionally we would accept a four students if the project is challenging enough yeah yes so it is possible to combine the project with other classes amines been done in the past what we want is you to to give a project and a poster that that is framed as cs2 30 wants it to different fabula and you discuss with us in order for us to validate if you can merge this project with another class because it requires to have deep learning of course you you're not supposed to combine this project with something that doesn't have the kerning it off okay all right one more question so you can you can retake the quizzes as much as you want on Coursera we will consider the last submitted quiz for this class okay so you can resubmit if you didn't get full way yeah okay thanks guys and see you on Friday