Hello everyone, and welcome to this practical Python tutorial. Today, we're going to build a simple web scraper. Web scraping is the process of automatically extracting information from websites. It's a very useful skill for data collection. We will be using two popular Python libraries: `requests` and `BeautifulSoup`.

First, what are these libraries? `requests` is a library that allows you to send HTTP requests easily. We'll use it to fetch the HTML content of a webpage. `BeautifulSoup` is a library that makes it easy to parse HTML and XML documents. We'll use it to navigate the HTML structure and find the data we want.

Before we start, you'll need to install these libraries. You can do this using pip:
```bash
pip install requests
pip install beautifulsoup4
```

Now, let's write the code. We're going to scrape the headlines from a news website. For this example, we'll use a fictional news site URL.

Here's the plan:
1.  Send an HTTP GET request to the URL.
2.  Check if the request was successful.
3.  Parse the HTML content of the page using BeautifulSoup.
4.  Find all the headline elements.
5.  Extract the text of each headline and print it.

Let's see the code in action.
```python
import requests
from bs4 import BeautifulSoup

# The URL of the website we want to scrape
URL = "http://example.com/news" # Replace with a real news website for a real project

def scrape_headlines(url):
    """
    Scrapes headlines from a given URL.
    """
    try:
        # Step 1: Send a GET request to the URL
        response = requests.get(url)

        # Step 2: Check if the request was successful (status code 200)
        if response.status_code == 200:
            # Step 3: Parse the HTML content
            soup = BeautifulSoup(response.content, 'html.parser')

            # Step 4: Find all the headline elements.
            # This is the tricky part. You need to inspect the website's HTML
            # to find the correct tags and classes for the headlines.
            # Let's assume headlines are in <h2> tags with a class of 'headline'.
            headlines = soup.find_all('h2', class_='headline')

            # Step 5: Extract and print the text
            if headlines:
                print("Found headlines:")
                for i, headline in enumerate(headlines):
                    print(f"{i+1}. {headline.text.strip()}")
            else:
                print("No headlines found with the specified tags/classes.")

        else:
            print(f"Failed to retrieve the webpage. Status code: {response.status_code}")

    except requests.exceptions.RequestException as e:
        print(f"An error occurred: {e}")

# Run the scraper
if __name__ == "__main__":
    scrape_headlines(URL)
```
In this code, the `scrape_headlines` function encapsulates the logic. We use a `try...except` block to handle potential network errors. The `soup.find_all('h2', class_='headline')` line is crucial. You would need to open the target website in your browser, use the developer tools to inspect the HTML structure, and find the right selectors for the elements you want to scrape. This will be different for every website.

Web scraping can be very powerful, but it's important to be responsible. Always check a website's `robots.txt` file and terms of service to see if they allow scraping. And be mindful not to send too many requests in a short period of time, as this can overload the website's server.

That's it for our simple web scraper! You can expand this code to scrape other types of data, save it to a file, or even follow links to scrape multiple pages. Happy scraping!
